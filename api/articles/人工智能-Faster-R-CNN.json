{"title":"目标检测 | Faster R-CNN，经典两阶段检测模型","slug":"人工智能-Faster-R-CNN","date":"2022-03-12T13:59:01.000Z","updated":"2022-03-12T13:59:01.000Z","comments":true,"path":"api/articles/人工智能-Faster-R-CNN.json","excerpt":null,"covers":["https://unpkg.com/justlovesmile-img/image-20211120141803069.png","https://unpkg.com/justlovesmile-img/image-20211120142753845.png","https://unpkg.com/justlovesmile-img/image-20211120143345989.png","https://unpkg.com/justlovesmile-img/fasterRCNN.png","https://unpkg.com/justlovesmile-img/image-20211120143554871.png","https://unpkg.com/justlovesmile-img/image-20211120143818038.png","https://unpkg.com/justlovesmile-img/image-20211120144113585.png","https://unpkg.com/justlovesmile-img/image-20211120144227681.png","https://unpkg.com/justlovesmile-img/image-20211120151522563.png","https://unpkg.com/justlovesmile-img/image-20211120144312326.png","https://unpkg.com/justlovesmile-img/image-20211120144459517.png","https://unpkg.com/justlovesmile-img/image-20211120151313142.png","https://unpkg.com/justlovesmile-img/image-20211120151353580.png","https://unpkg.com/justlovesmile-img/image-20211120151446230.png","https://unpkg.com/justlovesmile-img/image-20211120151656814.png"],"content":"<h1 id=\"1-论文信息\"><a href=\"#1-论文信息\" class=\"headerlink\" title=\"1. 论文信息\"></a>1. 论文信息</h1><p>论文标题：<code>《Faster R-CNN: Towards Real-Time ObjectDetection with Region Proposal Networks》</code></p>\n<blockquote>\n<p>论文发表：2015<br>论文链接：<a href=\"https://arxiv.org/abs/1506.01497\">https://arxiv.org/abs/1506.01497</a><br>论文代码：<a href=\"https://github.com/rbgirshick/py-faster-rcnn\">https://github.com/rbgirshick/py-faster-rcnn</a></p>\n</blockquote>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120141803069.png\" alt=\"image-20211120141803069\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@article&#123;ren2015faster,</span><br><span class=\"line\">  title=&#123;Faster r-cnn: Towards real-time object detection with region proposal networks&#125;,</span><br><span class=\"line\">  author=&#123;Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian&#125;,</span><br><span class=\"line\">  journal=&#123;Advances in neural information processing systems&#125;,</span><br><span class=\"line\">  volume=&#123;28&#125;,</span><br><span class=\"line\">  pages=&#123;91--99&#125;,</span><br><span class=\"line\">  year=&#123;2015&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2-归纳总结\"><a href=\"#2-归纳总结\" class=\"headerlink\" title=\"2. 归纳总结\"></a>2. 归纳总结</h1><table>\n<thead>\n<tr>\n<th>标签</th>\n<th>目的</th>\n<th>方法</th>\n<th>总结</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>#Anchor #两阶段</td>\n<td>-</td>\n<td>RPN</td>\n<td>首次提出RPN和Anchor</td>\n</tr>\n</tbody></table>\n<h1 id=\"3-主要工作\"><a href=\"#3-主要工作\" class=\"headerlink\" title=\"3. 主要工作\"></a>3. 主要工作</h1><p>Faster R-CNN是在R-CNN和Fast R-CNN的基础上提出的一种两阶段目标检测算法，其主要包括：</p>\n<ul>\n<li>特征提取网络（Backbone）</li>\n<li>RPN（Region Proposal Networks）</li>\n<li>RoI Pooling（Region of Interesting Pooling）</li>\n<li>分类回归（Classification and Regression）</li>\n</ul>\n<p>论文中的结构图如下：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120142753845.png\" alt=\"image-20211120142753845\"></p>\n<p>自己画的训练流程图如下：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120143345989.png\" alt=\"image-20211120143345989\"></p>\n<p>网上找的训练流程图如下：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/fasterRCNN.png\" alt=\"fasterRCNN\"></p>\n<blockquote>\n<p>图片来自<a href=\"https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_object_detection/faster_rcnn\">WZMIAOMIAO/deep-learning-for-image-processing (github.com)</a></p>\n</blockquote>\n<p>对于Backbone生成的特征图，首先输入到RPN结构中，用于生成Proposal。RPN，即区域推荐网络，对于目标检测任务而言，不仅需要对目标分类还需要对目标定位，因此Faster RCNN模型提出了Anchor机制，其中的做法是，在特征图的每个像素位置预设一组多尺度的先验框，即Anchor（作者使用了3种尺寸（128，256，512），3种比例（1:1，1:2，2:1）的Anchor，共9种）：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120143554871.png\" alt=\"image-20211120143554871\"></p>\n<p>如果输入一张800×600的图片，经过Backbone后被下采样16倍，那么这个特征图的尺寸为$\\frac{800}{16}×\\frac{600}{16}=1900$个像素，那么这个特征图上需要设置1900×9=17100个Anchor。但这一步得到的Anchor肯定不可能全部当作候选区域，因此在预设了Anchor之后，为了筛选有意义的proposal，还设置了一个3×3的卷积层后接两个1×1的卷积层来预测该区域是否包含目标(cls)以及偏移量预测(reg)，如果包含目标则需要根据预测的偏移量对该Anchor进行微调。</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120143818038.png\" alt=\"image-20211120143818038\"></p>\n<p>这两个1×1的卷积层的输出维度分别为2k和4k，其中k为每个位置的Anchor数量，2代表包含目标和不包含目标的概率，4代表对目标框坐标值（x,y,w,h）的偏移量预测：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120144113585.png\" alt=\"image-20211120144113585\"></p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120144227681.png\" alt=\"image-20211120144227681\"></p>\n<p>可以根据上述公式，计算出候选区域的坐标。并且当我们得到了该区域包含目标的概率之后，我们就可以进行一个简单的筛选，按照包含目标可能性排序，只保留前2000个作为候选区域，并且对于超出图片边界的边框还需要进行一个裁剪处理。</p>\n<p>尽管我们筛选出了2000个候选区域，但我们在计算Loss的时候并不是拿这2000个候选区域来计算，这里Faster RCNN定义了正负样本的概念，首先我们需要将特征图上的Anchor映射回原始图像，因为我们的Ground-Truth是在原始图像上标注的，RPN需要根据这个来进行学习，其次还需要了解IoU这个概念，IoU可以用来计算两个框之间的重合度，其值为两个框的交集与并集的比值。</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120151522563.png\" alt=\"image-20211120151522563\"></p>\n<p>那么我们就可以定义候选区域和ground-truth的IoU值大于0.7的为正样本，小于0.3的为负样本，其他的都不用于计算损失，然后从中分别随机抽取128个正负样本。RPN的损失函数如下：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120144312326.png\" alt=\"image-20211120144312326\"></p>\n<p>RoI Pooling的作用是将 RPN 输出的大小不等的候选框缩放到统一的尺寸。具体做法是，假设需要固定候选区域为7×7大小，那么就可以将其划分为7×7个块，然后对每个块进行最大值池化，最后输出的大小就是所需要的。</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120144459517.png\" alt=\"image-20211120144459517\"></p>\n<p>这样，将所有的候选区域统一大小后，将其展平为49×1大小，通道数为256的向量，输入到两个全连接层隐藏层，最后再分别接两个输出大小为类别数以及类别数×4的全连接层。来实现对候选区域包含目标所属类别概率以及对该目标框的偏移量的预测。分类回归的损失函数和之前RPN的损失函数类似，只是分类损失不再是二分类交叉熵而是多分类交叉熵。预测框的坐标计算也和之前RPN部分的一样。</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120151313142.png\" alt=\"image-20211120151313142\"></p>\n<p>而在得到了预测目标框和类别概率之后，还需要进一步筛选，因为之前保留了2000个候选区域，而实际场景中目标数量根本达不到那么多，因此我们使用了NMS算法对重叠目标框进行去重。NMS算法的流程如下图所示：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120151353580.png\" alt=\"image-20211120151353580\"></p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120151446230.png\" alt=\"image-20211120151446230\"></p>\n<p>首先对同一个类别所有的目标框进行排序，（这里默认之前预测的分类概率最大的类别为目标所属类别），然后从大到小依次选择一个目标框和其他剩余目标框计算IoU值，如果IoU值大于设定的阈值如0.5，就代表重叠，此时舍去得分小的目标框，否则就保留，然后依次比较之后，就能实现对重叠目标的去重处理。</p>\n<p>论文里的实验结果：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120151656814.png\" alt=\"image-20211120151656814\"></p>\n<h1 id=\"4-参考文献\"><a href=\"#4-参考文献\" class=\"headerlink\" title=\"4. 参考文献\"></a>4. 参考文献</h1><p><a href=\"https://zhuanlan.zhihu.com/p/31426458\">一文读懂Faster RCNN - 知乎 (zhihu.com)</a></p>\n","more":"<h1 id=\"1-论文信息\"><a href=\"#1-论文信息\" class=\"headerlink\" title=\"1. 论文信息\"></a>1. 论文信息</h1><p>论文标题：<code>《Faster R-CNN: Towards Real-Time ObjectDetection with Region Proposal Networks》</code></p>\n<blockquote>\n<p>论文发表：2015<br>论文链接：<a href=\"https://arxiv.org/abs/1506.01497\">https://arxiv.org/abs/1506.01497</a><br>论文代码：<a href=\"https://github.com/rbgirshick/py-faster-rcnn\">https://github.com/rbgirshick/py-faster-rcnn</a></p>\n</blockquote>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120141803069.png\" alt=\"image-20211120141803069\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@article&#123;ren2015faster,</span><br><span class=\"line\">  title=&#123;Faster r-cnn: Towards real-time object detection with region proposal networks&#125;,</span><br><span class=\"line\">  author=&#123;Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian&#125;,</span><br><span class=\"line\">  journal=&#123;Advances in neural information processing systems&#125;,</span><br><span class=\"line\">  volume=&#123;28&#125;,</span><br><span class=\"line\">  pages=&#123;91--99&#125;,</span><br><span class=\"line\">  year=&#123;2015&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2-归纳总结\"><a href=\"#2-归纳总结\" class=\"headerlink\" title=\"2. 归纳总结\"></a>2. 归纳总结</h1><table>\n<thead>\n<tr>\n<th>标签</th>\n<th>目的</th>\n<th>方法</th>\n<th>总结</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>#Anchor #两阶段</td>\n<td>-</td>\n<td>RPN</td>\n<td>首次提出RPN和Anchor</td>\n</tr>\n</tbody></table>\n<h1 id=\"3-主要工作\"><a href=\"#3-主要工作\" class=\"headerlink\" title=\"3. 主要工作\"></a>3. 主要工作</h1><p>Faster R-CNN是在R-CNN和Fast R-CNN的基础上提出的一种两阶段目标检测算法，其主要包括：</p>\n<ul>\n<li>特征提取网络（Backbone）</li>\n<li>RPN（Region Proposal Networks）</li>\n<li>RoI Pooling（Region of Interesting Pooling）</li>\n<li>分类回归（Classification and Regression）</li>\n</ul>\n<p>论文中的结构图如下：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120142753845.png\" alt=\"image-20211120142753845\"></p>\n<p>自己画的训练流程图如下：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120143345989.png\" alt=\"image-20211120143345989\"></p>\n<p>网上找的训练流程图如下：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/fasterRCNN.png\" alt=\"fasterRCNN\"></p>\n<blockquote>\n<p>图片来自<a href=\"https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_object_detection/faster_rcnn\">WZMIAOMIAO/deep-learning-for-image-processing (github.com)</a></p>\n</blockquote>\n<p>对于Backbone生成的特征图，首先输入到RPN结构中，用于生成Proposal。RPN，即区域推荐网络，对于目标检测任务而言，不仅需要对目标分类还需要对目标定位，因此Faster RCNN模型提出了Anchor机制，其中的做法是，在特征图的每个像素位置预设一组多尺度的先验框，即Anchor（作者使用了3种尺寸（128，256，512），3种比例（1:1，1:2，2:1）的Anchor，共9种）：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120143554871.png\" alt=\"image-20211120143554871\"></p>\n<p>如果输入一张800×600的图片，经过Backbone后被下采样16倍，那么这个特征图的尺寸为$\\frac{800}{16}×\\frac{600}{16}=1900$个像素，那么这个特征图上需要设置1900×9=17100个Anchor。但这一步得到的Anchor肯定不可能全部当作候选区域，因此在预设了Anchor之后，为了筛选有意义的proposal，还设置了一个3×3的卷积层后接两个1×1的卷积层来预测该区域是否包含目标(cls)以及偏移量预测(reg)，如果包含目标则需要根据预测的偏移量对该Anchor进行微调。</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120143818038.png\" alt=\"image-20211120143818038\"></p>\n<p>这两个1×1的卷积层的输出维度分别为2k和4k，其中k为每个位置的Anchor数量，2代表包含目标和不包含目标的概率，4代表对目标框坐标值（x,y,w,h）的偏移量预测：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120144113585.png\" alt=\"image-20211120144113585\"></p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120144227681.png\" alt=\"image-20211120144227681\"></p>\n<p>可以根据上述公式，计算出候选区域的坐标。并且当我们得到了该区域包含目标的概率之后，我们就可以进行一个简单的筛选，按照包含目标可能性排序，只保留前2000个作为候选区域，并且对于超出图片边界的边框还需要进行一个裁剪处理。</p>\n<p>尽管我们筛选出了2000个候选区域，但我们在计算Loss的时候并不是拿这2000个候选区域来计算，这里Faster RCNN定义了正负样本的概念，首先我们需要将特征图上的Anchor映射回原始图像，因为我们的Ground-Truth是在原始图像上标注的，RPN需要根据这个来进行学习，其次还需要了解IoU这个概念，IoU可以用来计算两个框之间的重合度，其值为两个框的交集与并集的比值。</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120151522563.png\" alt=\"image-20211120151522563\"></p>\n<p>那么我们就可以定义候选区域和ground-truth的IoU值大于0.7的为正样本，小于0.3的为负样本，其他的都不用于计算损失，然后从中分别随机抽取128个正负样本。RPN的损失函数如下：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120144312326.png\" alt=\"image-20211120144312326\"></p>\n<p>RoI Pooling的作用是将 RPN 输出的大小不等的候选框缩放到统一的尺寸。具体做法是，假设需要固定候选区域为7×7大小，那么就可以将其划分为7×7个块，然后对每个块进行最大值池化，最后输出的大小就是所需要的。</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120144459517.png\" alt=\"image-20211120144459517\"></p>\n<p>这样，将所有的候选区域统一大小后，将其展平为49×1大小，通道数为256的向量，输入到两个全连接层隐藏层，最后再分别接两个输出大小为类别数以及类别数×4的全连接层。来实现对候选区域包含目标所属类别概率以及对该目标框的偏移量的预测。分类回归的损失函数和之前RPN的损失函数类似，只是分类损失不再是二分类交叉熵而是多分类交叉熵。预测框的坐标计算也和之前RPN部分的一样。</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120151313142.png\" alt=\"image-20211120151313142\"></p>\n<p>而在得到了预测目标框和类别概率之后，还需要进一步筛选，因为之前保留了2000个候选区域，而实际场景中目标数量根本达不到那么多，因此我们使用了NMS算法对重叠目标框进行去重。NMS算法的流程如下图所示：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120151353580.png\" alt=\"image-20211120151353580\"></p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120151446230.png\" alt=\"image-20211120151446230\"></p>\n<p>首先对同一个类别所有的目标框进行排序，（这里默认之前预测的分类概率最大的类别为目标所属类别），然后从大到小依次选择一个目标框和其他剩余目标框计算IoU值，如果IoU值大于设定的阈值如0.5，就代表重叠，此时舍去得分小的目标框，否则就保留，然后依次比较之后，就能实现对重叠目标的去重处理。</p>\n<p>论文里的实验结果：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/image-20211120151656814.png\" alt=\"image-20211120151656814\"></p>\n<h1 id=\"4-参考文献\"><a href=\"#4-参考文献\" class=\"headerlink\" title=\"4. 参考文献\"></a>4. 参考文献</h1><p><a href=\"https://zhuanlan.zhihu.com/p/31426458\">一文读懂Faster RCNN - 知乎 (zhihu.com)</a></p>\n","categories":[{"name":"人工智能","path":"api/categories/人工智能.json"}],"tags":[{"name":"深度学习","path":"api/tags/深度学习.json"},{"name":"论文笔记","path":"api/tags/论文笔记.json"},{"name":"目标检测","path":"api/tags/目标检测.json"}]}