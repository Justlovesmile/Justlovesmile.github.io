{"title":"目标检测 | SSD，经典单阶段Anchor-Based目标检测模型","slug":"人工智能-SSD阅读笔记","date":"2022-03-28T02:57:59.000Z","updated":"2022-03-28T02:57:59.000Z","comments":true,"path":"api/articles/人工智能-SSD阅读笔记.json","excerpt":null,"covers":["https://unpkg.com/justlovesmile-img/20220305111710.png","https://unpkg.com/justlovesmile-img/20220328121925.png","https://unpkg.com/justlovesmile-img/20220305114612.png","https://unpkg.com/justlovesmile-img/20220305115052.png","https://unpkg.com/justlovesmile-img/20220328114611.png"],"content":"<h1 id=\"1-论文信息\"><a href=\"#1-论文信息\" class=\"headerlink\" title=\"1. 论文信息\"></a>1. 论文信息</h1><p>论文标题： 《SSD: Single Shot MultiBox Detector》</p>\n<blockquote>\n<p>论文发表：2016<br>论文链接：<a href=\"https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2\">SSD: Single Shot MultiBox Detector | SpringerLink</a></p>\n</blockquote>\n<p><img src=\"https://unpkg.com/justlovesmile-img/20220305111710.png\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@inproceedings&#123;liu2016ssd,</span><br><span class=\"line\">  title=&#123;Ssd: Single shot multibox detector&#125;,</span><br><span class=\"line\">  author=&#123;Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C&#125;,</span><br><span class=\"line\">  booktitle=&#123;European conference on computer vision&#125;,</span><br><span class=\"line\">  pages=&#123;21--37&#125;,</span><br><span class=\"line\">  year=&#123;2016&#125;,</span><br><span class=\"line\">  organization=&#123;Springer&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2-归纳总结\"><a href=\"#2-归纳总结\" class=\"headerlink\" title=\"2. 归纳总结\"></a>2. 归纳总结</h1><table>\n<thead>\n<tr>\n<th>标签</th>\n<th>目的</th>\n<th>方法</th>\n<th>总结</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>#Anchor #单阶段</td>\n<td>实现多尺度以及卷积预测，进一步提升精度和速度</td>\n<td>MultiBox，Anchor</td>\n<td>经典单阶段算法</td>\n</tr>\n</tbody></table>\n<h1 id=\"3-引言\"><a href=\"#3-引言\" class=\"headerlink\" title=\"3. 引言\"></a>3. 引言</h1><p>SSD算法，其英文全名是Single Shot MultiBox Detector, SSD的优势在于消除了bounding box proposal和pixel or feature resampling，并使用了multi-scale，因此达到了比faster rcnn和yolo更高的检测精度和更快的检测速度。</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/20220328121925.png\"></p>\n<p>图片来自<a href=\"https://zhuanlan.zhihu.com/p/33544892\">目标检测|SSD原理与实现 - 知乎 (zhihu.com)</a></p>\n<h1 id=\"4-SSD模型\"><a href=\"#4-SSD模型\" class=\"headerlink\" title=\"4. SSD模型\"></a>4. SSD模型</h1><p>SSD采用VGG16作为基础模型，然后在VGG16的基础上新增了卷积层来获得更多的特征图以用于检测，模型结构如下图：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/20220305114612.png\"></p>\n<p>SSD和Yolo一样都是采用一个CNN网络来进行检测，但是却采用了多尺度的特征图，网络的核心点：</p>\n<ul>\n<li>使用小的卷积核预测类别和边界框偏移量</li>\n<li>对多个（多尺度）特征图进行检测</li>\n<li>设置不同比例的先验框，如下图</li>\n</ul>\n<p><img src=\"https://unpkg.com/justlovesmile-img/20220305115052.png\"></p>\n<p>SSD将背景也当做了一个特殊的类别，如果检测目标共有c个类别，SSD其实需要预测c+1个置信度值，其中第一个置信度指的是不含目标或者属于背景的评分。在预测过程中，置信度最高的那个类别就是边界框所属的类别，特别地，当第一个置信度值最高时，表示边界框中并不包含目标。第二部分就是边界框的location，包含4个值(cx,cy,w,h)，分别表示边界框的中心坐标以及宽高。但是真实预测值其实只是边界框相对于先验框的转换值。先验框位置用$d=(d^{cx},d^{cy},d^{w},d^{h})$表示，其对应边界框用$b=(b^{cx},b^{cy},b^{w},b^{h})$表示，那么边界框的预测值$l$其实是b相对于d的转换值：<br><img src=\"https://unpkg.com/justlovesmile-img/20220328114611.png\"></p>\n<h1 id=\"5-模型训练\"><a href=\"#5-模型训练\" class=\"headerlink\" title=\"5. 模型训练\"></a>5. 模型训练</h1><h2 id=\"5-1-正负样本划分\"><a href=\"#5-1-正负样本划分\" class=\"headerlink\" title=\"5.1 正负样本划分\"></a>5.1 正负样本划分</h2><p>首先，对于图片中每个ground truth，找到与其IOU最大的先验框，该先验框与其匹配，这样，可以保证每个ground truth一定与某个先验框匹配。通常称与ground truth匹配的先验框为正样本，其次，通过判断先验框和ground truth之间的IoU值是否大于阈值（如0.5），大于则为正样本</p>\n<h2 id=\"5-2-损失计算\"><a href=\"#5-2-损失计算\" class=\"headerlink\" title=\"5.2 损失计算\"></a>5.2 损失计算</h2><p>损失包含两个部分：定位损失和分类损失</p>\n<p>$$L(x,c,l,g)=\\frac{1}{N}(L_{conf}(x,c)+\\alpha L_{loc}(x,l,g))$$</p>\n<p>其中N代表所匹配的正负样本数量，<code>l</code>代表预测框，<code>g</code>代表真实框，和faster rcnn相似，回归的偏移量的值是边界框的中心坐标(cx,cy)和框的宽度w和高度h。</p>\n<p>$$\\hat{g} _ {j}^{cx}=(g _ {j}^{cx}-d _ {i}^{cx})/d _ {i}^{w}$$</p>\n<p>$$\\hat{g} _ {j}^{cy}=(g_{j}^{cy}-d_{i}^{cy})/d_{i}^{h}$$</p>\n<p>$$\\hat{g} _ {j}^{w}=\\log(\\frac{g_{j}^{w}}{d_{i}^{w}})$$</p>\n<p>$$\\hat{g} _ {j}^{h}=\\log(\\frac{g_{j}^{h}}{d_{i}^{h}})$$</p>\n<p>因此定位损失函数为：$L_{loc}(x,l,g)=\\sum_{i \\in Pos}^N \\sum_{m\\in {cx,cy,w,h}}x_{ij}^{k}smooth_{L1}(l_i^m-\\hat{g} _ j^m)$<br>分类损失是一个softmax损失：$L_{conf}(x,c)=-\\sum_{i\\in Pos}^{N}x_{ij}^p\\log(\\hat{c} _ i^p)-\\sum _ {i\\in Neg}log(\\hat{c} _ i^0)$<br>其中$\\hat{c} _ i^p=\\frac{exp(c_i^p)}{\\sum_p(exp(c_i^p))}$</p>\n<h1 id=\"6-参考文献\"><a href=\"#6-参考文献\" class=\"headerlink\" title=\"6. 参考文献\"></a>6. 参考文献</h1><p><a href=\"https://zhuanlan.zhihu.com/p/33544892\">目标检测|SSD原理与实现 - 知乎 (zhihu.com)</a></p>\n","more":"<h1 id=\"1-论文信息\"><a href=\"#1-论文信息\" class=\"headerlink\" title=\"1. 论文信息\"></a>1. 论文信息</h1><p>论文标题： 《SSD: Single Shot MultiBox Detector》</p>\n<blockquote>\n<p>论文发表：2016<br>论文链接：<a href=\"https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2\">SSD: Single Shot MultiBox Detector | SpringerLink</a></p>\n</blockquote>\n<p><img src=\"https://unpkg.com/justlovesmile-img/20220305111710.png\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@inproceedings&#123;liu2016ssd,</span><br><span class=\"line\">  title=&#123;Ssd: Single shot multibox detector&#125;,</span><br><span class=\"line\">  author=&#123;Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C&#125;,</span><br><span class=\"line\">  booktitle=&#123;European conference on computer vision&#125;,</span><br><span class=\"line\">  pages=&#123;21--37&#125;,</span><br><span class=\"line\">  year=&#123;2016&#125;,</span><br><span class=\"line\">  organization=&#123;Springer&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2-归纳总结\"><a href=\"#2-归纳总结\" class=\"headerlink\" title=\"2. 归纳总结\"></a>2. 归纳总结</h1><table>\n<thead>\n<tr>\n<th>标签</th>\n<th>目的</th>\n<th>方法</th>\n<th>总结</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>#Anchor #单阶段</td>\n<td>实现多尺度以及卷积预测，进一步提升精度和速度</td>\n<td>MultiBox，Anchor</td>\n<td>经典单阶段算法</td>\n</tr>\n</tbody></table>\n<h1 id=\"3-引言\"><a href=\"#3-引言\" class=\"headerlink\" title=\"3. 引言\"></a>3. 引言</h1><p>SSD算法，其英文全名是Single Shot MultiBox Detector, SSD的优势在于消除了bounding box proposal和pixel or feature resampling，并使用了multi-scale，因此达到了比faster rcnn和yolo更高的检测精度和更快的检测速度。</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/20220328121925.png\"></p>\n<p>图片来自<a href=\"https://zhuanlan.zhihu.com/p/33544892\">目标检测|SSD原理与实现 - 知乎 (zhihu.com)</a></p>\n<h1 id=\"4-SSD模型\"><a href=\"#4-SSD模型\" class=\"headerlink\" title=\"4. SSD模型\"></a>4. SSD模型</h1><p>SSD采用VGG16作为基础模型，然后在VGG16的基础上新增了卷积层来获得更多的特征图以用于检测，模型结构如下图：</p>\n<p><img src=\"https://unpkg.com/justlovesmile-img/20220305114612.png\"></p>\n<p>SSD和Yolo一样都是采用一个CNN网络来进行检测，但是却采用了多尺度的特征图，网络的核心点：</p>\n<ul>\n<li>使用小的卷积核预测类别和边界框偏移量</li>\n<li>对多个（多尺度）特征图进行检测</li>\n<li>设置不同比例的先验框，如下图</li>\n</ul>\n<p><img src=\"https://unpkg.com/justlovesmile-img/20220305115052.png\"></p>\n<p>SSD将背景也当做了一个特殊的类别，如果检测目标共有c个类别，SSD其实需要预测c+1个置信度值，其中第一个置信度指的是不含目标或者属于背景的评分。在预测过程中，置信度最高的那个类别就是边界框所属的类别，特别地，当第一个置信度值最高时，表示边界框中并不包含目标。第二部分就是边界框的location，包含4个值(cx,cy,w,h)，分别表示边界框的中心坐标以及宽高。但是真实预测值其实只是边界框相对于先验框的转换值。先验框位置用$d=(d^{cx},d^{cy},d^{w},d^{h})$表示，其对应边界框用$b=(b^{cx},b^{cy},b^{w},b^{h})$表示，那么边界框的预测值$l$其实是b相对于d的转换值：<br><img src=\"https://unpkg.com/justlovesmile-img/20220328114611.png\"></p>\n<h1 id=\"5-模型训练\"><a href=\"#5-模型训练\" class=\"headerlink\" title=\"5. 模型训练\"></a>5. 模型训练</h1><h2 id=\"5-1-正负样本划分\"><a href=\"#5-1-正负样本划分\" class=\"headerlink\" title=\"5.1 正负样本划分\"></a>5.1 正负样本划分</h2><p>首先，对于图片中每个ground truth，找到与其IOU最大的先验框，该先验框与其匹配，这样，可以保证每个ground truth一定与某个先验框匹配。通常称与ground truth匹配的先验框为正样本，其次，通过判断先验框和ground truth之间的IoU值是否大于阈值（如0.5），大于则为正样本</p>\n<h2 id=\"5-2-损失计算\"><a href=\"#5-2-损失计算\" class=\"headerlink\" title=\"5.2 损失计算\"></a>5.2 损失计算</h2><p>损失包含两个部分：定位损失和分类损失</p>\n<p>$$L(x,c,l,g)=\\frac{1}{N}(L_{conf}(x,c)+\\alpha L_{loc}(x,l,g))$$</p>\n<p>其中N代表所匹配的正负样本数量，<code>l</code>代表预测框，<code>g</code>代表真实框，和faster rcnn相似，回归的偏移量的值是边界框的中心坐标(cx,cy)和框的宽度w和高度h。</p>\n<p>$$\\hat{g} _ {j}^{cx}=(g _ {j}^{cx}-d _ {i}^{cx})/d _ {i}^{w}$$</p>\n<p>$$\\hat{g} _ {j}^{cy}=(g_{j}^{cy}-d_{i}^{cy})/d_{i}^{h}$$</p>\n<p>$$\\hat{g} _ {j}^{w}=\\log(\\frac{g_{j}^{w}}{d_{i}^{w}})$$</p>\n<p>$$\\hat{g} _ {j}^{h}=\\log(\\frac{g_{j}^{h}}{d_{i}^{h}})$$</p>\n<p>因此定位损失函数为：$L_{loc}(x,l,g)=\\sum_{i \\in Pos}^N \\sum_{m\\in {cx,cy,w,h}}x_{ij}^{k}smooth_{L1}(l_i^m-\\hat{g} _ j^m)$<br>分类损失是一个softmax损失：$L_{conf}(x,c)=-\\sum_{i\\in Pos}^{N}x_{ij}^p\\log(\\hat{c} _ i^p)-\\sum _ {i\\in Neg}log(\\hat{c} _ i^0)$<br>其中$\\hat{c} _ i^p=\\frac{exp(c_i^p)}{\\sum_p(exp(c_i^p))}$</p>\n<h1 id=\"6-参考文献\"><a href=\"#6-参考文献\" class=\"headerlink\" title=\"6. 参考文献\"></a>6. 参考文献</h1><p><a href=\"https://zhuanlan.zhihu.com/p/33544892\">目标检测|SSD原理与实现 - 知乎 (zhihu.com)</a></p>\n","categories":[{"name":"人工智能","path":"api/categories/人工智能.json"}],"tags":[{"name":"深度学习","path":"api/tags/深度学习.json"},{"name":"论文笔记","path":"api/tags/论文笔记.json"},{"name":"目标检测","path":"api/tags/目标检测.json"}]}