{"title":"目标检测 | FPN，多尺度目标检测经典Backbone","slug":"人工智能-FPN论文笔记","date":"2022-04-08T04:46:28.000Z","updated":"2022-04-08T04:46:28.000Z","comments":true,"path":"api/articles/人工智能-FPN论文笔记.json","excerpt":null,"covers":["https://npm.elemecdn.com/justlovesmile-img/20220408112206.png","https://npm.elemecdn.com/justlovesmile-img/20220408115456.png","https://npm.elemecdn.com/justlovesmile-img/20220408120130.png","https://npm.elemecdn.com/justlovesmile-img/20220408122428.png","https://npm.elemecdn.com/justlovesmile-img/20220408122814.png","https://npm.elemecdn.com/justlovesmile-img/20220408123357.png"],"content":"<h1 id=\"1-论文信息\"><a href=\"#1-论文信息\" class=\"headerlink\" title=\"1. 论文信息\"></a>1. 论文信息</h1><p>论文标题： Feature Pyramid Networks for Object Detection</p>\n<blockquote>\n<p>论文发表：CVPR2017<br>论文链接：<a href=\"http://openaccess.thecvf.com/content_cvpr_2017/html/Lin_Feature_Pyramid_Networks_CVPR_2017_paper.html\">CVPR2017 open access</a></p>\n</blockquote>\n<p><img src= \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" data-lazy-src=\"https://npm.elemecdn.com/justlovesmile-img/20220408112206.png\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@inproceedings&#123;lin2017feature,</span><br><span class=\"line\">  title=&#123;Feature pyramid networks for object detection&#125;,</span><br><span class=\"line\">  author=&#123;Lin, Tsung-Yi and Doll&#123;\\&#x27;a&#125;r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge&#125;,</span><br><span class=\"line\">  booktitle=&#123;Proceedings of the IEEE conference on computer vision and pattern recognition&#125;,</span><br><span class=\"line\">  pages=&#123;2117--2125&#125;,</span><br><span class=\"line\">  year=&#123;2017&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2-归纳总结\"><a href=\"#2-归纳总结\" class=\"headerlink\" title=\"2. 归纳总结\"></a>2. 归纳总结</h1><table>\n<thead>\n<tr>\n<th>Name</th>\n<th>Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>标签</td>\n<td>#多尺度</td>\n</tr>\n<tr>\n<td>目的</td>\n<td>针对目标检测任务中，目标尺度变化的问题，设计了特征金字塔网络</td>\n</tr>\n<tr>\n<td>方法</td>\n<td>构建多层特征图之间的联系，合理利用高层语义信息和底层位置信息</td>\n</tr>\n<tr>\n<td>总结</td>\n<td>是目标检测模型的标配，较好地解决了多尺度检测问题</td>\n</tr>\n</tbody></table>\n<h1 id=\"3-问题背景\"><a href=\"#3-问题背景\" class=\"headerlink\" title=\"3. 问题背景\"></a>3. 问题背景</h1><p>作者提到，在2017年以前，目标检测中的一个基本挑战就是目标检测模型在处理目标多尺度变化问题的不足，因为在当时很多网络都使用了利用单个高层特征，(比如说Faster R-CNN利用下采样四倍的卷积层——Conv4，进行后续的物体的分类和bounding box的回归)，但是这样做有一个明显的缺陷，即小物体本身具有的像素信息较少，在下采样的过程中极易被丢失，而之前的图像金字塔结构虽然也能解决多尺度问题，但计算量大，内存消耗大，因此作者提出了特征金字塔结构，能在增加极小的计算量的情况下，处理好物体检测中的多尺度变化问题。</p>\n<h1 id=\"4-主要工作\"><a href=\"#4-主要工作\" class=\"headerlink\" title=\"4. 主要工作\"></a>4. 主要工作</h1><p>针对上诉问题，提出了一个利用深度卷积神经网络固有的多尺度金字塔结构来以极小的计算量构建特征金字塔的网络结构，即FPN。</p>\n<h2 id=\"4-1-模型结构\"><a href=\"#4-1-模型结构\" class=\"headerlink\" title=\"4.1 模型结构\"></a>4.1 模型结构</h2><p><img src= \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" data-lazy-src=\"https://npm.elemecdn.com/justlovesmile-img/20220408115456.png\"><br>作者对比了多种金字塔结构，其中：</p>\n<ul>\n<li>图（a）所示的是经典的图像金字塔结构，其通过对不同尺度的图像提取特征，来构建特征金字塔，因此其需要对不同尺度图像分别提取特征，计算量大且消耗内存多；</li>\n<li>图（b）所示的是2017年常见的利用最后一层（高层）特征图检测目标的模型结构，其对于多尺度目标的检测能力不足；</li>\n<li>图（c）是一种利用卷积神经网络固有的多尺度特征图构建的多尺度检测模型（如SSD），但是其没有结合高层语义信息和底层位置信息，因此检测精度一般；</li>\n<li>图（d）即FPN结构，是一种具有侧向连接（lateral connections）的自上而下的网络结构，用来构建不同尺寸的具有高级语义信息的特征图，并且很好的利用了不同层特征的信息。</li>\n</ul>\n<p>下图是FPN的网络结构：<br><img src= \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" data-lazy-src=\"https://npm.elemecdn.com/justlovesmile-img/20220408120130.png\"></p>\n<p><img src= \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" data-lazy-src=\"https://npm.elemecdn.com/justlovesmile-img/20220408122428.png\"></p>\n<p>其主要包含两个部分：</p>\n<ul>\n<li>自下而上的特征提取：即常规的前馈Backbone网络，以Faster R-CNN为例，假设选择ResNet每级最后一个Residual Block的输出，记为{C1,C2,C3,C4,C5}，那么FPN用2-5级参与预测，其中C2, C3, C4, C5表示conv2，conv3，conv4和conv5的输出层(最后一个残差block层)作为FPN的特征，分别对应于输入图片的下采样倍数为{4，8，16，32}。</li>\n<li>自上而下的特征融合以及横向连接：即将高层的语义信息和本层的细节信息相融合。自上而下的过程通过上采样（Up-Sampling）实现，上采样的方法是<strong>最近邻插值法</strong>，如下图所示。具体过程为：C5层先经过1 x 1卷积，改变特征图的通道数(文章中设置d=256，与Faster R-CNN中RPN层的维数相同便于分类与回归)。然后通过上采样，再加上(特征图中每一个相同位置元素直接相加)C4经过1 x 1卷积后的特征图M4（固定通道256）。这个过程再做两次，分别得到C3对应的特征图M3（固定通道256）以及C2对应的特征图M2（固定通道256）。M层特征图再经过3 x 3卷积(减轻最近邻近插值带来的混叠影响，周围的数都相同)，得到最终的P2，P3，P4，P5层特征。</li>\n</ul>\n<p><img src= \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" data-lazy-src=\"https://npm.elemecdn.com/justlovesmile-img/20220408122814.png\"><br>图片来自<a href=\"https://zhuanlan.zhihu.com/p/92005927\">【论文笔记】FPN —— 特征金字塔 - 知乎 (zhihu.com)</a></p>\n<h2 id=\"4-2-代码\"><a href=\"#4-2-代码\" class=\"headerlink\" title=\"4.2 代码\"></a>4.2 代码</h2><p>可参考Pytorch官方的代码<a href=\"https://github.com/pytorch/vision\">https://github.com/pytorch/vision</a></p>\n<h1 id=\"5-实验结果\"><a href=\"#5-实验结果\" class=\"headerlink\" title=\"5. 实验结果\"></a>5. 实验结果</h1><p><img src= \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" data-lazy-src=\"https://npm.elemecdn.com/justlovesmile-img/20220408123357.png\"></p>\n<h1 id=\"6-参考文献\"><a href=\"#6-参考文献\" class=\"headerlink\" title=\"6. 参考文献\"></a>6. 参考文献</h1><p><a href=\"https://zhuanlan.zhihu.com/p/92005927\">【论文笔记】FPN —— 特征金字塔 - 知乎 (zhihu.com)</a></p>\n","more":"<h1 id=\"1-论文信息\"><a href=\"#1-论文信息\" class=\"headerlink\" title=\"1. 论文信息\"></a>1. 论文信息</h1><p>论文标题： Feature Pyramid Networks for Object Detection</p>\n<blockquote>\n<p>论文发表：CVPR2017<br>论文链接：<a href=\"http://openaccess.thecvf.com/content_cvpr_2017/html/Lin_Feature_Pyramid_Networks_CVPR_2017_paper.html\">CVPR2017 open access</a></p>\n</blockquote>\n<p><img src=\"https://npm.elemecdn.com/justlovesmile-img/20220408112206.png\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@inproceedings&#123;lin2017feature,</span><br><span class=\"line\">  title=&#123;Feature pyramid networks for object detection&#125;,</span><br><span class=\"line\">  author=&#123;Lin, Tsung-Yi and Doll&#123;\\&#x27;a&#125;r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge&#125;,</span><br><span class=\"line\">  booktitle=&#123;Proceedings of the IEEE conference on computer vision and pattern recognition&#125;,</span><br><span class=\"line\">  pages=&#123;2117--2125&#125;,</span><br><span class=\"line\">  year=&#123;2017&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2-归纳总结\"><a href=\"#2-归纳总结\" class=\"headerlink\" title=\"2. 归纳总结\"></a>2. 归纳总结</h1><table>\n<thead>\n<tr>\n<th>Name</th>\n<th>Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>标签</td>\n<td>#多尺度</td>\n</tr>\n<tr>\n<td>目的</td>\n<td>针对目标检测任务中，目标尺度变化的问题，设计了特征金字塔网络</td>\n</tr>\n<tr>\n<td>方法</td>\n<td>构建多层特征图之间的联系，合理利用高层语义信息和底层位置信息</td>\n</tr>\n<tr>\n<td>总结</td>\n<td>是目标检测模型的标配，较好地解决了多尺度检测问题</td>\n</tr>\n</tbody></table>\n<h1 id=\"3-问题背景\"><a href=\"#3-问题背景\" class=\"headerlink\" title=\"3. 问题背景\"></a>3. 问题背景</h1><p>作者提到，在2017年以前，目标检测中的一个基本挑战就是目标检测模型在处理目标多尺度变化问题的不足，因为在当时很多网络都使用了利用单个高层特征，(比如说Faster R-CNN利用下采样四倍的卷积层——Conv4，进行后续的物体的分类和bounding box的回归)，但是这样做有一个明显的缺陷，即小物体本身具有的像素信息较少，在下采样的过程中极易被丢失，而之前的图像金字塔结构虽然也能解决多尺度问题，但计算量大，内存消耗大，因此作者提出了特征金字塔结构，能在增加极小的计算量的情况下，处理好物体检测中的多尺度变化问题。</p>\n<h1 id=\"4-主要工作\"><a href=\"#4-主要工作\" class=\"headerlink\" title=\"4. 主要工作\"></a>4. 主要工作</h1><p>针对上诉问题，提出了一个利用深度卷积神经网络固有的多尺度金字塔结构来以极小的计算量构建特征金字塔的网络结构，即FPN。</p>\n<h2 id=\"4-1-模型结构\"><a href=\"#4-1-模型结构\" class=\"headerlink\" title=\"4.1 模型结构\"></a>4.1 模型结构</h2><p><img src=\"https://npm.elemecdn.com/justlovesmile-img/20220408115456.png\"><br>作者对比了多种金字塔结构，其中：</p>\n<ul>\n<li>图（a）所示的是经典的图像金字塔结构，其通过对不同尺度的图像提取特征，来构建特征金字塔，因此其需要对不同尺度图像分别提取特征，计算量大且消耗内存多；</li>\n<li>图（b）所示的是2017年常见的利用最后一层（高层）特征图检测目标的模型结构，其对于多尺度目标的检测能力不足；</li>\n<li>图（c）是一种利用卷积神经网络固有的多尺度特征图构建的多尺度检测模型（如SSD），但是其没有结合高层语义信息和底层位置信息，因此检测精度一般；</li>\n<li>图（d）即FPN结构，是一种具有侧向连接（lateral connections）的自上而下的网络结构，用来构建不同尺寸的具有高级语义信息的特征图，并且很好的利用了不同层特征的信息。</li>\n</ul>\n<p>下图是FPN的网络结构：<br><img src=\"https://npm.elemecdn.com/justlovesmile-img/20220408120130.png\"></p>\n<p><img src=\"https://npm.elemecdn.com/justlovesmile-img/20220408122428.png\"></p>\n<p>其主要包含两个部分：</p>\n<ul>\n<li>自下而上的特征提取：即常规的前馈Backbone网络，以Faster R-CNN为例，假设选择ResNet每级最后一个Residual Block的输出，记为{C1,C2,C3,C4,C5}，那么FPN用2-5级参与预测，其中C2, C3, C4, C5表示conv2，conv3，conv4和conv5的输出层(最后一个残差block层)作为FPN的特征，分别对应于输入图片的下采样倍数为{4，8，16，32}。</li>\n<li>自上而下的特征融合以及横向连接：即将高层的语义信息和本层的细节信息相融合。自上而下的过程通过上采样（Up-Sampling）实现，上采样的方法是<strong>最近邻插值法</strong>，如下图所示。具体过程为：C5层先经过1 x 1卷积，改变特征图的通道数(文章中设置d=256，与Faster R-CNN中RPN层的维数相同便于分类与回归)。然后通过上采样，再加上(特征图中每一个相同位置元素直接相加)C4经过1 x 1卷积后的特征图M4（固定通道256）。这个过程再做两次，分别得到C3对应的特征图M3（固定通道256）以及C2对应的特征图M2（固定通道256）。M层特征图再经过3 x 3卷积(减轻最近邻近插值带来的混叠影响，周围的数都相同)，得到最终的P2，P3，P4，P5层特征。</li>\n</ul>\n<p><img src=\"https://npm.elemecdn.com/justlovesmile-img/20220408122814.png\"><br>图片来自<a href=\"https://zhuanlan.zhihu.com/p/92005927\">【论文笔记】FPN —— 特征金字塔 - 知乎 (zhihu.com)</a></p>\n<h2 id=\"4-2-代码\"><a href=\"#4-2-代码\" class=\"headerlink\" title=\"4.2 代码\"></a>4.2 代码</h2><p>可参考Pytorch官方的代码<a href=\"https://github.com/pytorch/vision\">https://github.com/pytorch/vision</a></p>\n<h1 id=\"5-实验结果\"><a href=\"#5-实验结果\" class=\"headerlink\" title=\"5. 实验结果\"></a>5. 实验结果</h1><p><img src=\"https://npm.elemecdn.com/justlovesmile-img/20220408123357.png\"></p>\n<h1 id=\"6-参考文献\"><a href=\"#6-参考文献\" class=\"headerlink\" title=\"6. 参考文献\"></a>6. 参考文献</h1><p><a href=\"https://zhuanlan.zhihu.com/p/92005927\">【论文笔记】FPN —— 特征金字塔 - 知乎 (zhihu.com)</a></p>\n","categories":[{"name":"人工智能","path":"api/categories/人工智能.json"}],"tags":[{"name":"深度学习","path":"api/tags/深度学习.json"},{"name":"论文笔记","path":"api/tags/论文笔记.json"},{"name":"目标检测","path":"api/tags/目标检测.json"}]}