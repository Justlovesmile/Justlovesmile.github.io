{"title":"小样本学习 | ProtoNet，基于度量的Few-Shot分类网络","slug":"人工智能-ProtoNet论文笔记","date":"2022-04-02T04:20:34.000Z","updated":"2022-04-02T04:20:34.000Z","comments":true,"path":"api/articles/人工智能-ProtoNet论文笔记.json","excerpt":null,"covers":["https://npm.elemecdn.com/justlovesmile-img/image-20211202215720417.png","https://npm.elemecdn.com/justlovesmile-img/202110071602172.png","https://npm.elemecdn.com/justlovesmile-img/202110271603163.png","https://npm.elemecdn.com/justlovesmile-img/image-20211202220308120.png","https://npm.elemecdn.com/justlovesmile-img/image-20211202220326742.png"],"content":"<h1 id=\"Prototypical-Networks-for-Few-shot-Learning\"><a href=\"#Prototypical-Networks-for-Few-shot-Learning\" class=\"headerlink\" title=\"Prototypical Networks for Few-shot Learning\"></a>Prototypical Networks for Few-shot Learning</h1><blockquote>\n<p>论文发表：Advances in neural information processing systems, 2017<br>论文链接：<a href=\"https://proceedings.neurips.cc/paper/6996-prototypical-networks-for-few-shot-learning\">https://proceedings.neurips.cc/paper/6996-prototypical-networks-for-few-shot-learning</a></p>\n</blockquote>\n<p><img src=\"https://npm.elemecdn.com/justlovesmile-img/image-20211202215720417.png\" alt=\"image-20211202215720417\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@article&#123;snell2017prototypical,</span><br><span class=\"line\">  title=&#123;Prototypical networks for few-shot learning&#125;,</span><br><span class=\"line\">  author=&#123;Snell, Jake and Swersky, Kevin and Zemel, Richard&#125;,</span><br><span class=\"line\">  journal=&#123;Advances in neural information processing systems&#125;,</span><br><span class=\"line\">  volume=&#123;30&#125;,</span><br><span class=\"line\">  year=&#123;2017&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"归纳总结\"><a href=\"#归纳总结\" class=\"headerlink\" title=\"归纳总结\"></a>归纳总结</h2><table>\n<thead>\n<tr>\n<th>标签</th>\n<th>目的</th>\n<th>方法</th>\n<th>总结</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>#度量学习 #嵌入网络</td>\n<td>解决小样本问题</td>\n<td>学习一个低纬嵌入空间</td>\n<td>将分类问题转换成度量问题</td>\n</tr>\n</tbody></table>\n<h2 id=\"主要工作\"><a href=\"#主要工作\" class=\"headerlink\" title=\"主要工作\"></a>主要工作</h2><p>ProtoNet，即原型网络，其想法非常直接但有效，即对每张图像都先用神经网络得到一个特征表示，然后对支持集中每个类别的所有特征取一个平均，作为这个类别的类中心，最后比较查询集和各个类中心之间的距离，取最近的一个类别作为预测结果。</p>\n<p>作者的思想是构建一个映射函数，可以将每一类映射到一个简单的原型特征点集中。因此作者使用神经网络学习了一个非线性映射，将输入映射到嵌入空间中，并且规定每一类的原型特征为每个嵌入空间的均值。之后就可以将分类任务看作是在嵌入空间中寻找距离最近的原型特征。</p>\n<p><img src=\"https://npm.elemecdn.com/justlovesmile-img/202110071602172.png\" alt=\"image-20211007160201702\">定义样本为S，类别为k，原型特征为$c_k=\\frac{1}{S_k}\\sum_{(x_i,y_i)\\in{S_k}}f_{\\phi}(x_i)$，衡量距离的函数为d，那么对于输入样本，其在嵌入空间的分布为$p_\\phi(y=k|x)=\\frac{\\exp(-d(f_\\phi(x),c_k))}{\\sum_{k^\\prime}\\exp(-d(f_\\phi(x),c_{k^{\\prime}}))}$，学习的过程就是最小化负对数损失$J(\\phi)=-\\log{p_\\phi(y=k|x)}$。</p>\n<p><img src=\"https://npm.elemecdn.com/justlovesmile-img/202110271603163.png\" alt=\"image-20211027160339284\"></p>\n<h2 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h2><p>其实验结果如下：</p>\n<p><img src=\"https://npm.elemecdn.com/justlovesmile-img/image-20211202220308120.png\" alt=\"image-20211202220308120\"></p>\n<p><img src=\"https://npm.elemecdn.com/justlovesmile-img/image-20211202220326742.png\" alt=\"image-20211202220326742\"></p>\n","more":"<h1 id=\"Prototypical-Networks-for-Few-shot-Learning\"><a href=\"#Prototypical-Networks-for-Few-shot-Learning\" class=\"headerlink\" title=\"Prototypical Networks for Few-shot Learning\"></a>Prototypical Networks for Few-shot Learning</h1><blockquote>\n<p>论文发表：Advances in neural information processing systems, 2017<br>论文链接：<a href=\"https://proceedings.neurips.cc/paper/6996-prototypical-networks-for-few-shot-learning\">https://proceedings.neurips.cc/paper/6996-prototypical-networks-for-few-shot-learning</a></p>\n</blockquote>\n<p><img src=\"https://npm.elemecdn.com/justlovesmile-img/image-20211202215720417.png\" alt=\"image-20211202215720417\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@article&#123;snell2017prototypical,</span><br><span class=\"line\">  title=&#123;Prototypical networks for few-shot learning&#125;,</span><br><span class=\"line\">  author=&#123;Snell, Jake and Swersky, Kevin and Zemel, Richard&#125;,</span><br><span class=\"line\">  journal=&#123;Advances in neural information processing systems&#125;,</span><br><span class=\"line\">  volume=&#123;30&#125;,</span><br><span class=\"line\">  year=&#123;2017&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"归纳总结\"><a href=\"#归纳总结\" class=\"headerlink\" title=\"归纳总结\"></a>归纳总结</h2><table>\n<thead>\n<tr>\n<th>标签</th>\n<th>目的</th>\n<th>方法</th>\n<th>总结</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>#度量学习 #嵌入网络</td>\n<td>解决小样本问题</td>\n<td>学习一个低纬嵌入空间</td>\n<td>将分类问题转换成度量问题</td>\n</tr>\n</tbody></table>\n<h2 id=\"主要工作\"><a href=\"#主要工作\" class=\"headerlink\" title=\"主要工作\"></a>主要工作</h2><p>ProtoNet，即原型网络，其想法非常直接但有效，即对每张图像都先用神经网络得到一个特征表示，然后对支持集中每个类别的所有特征取一个平均，作为这个类别的类中心，最后比较查询集和各个类中心之间的距离，取最近的一个类别作为预测结果。</p>\n<p>作者的思想是构建一个映射函数，可以将每一类映射到一个简单的原型特征点集中。因此作者使用神经网络学习了一个非线性映射，将输入映射到嵌入空间中，并且规定每一类的原型特征为每个嵌入空间的均值。之后就可以将分类任务看作是在嵌入空间中寻找距离最近的原型特征。</p>\n<p><img src=\"https://npm.elemecdn.com/justlovesmile-img/202110071602172.png\" alt=\"image-20211007160201702\">定义样本为S，类别为k，原型特征为$c_k=\\frac{1}{S_k}\\sum_{(x_i,y_i)\\in{S_k}}f_{\\phi}(x_i)$，衡量距离的函数为d，那么对于输入样本，其在嵌入空间的分布为$p_\\phi(y=k|x)=\\frac{\\exp(-d(f_\\phi(x),c_k))}{\\sum_{k^\\prime}\\exp(-d(f_\\phi(x),c_{k^{\\prime}}))}$，学习的过程就是最小化负对数损失$J(\\phi)=-\\log{p_\\phi(y=k|x)}$。</p>\n<p><img src=\"https://npm.elemecdn.com/justlovesmile-img/202110271603163.png\" alt=\"image-20211027160339284\"></p>\n<h2 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h2><p>其实验结果如下：</p>\n<p><img src=\"https://npm.elemecdn.com/justlovesmile-img/image-20211202220308120.png\" alt=\"image-20211202220308120\"></p>\n<p><img src=\"https://npm.elemecdn.com/justlovesmile-img/image-20211202220326742.png\" alt=\"image-20211202220326742\"></p>\n","categories":[{"name":"人工智能","path":"api/categories/人工智能.json"}],"tags":[{"name":"深度学习","path":"api/tags/深度学习.json"},{"name":"论文笔记","path":"api/tags/论文笔记.json"},{"name":"小样本学习","path":"api/tags/小样本学习.json"}]}