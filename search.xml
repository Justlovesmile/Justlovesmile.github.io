<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>深度学习 | 论文笔记（A Review on Generative Adversarial Networks）</title>
    <url>/posts/c63e7cba.html</url>
    <content><![CDATA[<h2 id="A-Review-on-Generative-Adversarial-Networks-Algorithms-Theory-and-Applications"><a href="#A-Review-on-Generative-Adversarial-Networks-Algorithms-Theory-and-Applications" class="headerlink" title="A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications"></a>A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201209235414.jpg" alt="0fe50f6cc4ef45dbaee2e011ea2940bb_th"></p>
<p><a href="https://arxiv.org/pdf/2001.06937.pdf">Arxiv Link : https://arxiv.org/pdf/2001.06937.pdf</a></p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>Generative Adversarial Networks (GANs)  have been widely studied since 2014. There are a large number of different GANs variants.</p>
<blockquote>
<p>生成对抗网络，始于2014年，现在已有很多变种</p>
</blockquote>
<h3 id="Index-Terms"><a href="#Index-Terms" class="headerlink" title="Index Terms"></a>Index Terms</h3><p>Deep Learning ; GANs ; Algorithm ; Theory ; Applications</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>GANs consists of two models: a generator and a discriminator. These two models are typically implemented by neural networks, but they can be implemented with any form of differentiable system that maps data from one space to the other.</p>
<blockquote>
<p>GANs包括两个模型：一个生成器和一个辨别器。一般是由神经网络实现，但是也可以由不同类型的能映射数据到另一个空间的可微系统实现。</p>
</blockquote>
<p>The generator tries to capture the distribution of true examples for new data example  generation. </p>
<blockquote>
<p>生成器试图捕获真实示例的分布，以生成新的数据示例。</p>
</blockquote>
<p>The discriminator is usually a binary classifier, discriminating generated examples from the true examples as accurately as possible.</p>
<blockquote>
<p>鉴别器通常是一个二进制分类器，尽可能准确地将生成的示例与真实的示例区分开来。</p>
</blockquote>
<p>The optimization of GANs is a minimax optimization problem. The goal is to reach Nash equilibrium.</p>
<blockquote>
<p>Nash equilibrium即纳什均衡，对于GANs，其损失是：</p>
<p>$$\min_G \max_D V(D,G)=\mathbb{E} _ {x \sim p_{data}(x)}[\log D(x)]+\mathbb{E} _ {z \sim p_z(z)}[\log (1-D(G(z)))] $$</p>
<p>生成器G和判别器D两者相互对抗，共同学习，不断优化</p>
</blockquote>
<h3 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h3><p>GANs belong to generative algorithms</p>
<blockquote>
<p>GANs 属于生成算法</p>
</blockquote>
<h4 id="2-1-Generative-algorithms"><a href="#2-1-Generative-algorithms" class="headerlink" title="2.1 Generative algorithms"></a>2.1 Generative algorithms</h4><p>Generative algorithms can be classified into two classes: explicit density model and implicit density model.</p>
<blockquote>
<p>生成算法可分为两类：显式密度模型和隐式密度模型。</p>
</blockquote>
<h5 id="2-1-1-Explicit-density-model"><a href="#2-1-1-Explicit-density-model" class="headerlink" title="2.1.1 Explicit density model"></a>2.1.1 Explicit density model</h5><p>An explicit density model assumes the distribution and utilizes true data to train the model containing the distribution or fit the distribution parameters. When finished, new examples are produced utilizing the learned model or distribution.</p>
<blockquote>
<p>显式密度模型假设分布，并利用真实数据训练包含分布的模型或拟合分布参数。完成后，利用学习的模型或分布产生新的示例。</p>
</blockquote>
<p>The explicit density models include maximum likelihood estimation (MLE), approximate inference, and Markov chain method.</p>
<blockquote>
<p>显式密度模型包括最大似然估计（MLE），近似推断和马尔可夫链方法。</p>
</blockquote>
<h5 id="2-1-2-Implicit-density-model"><a href="#2-1-2-Implicit-density-model" class="headerlink" title="2.1.2 Implicit density model"></a>2.1.2 Implicit density model</h5><p>It produces data instances from the distribution without an explicit hypothesis and utilizes the produced examples to modify the model.</p>
<blockquote>
<p>它在没有明确假设的情况下从分布中生成数据实例，并利用生成的实例来修改模型。</p>
</blockquote>
<p>GANs belong to the directed implicit density model category.</p>
<blockquote>
<p>GANs属于有向隐式密度模型类别。</p>
</blockquote>
<h5 id="2-1-3-The-comparison-between-GANs-and-other-generative-algorithms"><a href="#2-1-3-The-comparison-between-GANs-and-other-generative-algorithms" class="headerlink" title="2.1.3 The comparison between GANs and other generative algorithms"></a>2.1.3 The comparison between GANs and other generative algorithms</h5><p>The basic idea behind adversarial learning is that the generator tries to create as realistic examples as possible to deceive the discriminator. The discriminator tries to distinguish fake examples from true examples. Both the generator and discriminator improve through adversarial learning. </p>
<blockquote>
<p>对抗式学习背后的基本思想是，生成器试图创建尽可能真实的示例来欺骗鉴别器。鉴别器试图区分假例子和真例子。生成器和鉴别器都通过对抗性学习进行改进。</p>
</blockquote>
<h4 id="2-2-Adversarial-idea"><a href="#2-2-Adversarial-idea" class="headerlink" title="2.2 Adversarial idea"></a>2.2 Adversarial idea</h4><p>Adversarial machine learning is a minimax problem. The defender, who builds the classifier that we want to work correctly, is searching over the parameter space to find the parameters that reduce the cost of the classifier as much as possible. Simultaneously, the attacker is searching over the inputs of the model to maximize the cost.</p>
<blockquote>
<p>对抗性机器学习是一个极小极大问题。防守者(defender)构建了我们想要正确工作的分类器，他在参数空间中搜索尽可能降低分类器成本（cost）的参数（parameter）。同时，攻击者(attacker)搜索模型的输入以使成本（cost）最大化。</p>
</blockquote>
<h3 id="3-Algorithms"><a href="#3-Algorithms" class="headerlink" title="3. Algorithms"></a>3. Algorithms</h3><h4 id="3-1-Generative-Adversarial-Nets-（GANs）"><a href="#3-1-Generative-Adversarial-Nets-（GANs）" class="headerlink" title="3.1 Generative Adversarial Nets （GANs）"></a>3.1 Generative Adversarial Nets （GANs）</h4><p>In order to learn the generator’s distribution $p_g$ over data $x$, a prior on input noise variables is defined as $p_z(z)$ and $z$ is the noise variable. </p>
<blockquote>
<p>为了了解生成器在数据$x$上的分布$p_g$，将输入噪声变量的先验定义为$p_z(z)$，$z$是噪声变量。</p>
</blockquote>
<p>Then, GANs represent a mapping from noise space to data space as $G(z, \theta_g)$, where G is a differentiable function represented by a neural network with parameters $\theta_g$. </p>
<blockquote>
<p>GANs将噪声空间到数据空间的映射表示为$G(z, \theta_g)$，其中G是一个由参数$\theta_g$的神经网络表示的可微函数</p>
</blockquote>
<p>Other than G, the other neural network $D(x, \theta_d)$ is also defined with parameters $\theta_d$ and the output of $D(x)$ is a single scalar. $D(x)$ denotes the probability that x was from the data rather than the generator G. </p>
<blockquote>
<p>除G外，另一个神经网络$D(x, \theta_d)$ 也根据参数$\theta_d$定义，$D(x)$的输出为单标量。$D(x)$表示$x$来自数据而不是生成器G的概率。</p>
</blockquote>
<p>The discriminator D is trained to maximize the probability of giving the correct label to both training data and fake samples generated from the generator G. G is trained to minimize $\log (1 −D (G(z)))$ simultaneously .</p>
<blockquote>
<p>对鉴别器D进行训练以最大限度地提高对训练数据和从生成器G生成的伪样本给出正确标签的概率。G被训练以同时最小化$\log(1−D(G(z))$。</p>
</blockquote>
<h5 id="3-1-1-Objective-function"><a href="#3-1-1-Objective-function" class="headerlink" title="3.1.1 Objective function"></a>3.1.1 Objective function</h5><p><strong>(1) Original minimax game</strong></p>
<p>The objective function of GANs is :</p>
<p>$$\min_G \max_D V(D,G)=\mathbb{E} _ {x \sim p_{data}(x)}[\log D(x)]+\mathbb{E} _ {z \sim p_z(z)}[\log (1-D(G(z)))]$$</p>
<p>$\log D(x)$ is the cross-entropy between $\begin{bmatrix}1 &amp; 0 \end{bmatrix}^T$ and $\begin{bmatrix}D(x) &amp; 1-D(x) \end{bmatrix}^T$. Similarly, $\log(1-D(G(z)))$ is the cross-entropy between  $\begin{bmatrix}0 &amp; 1 \end{bmatrix}^T$ and $\begin{bmatrix}D(G(z)) &amp; 1-D(G(z)) \end{bmatrix}^T$ . </p>
<blockquote>
<p>$\log D(x)$是$\begin{bmatrix}1 &amp; 0 \end{bmatrix}^T$和$\begin{bmatrix}D(x) &amp; 1-D(x) \end{bmatrix}^T$之间的<a href="/posts/fdbf585c.html">交叉熵</a>。同样，$\log(1-D(G(z)))$是$\begin{bmatrix}0 &amp; 1 \end{bmatrix}^T$和$\begin{bmatrix}D(G(z)) &amp; 1-D(G(z)) \end{bmatrix}^T$之间的<a href="/posts/fdbf585c.html">交叉熵</a>。</p>
</blockquote>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>GAN</tag>
        <tag>论文笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 | 交叉熵损失函数</title>
    <url>/posts/fdbf585c.html</url>
    <content><![CDATA[<h1 id="Cross-Entropy-Error-Function"><a href="#Cross-Entropy-Error-Function" class="headerlink" title="Cross Entropy Error Function"></a>Cross Entropy Error Function</h1><p>交叉熵损失函数</p>
<h2 id="一，信息量"><a href="#一，信息量" class="headerlink" title="一，信息量"></a>一，信息量</h2><p><strong>信息量：</strong></p>
<p>任何事件都会承载着一定的信息量，包括已经发生的事件和未发生的事件，只是它们承载的信息量会有所不同。如昨天下雨这个已知事件，因为已经发生，是既定事实，那么它的信息量就为0。如明天会下雨这个事件，因为未有发生，那么这个事件的信息量就大。</p>
<p>从上面例子可以看出信息量是一个与事件发生概率相关的概念，而且可以得出，事件发生的概率越小，其信息量越大。</p>
<p>假设$x$是一个离散型随机变量，其取值集合为$X$，概率分布函数为$p(x)$，则定义事件$x=x_0$的信息量为：$I(x_0)=-\log(p(x_0))$</p>
<h2 id="二，熵"><a href="#二，熵" class="headerlink" title="二，熵"></a>二，熵</h2><p><strong>熵是表示随机变量不确定的度量，是对所有可能发生的事件产生的信息量的期望。</strong>熵值越大，表明这个系统的不确定性就越大。公式如下：</p>
<p>$$H(X)=-\sum_{i=1}^n p(x_i)\log(p(x_i))$$</p>
<p>对于0-1分布问题，熵的计算方法可以简化为：</p>
<p>$$H(x)=-\sum_{i=1}^np(x_i)log(p(x_i))\ =-p(x)\log(p(x))-(1-p(x))\log(1-p(x))$$</p>
<h2 id="三，相对熵（KL散度）"><a href="#三，相对熵（KL散度）" class="headerlink" title="三，相对熵（KL散度）"></a>三，相对熵（KL散度）</h2><p>相对熵又称KL散度，用于衡量对于同一个随机变量x的两个分布p(x)和q(x)之间的差异。在机器学习中，p(x)常用于描述样本的真实分布，例如[1,0,0,0]表示样本属于第一类，而q(x)则常常用于表示预测的分布，例如[0.7,0.1,0.1,0.1]。显然使用q(x)来描述样本不如p(x)准确，q(x)需要不断地学习来拟合准确的分布p(x)。</p>
<p>KL散度的公式如下：</p>
<p>$$D_{KL}(p||q)=\sum_{i=1}^np(x_i)\log(\frac{p(x_i)}{q(x_i)})$$</p>
<p>KL散度的值越小，表示两个分布越接近。在机器学习中，p往往用来表示样本的真实分布，q用来表示模型所预测的分布，那么KL散度就可以计算两个分布的差异，也就是Loss损失值。</p>
<h2 id="四，交叉熵"><a href="#四，交叉熵" class="headerlink" title="四，交叉熵"></a>四，交叉熵</h2><p>将KL散度的公式进行变形，得到：</p>
<p>$$D_{KL}(p||q)=\sum_{i=1}^np(x_i)\log(\frac{p(x_i)}{q(x_i)})\ =\sum_{i=1}^np(x_i)\log(p(x_i))-\sum_{i=1}^np(x_i)\log(q(x_i))$$</p>
<p>根据熵的定义，前半部分是$p(x)$的熵$H(x)=-\sum_{i=1}^np(x_i)\log(p(x_i))$，而后半部分则是交叉熵，定义为：</p>
<p>$$H(p,q)=-\sum_{i=1}^np(x_i)\log(q(x_i))$$</p>
<p>因此$D_{KL}(p||q)=H(p,q)-H(p)$ ，在机器学习中，我们需要评估label和predicts之间的差距，使用KL散度刚刚好，即 $D_{KL}(p|| \widetilde {q})$ ，由于KL散度中的前一部分$−H(p)$不变，故在优化过程中，只需要关注交叉熵就可以了。</p>
<h2 id="五，交叉熵损失函数"><a href="#五，交叉熵损失函数" class="headerlink" title="五，交叉熵损失函数"></a>五，交叉熵损失函数</h2><p>在线性回归问题中，常常使用MSE(Mean Squared Error)作为loss函数，而在分类问题中常常使用交叉熵作为loss函数，特别是在神经网络作分类问题时，并且由于交叉熵涉及到计算每个类别的概率，所以交叉熵几乎每次都和sigmoid或者softmax函数一起出现。</p>
<p><strong>(1)二分类</strong></p>
<p>在二分的情况下，对于每个类别我们的预测的到的概率为p和1-p。此时表达式为：</p>
<p>$$L=\frac{1}{N}\sum_iL_i=\frac{1}{N}\sum_i(-[y_i\log(p_i)+(1-y_i)\log(1-p_i)])$$</p>
<p>其中：</p>
<ul>
<li>$y_i$表示样本i的label，正类为1，负类为0</li>
<li>$p_i$表示样本i预测为正的概率</li>
</ul>
<p><strong>(2)多分类</strong></p>
<p>多分类问题实际上就是对二分类问题的扩展：</p>
<p>$$L=\frac{1}{N}\sum_iL_i=\frac{1}{N}\sum_i(-\sum_{j=1}^My_{ij}\log(p_{ij}))$$</p>
<p>其中：</p>
<ul>
<li>M 表示类别的数量</li>
<li>$y_{ij}$表示该类别和样本i类别是否相同，相同为1，不同为0</li>
<li>$p_{ij}$表示对于观测样本i属于类别j的预测概率</li>
</ul>
<p>例如：</p>
<table>
<thead>
<tr>
<th>id</th>
<th>predict</th>
<th>label</th>
<th>isCorrect</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>0.3 0.3 0.4</td>
<td>0 0 1</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>0.3 0.4 0.3</td>
<td>0 1 0</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>0.1 0.2 0.7</td>
<td>1 0 0</td>
<td>0</td>
</tr>
</tbody></table>
<p>那么求其Loss：<br>$$L_1=-(0\times \log 0.3+0\times \log 0.3+1\times \log 0.4)$$<br>$$L_2=-(0\times \log 0.3+1\times \log 0.4+0\times \log 0.3)$$<br>$$L_3=-(1\times \log 0.1+0\times \log 0.2+0\times \log 0.7)$$<br>对所有样本的Loss求平均<br>$$Loss=\frac{L_1+L_2+L_3}{3}$$</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/74075915">https://zhuanlan.zhihu.com/p/74075915</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/61944055">https://zhuanlan.zhihu.com/p/61944055</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/35709485">https://zhuanlan.zhihu.com/p/35709485</a></p>
<p><a href="https://blog.csdn.net/b1055077005/article/details/100152102">https://blog.csdn.net/b1055077005/article/details/100152102</a></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>损失函数</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 | Detectron2使用指南</title>
    <url>/posts/589ec011.html</url>
    <content><![CDATA[<p><code>Detectron2</code>是<code>Facebook AI Research</code>的检测和分割框架，其主要基于<code>PyTorch</code>实现，但具有更模块化设计，因此它是灵活且便于扩展的，具体简介可见<a href="https://github.com/facebookresearch/detectron2">Github库</a>和<a href="https://ai.facebook.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/">Meta AI Blog Post</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@misc&#123;wu2019detectron2,</span><br><span class="line">  author =       &#123;Yuxin Wu and Alexander Kirillov and Francisco Massa and</span><br><span class="line"> Wan-Yen Lo and Ross Girshick&#125;,</span><br><span class="line">  title =        &#123;Detectron2&#125;,</span><br><span class="line">  howpublished = &#123;\url&#123;https://github.com/facebookresearch/detectron2&#125;&#125;,</span><br><span class="line">  year =         &#123;2019&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="1-Detectron2安装"><a href="#1-Detectron2安装" class="headerlink" title="1. Detectron2安装"></a>1. Detectron2安装</h1><blockquote>
<p>首先官方要求的环境条件如下：</p>
<ul>
<li>Linux or macOS with Python ≥ 3.6</li>
<li>PyTorch ≥ 1.8 and <a href="https://github.com/pytorch/vision/">torchvision</a> that matches the PyTorch installation. Install them together at <a href="https://pytorch.org/">pytorch.org</a> to make sure of this</li>
<li>OpenCV is optional but needed by demo and visualization</li>
<li> gcc &amp; g++ ≥ 5.4 are required</li>
<li><a href="https://ninja-build.org/">ninja</a> is optional but recommended for faster build</li>
<li>Cuda &amp; Cudnn</li>
</ul>
</blockquote>
<p>因此想要安装并使用Detectron2，需要有：</p>
<ul>
<li>环境：Python，Cuda，Cudnn，gcc&amp;g++</li>
<li>Python包：pytorch，torchvision，python-opencv</li>
<li>推荐：Anaconda</li>
</ul>
<h2 id="1-1-Linux"><a href="#1-1-Linux" class="headerlink" title="1.1 Linux"></a>1.1 Linux</h2><p>Linux安装直接按照<a href="https://detectron2.readthedocs.io/en/latest/tutorials/install.html">官方文档</a>的安装步骤即可</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python -m pip install &#x27;git+https://github.com/facebookresearch/detectron2.git&#x27;</span><br><span class="line"><span class="meta">#</span><span class="bash"> (add --user <span class="keyword">if</span> you don<span class="string">&#x27;t have permission)</span></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="string"> Or, to install it from a local clone:</span></span></span><br><span class="line">git clone https://github.com/facebookresearch/detectron2.git</span><br><span class="line">python -m pip install -e detectron2</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="string"> On macOS, you may need to prepend the above commands with a few environment variables:</span></span></span><br><span class="line">CC=clang CXX=clang++ ARCHFLAGS=&quot;-arch x86_64&quot; python -m pip install ...</span><br></pre></td></tr></table></figure>

<p>如果以上安装失败，可以尝试直接安装预编译文件，同样在<a href="https://detectron2.readthedocs.io/en/latest/tutorials/install.html">官方文档有提供</a></p>
<h2 id="1-2-Windows"><a href="#1-2-Windows" class="headerlink" title="1.2 Windows"></a>1.2 Windows</h2><h3 id="1-2-1-VS2019-C-编译环境"><a href="#1-2-1-VS2019-C-编译环境" class="headerlink" title="1.2.1 VS2019 C++编译环境"></a>1.2.1 VS2019 C++编译环境</h3><p>Windows想要安装Detectron2，需要提前安装<strong>Microsoft Visual Studio 2019</strong>，然后选择安装“<strong>使用C++的桌面开发</strong>”，其他均默认即可。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220316165420.png"></p>
<h3 id="1-2-2-pycocotools"><a href="#1-2-2-pycocotools" class="headerlink" title="1.2.2 pycocotools"></a>1.2.2 pycocotools</h3><p>安装方法一：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI</span><br></pre></td></tr></table></figure>

<p>安装方法二：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/pdollar/coco.git</span><br><span class="line"></span><br><span class="line">cd coco/PythonAPI</span><br><span class="line"></span><br><span class="line">python setup.py build_ext --inplace</span><br><span class="line">python setup.py build_ext install</span><br></pre></td></tr></table></figure>

<p>如果安装失败（一般都会失败），尝试下载“Microsoft Visual C++ Build Tools.exe” ，官网链接：<a href="https://go.microsoft.com/fwlink/?LinkId=691126">https://go.microsoft.com/fwlink/?LinkId=691126</a>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220316171845.png"></p>
<p>如果在安装的过程中因网络问题失败，可以使用离线包，网盘链接：<a href="https://pan.baidu.com/s/1GeJ2c8MxnZP8lAYAwQACzg">https://pan.baidu.com/s/1GeJ2c8MxnZP8lAYAwQACzg</a>，提取码<code>1114</code>。</p>
<h3 id="1-2-3-Detectron2"><a href="#1-2-3-Detectron2" class="headerlink" title="1.2.3 Detectron2"></a>1.2.3 Detectron2</h3><p>使用Conda（推荐！之前有过同一个包使用conda安装的好用而pip安装的不好用的经历）或者pip下载包：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda install cython</span><br><span class="line">conda install ninja</span><br><span class="line">conda install pywin32</span><br></pre></td></tr></table></figure>

<p>下载Detectron2到本地:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/facebookresearch/detectron2.git</span><br><span class="line">python -m pip install -e detectron2</span><br></pre></td></tr></table></figure>

<p>或者</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/facebookresearch/detectron2.git</span><br><span class="line">cd detectron2 </span><br><span class="line">python setup.py build develop</span><br></pre></td></tr></table></figure>

<h1 id="2-自定义数据集"><a href="#2-自定义数据集" class="headerlink" title="2.  自定义数据集"></a>2.  自定义数据集</h1><h2 id="2-1-关于COCO格式"><a href="#2-1-关于COCO格式" class="headerlink" title="2.1 关于COCO格式"></a>2.1 关于COCO格式</h2><p>Detectron2已经写好了COCO格式的数据集图像和标注的读取，因此通常减少工作量，可以自己写一个脚本将<strong>数据集转为COCO格式</strong>的标注。</p>
<p>COCO的文件目录如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-coco/</span><br><span class="line">    |-train2017/</span><br><span class="line">    	|-1.jpg</span><br><span class="line">    	|-2.jpg</span><br><span class="line">    |-val2017/</span><br><span class="line">    	|-3.jpg</span><br><span class="line">    	|-4.jpg</span><br><span class="line">    |-test2017/</span><br><span class="line">    	|-5.jpg</span><br><span class="line">    	|-6.jpg</span><br><span class="line">    |-annotations/</span><br><span class="line">    	|-instances_train2017.json</span><br><span class="line">    	|-instances_val2017.json</span><br><span class="line">    	|-*.json</span><br></pre></td></tr></table></figure>

<p>其中标注文件（json）最为重要，其格式如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;info&quot;</span>: &#123;<span class="comment">//数据集信息，对于训练而言不重要</span></span><br><span class="line">		<span class="attr">&quot;year&quot;</span>: int, </span><br><span class="line">		<span class="attr">&quot;version&quot;</span>: str, </span><br><span class="line">		<span class="attr">&quot;description&quot;</span>: str, </span><br><span class="line">		<span class="attr">&quot;contributor&quot;</span>: str, </span><br><span class="line">		<span class="attr">&quot;url&quot;</span>: str, </span><br><span class="line">		<span class="attr">&quot;date_created&quot;</span>: datetime,</span><br><span class="line">	&#125;, </span><br><span class="line">	<span class="attr">&quot;images&quot;</span>: [&#123;</span><br><span class="line">		<span class="attr">&quot;id&quot;</span>: int, <span class="comment">//必要</span></span><br><span class="line">		<span class="attr">&quot;width&quot;</span>: int, <span class="comment">//必要</span></span><br><span class="line">		<span class="attr">&quot;height&quot;</span>: int, <span class="comment">//必要</span></span><br><span class="line">		<span class="attr">&quot;file_name&quot;</span>: str, <span class="comment">//必要</span></span><br><span class="line">		<span class="attr">&quot;license&quot;</span>: int,</span><br><span class="line">		<span class="attr">&quot;flickr_url&quot;</span>: str,</span><br><span class="line">		<span class="attr">&quot;coco_url&quot;</span>: str,</span><br><span class="line">		<span class="attr">&quot;date_captured&quot;</span>: datetime, </span><br><span class="line">	&#125;,&#123;...&#125;], <span class="comment">//列表</span></span><br><span class="line">	<span class="attr">&quot;annotations&quot;</span>: [&#123;</span><br><span class="line">		<span class="attr">&quot;id&quot;</span>: int, <span class="comment">//标注id</span></span><br><span class="line">		<span class="attr">&quot;image_id&quot;</span>: int, <span class="comment">//所属图像id</span></span><br><span class="line">		<span class="attr">&quot;category_id&quot;</span>: int, <span class="comment">//类别id</span></span><br><span class="line">		<span class="attr">&quot;segmentation&quot;</span>: RLE or [polygon], <span class="comment">//图像分割标注</span></span><br><span class="line">		<span class="attr">&quot;area&quot;</span>: float, <span class="comment">//区域面积</span></span><br><span class="line">		<span class="attr">&quot;bbox&quot;</span>: [x,y,width,height], <span class="comment">//目标框左上角坐标以及宽高</span></span><br><span class="line">		<span class="attr">&quot;iscrowd&quot;</span>: <span class="number">0</span> or <span class="number">1</span>, <span class="comment">//是否密集</span></span><br><span class="line">	&#125;,&#123;...&#125;], <span class="comment">//列表</span></span><br><span class="line">	<span class="attr">&quot;categories&quot;</span>: [&#123;</span><br><span class="line">		<span class="attr">&quot;id&quot;</span>: int, <span class="comment">//类别序号</span></span><br><span class="line">		<span class="attr">&quot;name&quot;</span>: str, <span class="comment">//类别名称</span></span><br><span class="line">		<span class="attr">&quot;supercategory&quot;</span>: str, <span class="comment">//父类别</span></span><br><span class="line">	&#125;], <span class="comment">//列表</span></span><br><span class="line">	<span class="attr">&quot;licenses&quot;</span>: [&#123;<span class="comment">//对于训练，不重要</span></span><br><span class="line">		<span class="attr">&quot;id&quot;</span>: int, </span><br><span class="line">		<span class="attr">&quot;name&quot;</span>: str, </span><br><span class="line">		<span class="attr">&quot;url&quot;</span>: str,</span><br><span class="line">	&#125;], <span class="comment">//列表</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="2-2-注册数据集"><a href="#2-2-注册数据集" class="headerlink" title="2.2 注册数据集"></a>2.2 注册数据集</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> detectron2.data <span class="keyword">import</span> DatasetCatalog, MetadataCatalog</span><br><span class="line"><span class="keyword">from</span> detectron2.data.datasets.register_coco <span class="keyword">import</span> register_coco_instances</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">DATA_ALL_CATEGORIES = [</span><br><span class="line"> &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;airplane&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;ship&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;storage tank&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;baseball diamond&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;tennis court&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;basketball court&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;ground track field&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;harbor&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">9</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;bridge&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">10</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;vehicle&#x27;</span>&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">DATA_SPLITS = &#123;&#125;</span><br><span class="line">DATA_SPLITS[<span class="string">&#x27;nwpu_all&#x27;</span>] = &#123;</span><br><span class="line">	<span class="string">&#x27;nwpu_all_trainval&#x27;</span>: (</span><br><span class="line">		os.path.join(DATA_ROOT,<span class="string">&quot;positive image set&quot;</span>),</span><br><span class="line">		os.path.join(DATA_ROOT,<span class="string">&#x27;trainval.json&#x27;</span>)</span><br><span class="line">	),</span><br><span class="line">	<span class="string">&#x27;nwpu_all_test&#x27;</span>: (</span><br><span class="line">		os.path.join(DATA_ROOT,<span class="string">&quot;positive image set&quot;</span>),</span><br><span class="line">		os.path.join(DATA_ROOT,<span class="string">&#x27;test.json&#x27;</span>)</span><br><span class="line">	)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_data_all_instance_meta</span>():</span></span><br><span class="line">    thing_ids = [k[<span class="string">&quot;id&quot;</span>] <span class="keyword">for</span> k <span class="keyword">in</span> DATA_ALL_CATEGORIES]</span><br><span class="line">    thing_dataset_id_to_contiguous_id = &#123;k: i <span class="keyword">for</span> i, k <span class="keyword">in</span> <span class="built_in">enumerate</span>(thing_ids)&#125;</span><br><span class="line">    thing_classes = [k[<span class="string">&quot;name&quot;</span>] <span class="keyword">for</span> k <span class="keyword">in</span> DATA_ALL_CATEGORIES]</span><br><span class="line">    ret = &#123;</span><br><span class="line">        <span class="string">&quot;thing_dataset&quot;</span>: thing_dataset_id_to_contiguous_id,</span><br><span class="line">        <span class="string">&quot;thing_classes&quot;</span>: thing_classes,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_builtin_metadata</span>(<span class="params">dataset_name</span>):</span></span><br><span class="line">    <span class="keyword">if</span> dataset_name == <span class="string">&quot;nwpu_all&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> _get_data_instance_meta(DATA_ALL_CATEGORIES)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">register_all</span>(<span class="params">root</span>):</span></span><br><span class="line">    <span class="keyword">for</span> dataset_name, splits_per_dataset <span class="keyword">in</span> DATA_SPLITS.items():</span><br><span class="line">        <span class="keyword">for</span> key, (image_root, json_file) <span class="keyword">in</span> splits_per_dataset.items():</span><br><span class="line">            <span class="keyword">assert</span> os.path.exists(os.path.join(root, json_file))</span><br><span class="line">            register_coco_instances(</span><br><span class="line">                key,</span><br><span class="line">                _get_builtin_metadata(dataset_name),</span><br><span class="line">                os.path.join(root, json_file) <span class="keyword">if</span> <span class="string">&quot;://&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> json_file <span class="keyword">else</span> json_file,</span><br><span class="line">                os.path.join(root, image_root),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">DATA_ROOT = <span class="string">&quot;D:/GISP/XIEMINGJIE/Code/Detection/dataset/NWPU VHR-10 dataset/&quot;</span></span><br><span class="line"></span><br><span class="line">register_all(DATA_ROOT)</span><br></pre></td></tr></table></figure>

<p>此时已完成<code>nwpu_all_trainval</code>以及<code>nwpu_all_test</code>数据集的注册，可以通过代码查看：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(DatasetCatalog.get(<span class="string">&quot;nwpu_all_trainval&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(DatasetCatalog.get(<span class="string">&quot;nwpu_all_test&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>当然，如果不想要使用COCO格式数据集也可以自定义注册函数，可以参考<code>register_coco_instances</code>的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">register_coco_instances</span>(<span class="params">name, metadata, json_file, image_root</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        name (str): the name that identifies a dataset, e.g. &quot;coco_2014_train&quot;.</span></span><br><span class="line"><span class="string">        metadata (dict): extra metadata associated with this dataset.  You can</span></span><br><span class="line"><span class="string">            leave it as an empty dict.</span></span><br><span class="line"><span class="string">        json_file (str): path to the json instance annotation file.</span></span><br><span class="line"><span class="string">        image_root (str or path-like): directory which contains all the images.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(name, <span class="built_in">str</span>), name</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(json_file, (<span class="built_in">str</span>, os.PathLike)), json_file</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(image_root, (<span class="built_in">str</span>, os.PathLike)), image_root</span><br><span class="line">    <span class="comment"># 1. register a function which returns dicts</span></span><br><span class="line">    DatasetCatalog.register(name, <span class="keyword">lambda</span>: load_coco_json(json_file, image_root, name))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. Optionally, add metadata about this dataset,</span></span><br><span class="line">    <span class="comment"># since they might be useful in evaluation, visualization or logging</span></span><br><span class="line">    MetadataCatalog.get(name).<span class="built_in">set</span>(</span><br><span class="line">        json_file=json_file, image_root=image_root, evaluator_type=<span class="string">&quot;coco&quot;</span>, **metadata</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<p>其中<code>load_coco_json</code>函数的功能是读取数据集标注文件，并以固定的形式返回，详细可见<a href="https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html#register-a-dataset">官网</a>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># load_coco_json返回的是一个列表</span></span><br><span class="line"><span class="comment"># 返回格式如下：</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_coco_json</span>(<span class="params">json_file, image_root, dataset_name=<span class="literal">None</span>, extra_annotation_keys=<span class="literal">None</span></span>):</span></span><br><span class="line">	<span class="comment"># read and do something</span></span><br><span class="line">	<span class="comment"># ...</span></span><br><span class="line">	<span class="comment"># generate dataset_dicts like: ↓</span></span><br><span class="line">    dataset_dicts = [&#123;<span class="string">&#x27;file_name&#x27;</span>: <span class="string">&#x27;...\\images\\001.jpg&#x27;</span>, <span class="string">&#x27;height&#x27;</span>: <span class="number">939</span>, <span class="string">&#x27;width&#x27;</span>: <span class="number">1356</span>, <span class="string">&#x27;image_id&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;annotations&#x27;</span>: [&#123;<span class="string">&#x27;iscrowd&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;bbox&#x27;</span>: [<span class="number">903</span>, <span class="number">57</span>, <span class="number">129</span>, <span class="number">123</span>], <span class="string">&#x27;category_id&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;bbox_mode&#x27;</span>: &lt;BoxMode.XYWH_ABS: <span class="number">1</span>&gt;&#125;]&#125;, &#123;...&#125;]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dataset_dicts</span><br></pre></td></tr></table></figure>

<h2 id="2-3-可视化工具"><a href="#2-3-可视化工具" class="headerlink" title="2.3 可视化工具"></a>2.3 可视化工具</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> detectron2.data <span class="keyword">import</span> MetadataCatalog</span><br><span class="line"><span class="keyword">from</span> detectron2.data <span class="keyword">import</span> detection_utils <span class="keyword">as</span> utils</span><br><span class="line"><span class="keyword">from</span> detectron2.utils.visualizer <span class="keyword">import</span> Visualizer</span><br><span class="line"></span><br><span class="line">datasets_dicts = DatasetCatalog.get(<span class="string">&quot;nwpu_all_trainval_1shot&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> random.sample(datasets_dicts, <span class="number">1</span>):</span><br><span class="line">    img = utils.read_image(data[<span class="string">&quot;file_name&quot;</span>])</span><br><span class="line">    visual = Visualizer(img, metadata=MetadataCatalog.get(<span class="string">&quot;nwpu_all_trainval&quot;</span>),scale=<span class="number">0.5</span>)</span><br><span class="line">    vis = visual.draw_dataset_dict(data)</span><br><span class="line">    cv2.imshow(<span class="string">&quot;window&quot;</span>, vis.get_image()[:, :, ::-<span class="number">1</span>])</span><br><span class="line">    cv2.waitKey()</span><br></pre></td></tr></table></figure>


<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220316211311.png"></p>
<h2 id="2-4-自定义数据增强"><a href="#2-4-自定义数据增强" class="headerlink" title="2.4 自定义数据增强"></a>2.4 自定义数据增强</h2><p>在注册了数据集之后就可以用<code>detectron2.data.build_detection_train_loader</code>和<code>detectron2.data.build_detection_test_loader</code>构建<code>Dataloader</code>，即数据集的加载方式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> detectron2.config <span class="keyword">import</span> get_cfg</span><br><span class="line"><span class="keyword">import</span> detectron2.data.transforms <span class="keyword">as</span> T</span><br><span class="line"><span class="keyword">from</span> detectron2.model_zoo <span class="keyword">import</span> model_zoo</span><br><span class="line"><span class="keyword">from</span> detectron2.data <span class="keyword">import</span> build_detection_train_loader</span><br><span class="line"><span class="keyword">from</span> detectron2.data <span class="keyword">import</span> DatasetMapper   <span class="comment"># the default mapper</span></span><br><span class="line"></span><br><span class="line">cfg = get_cfg()</span><br><span class="line">cfg.merge_from_file(model_zoo.get_config_file(<span class="string">&quot;COCO-Detection/retinanet_R_50_FPN_1x.yaml&quot;</span>))</span><br><span class="line">cfg.DATASETS.TRAIN = (<span class="string">&quot;nwpu_all_trainval&quot;</span>,)</span><br><span class="line"></span><br><span class="line">mapper = DatasetMapper(cfg,is_train=<span class="literal">True</span>,augmentations=[T.Resize((<span class="number">800</span>, <span class="number">800</span>))])</span><br><span class="line">train_loader = build_detection_train_loader(cfg,mapper=mapper)</span><br></pre></td></tr></table></figure>

<p><code>build_detection_train_loader()</code>的参数如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">build_detection_train_loader(</span><br><span class="line">    dataset,</span><br><span class="line">    *,</span><br><span class="line">    mapper,</span><br><span class="line">    sampler=<span class="literal">None</span>,</span><br><span class="line">    total_batch_size,</span><br><span class="line">    aspect_ratio_grouping=<span class="literal">True</span>,</span><br><span class="line">    num_workers=<span class="number">0</span>,</span><br><span class="line">    collate_fn=<span class="literal">None</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>其中<code>mapper</code>对应的就是数据增强部分，默认为<code>detectron2.data.DatasetMapper</code>，<code>sampler</code>对应的采样策略部分，通常只需要关注<code>mapper</code>即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DatasetMapper</span>:</span></span><br><span class="line"><span class="meta">    @configurable</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,is_train: <span class="built_in">bool</span></span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_config</span>(<span class="params">cls, cfg, is_train: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_transform_annotations</span>(<span class="params">self, dataset_dict, transforms, image_shape</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, dataset_dict</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span> dataset_dict</span><br></pre></td></tr></table></figure>

<p>官方给的自定义简化DataMapper：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> detectron2.data <span class="keyword">import</span> detection_utils <span class="keyword">as</span> utils</span><br><span class="line"><span class="keyword">import</span> detectron2.data.transforms <span class="keyword">as</span> T</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper</span>(<span class="params">dataset_dict</span>):</span></span><br><span class="line">    dataset_dict = copy.deepcopy(dataset_dict)  <span class="comment"># it will be modified by code below</span></span><br><span class="line">    <span class="comment"># can use other ways to read image</span></span><br><span class="line">    image = utils.read_image(dataset_dict[<span class="string">&quot;file_name&quot;</span>], <span class="built_in">format</span>=<span class="string">&quot;BGR&quot;</span>)</span><br><span class="line">    <span class="comment"># &quot;Data Augmentation&quot;</span></span><br><span class="line">    auginput = T.AugInput(image)</span><br><span class="line">    transform = T.Resize((<span class="number">800</span>, <span class="number">800</span>))(auginput)</span><br><span class="line">    image = torch.from_numpy(auginput.image.transpose(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    annos = [</span><br><span class="line">        utils.transform_instance_annotations(annotation, [transform], image.shape[<span class="number">1</span>:])</span><br><span class="line">        <span class="keyword">for</span> annotation <span class="keyword">in</span> dataset_dict.pop(<span class="string">&quot;annotations&quot;</span>)</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">       <span class="comment"># create the format that the model expects</span></span><br><span class="line">       <span class="string">&quot;image&quot;</span>: image,</span><br><span class="line">       <span class="string">&quot;instances&quot;</span>: utils.annotations_to_instances(annos, image.shape[<span class="number">1</span>:])</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">dataloader = build_detection_train_loader(cfg, mapper=mapper)</span><br></pre></td></tr></table></figure>

<p>因此自定义的数据增强需要满足，输入为<code>dataset_dict</code>，输出为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="string">&quot;images&quot;</span>: image_tensor,</span><br><span class="line"> <span class="string">&quot;instances&quot;</span>: utils.annotations_to_instances =&gt; Instances类</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="3-自定义模型"><a href="#3-自定义模型" class="headerlink" title="3. 自定义模型"></a>3. 自定义模型</h1><p>Detectron2的模型是分模块的，它将目标检测模型拆分为了4个核心模块：<code>backbone</code>，<code>proposal_generator</code>，<code>roi_heads</code>以及<code>meta_arch</code>。</p>
<h2 id="3-1-特征提取网络（backbone）"><a href="#3-1-特征提取网络（backbone）" class="headerlink" title="3.1 特征提取网络（backbone）"></a>3.1 特征提取网络（backbone）</h2><p>在<code>detectron2.modeling.backbone</code>路径下可以看到，目前只有<code>ResNet</code>、<code>FPN</code>和<code>RegNet</code></p>
<p>可直接使用的<code>backbone</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">build_resnet_backbone</span><br><span class="line">build_resnet_fpn_backbone</span><br><span class="line">build_retinanet_resnet_fpn_backbone</span><br></pre></td></tr></table></figure>

<p>官方的自定义<code>backbone</code>的案例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> detectron2.modeling <span class="keyword">import</span> BACKBONE_REGISTRY, Backbone, ShapeSpec</span><br><span class="line"></span><br><span class="line"><span class="meta">@BACKBONE_REGISTRY.register()</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToyBackbone</span>(<span class="params">Backbone</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, cfg, input_shape</span>):</span></span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    <span class="comment"># create your own backbone</span></span><br><span class="line">    self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">16</span>, padding=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, image</span>):</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;conv1&quot;</span>: self.conv1(image)&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">output_shape</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;conv1&quot;</span>: ShapeSpec(channels=<span class="number">64</span>, stride=<span class="number">16</span>)&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-2-候选框生成器（proposal-generator）"><a href="#3-2-候选框生成器（proposal-generator）" class="headerlink" title="3.2 候选框生成器（proposal_generator）"></a>3.2 候选框生成器（proposal_generator）</h2><p>同样可以自定义注册</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PROPOSAL_GENERATOR_REGISTRY.register()</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToyRPN</span>(<span class="params">RPN</span>):</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,*args, **kwargs</span>):</span></span><br><span class="line">		<span class="built_in">super</span>().__init__()</span><br><span class="line">	    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@RPN_HEAD_REGISTRY.register()</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToyRPNHead</span>(<span class="params">StandardRPNHead</span>):</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,*args, **kwargs</span>):</span></span><br><span class="line">	    <span class="built_in">super</span>().__init__()</span><br><span class="line">	    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h2 id="3-3-检测器（roi-heads）"><a href="#3-3-检测器（roi-heads）" class="headerlink" title="3.3 检测器（roi_heads）"></a>3.3 检测器（roi_heads）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ROI_MASK_HEAD_REGISTRY.register()</span></span><br><span class="line"><span class="meta">@ROI_KEYPOINT_HEAD_REGISTRY.register()</span></span><br><span class="line"><span class="meta">@ROI_HEADS_REGISTRY.register()</span></span><br><span class="line"><span class="meta">@ROI_BOX_HEAD_REGISTRY.register()</span></span><br></pre></td></tr></table></figure>

<h2 id="3-4-模型框架（meta-arch）"><a href="#3-4-模型框架（meta-arch）" class="headerlink" title="3.4 模型框架（meta_arch）"></a>3.4 模型框架（meta_arch）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@META_ARCH_REGISTRY.register()</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToyNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"><span class="meta">    @configurable</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,*args, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_config</span>(<span class="params">cls, cfg</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward_training</span>(<span class="params">self,*args, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">self,*args, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.no_grad()</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">label_anchors</span>(<span class="params">self,*args, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward_inference</span>(<span class="params">self,*args, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inference_single_image</span>(<span class="params">self,*args, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>具体可参考官方复现的<a href="https://github.com/facebookresearch/detectron2/tree/main/projects">projects</a></p>
<h1 id="4-模型训练"><a href="#4-模型训练" class="headerlink" title="4. 模型训练"></a>4. 模型训练</h1><h2 id="4-1-默认训练"><a href="#4-1-默认训练" class="headerlink" title="4.1 默认训练"></a>4.1 默认训练</h2><p>一般而言，我们可以继承使用默认的目标检测任务训练器<code>DefalutTrainer</code>，而<code>DefalutTrainer</code>又是继承自<code>TrainerBase</code>，<code>TrainerBase</code>中又使用到了<code>HookBase</code>。我的理解是<code>HookBase</code>和<code>TrainerBase</code>是将一个训练过程抽象并拆分成阶段步骤的过程，先看<code>HookBase</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HookBase</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">before_train</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Called before the first iteration.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">after_train</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Called after the last iteration.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">before_step</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Called before each iteration.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">after_step</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Called after each iteration.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">state_dict</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>对于训练而言，它将一个完整的训练拆分成：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TrainerBase</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self._hooks: <span class="type">List</span>[HookBase] = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">register_hooks</span>(<span class="params">self, hooks: <span class="type">List</span>[<span class="type">Optional</span>[HookBase]]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        hooks = [h <span class="keyword">for</span> h <span class="keyword">in</span> hooks <span class="keyword">if</span> h <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>]</span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> hooks:</span><br><span class="line">            <span class="keyword">assert</span> <span class="built_in">isinstance</span>(h, HookBase)</span><br><span class="line">            h.trainer = weakref.proxy(self)</span><br><span class="line">        self._hooks.extend(hooks)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">self, start_iter: <span class="built_in">int</span>, max_iter: <span class="built_in">int</span></span>):</span></span><br><span class="line">        self.<span class="built_in">iter</span> = self.start_iter = start_iter</span><br><span class="line">        self.max_iter = max_iter</span><br><span class="line">        <span class="keyword">with</span> EventStorage(start_iter) <span class="keyword">as</span> self.storage:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                self.before_train()</span><br><span class="line">                <span class="keyword">for</span> self.<span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(start_iter, max_iter):</span><br><span class="line">                    self.before_step()</span><br><span class="line">                    self.run_step()</span><br><span class="line">                    self.after_step()</span><br><span class="line">            <span class="keyword">finally</span>:</span><br><span class="line">                self.after_train()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">before_train</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> self._hooks:</span><br><span class="line">            h.before_train()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">after_train</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.storage.<span class="built_in">iter</span> = self.<span class="built_in">iter</span></span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> self._hooks:</span><br><span class="line">            h.after_train()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">before_step</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.storage.<span class="built_in">iter</span> = self.<span class="built_in">iter</span></span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> self._hooks:</span><br><span class="line">            h.before_step()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">after_step</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> self._hooks:</span><br><span class="line">            h.after_step()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run_step</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">state_dict</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_state_dict</span>(<span class="params">self, state_dict</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>简化一点，它将一个训练过程抽象成：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">hook.before_train()</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(start_iter, max_iter):</span><br><span class="line">    hook.before_step()</span><br><span class="line">    trainer.run_step()</span><br><span class="line">    hook.after_step()</span><br><span class="line"><span class="built_in">iter</span> += <span class="number">1</span></span><br><span class="line">hook.after_train()</span><br></pre></td></tr></table></figure>

<p>具体到目标检测任务，<code>DefaultTrainer</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DefaultTrainer</span>(<span class="params">TrainerBase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, cfg</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_hooks</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_writers</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span>	</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">cls, cfg, model, evaluators=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># </span></span><br><span class="line">    <span class="comment"># a lot of</span></span><br><span class="line">    <span class="comment"># def ...(...):</span></span><br><span class="line">    <span class="comment">#     .....</span></span><br><span class="line">    <span class="comment"># </span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_train_loader</span>(<span class="params">cls, cfg</span>):</span></span><br><span class="line">        <span class="keyword">return</span> build_detection_train_loader(cfg)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_test_loader</span>(<span class="params">cls, cfg, dataset_name</span>):</span></span><br><span class="line">        <span class="keyword">return</span> build_detection_test_loader(cfg, dataset_name)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_evaluator</span>(<span class="params">cls, cfg, dataset_name</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h2 id="4-2-自定义训练"><a href="#4-2-自定义训练" class="headerlink" title="4.2 自定义训练"></a>4.2 自定义训练</h2><p>由于Detectron2已经将训练过程模块化，因此只需要修改对应模块即可，而一般而言，我们只需要修改数据加载和<code>evaluate</code>部分：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> detectron2.engine <span class="keyword">import</span> DefaultTrainer</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Trainer</span>(<span class="params">DefaultTrainer</span>):</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_evaluator</span>(<span class="params">cls, cfg, dataset_name, output_folder=<span class="literal">None</span></span>):</span></span><br><span class="line">        evaluator_list = []</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span> DatasetEvaluators(evaluator_list)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_test_loader</span>(<span class="params">cls, cfg, dataset_name</span>):</span></span><br><span class="line">        <span class="keyword">return</span> build_detection_test_loader(cfg, dataset_name, mapper=my_mapper(cfg,<span class="string">&quot;test&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_train_loader</span>(<span class="params">cls, cfg</span>):</span></span><br><span class="line">        <span class="keyword">return</span> build_detection_train_loader(cfg, mapper=my_mapper(cfg, <span class="string">&quot;train&quot;</span>))</span><br></pre></td></tr></table></figure>

<h2 id="4-3-完整训练流程"><a href="#4-3-完整训练流程" class="headerlink" title="4.3 完整训练流程"></a>4.3 完整训练流程</h2><p>参考<code>tools/train_net.py</code>或者<code>tools/plain_train_net.py</code>，已经写的非常详细了👍，注意别忘了导入自己写好的注册数据集以及注册模型的文件，只要导入了就会自动注册，就可以在配置文件中使用。</p>
<h1 id="5-配置文件"><a href="#5-配置文件" class="headerlink" title="5. 配置文件"></a>5. 配置文件</h1><p>参考<code>configs</code>文件夹下的<code>yaml</code>文件格式，，可以通过<code>__BASE__</code>继承基础配置文件，还可以直接覆盖之前的配置，如<code>retinanet_R_50_FPN_3x.yaml</code>：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">_BASE_:</span> <span class="string">&quot;../Base-RetinaNet.yaml&quot;</span></span><br><span class="line"><span class="attr">MODEL:</span></span><br><span class="line">  <span class="attr">WEIGHTS:</span> <span class="string">&quot;detectron2://ImageNetPretrained/MSRA/R-50.pkl&quot;</span></span><br><span class="line">  <span class="attr">RESNETS:</span></span><br><span class="line">    <span class="attr">DEPTH:</span> <span class="number">50</span></span><br><span class="line"><span class="attr">SOLVER:</span></span><br><span class="line">  <span class="attr">STEPS:</span> <span class="string">(210000,</span> <span class="number">250000</span><span class="string">)</span></span><br><span class="line">  <span class="attr">MAX_ITER:</span> <span class="number">270000</span></span><br></pre></td></tr></table></figure>

<p>查看全部配置项：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> detectron2.config <span class="keyword">import</span> get_cfg</span><br><span class="line">cfg = get_cfg()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(cfg)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="built_in">print</span>(cfg.dump())</span><br></pre></td></tr></table></figure>

<p>在python文件中修改配置：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cfg.SOLVER.BASE_LR = <span class="number">0.001</span></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">cfg.merge_from_list([<span class="string">&quot;SOLVER.BASE_LR&quot;</span>, <span class="string">&quot;0.001&quot;</span>])</span><br></pre></td></tr></table></figure>

<p>合并多个文件中的配置项：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cfg.merge_from_file(<span class="string">&quot;my_cfg.yaml&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>由于配置项本质上还是转换成了字典类型，因此可以直接从python文件导入配置，并且也提供了python格式的配置文件该怎么进行训练的示例，参考<code>tools/lazyconfig_train_net.py</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># config.py</span></span><br><span class="line">NEW_MODEL = <span class="built_in">dict</span>(NUM=<span class="number">1</span>,SIZE=<span class="built_in">dict</span>(W=<span class="number">2</span>,H=<span class="number">3</span>))</span><br><span class="line">NEW_OPT = <span class="built_in">dict</span>(NAME=<span class="string">&quot;hhhh&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---</span></span><br><span class="line"><span class="keyword">from</span> detectron2.config <span class="keyword">import</span> LazyConfig</span><br><span class="line">cfg = LazyConfig.load(<span class="string">&quot;config.py&quot;</span>)</span><br><span class="line"><span class="keyword">assert</span> cfg.NEW_MODEL.SIZE.W==<span class="number">2</span></span><br><span class="line"><span class="comment"># cfg = LazyConfig.load(args.config_file)</span></span><br><span class="line"><span class="comment"># cfg = LazyConfig.apply_overrides(cfg, args.opts)</span></span><br></pre></td></tr></table></figure>

<p>并且Detectron2还提供了一个帮助创建配置字典的函数，<code>LazyCall</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> detectron2.config <span class="keyword">import</span> LazyCall <span class="keyword">as</span> L</span><br><span class="line"><span class="keyword">from</span> detectron2.modeling.backbone <span class="keyword">import</span> RegNet</span><br><span class="line"><span class="keyword">from</span> detectron2.modeling.backbone.regnet <span class="keyword">import</span> SimpleStem, ResBottleneckBlock</span><br><span class="line"></span><br><span class="line">bottom_up = L(RegNet)(</span><br><span class="line">    stem_class=SimpleStem,</span><br><span class="line">    stem_width=<span class="number">32</span>,</span><br><span class="line">    block_class=ResBottleneckBlock,</span><br><span class="line">    depth=<span class="number">23</span>,</span><br><span class="line">    w_a=<span class="number">38.65</span>,</span><br><span class="line">    w_0=<span class="number">96</span>,</span><br><span class="line">    w_m=<span class="number">2.43</span>,</span><br><span class="line">    group_width=<span class="number">40</span>,</span><br><span class="line">    norm=<span class="string">&quot;SyncBN&quot;</span>,</span><br><span class="line">    out_features=[<span class="string">&quot;s1&quot;</span>, <span class="string">&quot;s2&quot;</span>, <span class="string">&quot;s3&quot;</span>, <span class="string">&quot;s4&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(bottom_up)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Detectron2</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测 | FCOS，经典单阶段Anchor-Free目标检测模型</title>
    <url>/posts/bc226294.html</url>
    <content><![CDATA[<h1 id="FCOS-Fully-Convolutional-One-Stage-Object-Detection"><a href="#FCOS-Fully-Convolutional-One-Stage-Object-Detection" class="headerlink" title="FCOS: Fully Convolutional One-Stage Object Detection"></a>FCOS: Fully Convolutional One-Stage Object Detection</h1><blockquote>
<p>论文来源：ICCV2019<br>论文链接：<a href="https://arxiv.org/abs/1904.01355">https://arxiv.org/abs/1904.01355</a><br>论文代码：<a href="https://github.com/tianzhi0549/FCOS/">https://github.com/tianzhi0549/FCOS/</a></p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20211119114214.png" alt="20211119114214"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@inproceedings&#123;tian2019fcos,</span><br><span class="line">  title=&#123;Fcos: Fully convolutional one-stage object detection&#125;,</span><br><span class="line">  author=&#123;Tian, Zhi and Shen, Chunhua and Chen, Hao and He, Tong&#125;,</span><br><span class="line">  booktitle=&#123;Proceedings of the IEEE/CVF international conference on computer vision&#125;,</span><br><span class="line">  pages=&#123;9627--9636&#125;,</span><br><span class="line">  year=&#123;2019&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="归纳总结"><a href="#归纳总结" class="headerlink" title="归纳总结"></a>归纳总结</h2><table>
<thead>
<tr>
<th>标签</th>
<th>目的</th>
<th>方法</th>
<th>总结</th>
</tr>
</thead>
<tbody><tr>
<td>#Anchor-Free #单阶段</td>
<td>解决Anchor-Base算法超参数设置复杂，计算量大的问题</td>
<td>FCN，Center-ness</td>
<td>Anchor-Free经典算法</td>
</tr>
</tbody></table>
<h2 id="主要工作"><a href="#主要工作" class="headerlink" title="主要工作"></a>主要工作</h2><p>FCOS是一种基于全卷积的单阶段目标检测算法，并且是一种Anchor box free的算法。其实现了无Anchor，无Proposal，并且提出了Center-ness的思想，极大的提升了Anchor-Free目标检测算法的性能。</p>
<p>Anchor free的好处是：</p>
<ul>
<li>避免了Anchor Box带来的复杂计算，如计算重合度IoU；</li>
<li>避免了Anchor Box相关的超参数设置，其对性能影响较大；</li>
</ul>
<p>因此，FCOS的优点是：</p>
<ul>
<li>其可以和其他使用FCN结构的任务相统一，方便其他任务方法之间的re-use</li>
<li>proposal free和anchor free，减少了超参数数量，更简单</li>
<li>减少了计算复杂度，如IoU计算</li>
<li>FCOS在单阶段算法中性能不错，并且证明了FCOS替换两阶段算法里的RPNs也可以取得更好的性能</li>
<li>适用于各种instance-wise的预测问题</li>
</ul>
<h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p>模型结构如下图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211119160053912.png" alt="image-20211119160053912"></p>
<p>FCOS包含三个大模块：</p>
<ul>
<li>Backbone：提取图像特征，如结构图左侧所示，其中特征图尺寸逐层减半，如左侧$H×W$所示，$s=\frac{W^*}{W}$代表步长。对于坐标为$(x,y)$的位置，其映射回原图为$(\lfloor\frac{s}{2}\rfloor + xs,\lfloor\frac{s}{2}\rfloor+ys)$;</li>
<li>FPN：多层级预测，提高检测器对不同尺寸目标的检测性能；与Anchor Based不同的是，FCOS通过限制不同层级边界框回归范围来分配层级</li>
<li>Classification+Center-ness+Regression Head</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211119155237711.png" alt="image-20211119155237711"></p>
<p>对于FCOS，其直接将每个位置$(x,y)$视为训练样本，其需要回归的值为一个4维向量$t=(l,t,r,b)$，如上图所示。<br>由于一张图片中的目标数量有限，所以导致基于Anchor的算法会产生更多的负样本，因此FCOS对于每个像素点只回归一组值（可以理解为Anchor数量为1），可以利用更多的前景（正）样本信息去训练。如果坐标落在任何ground-truth box中即为正样本，且该位置的类别为这个gt box的类别$c^*$，否则为负样本（即背景，类别为0），如果落在多个gt box中，则认为其是一个歧义样本（ambiguous sample），针对这种情况，可通过FPN解决。计算$(l^*, t^*, r^*, b^*)$，$m_i$为每个特征层最大距离（论文里作者设置$m_2$~$m_7$分别为0，64，128，256，512，$\infty$），如果$\max(l^*, t^*, r^*, b^*) &gt; m_i$ 或者 $\max(l^*, t^*, r^*, b^*) &lt; m_{i−1}$,则此位置为负样本，不进行计算；对于大小相近又存在重叠的gt box，FPN无法区别，则选择面积最小的gt box为回归目标。</p>
<h3 id="正负样本定义"><a href="#正负样本定义" class="headerlink" title="正负样本定义"></a>正负样本定义</h3><p>一个目标检测算法性能的优异性，最大影响因素就是<strong>如何定义正负样本</strong>。而FCOS的定义方式非常通俗易懂。主要分为两步：<br><strong>(1) 设置regress_ranges=((-1, 64), (64, 128), (128, 256), (256, 512),(512, INF)，用于将不同大小的bbox分配到不同的FPN层进行预测即距离4条边的最大值在给定范围内</strong><br><strong>(2) 设置center_sampling_ratio=1.5,用于确定对于任意一个输出层距离bbox中心多远的区域属于正样本（基于gt bbox中心点进行扩展出正方形，扩展范围是center_sample_radius×stride，正方形区域就当做新的gt bbox），该值越大，扩张比例越大，选择正样本区域越大；（细节：如果扩展比例过大，导致中心采样区域超过了gt bbox本身范围了，此时需要截断操作）</strong></p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>FCOS的损失函数为：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211119173209315.png" alt="image-20211119173209315"></p>
<p>其中$L_{cls}$是focal loss，$L_{reg}$是IoU loss，$N_{pos}$代表正样本数量，$\lambda$用于平衡$L_{reg}$的权重；$\mathbb{1} _ {c^{ * }<em>{i}}$当$c^{ * }</em>{i}&gt;0$时为1，否则为0；</p>
<p>为了减少低质量检测框，减少误检，FCOS增加了一个一层的分支，用于预测Center-ness，其描绘了位置到目标中心的归一化距离，下图展示了使用Center-ness（左）和不使用Center-ness（右）的区别。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211119175758242.png" alt="image-20211119175758242"></p>
<p>Center-ness的计算公式如下，其范围为0-1，训练阶段使用BCE Loss并和之前的损失函数相加，测试阶段用于加权预测得分：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211119180027086.png" alt="image-20211119180027086"></p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>对比实验结果：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211119180536280.png" alt="image-20211119180536280"></p>
<p>有无Center-ness分支的消融实验：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220326134621.png"></p>
<p>替换RPN的消融实验：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220326134721.png"></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://zhuanlan.zhihu.com/p/267346645">mmdetection最小复刻版(六)：FCOS深入可视化分析 - 知乎 (zhihu.com)</a></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文笔记</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测 | FPN，多尺度目标检测经典Backbone</title>
    <url>/posts/4c29d81e.html</url>
    <content><![CDATA[<h1 id="Feature-Pyramid-Networks-for-Object-Detection"><a href="#Feature-Pyramid-Networks-for-Object-Detection" class="headerlink" title="Feature Pyramid Networks for Object Detection"></a>Feature Pyramid Networks for Object Detection</h1><blockquote>
<p>论文发表：CVPR2017<br>论文链接：<a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Lin_Feature_Pyramid_Networks_CVPR_2017_paper.html">CVPR2017 open access</a></p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220408112206.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@inproceedings&#123;lin2017feature,</span><br><span class="line">  title=&#123;Feature pyramid networks for object detection&#125;,</span><br><span class="line">  author=&#123;Lin, Tsung-Yi and Doll&#123;\&#x27;a&#125;r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge&#125;,</span><br><span class="line">  booktitle=&#123;Proceedings of the IEEE conference on computer vision and pattern recognition&#125;,</span><br><span class="line">  pages=&#123;2117--2125&#125;,</span><br><span class="line">  year=&#123;2017&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="1-归纳总结"><a href="#1-归纳总结" class="headerlink" title="1. 归纳总结"></a>1. 归纳总结</h2><table>
<thead>
<tr>
<th>Name</th>
<th>Value</th>
</tr>
</thead>
<tbody><tr>
<td>标签</td>
<td>#多尺度</td>
</tr>
<tr>
<td>目的</td>
<td>针对目标检测任务中，目标尺度变化的问题，设计了特征金字塔网络</td>
</tr>
<tr>
<td>方法</td>
<td>构建多层特征图之间的联系，合理利用高层语义信息和底层位置信息</td>
</tr>
<tr>
<td>总结</td>
<td>是目标检测模型的标配，较好地解决了多尺度检测问题</td>
</tr>
</tbody></table>
<h2 id="2-问题背景"><a href="#2-问题背景" class="headerlink" title="2. 问题背景"></a>2. 问题背景</h2><p>作者提到，在2017年以前，目标检测中的一个基本挑战就是目标检测模型在处理目标多尺度变化问题的不足，因为在当时很多网络都使用了利用单个高层特征，(比如说Faster R-CNN利用下采样四倍的卷积层——Conv4，进行后续的物体的分类和bounding box的回归)，但是这样做有一个明显的缺陷，即小物体本身具有的像素信息较少，在下采样的过程中极易被丢失，而之前的图像金字塔结构虽然也能解决多尺度问题，但计算量大，内存消耗大，因此作者提出了特征金字塔结构，能在增加极小的计算量的情况下，处理好物体检测中的多尺度变化问题。</p>
<h2 id="3-主要工作"><a href="#3-主要工作" class="headerlink" title="3. 主要工作"></a>3. 主要工作</h2><p>针对上诉问题，提出了一个利用深度卷积神经网络固有的多尺度金字塔结构来以极小的计算量构建特征金字塔的网络结构，即FPN。</p>
<h3 id="3-1-模型结构"><a href="#3-1-模型结构" class="headerlink" title="3.1 模型结构"></a>3.1 模型结构</h3><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220408115456.png"><br>作者对比了多种金字塔结构，其中：</p>
<ul>
<li>图（a）所示的是经典的图像金字塔结构，其通过对不同尺度的图像提取特征，来构建特征金字塔，因此其需要对不同尺度图像分别提取特征，计算量大且消耗内存多；</li>
<li>图（b）所示的是2017年常见的利用最后一层（高层）特征图检测目标的模型结构，其对于多尺度目标的检测能力不足；</li>
<li>图（c）是一种利用卷积神经网络固有的多尺度特征图构建的多尺度检测模型（如SSD），但是其没有结合高层语义信息和底层位置信息，因此检测精度一般；</li>
<li>图（d）即FPN结构，是一种具有侧向连接（lateral connections）的自上而下的网络结构，用来构建不同尺寸的具有高级语义信息的特征图，并且很好的利用了不同层特征的信息。</li>
</ul>
<p>下图是FPN的网络结构：<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220408120130.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220408122428.png"></p>
<p>其主要包含两个部分：</p>
<ul>
<li>自下而上的特征提取：即常规的前馈Backbone网络，以Faster R-CNN为例，假设选择ResNet每级最后一个Residual Block的输出，记为{C1,C2,C3,C4,C5}，那么FPN用2-5级参与预测，其中C2, C3, C4, C5表示conv2，conv3，conv4和conv5的输出层(最后一个残差block层)作为FPN的特征，分别对应于输入图片的下采样倍数为{4，8，16，32}。</li>
<li>自上而下的特征融合以及横向连接：即将高层的语义信息和本层的细节信息相融合。自上而下的过程通过上采样（Up-Sampling）实现，上采样的方法是<strong>最近邻插值法</strong>，如下图所示。具体过程为：C5层先经过1 x 1卷积，改变特征图的通道数(文章中设置d=256，与Faster R-CNN中RPN层的维数相同便于分类与回归)。然后通过上采样，再加上(特征图中每一个相同位置元素直接相加)C4经过1 x 1卷积后的特征图M4（固定通道256）。这个过程再做两次，分别得到C3对应的特征图M3（固定通道256）以及C2对应的特征图M2（固定通道256）。M层特征图再经过3 x 3卷积(减轻最近邻近插值带来的混叠影响，周围的数都相同)，得到最终的P2，P3，P4，P5层特征。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220408122814.png"><br>图片来自<a href="https://zhuanlan.zhihu.com/p/92005927">【论文笔记】FPN —— 特征金字塔 - 知乎 (zhihu.com)</a></p>
<h3 id="3-2-代码"><a href="#3-2-代码" class="headerlink" title="3.2 代码"></a>3.2 代码</h3><p>可参考Pytorch官方的代码<a href="https://github.com/pytorch/vision">https://github.com/pytorch/vision</a></p>
<h2 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4. 实验结果"></a>4. 实验结果</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220408123357.png"></p>
<h2 id="5-参考文献"><a href="#5-参考文献" class="headerlink" title="5. 参考文献"></a>5. 参考文献</h2><p><a href="https://zhuanlan.zhihu.com/p/92005927">【论文笔记】FPN —— 特征金字塔 - 知乎 (zhihu.com)</a></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文笔记</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测 | Faster R-CNN，经典两阶段检测模型</title>
    <url>/posts/fc798de3.html</url>
    <content><![CDATA[<h1 id="Faster-R-CNN-Towards-Real-Time-ObjectDetection-with-Region-Proposal-Networks"><a href="#Faster-R-CNN-Towards-Real-Time-ObjectDetection-with-Region-Proposal-Networks" class="headerlink" title="Faster R-CNN: Towards Real-Time ObjectDetection with Region Proposal Networks"></a>Faster R-CNN: Towards Real-Time ObjectDetection with Region Proposal Networks</h1><blockquote>
<p>论文发表：2015<br>论文链接：<a href="https://arxiv.org/abs/1506.01497">https://arxiv.org/abs/1506.01497</a><br>论文代码：<a href="https://github.com/rbgirshick/py-faster-rcnn">https://github.com/rbgirshick/py-faster-rcnn</a></p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120141803069.png" alt="image-20211120141803069"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@article&#123;ren2015faster,</span><br><span class="line">  title=&#123;Faster r-cnn: Towards real-time object detection with region proposal networks&#125;,</span><br><span class="line">  author=&#123;Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian&#125;,</span><br><span class="line">  journal=&#123;Advances in neural information processing systems&#125;,</span><br><span class="line">  volume=&#123;28&#125;,</span><br><span class="line">  pages=&#123;91--99&#125;,</span><br><span class="line">  year=&#123;2015&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="归纳总结"><a href="#归纳总结" class="headerlink" title="归纳总结"></a>归纳总结</h2><table>
<thead>
<tr>
<th>标签</th>
<th>目的</th>
<th>方法</th>
<th>总结</th>
</tr>
</thead>
<tbody><tr>
<td>#Anchor #两阶段</td>
<td>-</td>
<td>RPN</td>
<td>首次提出RPN和Anchor</td>
</tr>
</tbody></table>
<h2 id="主要工作"><a href="#主要工作" class="headerlink" title="主要工作"></a>主要工作</h2><p>Faster R-CNN是在R-CNN和Fast R-CNN的基础上提出的一种两阶段目标检测算法，其主要包括：</p>
<ul>
<li>特征提取网络（Backbone）</li>
<li>RPN（Region Proposal Networks）</li>
<li>RoI Pooling（Region of Interesting Pooling）</li>
<li>分类回归（Classification and Regression）</li>
</ul>
<p>论文中的结构图如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120142753845.png" alt="image-20211120142753845"></p>
<p>自己画的训练流程图如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120143345989.png" alt="image-20211120143345989"></p>
<p>网上找的训练流程图如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/fasterRCNN.png" alt="fasterRCNN"></p>
<blockquote>
<p>图片来自<a href="https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_object_detection/faster_rcnn">WZMIAOMIAO/deep-learning-for-image-processing (github.com)</a></p>
</blockquote>
<p>对于Backbone生成的特征图，首先输入到RPN结构中，用于生成Proposal。RPN，即区域推荐网络，对于目标检测任务而言，不仅需要对目标分类还需要对目标定位，因此Faster RCNN模型提出了Anchor机制，其中的做法是，在特征图的每个像素位置预设一组多尺度的先验框，即Anchor（作者使用了3种尺寸（128，256，512），3种比例（1:1，1:2，2:1）的Anchor，共9种）：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120143554871.png" alt="image-20211120143554871"></p>
<p>如果输入一张800×600的图片，经过Backbone后被下采样16倍，那么这个特征图的尺寸为$\frac{800}{16}×\frac{600}{16}=1900$个像素，那么这个特征图上需要设置1900×9=17100个Anchor。但这一步得到的Anchor肯定不可能全部当作候选区域，因此在预设了Anchor之后，为了筛选有意义的proposal，还设置了一个3×3的卷积层后接两个1×1的卷积层来预测该区域是否包含目标(cls)以及偏移量预测(reg)，如果包含目标则需要根据预测的偏移量对该Anchor进行微调。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120143818038.png" alt="image-20211120143818038"></p>
<p>这两个1×1的卷积层的输出维度分别为2k和4k，其中k为每个位置的Anchor数量，2代表包含目标和不包含目标的概率，4代表对目标框坐标值（x,y,w,h）的偏移量预测：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120144113585.png" alt="image-20211120144113585"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120144227681.png" alt="image-20211120144227681"></p>
<p>可以根据上述公式，计算出候选区域的坐标。并且当我们得到了该区域包含目标的概率之后，我们就可以进行一个简单的筛选，按照包含目标可能性排序，只保留前2000个作为候选区域，并且对于超出图片边界的边框还需要进行一个裁剪处理。</p>
<p>尽管我们筛选出了2000个候选区域，但我们在计算Loss的时候并不是拿这2000个候选区域来计算，这里Faster RCNN定义了正负样本的概念，首先我们需要将特征图上的Anchor映射回原始图像，因为我们的Ground-Truth是在原始图像上标注的，RPN需要根据这个来进行学习，其次还需要了解IoU这个概念，IoU可以用来计算两个框之间的重合度，其值为两个框的交集与并集的比值。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120151522563.png" alt="image-20211120151522563"></p>
<p>那么我们就可以定义候选区域和ground-truth的IoU值大于0.7的为正样本，小于0.3的为负样本，其他的都不用于计算损失，然后从中分别随机抽取128个正负样本。RPN的损失函数如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120144312326.png" alt="image-20211120144312326"></p>
<p>RoI Pooling的作用是将 RPN 输出的大小不等的候选框缩放到统一的尺寸。具体做法是，假设需要固定候选区域为7×7大小，那么就可以将其划分为7×7个块，然后对每个块进行最大值池化，最后输出的大小就是所需要的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120144459517.png" alt="image-20211120144459517"></p>
<p>这样，将所有的候选区域统一大小后，将其展平为49×1大小，通道数为256的向量，输入到两个全连接层隐藏层，最后再分别接两个输出大小为类别数以及类别数×4的全连接层。来实现对候选区域包含目标所属类别概率以及对该目标框的偏移量的预测。分类回归的损失函数和之前RPN的损失函数类似，只是分类损失不再是二分类交叉熵而是多分类交叉熵。预测框的坐标计算也和之前RPN部分的一样。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120151313142.png" alt="image-20211120151313142"></p>
<p>而在得到了预测目标框和类别概率之后，还需要进一步筛选，因为之前保留了2000个候选区域，而实际场景中目标数量根本达不到那么多，因此我们使用了NMS算法对重叠目标框进行去重。NMS算法的流程如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120151353580.png" alt="image-20211120151353580"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120151446230.png" alt="image-20211120151446230"></p>
<p>首先对同一个类别所有的目标框进行排序，（这里默认之前预测的分类概率最大的类别为目标所属类别），然后从大到小依次选择一个目标框和其他剩余目标框计算IoU值，如果IoU值大于设定的阈值如0.5，就代表重叠，此时舍去得分小的目标框，否则就保留，然后依次比较之后，就能实现对重叠目标的去重处理。</p>
<p>论文里的实验结果：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120151656814.png" alt="image-20211120151656814"></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://zhuanlan.zhihu.com/p/31426458">一文读懂Faster RCNN - 知乎 (zhihu.com)</a></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文笔记</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 | GAN，什么是生成对抗网络</title>
    <url>/posts/6a054795.html</url>
    <content><![CDATA[<h1 id="GAN学习笔记"><a href="#GAN学习笔记" class="headerlink" title="GAN学习笔记"></a>GAN学习笔记</h1><h2 id="1-GAN原理"><a href="#1-GAN原理" class="headerlink" title="1. GAN原理"></a>1. GAN原理</h2><p>论文链接：<a href="https://arxiv.org/abs/1406.2661">Generative Adversarial Networks</a></p>
<blockquote>
<p>生成式对抗网络(GAN, Generative Adversarial Networks)是一种深度学习模型，是近年来复杂分布上无监督学习最具前景的方法之一。模型通过框架中（至少）两个模块：生成模型（Generative Model）和判别模型（Discriminative Model）的互相博弈学习产生相当好的输出。原始 GAN 理论中，并不要求 G 和 D 都是神经网络，只需要是能拟合相应生成和判别的函数即可。但实用中一般均使用深度神经网络作为 G 和 D 。一个优秀的GAN应用需要有良好的训练方法，否则可能由于神经网络模型的自由性而导致输出不理想。<br>Ian J. Goodfellow等人于2014年10月在<a href="https://arxiv.org/abs/1406.2661">Generative Adversarial Networks</a>中提出了一个通过对抗过程估计生成模型的新框架。框架中同时训练两个模型：捕获数据分布的生成模型G，和估计样本来自训练数据的概率的判别模型D。G的训练程序是将D错误的概率最大化。这个框架对应一个最大值集下限的双方对抗游戏。可以证明在任意函数G和D的空间中，存在唯一的解决方案，使得G重现训练数据分布，而D=0.5。在G和D由多层感知器定义的情况下，整个系统可以用反向传播进行训练。在训练或生成样本期间，不需要任何马尔科夫链或展开的近似推理网络。实验通过对生成的样品的定性和定量评估证明了本框架的潜力。<br>  —- 摘自<a href="https://baike.baidu.com/item/Gan/22181905?fr=aladdin">百度百科</a></p>
</blockquote>
<p>GAN是由两部分组成的，第一部分是生成，第二部分是对抗。简单来说，就是有一个生成网络G和一个判别网络D，通过训练让两个网络相互竞争，生成网络G接受一个随机噪声z来生成假的数据G(z)，对抗网络D通过判别器去判别真伪概率，最后希望生成器G生成的数据能够以假乱真。在最理想的状态下，D(G(z)) = 0.5。</p>
<p>以上原理的数学公式为：</p>
<p>$$ min_{G}max_{D}V(D,G) = \mathbb{E} _ {x \sim p_{data}(x)} [\log D(x)] + \mathbb{E} _ {z \sim p_{z}(z) [\log (1-D(G(z)))]} $$</p>
<p>式子中，x表示真实数据，z表示噪声，G(z)表示G网络根据z生成的数据，D(x)表示D网络判断真实数据是否为真的概率，因此D(x)接近1越好。而D(G(z))代表D网络判断G网络生成的虚假数据是真实的概率。<br>因此，对于D网络(辨别器)：</p>
<ul>
<li>如果x来自$P_{data}$，那么D(x)要越大越好，可以用$\log(D(x)) \uparrow$表示。</li>
<li>如果x来自于$P_{generator}$，那么D(G(z))越小越好，进而表示为$\log[1−D(G(z))] \uparrow$。</li>
<li>因此需要最大化$max_D$<br>对于G网络(生成器)：</li>
<li>$D(G(z))$越大越好，进而表示为log[1−D(G(z))]↓</li>
<li>因此需要最小化$min_{G}$。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210223180633.png"></p>
<p>第一步我们训练D，D是希望V(D,G)越大越好，所以是加上梯度(ascending)。第二步训练G时，V(D,G)越小越好，所以是减去梯度(descending)。整个训练过程交替进行。</p>
<h2 id="2-GAN实例"><a href="#2-GAN实例" class="headerlink" title="2. GAN实例"></a>2. GAN实例</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn,optim</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> tfs</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">transforms = tfs.Compose([</span><br><span class="line">    tfs.Resize((<span class="number">32</span>,<span class="number">32</span>)),</span><br><span class="line">    tfs.ToTensor(),</span><br><span class="line">    <span class="comment">#tfs.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">flat_img = <span class="number">32</span>*<span class="number">32</span>*<span class="number">3</span></span><br><span class="line">noise_dim = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&#x27;1.jpg&#x27;</span>)</span><br><span class="line">real_img = transforms(img)</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">2</span>)</span><br><span class="line">fake_img = torch.rand(<span class="number">1</span>,noise_dim)</span><br><span class="line"></span><br><span class="line">plt.imshow(np.transpose(real_img.numpy(),(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br><span class="line"><span class="comment">#print(real_img)</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210224172221.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.linear = nn.Sequential(</span><br><span class="line">            nn.Linear(flat_img, <span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid() <span class="comment">#sigmoid常用于二分类问题</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        img = img.view(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        out = self.linear(img)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.linear = nn.Sequential(</span><br><span class="line">            nn.Linear(noise_dim, <span class="number">1024</span>),</span><br><span class="line">            nn.LeakyReLU(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.LeakyReLU(),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, flat_img)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, latent_space</span>):</span></span><br><span class="line">        latent_space = latent_space.view(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        out = self.linear(latent_space)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device = <span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line"></span><br><span class="line">discr = Discriminator().to(device)</span><br><span class="line">gen = Generator().to(device)</span><br><span class="line"></span><br><span class="line">opt_d = optim.SGD(discr.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">opt_g = optim.SGD(gen.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">criterion = nn.BCELoss()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">epochs = <span class="number">200</span></span><br><span class="line">discr_e = <span class="number">4</span></span><br><span class="line">gen_e = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#whole model training starts here</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line"></span><br><span class="line">    <span class="comment">#discriminator training</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(discr_e):</span><br><span class="line">        out_d1 = discr(real_img.to(device))</span><br><span class="line">        <span class="comment">#loss for real image</span></span><br><span class="line">        loss_d1 = criterion(out_d1, torch.ones((<span class="number">1</span>, <span class="number">1</span>)).to(device))</span><br><span class="line"></span><br><span class="line">        out_d2 = gen(fake_img.to(device)).detach()</span><br><span class="line">        <span class="comment">#loss for fake image</span></span><br><span class="line">        loss_d2 = criterion(discr(out_d2.to(device)), torch.zeros((<span class="number">1</span>, <span class="number">1</span>)).to(device))</span><br><span class="line"></span><br><span class="line">        opt_d.zero_grad()</span><br><span class="line">        loss_d = loss_d1+loss_d2</span><br><span class="line">        loss_d.backward()</span><br><span class="line">        opt_d.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#generator training</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(gen_e):</span><br><span class="line">        out_g = gen(fake_img.to(device))</span><br><span class="line">        <span class="comment">#Binary cross entropy loss</span></span><br><span class="line">        loss_g = criterion(discr(out_g.to(device)), torch.ones(<span class="number">1</span>, <span class="number">1</span>).to(device))</span><br><span class="line">        <span class="comment">#Loss function in the GAN paper</span></span><br><span class="line">        <span class="comment">#[log(1 - D(G(z)))]</span></span><br><span class="line">        <span class="comment">#loss_g = torch.log(torch.ones(1, 1).to(device) - (discr(out_g.to(device))))</span></span><br><span class="line">        </span><br><span class="line">        opt_g.zero_grad()</span><br><span class="line">        loss_g.backward()</span><br><span class="line">        opt_g.step()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (epoch+<span class="number">1</span>)%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch[&#123;&#125;/&#123;&#125;],d_loss:&#123;:.6f&#125;,g_loss:&#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>,epochs,loss_d.data.item(),loss_g.data.item()))</span><br><span class="line"></span><br><span class="line">out=gen(fake_img.to(device)).detach()</span><br><span class="line">out_score=discr(out_g.to(device))</span><br><span class="line">loss = criterion(out_score, torch.ones(<span class="number">1</span>, <span class="number">1</span>).to(device))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;score:&quot;</span>,out_score.item(),<span class="string">&quot;loss:&quot;</span>,loss.item())</span><br><span class="line"></span><br><span class="line">out=out.reshape((<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>)).cpu()</span><br><span class="line"></span><br><span class="line"><span class="comment">#print(out)</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;fake&#x27;</span>)</span><br><span class="line">plt.imshow(np.transpose(out.numpy(),(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;real&#x27;</span>)</span><br><span class="line">plt.imshow(np.transpose(real_img.numpy(),(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210224183510.png"></p>
<h2 id="3-DCGAN原理"><a href="#3-DCGAN原理" class="headerlink" title="3. DCGAN原理"></a>3. DCGAN原理</h2><p><a href="https://arxiv.org/pdf/1511.06434.pdf">https://arxiv.org/pdf/1511.06434.pdf</a></p>
<p>DCGAN的原理和GAN是一样的。只不过DCGANs体系结构有所改变：</p>
<ul>
<li>使用指定步长的卷积层代替池化层</li>
<li>在生成器和鉴别器中使用batch norm。</li>
<li>移除全连接层，以实现更深层次的体系结构，减少参数。</li>
<li>在生成器中使用ReLU激活，但输出使用Tanh。</li>
<li>在鉴别器中使用LeakyReLU激活</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210224183753.png"></p>
<p>DCGAN中提到了网络的训练细节：</p>
<ul>
<li>使用Adam算法更新参数，betas=(0.5, 0.999)；</li>
<li>batch size选为128；</li>
<li>权重使用正太分布，均值为0，标准差为0.02；</li>
<li>学习率0.0002。</li>
</ul>
<h2 id="4-DCGAN实例"><a href="#4-DCGAN实例" class="headerlink" title="4. DCGAN实例"></a>4. DCGAN实例</h2><p>生成动漫头像，数据集来自<a href="https://www.kaggle.com/soumikrakshit/anime-faces">https://www.kaggle.com/soumikrakshit/anime-faces</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> imageio</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> torch,torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, utils</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">avatar_img_path = <span class="string">&quot;E:/python/dataset/anime face/data&quot;</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trans = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">noise_dim = <span class="number">100</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line">beta1=<span class="number">0.5</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">#自定义数据集</span></span><br><span class="line"><span class="string">file_train=[]</span></span><br><span class="line"><span class="string">for image_name in tqdm(os.listdir(avatar_img_path)):</span></span><br><span class="line"><span class="string">    file_train.append(os.path.join(avatar_img_path,image_name))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">def default_loader(path):</span></span><br><span class="line"><span class="string">    img = imageio.imread(path)</span></span><br><span class="line"><span class="string">    img = img/255</span></span><br><span class="line"><span class="string">    img = trans(img)</span></span><br><span class="line"><span class="string">    return img</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">class trainset(Dataset):</span></span><br><span class="line"><span class="string">    def __init__(self, loader=default_loader):</span></span><br><span class="line"><span class="string">    #定义好 image 的路径</span></span><br><span class="line"><span class="string">        self.images = file_train</span></span><br><span class="line"><span class="string">        self.target = 0</span></span><br><span class="line"><span class="string">        self.loader = loader</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def __getitem__(self, index):</span></span><br><span class="line"><span class="string">        fn = self.images[index]</span></span><br><span class="line"><span class="string">        img = self.loader(fn)</span></span><br><span class="line"><span class="string">        target = self.target</span></span><br><span class="line"><span class="string">        return img,target</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    def __len__(self):</span></span><br><span class="line"><span class="string">        return len(self.images)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">img_dataset=torchvision.datasets.ImageFolder(<span class="string">&quot;E:/python/dataset/anime face&quot;</span>, transform=trans)</span><br><span class="line"><span class="comment">#img_dataset=trainset()</span></span><br><span class="line">img_dataloader=DataLoader(img_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#print(img_dataset)</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, z_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Generator,self).__init__()</span><br><span class="line">        self.z_dim = z_dim</span><br><span class="line">        self.generator = nn.Sequential(</span><br><span class="line">            nn.ConvTranspose2d(self.z_dim,<span class="number">512</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">0</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(num_features=<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">512</span>,<span class="number">256</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(num_features=<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">256</span>,<span class="number">128</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(num_features=<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">128</span>,<span class="number">64</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(num_features=<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">64</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line">        self.weight_init()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weight_init</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.generator.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.ConvTranspose2d):</span><br><span class="line">                nn.init.normal_(m.weight.data, <span class="number">0</span>, <span class="number">0.02</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">                nn.init.normal_(m.weight.data, <span class="number">0</span>, <span class="number">0.02</span>)</span><br><span class="line">                nn.init.constant_(m.bias.data, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out = self.generator(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        initialize</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        :param image_size: tuple (3, h, w)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(Discriminator,self).__init__()</span><br><span class="line">        self.discriminator = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">64</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(num_features=<span class="number">64</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>,<span class="number">128</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(num_features=<span class="number">128</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>,<span class="number">256</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(num_features=<span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>,<span class="number">512</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(num_features=<span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">0</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line">        self.weight_init()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weight_init</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.discriminator.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.ConvTranspose2d):</span><br><span class="line">                nn.init.normal_(m.weight.data, <span class="number">0</span>, <span class="number">0.02</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">                nn.init.normal_(m.weight.data, <span class="number">0</span>, <span class="number">0.02</span>)</span><br><span class="line">                nn.init.constant_(m.bias.data, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out = self.discriminator(x)</span><br><span class="line">        out = out.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">generator = Generator(noise_dim).to(device)</span><br><span class="line">discriminator = Discriminator().to(device)</span><br><span class="line"></span><br><span class="line">bce_loss = nn.BCELoss()</span><br><span class="line"><span class="comment">#optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(beta1, 0.999))</span></span><br><span class="line">optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=<span class="number">0.00005</span>, betas=(beta1, <span class="number">0.999</span>))</span><br><span class="line">optimizer_G = torch.optim.Adam(generator.parameters(), lr=<span class="number">0.0002</span>, betas=(beta1, <span class="number">0.999</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">epochs=<span class="number">20</span></span><br><span class="line"></span><br><span class="line">fixed_z=torch.randn(batch_size,noise_dim,<span class="number">1</span>,<span class="number">1</span>,device=device)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="keyword">for</span> step,(image,_) <span class="keyword">in</span> <span class="built_in">enumerate</span>(img_dataloader):</span><br><span class="line">        batch_size=image.size(<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#=====训练辨别器====</span></span><br><span class="line">        optimizer_D.zero_grad()</span><br><span class="line">        <span class="comment"># 计算判别器对真实样本给出为真的概率</span></span><br><span class="line">        d_out_real = discriminator(image.<span class="built_in">type</span>(torch.FloatTensor).to(device))</span><br><span class="line">        real_loss = bce_loss(d_out_real, torch.ones(size=(batch_size, <span class="number">1</span>)).to(device))</span><br><span class="line">        real_scores = d_out_real</span><br><span class="line">        <span class="comment">#real_loss.backward()</span></span><br><span class="line">        <span class="comment"># 计算判别器对假样本给出为真的概率</span></span><br><span class="line">        noise = torch.randn(batch_size,noise_dim,<span class="number">1</span>,<span class="number">1</span>,device=device)</span><br><span class="line">        fake_img = generator(noise)</span><br><span class="line">        d_out_fake = discriminator(fake_img.detach())</span><br><span class="line">        fake_loss = bce_loss(d_out_fake, torch.zeros(size=(batch_size, <span class="number">1</span>)).to(device))</span><br><span class="line">        fake_scores = d_out_fake</span><br><span class="line">        <span class="comment">#fake_loss.backward()</span></span><br><span class="line">        <span class="comment"># 更新判别器参数</span></span><br><span class="line">        d_loss = (real_loss + fake_loss)/<span class="number">2</span></span><br><span class="line">        d_loss.backward()</span><br><span class="line">        optimizer_D.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#=====训练生成器====</span></span><br><span class="line">        optimizer_G.zero_grad()</span><br><span class="line">        <span class="comment"># 计算判别器对伪造样本的输出的为真样本的概率值</span></span><br><span class="line">        d_out_fake = discriminator(fake_img)</span><br><span class="line">        <span class="comment"># 计算生成器伪造样本不被认为是真的损失</span></span><br><span class="line">        g_loss = bce_loss(d_out_fake, torch.ones(size=(batch_size, <span class="number">1</span>)).to(device))</span><br><span class="line">        <span class="comment"># 更新生成器</span></span><br><span class="line">        g_loss.backward()</span><br><span class="line">        optimizer_G.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># #################################################</span></span><br><span class="line">        <span class="comment"># 4：打印损失，保存图片</span></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            generator.<span class="built_in">eval</span>()</span><br><span class="line">            fixed_image = generator(fixed_z)</span><br><span class="line">            generator.train()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;[epoch: &#123;&#125;/&#123;&#125;], [iter: &#123;&#125;], [G loss: &#123;:.3f&#125;], [D loss: &#123;:.3f&#125;], [R Score: &#123;:.3f&#125;], [F Score: &#123;:.3f&#125;]&quot;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>,epochs,step, g_loss.item(), d_loss.item(),real_scores.data.mean(), fake_scores.data.mean()))</span><br><span class="line">            utils.save_image(fixed_image.detach(), <span class="built_in">str</span>(epoch+<span class="number">1</span>)+<span class="string">&quot;fake.jpg&quot;</span>,normalize=<span class="literal">True</span>)</span><br><span class="line">            utils.save_image(image,<span class="built_in">str</span>(epoch+<span class="number">1</span>)+<span class="string">&quot;real.jpg&quot;</span>,normalize=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>结果如下：<br>    [epoch: 1/20], [iter: 0], [G loss: 0.699], [D loss: 0.694], [R Score: 0.499], [F Score: 0.500]<br>    [epoch: 1/20], [iter: 200], [G loss: 0.803], [D loss: 0.715], [R Score: 0.512], [F Score: 0.529]<br>    [epoch: 1/20], [iter: 400], [G loss: 0.734], [D loss: 0.692], [R Score: 0.492], [F Score: 0.491]<br>    [epoch: 1/20], [iter: 600], [G loss: 0.730], [D loss: 0.693], [R Score: 0.496], [F Score: 0.496]<br>    [epoch: 1/20], [iter: 800], [G loss: 0.748], [D loss: 0.686], [R Score: 0.500], [F Score: 0.492]<br>    [epoch: 1/20], [iter: 1000], [G loss: 0.745], [D loss: 0.680], [R Score: 0.514], [F Score: 0.499]<br>    [epoch: 1/20], [iter: 1200], [G loss: 0.715], [D loss: 0.701], [R Score: 0.527], [F Score: 0.532]<br>    [epoch: 2/20], [iter: 0], [G loss: 0.762], [D loss: 0.679], [R Score: 0.524], [F Score: 0.508]<br>    [epoch: 2/20], [iter: 200], [G loss: 0.815], [D loss: 0.686], [R Score: 0.507], [F Score: 0.498]<br>    [epoch: 2/20], [iter: 400], [G loss: 0.836], [D loss: 0.665], [R Score: 0.509], [F Score: 0.479]<br>    [epoch: 2/20], [iter: 600], [G loss: 0.759], [D loss: 0.694], [R Score: 0.523], [F Score: 0.520]<br>    [epoch: 2/20], [iter: 800], [G loss: 0.973], [D loss: 0.646], [R Score: 0.551], [F Score: 0.499]<br>    [epoch: 2/20], [iter: 1000], [G loss: 0.926], [D loss: 0.671], [R Score: 0.531], [F Score: 0.495]<br>    [epoch: 2/20], [iter: 1200], [G loss: 1.100], [D loss: 0.582], [R Score: 0.497], [F Score: 0.362]</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210225180739.png"></p>
<p>第7个epoch：<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210226103604.jpg"></p>
<p>batch_size以及其他参数可自行调整。</p>
<h2 id="5-WGAN原理"><a href="#5-WGAN原理" class="headerlink" title="5. WGAN原理"></a>5. WGAN原理</h2><p>论文：<a href="https://arxiv.org/pdf/1701.07875.pdf">Wasserstein GAN</a><br><a href="https://arxiv.org/abs/1701.04862">Towards Principled Methods for Training Generative Adversarial Networks</a></p>
<p>总所周知，GAN的训练存在很多问题和挑战：</p>
<ul>
<li>训练困难，需要精心设计模型结构，协调G和D的训练程度</li>
<li>G和D的损失函数无法指示训练过程，缺乏一个有意义的指标和生成图片的质量相关联</li>
<li>模式崩坏（mode collapse），生成的图片虽然看起来像是真的，但是缺乏多样性</li>
</ul>
<p>WGAN相比较于传统的GAN，做了如下修改：</p>
<ul>
<li>D最后一层去掉sigmoid</li>
<li>G和D的loss不取log</li>
<li>每次更新D的参数后，将其绝对值截断到不超过一个固定常数c</li>
<li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210303105435.png"></p>
<p>G的损失函数原本为$\mathbb{E} _ {z \sim p _ z}[\log(1-D(G(z)))]$ ，其导致的结果是，如果D训练得太好，G将学习不到有效的梯度。但是，如果D训练得不够好，G也学习不到有效的梯度。<br>因此以上损失函数导致GAN训练特别不稳定，需要小心协调G和D的训练程度。</p>
<blockquote>
<p>WGAN参考资料：<br><a href="https://zhuanlan.zhihu.com/p/44169714">https://zhuanlan.zhihu.com/p/44169714</a><br><a href="https://www.cnblogs.com/Allen-rg/p/10305125.html">https://www.cnblogs.com/Allen-rg/p/10305125.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能 | 测评推荐好用的GPU算力平台</title>
    <url>/posts/80a64b4b.html</url>
    <content><![CDATA[<h1 id="一、免费GPU算力平台"><a href="#一、免费GPU算力平台" class="headerlink" title="一、免费GPU算力平台"></a>一、免费GPU算力平台</h1><h2 id="1-Google-Colab"><a href="#1-Google-Colab" class="headerlink" title="1. Google Colab"></a>1. Google Colab</h2><h3 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1 简介"></a>1.1 简介</h3><p>Colab全称为Colaboratory，是Google提供的免费Jupyter notebook运行环境，并且完全在云端运行。<br>优点：</p>
<ul>
<li>可以免费使用</li>
<li>不需要自己去装深度学习的环境</li>
<li>数据可以通过谷歌网盘拉取<br>缺点：</li>
<li>需要翻墙，因此网络不稳定，容易断开连接</li>
<li>前台连接训练，如果需要后台训练需要购买Colab Pro</li>
<li>免费版GPU的挂载有时长限制（12h），超时需要重新挂载，注意保存训练结果</li>
</ul>
<h3 id="1-2-使用指南"><a href="#1-2-使用指南" class="headerlink" title="1.2 使用指南"></a>1.2 使用指南</h3><h4 id="1-2-1-连接GPU"><a href="#1-2-1-连接GPU" class="headerlink" title="1.2.1 连接GPU"></a>1.2.1 连接GPU</h4><p>进入Colab，官网地址：<a href="https://colab.research.google.com/">欢迎使用 Colaboratory - Colaboratory (google.com)</a>，创建一个jupyter notebook：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220322172825.png"></p>
<p>编写代码，连接Colab的GPU：点击左上角“修改-笔记本设置-GPU”</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220322173142.png"></p>
<p>更换成功后，可在notebook输入<code>!nvidia-smi</code>以查看GPU信息：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220322173421.png"></p>
<h4 id="1-2-2-获取数据集"><a href="#1-2-2-获取数据集" class="headerlink" title="1.2.2 获取数据集"></a>1.2.2 获取数据集</h4><p>首先将数据集上传至谷歌网盘，地址：<a href="https://drive.google.com/drive/">Google 云端硬盘</a>，然后在notebook中绑定硬盘：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line"></span><br><span class="line">drive.mount(<span class="string">&#x27;/content/drive/&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>然后可以通过代码处理数据集或者数据集压缩包。</p>
<p>其他的使用和服务器是一样的，可以参考detectron2给的<a href="https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5">Colab</a>代码。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323112055.png"></p>
<h2 id="2-Kaggle"><a href="#2-Kaggle" class="headerlink" title="2. Kaggle"></a>2. Kaggle</h2><h3 id="2-1-简介"><a href="#2-1-简介" class="headerlink" title="2.1 简介"></a>2.1 简介</h3><p>Kaggle是由 Anthony Goldbloom 2010年在墨尔本创立的，主要为开发商和数据科学家提供举办机器学习竞赛、托管数据库、编写和分享代码的平台。每周有30-43小时的GPU使用时长。</p>
<p>官网:<a href="https://www.kaggle.com/">Kaggle: Your Home for Data Science</a></p>
<h3 id="2-2-使用指南"><a href="#2-2-使用指南" class="headerlink" title="2.2 使用指南"></a>2.2 使用指南</h3><p>数据集可以直接引用别人上传的数据集,也可以自己上传打包好的数据集。</p>
<p>点击工具栏中Data，在右方出现的界面中，点击New Dataset</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323113136.png"></p>
<p>之后建立Notebook:<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323113427.png"></p>
<p>可以选择运算资源:<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323113555.png"></p>
<h2 id="3-阿里天池GPU"><a href="#3-阿里天池GPU" class="headerlink" title="3. 阿里天池GPU"></a>3. 阿里天池GPU</h2><p>阿里云天池GPU平台提供在线 Jupyter notebook , 每次连接可以使用 8 小时的GPU算力，官网: <a href="https://tianchi.aliyun.com/">天池大数据众智平台-阿里云天池 (aliyun.com)</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323114733.png"></p>
<h2 id="4-华为NAIE"><a href="#4-华为NAIE" class="headerlink" title="4. 华为NAIE"></a>4. 华为NAIE</h2><p>网络人工智能引擎iMaster NAIE是自动驾驶网络的网络AI设计和开发基础平台，支持对上传到云端的各种网络数据，持续进行AI训练和知识提取，生成AI模型和网络知识成果。最开始注册可以免费使用三个月(不过现在好像只能免费使用几天).</p>
<p>官网:<a href="https://www.hwtelcloud.com/">网络人工智能引擎 (hwtelcloud.com)</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323115017.png"></p>
<p>值得注意的是,该平台需要使用NAIE自带的包来处理数据加载和保存.</p>
<h2 id="5-百度飞桨Ai-Studio"><a href="#5-百度飞桨Ai-Studio" class="headerlink" title="5. 百度飞桨Ai Studio"></a>5. 百度飞桨Ai Studio</h2><p>只能用PaddlePaddle框架,运行项目或者学习课程可以免费白嫖算力卡,官网:<a href="https://aistudio.baidu.com/aistudio/index">飞桨AI Studio - 人工智能学习实训社区 (baidu.com)</a><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323120131.png"></p>
<h1 id="二、付费GPU算力平台"><a href="#二、付费GPU算力平台" class="headerlink" title="二、付费GPU算力平台"></a>二、付费GPU算力平台</h1><h2 id="1-矩池云"><a href="#1-矩池云" class="headerlink" title="1. 矩池云"></a>1. 矩池云</h2><h3 id="1-1-简介-1"><a href="#1-1-简介-1" class="headerlink" title="1.1 简介"></a>1.1 简介</h3><p>矩池云是一个 GPU 云共享平台，可以按需租用到性价比极高的 GPU 云主机，并且注册并绑定公众号即可免费体验2小时GPU服务以及5元代金券，官网：<a href="https://matpool.com/">矩池云 - 专注于人工智能领域的云服务商 (matpool.com)</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323103316.png"></p>
<h3 id="1-2-使用指南-1"><a href="#1-2-使用指南-1" class="headerlink" title="1.2 使用指南"></a>1.2 使用指南</h3><p>首先将数据集打包上传至矩池云网盘，默认最大容量为5G，数据集太大的话可以购买容量。</p>
<p>然后可以在官网充值，学生或老师有优惠，充值后直接在GPU主机市场租用服务器，系统镜像丰富，选择自己需要的就行。<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323103526.png"></p>
<p>租用后即可在“我的租用”列表里看见服务器，启动后有三种连接方式：</p>
<ul>
<li>SSH</li>
<li>VNC</li>
<li>Jupyter Lab</li>
</ul>
<p>连接后就可以正常使用了，值得注意的是结束训练后记得保存环境，停止并释放资源。保存的环境会存储在网盘中，注意查看网盘容量。</p>
<h2 id="2-恒源云"><a href="#2-恒源云" class="headerlink" title="2. 恒源云"></a>2. 恒源云</h2><p>恒源云是一个专注 AI 行业的共享算力平台，旨在为用户提供高性价比的GPU云主机和存储服务，让用户拥有高效的云端编程和训练体验，不再担忧硬件迭代/环境搭建/数据存储等一系列问题。其价格相比较矩池云更便宜。官网：<a href="https://gpushare.com/">恒源云_GPUSHARE-恒源智享云</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323104206.png"></p>
<h2 id="3-AutoDL"><a href="#3-AutoDL" class="headerlink" title="3. AutoDL"></a>3. AutoDL</h2><p>AutoDL针对不同会员等级有不同的优惠，学生可以免费升级会员，性价比较高。官网：<a href="https://www.autodl.com/home">AutoDL-品质GPU租用平台-租GPU就上AutoDL</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323105140.png"></p>
<h2 id="4-智星云"><a href="#4-智星云" class="headerlink" title="4. 智星云"></a>4. 智星云</h2><p>智星云提供了弹性灵活的分时租用方式，分时租用在服务器启动时开始计费并每分钟扣费。例如RTX2080Ti分时租用价格为3元/小时，系统会按照3除以60的金额每分钟扣费0.05元并在1小时总共扣除3元。官网：<a href="http://gpu.ai-galaxy.cn/store">智星云 AI Galaxy | GPU云服务器 (ai-galaxy.cn)</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323104607.png"></p>
<h2 id="5-FEATURIZE"><a href="#5-FEATURIZE" class="headerlink" title="5. FEATURIZE"></a>5. FEATURIZE</h2><p>官网：<a href="https://featurize.cn/">Featurize</a><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323110835.png"></p>
<h2 id="6-滴滴云"><a href="#6-滴滴云" class="headerlink" title="6. 滴滴云"></a>6. 滴滴云</h2><p>目前提供P4，P40，P100，T4四种机型，官网：<a href="https://www.didiyun.com/production/gpu.html">GPU云服务器-滴滴出行的云计算服务 (didiyun.com)</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323111514.png"></p>
<h2 id="7-其他"><a href="#7-其他" class="headerlink" title="7. 其他"></a>7. 其他</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323111747.png"><br>图片来自机器之心</p>
<h1 id="三、云计算巨头"><a href="#三、云计算巨头" class="headerlink" title="三、云计算巨头"></a>三、云计算巨头</h1><h2 id="1-阿里云GPU服务器"><a href="#1-阿里云GPU服务器" class="headerlink" title="1. 阿里云GPU服务器"></a>1. 阿里云GPU服务器</h2><p>官网：<a href="https://www.aliyun.com/product/ecs/gpu">GPU云服务器_GPU云计算_异构计算_弹性计算-阿里云 (aliyun.com)</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323105342.png"></p>
<h2 id="2-腾讯云GPU服务器"><a href="#2-腾讯云GPU服务器" class="headerlink" title="2. 腾讯云GPU服务器"></a>2. 腾讯云GPU服务器</h2><p>官网：<a href="https://cloud.tencent.com/product/gpu">GPU云服务器_并行计算_弹性计算_人工智能_深度学习 (tencent.com)</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323105639.png"></p>
<h2 id="3-华为云GPU服务器"><a href="#3-华为云GPU服务器" class="headerlink" title="3. 华为云GPU服务器"></a>3. 华为云GPU服务器</h2><p>官网：<a href="https://www.huaweicloud.com/product/gpu.html">GPU加速云服务器_GPU云服务器_GPU云主机-华为云 (huaweicloud.com)</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220323105856.png"></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 | 论文笔记（Lifelong Zero-Shot Learning）</title>
    <url>/posts/f6289062.html</url>
    <content><![CDATA[<h1 id="Lifelong-Zero-Shot-Learning-论文翻译"><a href="#Lifelong-Zero-Shot-Learning-论文翻译" class="headerlink" title="Lifelong Zero-Shot Learning(论文翻译)"></a>Lifelong Zero-Shot Learning(论文翻译)</h1><p><strong>终身零样本学习</strong></p>
<p>作者：<strong>Kun Wei, Cheng Deng, Xu Yang</strong></p>
<p><a href="https://www.ijcai.org/Proceedings/2020/0077.pdf">https://www.ijcai.org/Proceedings/2020/0077.pdf</a></p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>零样本学习(Zero-Shot Learning, ZSL)解决了一些测试类别在训练集中从未出现的问题。现有的零样本学习方法是被设计用来从一个固定的训练集中学习的，不具备对多种训练集的知识进行捕获和积累的能力，因此不适合许多现实生活中的应用。在本文中，我们提出了一种新的零样本学习方法，称为终身零样本学习(Lifelong Zero-Shot Learning，LZSL)，其目的是在多种数据集的学习过程中积累知识，并对所有训练数据集的从未出现的类别进行识别。此外，我们提出了一种革新的方法用来实现终身零样本学习，有效地缓解了连续训练过程中的灾难性遗忘。针对包含不同语义嵌入的数据集，我们利用变分自动编码器实现统一的语义表示。然后，在微调整个模型时，我们利用选择性再训练策略来保留先前任务的训练权重，并避免负迁移。最后，利用知识蒸馏，将之前的训练阶段的知识转移到当前阶段。我们还设计了终身零样本学习评估协议和高要求的基准。在这些基准上的大量实验表明，当现有的零样本学习方法失败时，我们的方法有效地解决了零样本学习问题。</p>
<h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h2><p>在最近几年，零样本学习在计算机视觉和机器学习社区中获得了越来越多的关注。与在训练阶段要求所有类别都有足够的样本的传统的分类任务不同，零样本学习的目标是识别在训练阶段从未出现过的新的类别的样本。在流行的零样本学习方法中，学习模型只在单个数据集的可见类上进行训练，然后在同一数据集的不可见类上进行测试，该数据集的可见类和不可见类是不相交的。然而，在许多现实世界的应用中，识别系统需要具有从获得的训练数据中不断学习的能力，并以终身的方式改进系统。</p>
<p>为了满足这一要求，我们提出了一种更实用的零样本学习方法，称为终身零样本学习(Lifelong Zero-Shot Learning,LZSL)，它要求模型积累不同数据集的知识，并对所有面向数据集的未出现的类别进行识别。如图1所示，该模型在多个学习阶段进行训练，每个阶段都包含来自新数据集的图像和语义嵌入。这些数据集的语义嵌入是多样而复杂的，例如，这些数据集的属性列表是不同的。在完成所有训练阶段后，模型将对所有数据集上的可见的和不可见的测试图像进行评估。</p>
<p>主流的零样本学习方法旨在学习图像之间的映射和相应的语义嵌入。这些方法根据分类空间可分为三种类型，即视觉空间、语义空间和常见嵌入空间。除此之外，还有一些零样本学习方法通过训练生成模型来获取不可见的类别的特征。然后，利用可见类别的视觉特征和生成的不可见类别的视觉特征训练分类器。这些方法将零样本学习任务转换为监督学习任务。然而，这些方法不能有效地处理终身零样本学习问题，因为它们缺乏在没有排查的情况下从之前训练的任务中积累知识的机制。</p>
<p>为了解决上述问题，实现终身零样本学习，我们提出了一种将统一语义嵌入、选择性再训练和知识蒸馏策略无缝集成的新方法。选择交叉和分布对齐变分自编码器(Cross and Distribution Aligned VAE, CACD-VAE)作为基础模型，训练VAEs [Kingma and Welling, 2013]分别对视觉嵌入和语义嵌入的特征进行编码和解码，并使用学习到的潜在特征训练一个零样本学习分类器。为了使CACD-VAE具备终身学习的能力，我们首先利用训练后的VAEs在每个训练阶段获得统一的语义嵌入。利用统一的语义嵌入，分别学习和固定不同任务的潜在空间。为了保证视觉特征能够准确地投射到固定的潜在空间中，利用选择性再训练策略提高了不同任务的分类空间之间的相似性，也避免了在获取新任务知识过程中的负迁移。此外，知识蒸馏被用来将知识从之前的任务转移到当前任务。大量的实验表明，当其他最先进的零样本学习方法无效时，我们的方法可以有效地从之前学习的任务中积累知识并缓解灾难性遗忘。我们的方法的贡献总结如下:</p>
<ul>
<li><p>据我们所知，我们是第一个提出并解决终身零样本学习问题的。我们以一种新颖的方式设计了终身零样本学习的基准和评估协议。</p>
</li>
<li><p>针对不同数据集的异构语义嵌入的挑战，我们采用了可以固定相应任务的潜在空间的VAEs算法去获得统一的语义嵌入。</p>
</li>
<li><p>利用选择性再训练提高不同数据集的分类空间之间的相似性，并通过知识蒸馏损失来监督，规范了知识从之前的任务向当前任务转移的过程。</p>
</li>
<li><p>在提出的基准上的大量的实验结果证明了我们提出的方法的有效性，它显著优于最先进的零样本学习方法。</p>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201230132259.png" alt="1"></p>
<p>图1:终身零样本学习的概述。当新任务到来时，模型按顺序学习新任务，从所有面临的任务中积累知识。将先前任务中的知识转移到当前任务中，可以有效地对不同数据集的不可见的类别进行分类。</p>
<h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2. 相关工作"></a>2. 相关工作</h2><h3 id="2-1-零样本学习"><a href="#2-1-零样本学习" class="headerlink" title="2.1 零样本学习"></a>2.1 零样本学习</h3><p>零样本学习已经成为一个热门的研究课题，其目标是在没有任何标记的训练数据的情况下识别不可见的类别。此外，零样本学习是迁移学习的一个子问题，其重点是将知识从可见的类别转移到不可见的类别。在测试阶段，测试样本从视觉空间中获取，而我们只在语义空间中进行不可见的类别的语义嵌入。因此，零样本学习方法的主流方法是构建视觉空间与语义空间的连接。典型的方法是学习将视觉特征和语义特征映射到一个共同的嵌入空间的函数，在这个空间中视觉特征和语义特征的嵌入是匹配的。最近，生成对抗网络(GANs)被提出并成功引入到零样本学习问题中。生成零样本学习方法的任务是根据语义特征生成不可见的类别的视觉特征，将零样本学习转换为传统的监督分类任务。例如，f-CLSWGAN是利用conditional Wasserstein GANs提出的，它生成了差别性的不可见的视觉特征。基于f-CLSWGAN, Cycle-WGAN 重建正则化的目的是，保留转移过程中的类别的不同特征。</p>
<p>然而，上述所有方法都仅在单个数据集上进行训练，因为顺序学习各种数据集的能力有限。据我们所知，我们是第一个提出并解决终身零样本学习问题的。</p>
<h3 id="2-2-终身学习"><a href="#2-2-终身学习" class="headerlink" title="2.2 终身学习"></a>2.2 终身学习</h3><p>终身学习(Lifelong Learning)是一种学习模式，它要求模型拥有从一系列任务中进行学习，并能将从之前任务中获得的知识转移到后续任务中的能力。终身学习的关键挑战是灾难性遗忘，即当新任务到来时，被训练的模型会忘记之前任务中得到的知识。有很多终身学习的方法被提出，主要分为三部分，即，存储之前任务的训练样本，新任务到来时的正则化参数更新，以及使用额外的生成模型来重现之前任务的训练样本的记忆重现。</p>
<p>与传统的终身学习问题不同的是，在流行的终身学习分类问题中，传统的终身学习问题的训练和测试的类别是相同的，而在终身零样本学习中，这些是不相交的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201230132412.png" alt="2"></p>
<p>图2:我们提出的在$t^{th}$训练阶段上方法框架，该框架由两个VAEs和一个在$(t−1)^{th}$训练阶段训练过的视觉模态编码器组成。给定一张图像,视觉特征提取器可以捕获它的视觉特征$x^t$,映射到的潜在空间作为$\mu^t_v$和$\sum^t_v$。同时，相应的语义嵌入$c^t$映射到潜在的空间作为$\mu^t_a$和$\sum ^ t _ a$。 为了实现潜在的分布对齐，在训练阶段将潜在分布之间的Wasserstein距离($L _ {DA}$)最小化。然后，利用交叉对齐损失( $L _ {CA}$ )，通过交叉模态重构，来保证潜在分布的对齐。此外，我们利用知识蒸馏( $L _ {KD}$ )将之前任务中获得的知识转移到当前任务中。</p>
<h2 id="3-方法"><a href="#3-方法" class="headerlink" title="3. 方法"></a>3. 方法</h2><p>针对终身零样本学习问题，我们提出终身零样本学习方法，将终身学习和零样本学习无缝结合。我们的方法框架如图2所示。首先，我们利用VAEs实现不同数据集的统一语义嵌入;然后，我们采用选择性再训练策略逼近不同数据集的分类空间，避免负迁移。最后，我们采用知识蒸馏的方法，将先前任务中的知识转移到当前任务中。</p>
<h3 id="3-1-问题公式"><a href="#3-1-问题公式" class="headerlink" title="3.1 问题公式"></a>3.1 问题公式</h3><p>在第$t^{th}$个训练阶段，给出一个数据集$S^t = {(x^t, y^t, c^t)|x^t \in X^t, y^t \in Y^t_s, c^t \in C^t }$， 其由一个预训练卷积神经网络(CNN)提取的图像特征$x^t$、可见的类别$Y^t_s$的标签$y^t$和对应类别的语义嵌入$c^t$组成。此外，还有一个可获得的数据集$U^t= {(u^t, c^t_u) | u^t \in Y^t_u, c^t_u \in C^t }$，该数据集包含集合$Y^t_u$中的不可见的类别的标签$u^t$和不可见的类别的语义嵌入$c^t_u$。对于最现实和最具挑战性的广义零学习(Generalized Zero-Learning, GZSL)，其目标是学习一个分类器$f^t_{GZSL}: X^t \rightarrow Y^t_s\cup Y^t_u$。然而，我们的方法主要集中在通过顺序训练不同的数据集来学习一个生成模型，然后针对不同的数据集构造几个分类器。</p>
<h3 id="3-2-背景-交叉分布对齐变分自编码器-CACD-VAE"><a href="#3-2-背景-交叉分布对齐变分自编码器-CACD-VAE" class="headerlink" title="3.2 背景: 交叉分布对齐变分自编码器(CACD-VAE)"></a>3.2 背景: 交叉分布对齐变分自编码器(CACD-VAE)</h3><p>本文首先介绍了一种最先进的零样本学习方法–交叉分布对齐变分自编码器 (CADA-VAE)，它是我们方法的基本模型。它的目标是搜索一个共同的分类空间，其中嵌入的语义特征和视觉特征是一致的。该模型包含两个VAEs，一个用于语义特征，另一个用于视觉特征，每个都包含一个编码器和一个解码器。每个VAE的目标函数是给定样本的边际似然的变分下界，它可以表述为:</p>
<p>$$ L = \mathbb{E} _ {q_{\phi} (z|x)}\left[\log p_{\phi} (x|z)\right] - \lambda D_{KL}(q_{\phi} (z|x)||p_{\theta} (z)),  (1) $$</p>
<p>其中，第一项为重构损失，第二项为解开的<code>Kullback-Leibler散度</code>，对推理模型$q(z|x)$和$p(z)$进行规则化。此外，$\lambda$被用来加权KL-散度。编码器预测$\mu$和$\sum$，所以有$q_{\phi}(z | x) = N(\mu, \sum)$，并且通过应用重新参数化技巧获取一个潜在的向量$z$。编码器被用于将特征投影到公共空间，并且解码器用于重建原始数据。<br>整个模型的VAE损失是两个VAE基本损失的总和:</p>
<p>$$ L_{VAE} = L_{VAE}^a + L_{VAE}^v,  (2) $$</p>
<p>其中$L_{VAE}^a$和$L_{VAE}^v$分别表示语义模态和视觉模态的VAE损失。此外，针对语义空间和视觉空间的嵌入在公共空间中的匹配问题，该模型对潜在分布进行了精确对齐，需要一个交叉重建准则来保证。因此，我们设计并应用了交叉对齐损失(CA)和分布对齐损失(DA)。</p>
<p>交叉对齐损失使来自另一个模态的重构特征与原始模态特征相似。交叉对齐损失为:</p>
<p>$$ L_{CA} = \left| c-D_a(E_v(x)) \right| + \left|x-D_v(E_a(x))\right|,  (3) $$</p>
<p>其中，$c$、$D_a$和$E_a$是语义模态的特征、解码器和编码器，$x$、$D_v$和$E_v$是视觉模态的特征、解码器和编码器。</p>
<p>利用分布对齐损失最小化语义模态的潜在高斯分布与视觉模态的之间的Wasserstein距离，使语义空间和视觉空间的隐性嵌入相匹配。<br>距离表示为:</p>
<p>$$ L_{DA} = (||\mu_a - \mu_v||_2^2 + ||\sum^{\frac{1}{2}}_a-\sum_a^{frac{1}{2}}||^2_Frobenius)^{frac{1}{2}} ,  (4) $$</p>
<p>其中$\mu_a$和$\sum_a$通过编码器$E_a$预测,而$µ_v$和$\sum_v$通过编码器$E_v$预测。<br>目标函数可以表示为:</p>
<p>$$ L_{CACD - VAE} = L_{VAE} + \gamma L_{CA} + \delta L_{DA}, (5)  $$</p>
<p>其中，$\gamma$ 和 $\delta$ 是交叉对齐和分布对齐损失的超参数，用于权衡这些损失。</p>
<h3 id="3-3-统一的语义嵌入"><a href="#3-3-统一的语义嵌入" class="headerlink" title="3.3 统一的语义嵌入"></a>3.3 统一的语义嵌入</h3><p>由于不同数据集的属性数量和种类不同，首先需要解决的挑战是不同数据集的语义嵌入是多种多样和复杂的。为了解决这一问题，我们尝试寻找不同数据集的统一语义嵌入。在训练$t^{th}$任务之后,语义嵌入$c^t$被预测为通过$E^t_a$映射的$\mu^t_a$和$\sum^t_a$。隐向量z是采用再参数化的技巧生成的,其过程是从点数据生成各种隐向量的过程。生成的隐向量可以作为最终分类器的训练数据，其中包含了对应类的判别信息。在此基础上,我们替换原始语义嵌入$c^t$和$\mu^t_a$,$\sum_a^t$,从一个点数据到两个点数据,数据可被视为更具代表性的语义映射。在训练完所有任务后，我们可以利用这些新的语义嵌入再现所有数据集的隐向量，并训练更强健的分类器。</p>
<h3 id="3-4-选择性再训练"><a href="#3-4-选择性再训练" class="headerlink" title="3.4 选择性再训练"></a>3.4 选择性再训练</h3><p>对于这项新任务，一种自然的方法是对整个模型进行微调。然而，对整个模型进行微调会改变先前任务的权重，导致神经网络的灾难性遗忘。因此，我们采用选择性再训练策略对整个模型进行微调。当获得统一的语义嵌入时，不同数据集的分类空间是固定的，这也是之前任务的潜在空间。因此,模型是从视觉空间到分类空间的投影,是视觉模态的编码器$E_v^t$。我们表示$W^t$作为$E^t_v$和$W^t_l$的参数，被表示为l层的参数，而l层的数量是L。当一个新的任务到达时，我们首先冻结参数$W^{t - 1}_l$，并对模型进行微调，以获得$L - 1$层之间输出单元$o_t$和隐藏单元的连接。然后，我们可以选择在训练过程中受影响的所有单位和权重，并保持与输出单位无关的部分不变。选择操作可以看作是对模型进行初始化，保证优化的方向是保护前一个任务的分类空间。最后，我们只对选定的权值进行微调，记为$W_S^t$。算法1描述了选择性再训练的过程。</p>
<table>
<thead>
<tr>
<th><strong>算法1</strong> 选择性再训练的过程</th>
</tr>
</thead>
<tbody><tr>
<td>输入：数据集$S^t$，之前的参数$W^{t-1}$</td>
</tr>
<tr>
<td>输出：选择参数$W_s^t$</td>
</tr>
<tr>
<td>1: 冻结参数$W^{t-1}_L$，$S^t={o_t}$</td>
</tr>
<tr>
<td>2: 微调网络</td>
</tr>
<tr>
<td>3: $\text{for l = L,…,l do}$</td>
</tr>
<tr>
<td>4: 添加神经元$i$到$S^t$，如果存在一些神经元$j \in S$，且$W_{l,ij}^{t-1}≠0$</td>
</tr>
<tr>
<td>5: $\text{end for}$</td>
</tr>
<tr>
<td>6: 微调选择的参数$W^t_S$</td>
</tr>
</tbody></table>
<h3 id="3-5-知识蒸馏"><a href="#3-5-知识蒸馏" class="headerlink" title="3.5 知识蒸馏"></a>3.5 知识蒸馏</h3><p>通过选择性再训练，选择性神经元发生变化并且其他神经元被冻结，但不能保证整个模型的优化方向，即激励模型保持之前任务的知识。为了将知识从之前的任务中转移到当前任务中，我们采用了知识蒸馏策略。当$t^{th}$任务到达时，我们希望在相同输入$x^t$的情况下，$E^t_v$的输出与$E^{t−1}_v$的输出相似，这样可以保证$t^{th}$任务和$(t-1)^{th}$任务的分类空间近似。在顺序训练所有数据集后,当$E_v^t$输入相同的图像特征$x^t$时，最后的$e_v$有能力预测相似的$\mu^t_v$和$\sum^t_v$。蒸馏损失记为:</p>
<p>$$ L_{KD} = ||\mu_v^t - \widehat{\mu _v^t}||_1 + ||\sum_v^t - \widehat{\sum_v^t}||_1 ,  (6) $$</p>
<p>其中$\mu_v^t$和$\sum_v^t$通过$E^t_v$预测，而$\widehat{\mu_v^t}$和$\widehat{\sum_v^t}$通过$E^{t-1}_v$。</p>
<p>当$t&gt;1$时，目标函数表示为：</p>
<p>$$L = L_{CACD-VAE} +\beta L_{KD},  (7) $$</p>
<p>其中$\beta$为加权知识蒸馏损失的超参数，设为1。</p>
<h3 id="3-6-训练和推理"><a href="#3-6-训练和推理" class="headerlink" title="3.6 训练和推理"></a>3.6 训练和推理</h3><p>在训练中，我们对数据集进行顺序训练，并保存所有类别的统一语义嵌入。<br>在VAEs的训练阶段结束后，我们利用保存的语义嵌入再现所有类的隐向量。隐向量的生成过程对每个可见类别重复$n_s$次，对每个不可见类别重复$n_u$次。$n_s$和$n_u$分别设置为200和400。这些隐向量包含了这些类别的判别信息。利用不同数据集的隐向量分别训练<code>softmax分类器</code>。</p>
<p>在测试阶段，通过视觉模态$E_v$编码器将被测试可见类和不可见类的视觉特征投影为隐向量。然后将测试特征输入到训练好的分类器，得到不同数据集的分类结果。</p>
<table>
<thead>
<tr>
<th>数据集</th>
<th>语义维度</th>
<th>图像</th>
<th>可见类</th>
<th>不可见类</th>
</tr>
</thead>
<tbody><tr>
<td>APY</td>
<td>64</td>
<td>15339</td>
<td>20</td>
<td>12</td>
</tr>
<tr>
<td>AWA1</td>
<td>85</td>
<td>30475</td>
<td>40</td>
<td>10</td>
</tr>
<tr>
<td>CUB</td>
<td>312</td>
<td>11788</td>
<td>150</td>
<td>50</td>
</tr>
<tr>
<td>SUN</td>
<td>102</td>
<td>14340</td>
<td>645</td>
<td>72</td>
</tr>
</tbody></table>
<p>表1：实验使用的数据集及其统计信息。</p>
<h2 id="4-实验"><a href="#4-实验" class="headerlink" title="4. 实验"></a>4. 实验</h2><p>在本节中，我们将详细介绍所涉及的数据集、评估指标和实现细节。然后，我们将呈现几个最先进的竞争对手以及我们的方法的实验结果。最后，消融研究将证明我们所提出方法的有效性。</p>
<h3 id="4-1-基准和评估标准"><a href="#4-1-基准和评估标准" class="headerlink" title="4.1 基准和评估标准"></a>4.1 基准和评估标准</h3><p>我们在四个数据集上评估我们的方法: <code>Attribute Pascal</code>和<code>Yahoo数据集(aPY)</code>，<code>Animals with Attributes 1 (AW A1)</code>，<code>Caltech-UCSD-Birds 200-2011数据集(CUB)</code>和<code>SUN Attribute数据集(SUN)</code>。数据集统计如表1所示。对于所有数据集，我们使用预先训练的101层的<code>ResNet</code>提取2048维视觉特征。训练数据集的顺序为<code>aPY</code>, <code>AWA1</code>, <code>CUB</code>和<code>SUN</code>，都是按字母顺序排列的。</p>
<p>遵循广义零样本学习方法，我们对终身零样本学习采用相同的评价指标:</p>
<ul>
<li><p>u：是对每类带有预测标签集的不可见类别的测试图像进行分类的平均准确率，用于衡量识别不可见类的能力。</p>
</li>
<li><p>s：是对每类带有预测标签集的可见类的测试图像进行分类的平均准确率，用于衡量识别增量可见类的能力。</p>
</li>
<li><p>H：u和s的调和均值，公式为：$H=\frac{2×u×s}{u+s}$。</p>
</li>
</ul>
<p>我们任务中最重要的指标是，H平衡u和s指标之间的性能。对所有数据集进行训练后，对三个度量的所有结果进行测量。</p>
<h3 id="4-2-实施细则"><a href="#4-2-实施细则" class="headerlink" title="4.2 实施细则"></a>4.2 实施细则</h3><p>所有的编码器和解码器都是多层感知机，有一个隐藏层。我们使用了1560个隐藏单元作为图像特征编码器，1660个作为解码器。编码器和解码器的属性分别有1450个和660个隐藏单元。$\delta$从第6个epoch到第22个epoch以每轮0.54的速率增加，而$\gamma$从第21个epoch到第75个epoch以每个epoch按0.044的速率增加。KL散度的权重$\lambda$以每个epoch按照0.0026的速率增加，直到第90个epoch。此外，我们使用L1距离作为重构误差，得到了比L2更好的结果。</p>
<p>对于每个数据集，epoch的数量设置为100，批处理大小(batch size)设置为50。VAEs学习率设置为0.00015，分类器学习率设置为0.001。另外，我们的方法是用<code>PyTorch</code>实现的，并通过<code>ADAM</code>优化器进行优化。</p>
<h3 id="4-3-与现存基准程序的比较"><a href="#4-3-与现存基准程序的比较" class="headerlink" title="4.3 与现存基准程序的比较"></a>4.3 与现存基准程序的比较</h3><p><strong>基线模型</strong>。由于之前没有关于终身零样本学习的研究，我们将结合了CACD-VAE与传统的终身学习方法的基线进行比较。<br>(a) 顺序微调(SFT): 当一个新任务按顺序到达时，模型被微调，该模型的参数从在前一个任务训练或微调的模型进行初始化。<br>(b) L2正则化(L2): 在每个任务t上，$W_t$初始化为$W_{t−1}$，在$W_t$和$W_{t−1}$之间持续进行L2正则化训练。<br>(C) L1正则化(L1): 在每个任务t上，$W_t$初始化为$W_{t−1}$，在$W_t$和$W_{t−1}$之间持续进行L1正则化训练。</p>
<p><strong>结果和分析</strong>。表2总结了在四个基准数据集上的所有的对比方法以及我们的方法在三个评价指标下的结果。对于GZSL指标上的零样本学习方法，H是评价零样本学习方法性能最重要的指标，它平衡了u和s指标的性能。</p>
<p>表2中的“Base”表示模型在没有任何终身策略的情况下按顺序训练，“Original”表示分别训练数据集的模型。显然，我们可以发现Base的结果获得了之前数据集的最差性能，当新任务到来时，这些数据集不具备积累之前数据集的知识的能力。此外，采用顺序微调策略的模型比不采用该策略的模型的结果更差，这表明了零样本学习中存在灾难性遗忘问题。</p>
<p>与其他基准相比，我们的方法在前三个数据集中获得了三个评价指标的最佳性能。在<code>aPY数据集</code>上，我们的模型的u达到了29.11%，s达到了43.29%和H达到了34.81%，其中u提升了2.69%，s提升了13.50%，并且H提升了6.80%。在<code>AWA1数据集</code>上，我们的模型的u达到了51.17%，s达到了63.66%和H达到了56.73%，其中u提升了1.53%,s提升了4.59%，并且H提升了3.14%。在<code>CUB数据集</code>上，我们的模型的u达到了38.82%,s达到了45.81%和H达到了42.03%，其中u提升了3.29%,s提升了11.07%，并且H提升了7.68%。尽管我们的方法没有在SUN数据集上获得最好的结果，但是与其他数据集的改进相比，结果只下降了很少，这是因为我们的方法更好地平衡了从之前任务积累知识的能力以及当前任务获取知识的能力。我们还计算了这些方法在四个数据集上的平均H值。Base、SFT、L1、L2以及我们方法的平均H值分别为10.2%、36.73%、38.03%、36.73%和42.48%，平均H值提高了4.45%。综上所述，我们的方法在之前任务和当前任务中获得了均衡的性能，并且明显优于基线程序。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201230134611.png" alt="3"></p>
<h3 id="4-4-消融研究"><a href="#4-4-消融研究" class="headerlink" title="4.4 消融研究"></a>4.4 消融研究</h3><p>我们进行了两组消融实验来研究我们方法的有效性。</p>
<p>表3显示了添加了不同模块的基本模型的结果。基本模型为使用了连续微调训练策略的CACD-VAE。在基础模型的基础上，加入知识蒸馏模块和选择性再训练模块，分别用“KD”和“SR”表示。如表3所示，知识蒸馏和选择性再训练都可以提高前三个数据集的性能。加入“KD”的改进表明知识蒸馏可以将前一个任务的知识转移到当前任务中，在一定程度上缓解了灾难性遗忘的不利影响。此外，添加“SR”的改进表明选择性再训练可以保留之前任务中受影响的权重，避免负迁移，因为没有被选择的神经元不会受到再训练过程的影响。当添加所有模块时，我们的方法表现得最好。</p>
<p>我们做了一个实验来讨论数字$n_s$和$n_u$重放的影响，其平均H结果如图3所示。<br>当$n_s$和$n_u$被设置为200和400时，可以获得最佳性能。显然，我们可以注意到一个现象：在平均H达到峰值性能之前，平均H随着$n_s$和$n_u$的增加而增加。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201230134705.png" alt="4"></p>
<p>图3:不同$n_s$和$n_u$超参数下的平均H结果。</p>
<h2 id="5-结论"><a href="#5-结论" class="headerlink" title="5. 结论"></a>5. 结论</h2><p>据我们所知，本文是第一个尝试介绍和解决终身零样本学习的。首先，我们采用VAEs方法获得统一的语义嵌入，从而弥补了不同数据集语义嵌入之间的差距。然后，利用选择性再训练策略，在很大程度上保留前一训练阶段构造的投影。最后，我们从之前的任务中提炼出知识，并转移到当前的训练阶段。实验结果表明，该方法在4个基准数据集上性能均明显优于以往的方法。</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文笔记</tag>
        <tag>小样本学习</tag>
      </tags>
  </entry>
  <entry>
    <title>小样本学习 | ProtoNet，基于度量的Few-Shot分类网络</title>
    <url>/posts/286eabe4.html</url>
    <content><![CDATA[<h1 id="Prototypical-Networks-for-Few-shot-Learning"><a href="#Prototypical-Networks-for-Few-shot-Learning" class="headerlink" title="Prototypical Networks for Few-shot Learning"></a>Prototypical Networks for Few-shot Learning</h1><blockquote>
<p>论文发表：Advances in neural information processing systems, 2017<br>论文链接：<a href="https://proceedings.neurips.cc/paper/6996-prototypical-networks-for-few-shot-learning">https://proceedings.neurips.cc/paper/6996-prototypical-networks-for-few-shot-learning</a></p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211202215720417.png" alt="image-20211202215720417"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@article&#123;snell2017prototypical,</span><br><span class="line">  title=&#123;Prototypical networks for few-shot learning&#125;,</span><br><span class="line">  author=&#123;Snell, Jake and Swersky, Kevin and Zemel, Richard&#125;,</span><br><span class="line">  journal=&#123;Advances in neural information processing systems&#125;,</span><br><span class="line">  volume=&#123;30&#125;,</span><br><span class="line">  year=&#123;2017&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="归纳总结"><a href="#归纳总结" class="headerlink" title="归纳总结"></a>归纳总结</h2><table>
<thead>
<tr>
<th>标签</th>
<th>目的</th>
<th>方法</th>
<th>总结</th>
</tr>
</thead>
<tbody><tr>
<td>#度量学习 #嵌入网络</td>
<td>解决小样本问题</td>
<td>学习一个低纬嵌入空间</td>
<td>将分类问题转换成度量问题</td>
</tr>
</tbody></table>
<h2 id="主要工作"><a href="#主要工作" class="headerlink" title="主要工作"></a>主要工作</h2><p>ProtoNet，即原型网络，其想法非常直接但有效，即对每张图像都先用神经网络得到一个特征表示，然后对支持集中每个类别的所有特征取一个平均，作为这个类别的类中心，最后比较查询集和各个类中心之间的距离，取最近的一个类别作为预测结果。</p>
<p>作者的思想是构建一个映射函数，可以将每一类映射到一个简单的原型特征点集中。因此作者使用神经网络学习了一个非线性映射，将输入映射到嵌入空间中，并且规定每一类的原型特征为每个嵌入空间的均值。之后就可以将分类任务看作是在嵌入空间中寻找距离最近的原型特征。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110071602172.png" alt="image-20211007160201702">定义样本为S，类别为k，原型特征为$c_k=\frac{1}{S_k}\sum_{(x_i,y_i)\in{S_k}}f_{\phi}(x_i)$，衡量距离的函数为d，那么对于输入样本，其在嵌入空间的分布为$p_\phi(y=k|x)=\frac{\exp(-d(f_\phi(x),c_k))}{\sum_{k^\prime}\exp(-d(f_\phi(x),c_{k^{\prime}}))}$，学习的过程就是最小化负对数损失$J(\phi)=-\log{p_\phi(y=k|x)}$。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110271603163.png" alt="image-20211027160339284"></p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>其实验结果如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211202220308120.png" alt="image-20211202220308120"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211202220326742.png" alt="image-20211202220326742"></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文笔记</tag>
        <tag>小样本学习</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测 | RetinaNet，经典单阶段Anchor-Based目标检测模型</title>
    <url>/posts/bb608df3.html</url>
    <content><![CDATA[<h1 id="Focal-Loss-for-Dense-Object-Detection"><a href="#Focal-Loss-for-Dense-Object-Detection" class="headerlink" title="Focal Loss for Dense Object Detection"></a>Focal Loss for Dense Object Detection</h1><blockquote>
<p>论文来源：IEEE Transactions on Pattern Analysis and Machine Intelligence 2020<br>论文链接：<a href="https://ieeexplore.ieee.org/document/8417976">Focal Loss for Dense Object Detection | IEEE Xplore</a><br>论文代码：<a href="https://github.com/facebookresearch/Detectron">https://github.com/facebookresearch/Detectron</a></p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211119213555220.png" alt="image-20211119213555220"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@inproceedings&#123;lin2017focal,</span><br><span class="line">  title=&#123;Focal loss for dense object detection&#125;,</span><br><span class="line">  author=&#123;Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll&#123;\&#x27;a&#125;r, Piotr&#125;,</span><br><span class="line">  booktitle=&#123;Proceedings of the IEEE international conference on computer vision&#125;,</span><br><span class="line">  pages=&#123;2980--2988&#125;,</span><br><span class="line">  year=&#123;2017&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="归纳总结"><a href="#归纳总结" class="headerlink" title="归纳总结"></a>归纳总结</h2><table>
<thead>
<tr>
<th>标签</th>
<th>目的</th>
<th>方法</th>
<th>总结</th>
</tr>
</thead>
<tbody><tr>
<td>#Anchor #单阶段</td>
<td>解决正负样本严重不均衡的问题</td>
<td>retinanet和focal loss</td>
<td>针对训练过程中的实际问题，修改损失函数以达到优化的目的</td>
</tr>
</tbody></table>
<h2 id="主要工作"><a href="#主要工作" class="headerlink" title="主要工作"></a>主要工作</h2><p>作者认为之前的单阶段检测算法精度不高的原因可能是前后景类别（正负样本）严重不均衡导致的。因此作者重新设计了一个损失：Focal Loss，其能降低可以较好分类的样本的损失权重，防止训练过程中大量的easy negatives给检测器带来的压制影响，并基于Focal Loss设计提出并训练了RetinaNet。</p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>RetinaNet的结构如下图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120135540595.png" alt="image-20211120135540595"></p>
<p>主要包括三个部分：</p>
<ul>
<li>Backbone：使用了ResNet+FPN，用于生成多尺度{p3~p7}卷积特征图</li>
<li>Anchor：p3-p7特征图的base_size设置为$[32^2,64^2,128^2,256^2,512^2]$，在每一层特征图针对denser scale coverage，设置{${2^0,2^{1/3},2^{2/3}}$}三种不同的anchor size，比例为{1:2,1:1,2:1}，即每个位置9种Anchor。</li>
<li>subnets：用于分类和回归，结构相同但参数不共享的小型FCN结构</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120135222791.png" alt="image-20211120135222791"></p>
<h3 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h3><p>作者提到基于R-CNN模式的两阶段算法在解决训练过程中的正负样本不均衡的方法是：</p>
<ul>
<li>两阶段级联：在proposal阶段过滤掉大量负样本</li>
<li>启发式采样：例如固定正负样本比例（例如1:3）或者在线难样本挖掘（Online Hard Example Mining，OHEM）</li>
</ul>
<p>Focal loss的做法是设置一个sacling factor，如下图的$(1-p_t)^{\gamma}$，其可以自动的对easy example进行降权，从而使模型更关注hard example。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120135146831.png" alt="image-20211120135146831"></p>
<p>首先，对于二分类任务，普通的交叉熵如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120132951497.png" alt="image-20211120132951497"></p>
<p>如果定义$p_t$：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120133459396.png" alt="image-20211120133459396"></p>
<p>那么交叉熵可以写成$CE(p,y)=CE(p_t)=-log(p_t)$</p>
<p>有一种常见的用于解决类别不均衡的方法是添加一个权重变量$\alpha \in [0,1]$：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120133655071.png" alt="image-20211120133655071"></p>
<p>Focal Loss的做法是添加了一个权重变量$(1-p_t)^{\gamma}$：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120133916235.png" alt="image-20211120133916235"></p>
<p>因此当$p_t$趋近于1时，可以较好分类的样本被降权；而$\gamma$可以用来调节权重比率。除此之外，还可以将$\alpha$和FL损失相结合：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120134227038.png" alt="image-20211120134227038"></p>
<p>除此之外还有其他的Focal Loss变种形式。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120141212266.png" alt="image-20211120141212266"></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文笔记</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测 | SSD，经典单阶段Anchor-Based目标检测模型</title>
    <url>/posts/8163bb15.html</url>
    <content><![CDATA[<h1 id="SSD-Single-Shot-MultiBox-Detector"><a href="#SSD-Single-Shot-MultiBox-Detector" class="headerlink" title="SSD: Single Shot MultiBox Detector"></a>SSD: Single Shot MultiBox Detector</h1><blockquote>
<p>论文发表：2016<br>论文链接：<a href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2">SSD: Single Shot MultiBox Detector | SpringerLink</a></p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220305111710.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@inproceedings&#123;liu2016ssd,</span><br><span class="line">  title=&#123;Ssd: Single shot multibox detector&#125;,</span><br><span class="line">  author=&#123;Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C&#125;,</span><br><span class="line">  booktitle=&#123;European conference on computer vision&#125;,</span><br><span class="line">  pages=&#123;21--37&#125;,</span><br><span class="line">  year=&#123;2016&#125;,</span><br><span class="line">  organization=&#123;Springer&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="归纳总结"><a href="#归纳总结" class="headerlink" title="归纳总结"></a>归纳总结</h2><table>
<thead>
<tr>
<th>标签</th>
<th>目的</th>
<th>方法</th>
<th>总结</th>
</tr>
</thead>
<tbody><tr>
<td>#Anchor #单阶段</td>
<td>实现多尺度以及卷积预测，进一步提升精度和速度</td>
<td>MultiBox，Anchor</td>
<td>经典单阶段算法</td>
</tr>
</tbody></table>
<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>SSD算法，其英文全名是Single Shot MultiBox Detector, SSD的优势在于消除了bounding box proposal和pixel or feature resampling，并使用了multi-scale，因此达到了比faster rcnn和yolo更高的检测精度和更快的检测速度。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220328121925.png"></p>
<p>图片来自<a href="https://zhuanlan.zhihu.com/p/33544892">目标检测|SSD原理与实现 - 知乎 (zhihu.com)</a></p>
<h2 id="2-SSD模型"><a href="#2-SSD模型" class="headerlink" title="2. SSD模型"></a>2. SSD模型</h2><p>SSD采用VGG16作为基础模型，然后在VGG16的基础上新增了卷积层来获得更多的特征图以用于检测，模型结构如下图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220305114612.png"></p>
<p>SSD和Yolo一样都是采用一个CNN网络来进行检测，但是却采用了多尺度的特征图，网络的核心点：</p>
<ul>
<li>使用小的卷积核预测类别和边界框偏移量</li>
<li>对多个（多尺度）特征图进行检测</li>
<li>设置不同比例的先验框，如下图</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220305115052.png"></p>
<p>SSD将背景也当做了一个特殊的类别，如果检测目标共有c个类别，SSD其实需要预测c+1个置信度值，其中第一个置信度指的是不含目标或者属于背景的评分。在预测过程中，置信度最高的那个类别就是边界框所属的类别，特别地，当第一个置信度值最高时，表示边界框中并不包含目标。第二部分就是边界框的location，包含4个值(cx,cy,w,h)，分别表示边界框的中心坐标以及宽高。但是真实预测值其实只是边界框相对于先验框的转换值。先验框位置用$d=(d^{cx},d^{cy},d^{w},d^{h})$表示，其对应边界框用$b=(b^{cx},b^{cy},b^{w},b^{h})$表示，那么边界框的预测值$l$其实是b相对于d的转换值：<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220328114611.png"></p>
<h2 id="3-模型训练"><a href="#3-模型训练" class="headerlink" title="3. 模型训练"></a>3. 模型训练</h2><h3 id="3-1-正负样本划分"><a href="#3-1-正负样本划分" class="headerlink" title="3.1 正负样本划分"></a>3.1 正负样本划分</h3><p>首先，对于图片中每个ground truth，找到与其IOU最大的先验框，该先验框与其匹配，这样，可以保证每个ground truth一定与某个先验框匹配。通常称与ground truth匹配的先验框为正样本，其次，通过判断先验框和ground truth之间的IoU值是否大于阈值（如0.5），大于则为正样本</p>
<h3 id="3-2-损失计算"><a href="#3-2-损失计算" class="headerlink" title="3.2 损失计算"></a>3.2 损失计算</h3><p>损失包含两个部分：定位损失和分类损失<br>$$L(x,c,l,g)=\frac{1}{N}(L_{conf}(x,c)+\alpha L_{loc}(x,l,g))$$<br>其中N代表所匹配的正负样本数量，<code>l</code>代表预测框，<code>g</code>代表真实框，和faster rcnn相似，回归的偏移量的值是边界框的中心坐标(cx,cy)和框的宽度w和高度h。<br>$$\hat{g}<em>{j}^{cx}=(g</em>{j}^{cx}-d_{i}^{cx})/d_{i}^{w}$$<br>$$\hat{g}<em>{j}^{cy}=(g</em>{j}^{cy}-d_{i}^{cy})/d_{i}^{h}$$<br>$$\hat{g}<em>{j}^{w}=\log(\frac{g</em>{j}^{w}}{d_{i}^{w}})$$<br>$$\hat{g}<em>{j}^{h}=\log(\frac{g</em>{j}^{h}}{d_{i}^{h}})$$<br>因此定位损失函数为：$L_{loc}(x,l,g)=\sum_{i \in Pos}^N \sum_{m\in {cx,cy,w,h}}x_{ij}^{k}smooth_{L1}(l_i^m-\hat{g}<em>j^m)$<br>分类损失是一个softmax损失：$L</em>{conf}(x,c)=-\sum_{i\in Pos}^{N}x_{ij}^p\log(\hat{c}<em>i^p)-\sum</em>{i\in Neg}log(\hat{c}_i^0)$<br>其中$\hat{c}_i^p=\frac{exp(c_i^p)}{\sum_p(exp(c_i^p))}$</p>
<h2 id="4-参考文献"><a href="#4-参考文献" class="headerlink" title="4. 参考文献"></a>4. 参考文献</h2><p><a href="https://zhuanlan.zhihu.com/p/33544892">目标检测|SSD原理与实现 - 知乎 (zhihu.com)</a></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文笔记</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 | Wasserstein距离</title>
    <url>/posts/ebe3a70b.html</url>
    <content><![CDATA[<h1 id="Wasserstein-距离"><a href="#Wasserstein-距离" class="headerlink" title="Wasserstein 距离"></a>Wasserstein 距离</h1><p>对于绝大多数的机器学习问题，尤其是预测问题和隐变量模型（<code>latent factor model</code>）中，学习到数据集背后所服从的分布往往是模型所要解决的最终问题。在变分推断（<code>variational inference</code>）等领域中，往往会先从一个简单的分布引入，比如高斯分布或者多项式分布等；希望由这个简单的分布模型能不断学习进而逼近最终想要的、符合数据背后规律的分布，注意这时候的分布往往可能在形状上与初始假设的分布有所差异。</p>
<h2 id="KL散度和JS散度"><a href="#KL散度和JS散度" class="headerlink" title="KL散度和JS散度"></a>KL散度和JS散度</h2><p>在学习Wasserstein距离，首先回顾在机器学习算法中，衡量两个分布相似程度的指标常常是KL散度（<code>Kullback-Leibler Divergence</code>）以及JS散度 （<code>Jensen-Shannon Divergence</code>）。</p>
<h3 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度"></a>KL散度</h3><p>KL散度描述的是，评价训练所得的概率分布p与目标分布q之间的距离，可以表示为：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210131104040.png" alt="image-20210131104033253"></p>
<p>机器学习的算法最终的目的是缩小 $D _ {KL}$ 的值，可以看到当 $p(x)==q(x)$ 的时候，KL散度处处为0，达到最优结果。 但同时必须注意的是，由于KL散度中，对数项中$p(x)$与$q(x)$相对位置的关系，决定了KL散度其实是非对称的，即 $D_{KL}(p||q) \neq D_{KL}(q||p)$ .从物理学参考系的角度可以直观感受出，如果要想评价两个物体（分布）的相似程度，相似程度的值（比如KL散度）应该不能因为选取的参考目标（目标分布）的不同而改变。</p>
<h3 id="JS散度"><a href="#JS散度" class="headerlink" title="JS散度"></a>JS散度</h3><p>既然KL散度不具备对称性，那么依然从参考系的角度出发，那我们直接把所有参考系下计算的距离平均即可（在本文环境下只有目标分布和预测分布两个参考系）。这样便是JS散度的思想，具体的定义为:</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210131104625.png" alt="image-20210131104625712"></p>
<p>因而JS散度便有了对称性，并且形式上更为平滑，更适合作为最后最大似然的函数，这点在生成对抗网络（GAN）的损失函数取得了不错的成绩。</p>
<h2 id="Wasserstein距离"><a href="#Wasserstein距离" class="headerlink" title="Wasserstein距离"></a>Wasserstein距离</h2><p>Wasserstein距离也叫做推土机距离（Earth Mover’s distance），这也是由于它的推导过程可以很形象的用挖土填土来解释，这也是因为该距离定义中由一个分布转变为另一个分布所需要的代价和挖土填土的过程十分相似。考虑两个离散的分布P和Q:</p>
<ul>
<li><p>P1 = 3, P2 = 2, P3 = 1, P4 = 4</p>
</li>
<li><p>Q1 = 1, Q2 = 2, Q3 = 4, Q4 = 3</p>
</li>
</ul>
<p>为了让两个分布相同，我们一个个变量地观察，</p>
<ul>
<li>为了让P1和Q1相同，我们需要P1把手头上的3分2到P2去，这样P1和Q1都等于1，此时P2=4，其他数保持不变，这个过程是不是非常像挖掉P1的土填到P2上</li>
<li>为了让P2和Q2相同，我们也要做类似的挖土填土工作，但注意，此时P2手头上由P1填的2，因此现在P2是4，但是Q2依然是2，因而P2也要挖2分土给P3，保持和Q2一样。</li>
<li>P3和Q3也是一样，但此时P3为3，Q3为4，因为我们只能先挖土再填土，因此要Q3挖1分土给Q4，这样P4和Q4也能够一样。</li>
</ul>
<p>每一步的代价计算公式为$\delta_{i+1} = \delta_{i} + P_{i} -Q_i$，第0步我们规定为0，故有</p>
<ul>
<li><p>$\delta_{0} = 0$</p>
</li>
<li><p>$\delta_{1} = 0+3-1 = 2$</p>
</li>
<li><p>$\delta_{2} = 2+2-2 = 2$</p>
</li>
<li><p>$\delta_{3} = 2+1-4 = -1$</p>
</li>
<li><p>$\delta_{4} = -1+4-3 = 0$</p>
<p>所以最终的总代价，也即Wasserstein距离则为$W=\sum_i |\delta_i|=5$</p>
</li>
</ul>
<p>该挖土填土的过程可以由下图表示:(图片来源：<a href="https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html#kullbackleibler-and-jensenshannon-divergence">From GAN to WGAN</a>)</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210131105502.jpeg" alt="img"></p>
<p>由离散情况理解了距离计算以后，针对一般的<strong>连续分布</strong>，Wasserstein距离则变成如下形式:</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210131105656.png" alt="image-20210131105656319"></p>
<p>其中<code>inf</code>指代最大下界，$S(p_r,p_g)$表示的是分布$p_r$和$p_g$中所有可能的联合分布，每一个联合分布$\gamma \in S(p_r,p_g)$都是之前提到的“土”，用于刻画连续空间中分布间转换的代价，更具体而言，$\gamma(x,y)$刻画从x点转移到y点从而让x，y服从相同分布所需要的“土”的百分比。因此$\gamma$的边缘分布可以表示为$\sum_x \gamma(x,y)=p_g(y),\sum_y \gamma(x,y)=p_r(x)$</p>
<p>当我们将x作为我们的起始点，y作为我们要逼近的终点时，挖土填土的总量即为$\gamma(x,y)$，也即上文离散情况下计算的代价$\delta$，而点与点之间的距离则为||x-y||，因而总代价为$\sum_{x,y} \gamma(x,y)||x-y||$,总代价最后可以使用EM等方法求得最小值。</p>
<h3 id="为什么Wasserstein距离优于KL和JS散度"><a href="#为什么Wasserstein距离优于KL和JS散度" class="headerlink" title="为什么Wasserstein距离优于KL和JS散度"></a>为什么Wasserstein距离优于KL和JS散度</h3><p>P,Q两个分布完全重合，此时这三种距离度量方式均为0。可以看出KL散度在两个分布完全没有任何交集的时候会得出无穷的结果，而JS散度则会有突然的阶跃，并且在0点出不可微，只有Wasserstein距离能够提供更为平滑的结果用于梯度下降法的参数更新。不过值得一提的是，目前主流的分布距离度量依然是KL散度，这是由于KL散度的计算方式简单，计算成本较Wasserstein低，但近年来Wasserstein距离的近似<code>Sinkhorn distance</code>以及其他加快距离计算方法的论文也在不断涌现.</p>
<blockquote>
<p>转自：<a href="https://zhuanlan.zhihu.com/p/84617531">https://zhuanlan.zhihu.com/p/84617531</a></p>
</blockquote>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>损失函数</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测 | YOLOv1，经典单阶段Anchor-Free目标检测模型</title>
    <url>/posts/d50da5ec.html</url>
    <content><![CDATA[<blockquote>
<p>PS:参考YOLO官网的配色和logo做的封面图，感觉还挺好看的，hhhh</p>
</blockquote>
<h1 id="You-Only-Look-Once-Unified-Real-Time-Object-Detection"><a href="#You-Only-Look-Once-Unified-Real-Time-Object-Detection" class="headerlink" title="You Only Look Once: Unified, Real-Time Object Detection"></a>You Only Look Once: Unified, Real-Time Object Detection</h1><blockquote>
<p>论文发表：CVPR 2016<br>论文链接：<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf">You Only Look Once: Unified, Real-Time Object Detection (cv-foundation.org)</a><br>论文官网：<a href="https://pjreddie.com/darknet/yolo/">YOLO: Real-Time Object Detection (pjreddie.com)</a></p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/1648433292(1).png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@inproceedings&#123;redmon2016you,</span><br><span class="line">  title=&#123;You only look once: Unified, real-time object detection&#125;,</span><br><span class="line">  author=&#123;Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali&#125;,</span><br><span class="line">  booktitle=&#123;Proceedings of the IEEE conference on computer vision and pattern recognition&#125;,</span><br><span class="line">  pages=&#123;779--788&#125;,</span><br><span class="line">  year=&#123;2016&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="1-归纳总结"><a href="#1-归纳总结" class="headerlink" title="1. 归纳总结"></a>1. 归纳总结</h2><table>
<thead>
<tr>
<th>标签</th>
<th>目的</th>
<th>方法</th>
<th>总结</th>
</tr>
</thead>
<tbody><tr>
<td>#Anchor-Free</td>
<td>解决两阶段算法检测慢的问题</td>
<td>将目标检测（cls和reg）都视为回归问题</td>
<td>经典单阶段算法</td>
</tr>
</tbody></table>
<h2 id="2-问题背景"><a href="#2-问题背景" class="headerlink" title="2. 问题背景"></a>2. 问题背景</h2><p>随着深度学习的大火，在YOLO提出那一年，主流的目标检测算法框架主要分为两类：</p>
<ul>
<li>两阶段算法：基于Region Proposal的RCNN系列算法，先生成Proposal，再分类回归</li>
<li>单阶段算法：直接预测不同目标的类别和位置<br>这两种算法各有优点，一般而言，两阶段算法准确度高，但速度慢；单阶段算法速度快，但准确度相对低。</li>
</ul>
<p>作者认为人可以一眼看到目标在哪，并且能立即知道是什么，并且对于很多实际场景而言，如自动驾驶，实时性和准确性都是非常重要的。</p>
<h2 id="3-主要工作"><a href="#3-主要工作" class="headerlink" title="3. 主要工作"></a>3. 主要工作</h2><p>针对上述问题，作者提出了经典的YOLO算法，它是一个统一的，端到端的单阶段目标检测算法。YOLO具体做法是，首先将输入图片缩放到448x448，然后送入CNN网络，最后使用NMS过滤网络预测结果得到检测的目标。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220328103035.png"></p>
<p>而在CNN网络里，它首先将图片划分为S×S大小的网格，然后每个单元格负责检测中心点落在该格子的目标，如下图，每个单元格会输出B个边界框（每个边界框输出5个预测值：x, y, w, h, confidence）以及边界框类别概率C，例如：作者在PASCAL VOC的检测实验里使用S=7，B=2，C=类别数量20，一共预测7×7×(2×5+20)个向量。同时这里的confidence代表边界框置信度，它的定义为: </p>
<p>$$Pr(object)\times IoU_{pred}^{truth}$$</p>
<p>其中边界框包含目标时，$Pr(object)=1$，否则为0。而C代表每个类别的置信度，即：</p>
<p>$$Pr(Class_i|Object)\times Pr(objec) \times IoU_{pred}^{truth}=Pr(class_i)\times IoU_{pred}^{truth}$$</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220328103753.png"></p>
<h3 id="3-1-模型结构"><a href="#3-1-模型结构" class="headerlink" title="3.1 模型结构"></a>3.1 模型结构</h3><p>YOLO采用卷积网络来提取特征，然后使用全连接层来得到预测值。网络结构参考GooLeNet模型，包含24个卷积层和2个全连接层。对于卷积层，主要使用1x1卷积来做channle reduction，然后紧跟3x3卷积。对于卷积层和全连接层，采用Leaky ReLU激活函数$max(x,0.1x)$，但是最后一层却采用线性激活函数。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220328103101.png"></p>
<h3 id="3-2-模型训练"><a href="#3-2-模型训练" class="headerlink" title="3.2 模型训练"></a>3.2 模型训练</h3><p>在训练之前，先在ImageNet上进行了预训练，其预训练的分类模型采用图8中前20个卷积层，然后添加一个average-pool层和全连接层。预训练之后，在预训练得到的20层卷积层之上加上随机初始化的4个卷积层和2个全连接层。由于检测任务一般需要更高清的图片，所以将网络的输入从224x224增加到了448x448。</p>
<h3 id="3-3-模型损失"><a href="#3-3-模型损失" class="headerlink" title="3.3 模型损失"></a>3.3 模型损失</h3><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220328110113.png"></p>
<p>Yolo算法将目标检测看成回归问题，所以采用的是均方差损失函数。但是对不同的部分采用了不同的权重值。首先区分定位误差和分类误差。对于定位误差，即边界框坐标预测误差，采用较大的权重 $\lambda_{coord}=5$ 。然后其区分不包含目标的边界框与含有目标的边界框的置信度，对于前者，采用较小的权重值 $\lambda_{noobj}=0.5$ 。其它权重值均设为1。然后采用均方误差，其同等对待大小不同的边界框，但是实际上较小的边界框的坐标误差应该要比较大的边界框要更敏感。为了保证这一点，将网络的边界框的宽与高预测改为对其平方根的预测，即预测值变为$(x,y,\sqrt{w},\sqrt{h})$。</p>
<p>损失函数中，第一项为边界框中心坐标的误差项，$\mathbb{1} _ {ij}^{obj}$ 是指第 i 个单元格存在目标，且该单元格中的第 j 个边界框负责预测该目标，第二项是边界框的高与宽的误差项。第三项是包含目标的边界框的置信度误差项。第四项是不包含目标的边界框的置信度误差项。最后一项是包含目标的单元格的分类误差项，$\mathbb{1} _ {i}^{obj}$值是指第 i 个单元格存在目标。</p>
<h2 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4. 实验结果"></a>4. 实验结果</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220328105647.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220328105758.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220328105711.png"></p>
<h2 id="5-参考文献"><a href="#5-参考文献" class="headerlink" title="5. 参考文献"></a>5. 参考文献</h2><p><a href="https://zhuanlan.zhihu.com/p/32525231">目标检测|YOLO原理与实现 - 知乎 (zhihu.com)</a></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文笔记</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 | 什么是知识图谱</title>
    <url>/posts/ba289ad3.html</url>
    <content><![CDATA[<h1 id="什么是知识图谱"><a href="#什么是知识图谱" class="headerlink" title="什么是知识图谱"></a>什么是知识图谱</h1><h2 id="1-来源"><a href="#1-来源" class="headerlink" title="1. 来源"></a>1. 来源</h2><p>2012年5月17日，<strong>Google</strong>正式提出了<strong>知识图谱</strong>（Knowledge Graph）的概念，其初衷是为了优化搜索引擎返回的结果，增强用户搜索质量及体验。</p>
<p>实际上，知识图谱并不是一个全新的概念，早在 2006 年就有文献提出了语义网（Semantic Network）的概念，呼吁推广、完善使用本体模型来形式化表达数据中的隐含语义，RDF（resource description framework，资源描述框架）模式和 OWL（Web ontology language，万维网本体语言）就是基于上述目的产生的。用电子科技大学徐增林教授的论文原文来说：</p>
<p>知识图谱技术的出现正是基于以上相关研究，是对语义网标准与技术的一次扬弃与升华。</p>
<p>目前，随着智能信息服务应用的不断发展，知识图谱已广泛应用于智能搜索，智能问答，个性化推荐等领域。</p>
<h2 id="2-定义"><a href="#2-定义" class="headerlink" title="2. 定义"></a>2. 定义</h2><p><strong>知识图谱</strong>，本质上，是一种揭示<strong>实体</strong>之间<strong>关系</strong>的语义网络。</p>
<p>看一张简单的知识图谱：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201223193032.jpg" alt="img"></p>
<p>如图所示，你可以看到，如果两个节点之间存在关系，他们就会被一条无向边连接在一起，那么这个节点，我们就称为<strong>实体</strong>（Entity），它们之间的这条边，我们就称为<strong>关系</strong>（Relationship）。</p>
<p>如果你看过网络综艺《奇葩说》第五季第17期：你是否支持全人类一秒知识共享，你也许会被辩手陈铭的辩论印象深刻。他在节目中区分了信息和知识两个概念：</p>
<p>信息是指外部的客观事实。举例：这里有一瓶水，它现在是7°。</p>
<p>知识是对外部客观规律的归纳和总结。举例：水在零度的时候会结冰。</p>
<p>“客观规律的归纳和总结” 似乎有些难以实现。Quora 上有另一种经典的解读，区分 “信息” 和 “知识” 。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201223193045.jpg" alt="img"></p>
<p>这样我们就很容易理解，在信息的基础上，建立实体之间的联系，就能行成 “知识”，或者称为叫事实（Fact）更为合适。换句话说，知识图谱是由一条条知识组成，每条知识表示为一个SPO<strong>三元组</strong>(Subject-Predicate-Object)。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201223193127.png" alt="img"></p>
<p>知识图谱实际上就是如此工作的。曾经知识图谱非常流行<strong>自顶向下</strong>(top-down)的构建方式。自顶向下指的是先为知识图谱定义好本体与数据模式，再将实体加入到知识库。该构建方式需要利用一些现有的结构化知识库作为其基础知识库，例如 Freebase 项目就是采用这种方式，它的绝大部分数据是从维基百科中得到的。</p>
<p>然而目前，大多数知识图谱都采用<strong>自底向上</strong>(bottom-up)的构建方式。自底向上指的是从一些开放链接数据（也就是 “信息”）中提取出实体，选择其中置信度较高的加入到知识库，再构建实体与实体之间的联系。</p>
<h2 id="3-数据类型和存储方式"><a href="#3-数据类型和存储方式" class="headerlink" title="3. 数据类型和存储方式"></a>3. 数据类型和存储方式</h2><p>知识图谱的原始数据类型一般来说有三类（也是互联网上的三类原始数据）：</p>
<ul>
<li><p>结构化数据（Structed Data）：如关系数据库</p>
</li>
<li><p>半结构化数据（Semi-Structed Data）：如XML、JSON、百科</p>
</li>
<li><p>非结构化数据（UnStructed Data）：如图片、音频、视频、文本</p>
</li>
</ul>
<p>如何存储上面这三类数据类型呢？一般有两种选择，一个是通过RDF（资源描述框架）这样的规范存储格式来进行存储，还有一种方法，就是使用图数据库来进行存储，常用的有Neo4j等。</p>
<h2 id="4-体系架构"><a href="#4-体系架构" class="headerlink" title="4. 体系架构"></a>4. 体系架构</h2><p>知识图谱的架构主要包括自身的<strong>逻辑结构</strong>以及<strong>体系架构</strong>。</p>
<p>知识图谱在<strong>逻辑结构</strong>上可分为<strong>模式层</strong>与<strong>数据层</strong>两个层次，<strong>数据层</strong>主要是由一系列的事实组成，而知识将以事实为单位进行存储。如果用（实体1，关系，实体2）、（实体、属性，属性值）这样的三元组来表达事实，可选择图数据库作为存储介质，例如开源的 Neo4j、Twitter 的 FlockDB、JanusGraph 等。<strong>模式层</strong>构建在数据层之上，主要是通过本体库来规范数据层的一系列事实表达。本体是结构化知识库的概念模板，通过本体库而形成的知识库不仅层次结构较强，并且冗余程度较小。</p>
<p>知识图谱的<strong>体系架构</strong>是指其构建模式的结构，如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201223193136.jpg" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201223193143.jpg" alt="img"></p>
<p>大规模知识库的构建与应用需要多种智能信息处理技术的支持。通过知识抽取技术，可以从一些公开的半结构化、非结构化的数据中提取出实体、关系、属性等知识要素。通过知识融合，可消除实体、关系、属性等指称项与事实对象之间的歧义，形成高质量的知识库。知识推理则是在已有的知识库基础上进一步挖掘隐含的知识，从而丰富、扩展知识库。分布式的知识表示形成的综合向量对知识库的构建、推理、融合以及应用均具有重要的意义。</p>
<h2 id="5-知识抽取"><a href="#5-知识抽取" class="headerlink" title="5. 知识抽取"></a>5. 知识抽取</h2><p>知识抽取主要是面向开放的链接数据，通过自动化的技术抽取出可用的知识单元，知识单元主要包括实体(概念的外延)、关系以及属性3个知识要素，并以此为基础，形成一系列高质量的事实表达，为上层模式层的构建奠定基础。知识抽取有三个主要工作：</p>
<ul>
<li><p><strong>实体抽取</strong>：在技术上，更多称为 NER（named entity recognition，命名实体识别），指的是从原始语料中自动识别出命名实体。由于实体是知识图谱中的最基本元素，其抽取的完整性、准确、召回率等将直接影响到知识库的质量。因此，实体抽取是知识抽取中最为基础与关键的一步；</p>
</li>
<li><p><strong>关系抽取</strong>：目标是解决实体间语义链接的问题，早期的关系抽取主要是通过人工构造语义规则以及模板的方法识别实体关系。随后，实体间的关系模型逐渐替代了人工预定义的语法与规则。</p>
</li>
<li><p><strong>属性抽取</strong>：属性抽取主要是针对实体而言的，通过属性可形成对实体的完整勾画。由于实体的属性可以看成是实体与属性值之间的一种名称性关系，因此可以将实体属性的抽取问题转换为关系抽取问题。</p>
</li>
</ul>
<h2 id="6-知识表示"><a href="#6-知识表示" class="headerlink" title="6. 知识表示"></a>6. 知识表示</h2><p>近年来，以深度学习为代表的表示学习技术取得了重要的进展，可以将实体的语义信息表示为稠密低维实值向量，进而在低维空间中高效计算实体、关系及其之间的复杂语义关联，对知识库的构建、推理、融合以及应用均具有重要的意义。</p>
<h2 id="7-知识融合"><a href="#7-知识融合" class="headerlink" title="7. 知识融合"></a>7. 知识融合</h2><p>由于知识图谱中的知识来源广泛，存在知识质量良莠不齐、来自不同数据源的知识重复、知识间的关联不够明确等问题，所以必须要进行知识的融合。知识融合是高层次的知识组织，使来自不同知识源的知识在同一框架规范下进行异构数据整合、消歧、加工、推理验证、更新等步骤，达到数据、信息、方法、经验以及人的思想的融合，形成高质量的知识库。知识融合包括两部分内容：<strong>实体链接</strong>，<strong>知识合并</strong>。</p>
<ul>
<li><p><strong>实体链接</strong>：是指对于从文本中抽取得到的实体对象，将其链接到知识库中对应的正确实体对象的操作。</p>
</li>
<li><p><strong>知识合并</strong>：常见的知识合并需求有两个，一个是合并外部知识库，另一个是合并关系数据库。</p>
</li>
</ul>
<h2 id="8-知识加工"><a href="#8-知识加工" class="headerlink" title="8. 知识加工"></a>8. 知识加工</h2><p>事实本身并不等于知识。要想最终获得结构化，网络化的知识体系，还需要经历知识加工的过程。<strong>知识加工</strong>主要包括三方面内容：<strong>本体构建</strong>、<strong>知识推理</strong>和<strong>质量评估</strong>。</p>
<h2 id="9-知识更新"><a href="#9-知识更新" class="headerlink" title="9. 知识更新"></a>9. 知识更新</h2><p>从逻辑上看，知识库的更新包括<strong>概念层的更新</strong>和<strong>数据层的更新</strong>。</p>
<ul>
<li><p><strong>概念层的更新</strong>是指新增数据后获得了新的概念，需要自动将新的概念添加到知识库的概念层中。</p>
</li>
<li><p><strong>数据层的更新</strong>主要是新增或更新实体、关系、属性值，对数据层进行更新需要考虑数据源的可靠性、数据的一致性（是否存在矛盾或冗杂等问题）等可靠数据源，并选择在各数据源中出现频率高的事实和属性加入知识库。</p>
</li>
</ul>
<p>知识图谱的内容更新有两种方式：</p>
<ul>
<li><p> <strong>全面更新</strong>：指以更新后的全部数据为输入，从零开始构建知识图谱。这种方法比较简单，但资源消耗大，而且需要耗费大量人力资源进行系统维护；</p>
</li>
<li><p> <strong>增量更新</strong>：以当前新增数据为输入，向现有知识图谱中添加新增知识。这种方式资源消耗小，但目前仍需要大量人工干预（定义规则等），因此实施起来十分困难。</p>
</li>
</ul>
<h2 id="10-知识图谱应用"><a href="#10-知识图谱应用" class="headerlink" title="10.   知识图谱应用"></a>10.   知识图谱应用</h2><p>知识图谱为互联网上海量、异构、动态的大数据表达、组织、管理以及利用提供了一种更为有效的方式，使得网络的智能化水平更高，更加接近于人类的认知思维。</p>
<p><strong>智能搜索，智能问答，社交网络，个性化推荐，情报分析，反欺诈</strong>等等</p>
<h2 id="11-总结"><a href="#11-总结" class="headerlink" title="11.   总结"></a>11.   总结</h2><p>从技术来说，知识图谱的难点在于 NLP，因为我们需要机器能够理解海量的文字信息。但在工程上，我们面临更多的问题，来源于知识的获取，知识的融合。搜索领域能做的越来越好，是因为有成千上万（成百万上亿）的用户，用户在查询的过程中，实际也在优化搜索结果，这也是为什么百度的英文搜索不可能超过 Google，因为没有那么多英文用户。知识图谱也是同样的道理，如果将用户的行为应用在知识图谱的更新上，才能走的更远。</p>
<p>知识图谱肯定不是人工智能的最终答案，但知识图谱这种综合各项计算机技术的应用方向，一定是人工智能未来的形式之一。</p>
<h2 id="12-参考资料"><a href="#12-参考资料" class="headerlink" title="12.   参考资料"></a>12.   参考资料</h2><p><a href="https://www.cnblogs.com/huangyc/p/10043749.html">https://www.cnblogs.com/huangyc/p/10043749.html</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/71128505">https://zhuanlan.zhihu.com/p/71128505</a></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 | 如何理解卷积</title>
    <url>/posts/ef2381bd.html</url>
    <content><![CDATA[<h2 id="1-什么是卷积"><a href="#1-什么是卷积" class="headerlink" title="1.什么是卷积"></a>1.什么是卷积</h2><p>对于卷积的定义，如下：</p>
<p><strong>连续形式</strong></p>
<p>$$(f×g)(n)=\int_{-\infty}^{\infty}f(\tau )g(n-\tau)d\tau$$</p>
<p><strong>离散形式</strong></p>
<p>$$(f×g)(n)=\sum_{\tau=-\infty}^{\infty}f(\tau)g(n-\tau)$$</p>
<blockquote>
<p>先对g函数进行翻转，相当于在数轴上把g函数从右边褶到左边去，也就是卷积的“卷”的由来。<br>然后再把g函数平移到n，在这个位置对两个函数的对应点相乘，然后相加，这个过程是卷积的“积”的过程。</p>
</blockquote>
<p>上述公式中有一个共同的特征：<br>$$n=\tau + (n - \tau)$$</p>
<p>对于这个特征，我们可以令$x=\tau$,$y=n-\tau$，那么x+y=n就是一些直线</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/v2-8be52f6bada3f7a21cebfc210d2e7ea0_hd.gif"></p>
<p>如果遍历这些直线，就好比，把毛巾沿着角卷起来：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/v2-1d0c819fc7ca6f8da25435da070a2715_hd.webp"></p>
<h2 id="2-通俗易懂的理解卷积"><a href="#2-通俗易懂的理解卷积" class="headerlink" title="2.通俗易懂的理解卷积"></a>2.通俗易懂的理解卷积</h2><h3 id="2-1离散卷积的例子：丢骰子"><a href="#2-1离散卷积的例子：丢骰子" class="headerlink" title="2.1离散卷积的例子：丢骰子"></a>2.1离散卷积的例子：丢骰子</h3><p><strong>问题：</strong></p>
<p>把两枚骰子抛出去，两枚骰子点数之和为4的概率是多少</p>
<p><strong>表示：</strong></p>
<p>如果用f(x)表示第一枚骰子投出x（x∈{1,2,3,4,5,6}）的概率，g(y)表示第二枚骰子投出y（y∈{1,2,3,4,5,6}）的概率</p>
<p><strong>结果：</strong></p>
<p>两枚骰子点数加起来等于4的情况有：<br>f(1)g(3)和f(2)g(2)和f(3)g(1)</p>
<p>那么概率为P=f(1)g(3)+f(2)g(2)+f(3)g(1)，符合卷积的定义，把他写成标准形式就是<br>$$(f×g)(4)=\sum_{m=1}^{3}f(m)g(4-m)$$</p>
<h3 id="2-2连续卷积的例子：做馒头"><a href="#2-2连续卷积的例子：做馒头" class="headerlink" title="2.2连续卷积的例子：做馒头"></a>2.2连续卷积的例子：做馒头</h3><p><strong>问题：</strong></p>
<p>如果有一家包子铺，会生产包子，但是包子会坏掉，那么一天后包子总共坏掉了多少？</p>
<p><strong>表示：</strong></p>
<p>假设包子生产速度是f(t)，对于包子铺一天生产的包子数量是<br>$$\int_{0}^{24}f(t)dt$$<br>假设腐败速度是g(t)，那么n个包子生产出来后，24小时会腐败个数<br>$$n * g(t)$$</p>
<p><strong>结果：</strong></p>
<p>一天后，包子总共腐败了：<br>$$\int_{0}^{24}f(t)g(24-t)dt$$</p>
<h3 id="2-3卷积提取图像特征"><a href="#2-3卷积提取图像特征" class="headerlink" title="2.3卷积提取图像特征"></a>2.3卷积提取图像特征</h3><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/v2-05f7af4e1d59e82412832c01b1144f52_720w.jpg"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/v2-c9b00043ba326451979abda5417bfcdf_720w.jpg"></p>
<p>卷积核和图像进行点乘（dot product), 就代表卷积核里的权重单独对相应位置的Pixel进行作用</p>
<p><strong>这里我想强调一下点乘，虽说我们称为卷积，实际上是位置一一对应的点乘，不是真正意义的卷积</strong></p>
<p>比如图像位置（1,1）乘以卷积核位置（1,1），仔细观察右上角你就会发现了</p>
<p>例如：对于一张图片</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201103204533.png"></p>
<p>我们进行手动卷积</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> torch,torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">path=<span class="string">&quot;./1.jpg&quot;</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">transform = transforms.Compose([transforms.ToTensor()])<span class="comment">#totensor 得到（C*H*W)</span></span><br><span class="line">im = transform(img)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span>(<span class="params">img</span>):</span></span><br><span class="line">    npimg = img</span><br><span class="line">    plt.imshow(np.transpose(npimg,(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>))) <span class="comment">#chw-&gt;hwc</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">k = torch.ShortTensor([[<span class="number">0</span>,-<span class="number">4</span>,<span class="number">0</span>],[-<span class="number">4</span>,<span class="number">16</span>,-<span class="number">4</span>],[<span class="number">0</span>,-<span class="number">4</span>,<span class="number">0</span>]])</span><br><span class="line">stride=<span class="number">2</span> <span class="comment">#步长</span></span><br><span class="line">padding=<span class="number">0</span> <span class="comment"># 补0</span></span><br><span class="line">f = k.size(<span class="number">0</span>) <span class="comment"># 卷积核的形状</span></span><br><span class="line">channels = im.size(<span class="number">0</span>) <span class="comment">#输入的图片的通道数</span></span><br><span class="line">hin = im.size(<span class="number">1</span>) <span class="comment">#输入的图片的高</span></span><br><span class="line">win = im.size(<span class="number">2</span>) <span class="comment">#输入的图片的宽</span></span><br><span class="line">hout = math.floor((hin-f+<span class="number">2</span>*padding)/stride+<span class="number">1</span>) <span class="comment">#输出的图片的高</span></span><br><span class="line">wout = math.floor((win-f+<span class="number">2</span>*padding)/stride+<span class="number">1</span>) <span class="comment">#输出的图片的宽</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;input[&#123;&#125;,&#123;&#125;],output[&#123;&#125;,&#123;&#125;]&quot;</span>.<span class="built_in">format</span>(hin,win,hout,wout))</span><br><span class="line">output=[]</span><br><span class="line">im = im.numpy()</span><br><span class="line">k = k.numpy()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Waite for calculating...&quot;</span>)</span><br><span class="line"><span class="comment"># 自定义卷积，一一对应相乘</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(channels):</span><br><span class="line">    lines=[]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(hout):</span><br><span class="line">        line=[]</span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(wout):</span><br><span class="line">            a=[[im[i][j*stride][n*stride],im[i][j*stride][n*stride+<span class="number">1</span>],im[i][j*stride][n*stride+<span class="number">2</span>]],[im[i][j*stride+<span class="number">1</span>][n*stride],im[i][j*stride+<span class="number">1</span>][n*stride+<span class="number">1</span>],im[i][j*stride+<span class="number">1</span>][n*stride+<span class="number">2</span>]],[im[i][j*stride+<span class="number">2</span>][n*stride],im[i][j*stride+<span class="number">2</span>][n*stride+<span class="number">1</span>],im[i][j*stride+<span class="number">2</span>][n*stride+<span class="number">2</span>]]]</span><br><span class="line">            line.append(<span class="built_in">sum</span>(<span class="built_in">sum</span>(a*k)))</span><br><span class="line">        lines.append(line)</span><br><span class="line">    output.append(lines)</span><br><span class="line"></span><br><span class="line">oo=np.array(output)</span><br><span class="line"><span class="built_in">print</span>(oo.shape)</span><br><span class="line">imshow(oo)</span><br></pre></td></tr></table></figure>

<p><strong>提取特征效果如下：</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201103211407111.png"></p>
<p>部分内容参考<a href="https://www.zhihu.com/question/22298352/answer/637156871">知乎:如何通俗易懂的理解卷积</a></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>卷积</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 | 小样本学习基础概念</title>
    <url>/posts/d150f284.html</url>
    <content><![CDATA[<h1 id="小样本学习"><a href="#小样本学习" class="headerlink" title="小样本学习"></a>小样本学习</h1><p>人类非常擅长通过极少量的样本识别一个新物体，比如小孩子只需要书中的一些图片就可以认识什么是“斑马”，什么是“犀牛”。在人类的快速学习能力的启发下，研究人员希望机器学习模型在学习了一定类别的大量数据后，对于新的类别，只需要少量的样本就能快速学习，这就是 Few-shot Learning 要解决的问题。Few-shot learning (FSL) 在机器学习领域具有重大意义和挑战性，是否拥有从少量样本中学习和概括的能力，是将人工智能和人类智能进行区分的明显分界点，因为人类可以仅通过一个或几个示例就可以轻松地建立对新事物的认知，而机器学习算法通常需要成千上万个有监督样本来保证其泛化能力。</p>
<h2 id="1-基础概念"><a href="#1-基础概念" class="headerlink" title="1.基础概念"></a>1.基础概念</h2><p>机器学习定义：A computer program is said to learn from experience <code>E</code> with respect to some classes of task <code>T</code> and performance measure <code>P</code> if its performance can improve with <code>E</code> on <code>T</code> measured by <code>P</code>.</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109201329876.png" alt="image-20210920132843364"></p>
<p>小样本学习定义：Few-Shot Learning (FSL) is a type of machine learning problems (specified by <code>E</code>, <code>T</code> and <code>P</code>), where <code>E</code> contains only a limited number of examples with supervised information for the target <code>T</code>.</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109201329400.png" alt="image-20210920132907931"></p>
<p>小样本学习（Few-shot learning），或者称为少样本学习（Low-shot learning），包含了n-shot learning，其中<code>n</code>代表样本数量，<code>n=1</code>的情况下，也被称One-shot learning，而<code>n=0</code>的情况下，被称为Zero-shot learning。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109201348334.png" alt="image-20210920134843156"></p>
<p>小样本学习的主要思想是利用先验知识使其快速适用于只包含少量带有监督信息的样本的任务中。</p>
<h2 id="2-方法分类"><a href="#2-方法分类" class="headerlink" title="2. 方法分类"></a>2. 方法分类</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109201336741.png" alt="image-20210920133613257"></p>
<p>小样本学习问题的解决方法可以根据先验知识的利用方式分为三类：</p>
<ul>
<li>数据：此类方法利用先验知识来增强训练数据集或者增加样本数量（从样本量的角度）<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110051544192.png" alt="image-20211005154338367"></li>
<li>1.使用旋转，翻转，裁剪等方法对训练集图像增强</li>
<li>2.从其他数据集获取图像用于扩充训练集</li>
<li>3.使用GAN来生成具有相似分布的数据用于扩充训练集</li>
</ul>
</li>
<li>模型：此类方法利用先验知识来限制假设空间的复杂性（从模型训练的角度）<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110051544913.png" alt="image-20211005154419771"></li>
<li>1.多任务学习（同时进行多个相关任务训练，共享表示，以获得更好的泛化能力）与迁移学习不同（将源任务中学到的知识运用到目标任务中）<ul>
<li>parameter sharing：多任务间共享参数（例如最开始几层网络结构共享，最后输出层单独训练）</li>
<li>parameter typing：对不同任务的参数正则化处理，使其参数相似（encourages parameters of different tasks to be similar using regularization）</li>
</ul>
</li>
<li>2.嵌入学习（将样本映射（嵌入）到低纬度空间后，相似样本距离更近，不相似样本距离远）<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110052028366.png" alt="image-20211005202850882"></li>
<li>Task-Specific Embedding Model:只使用来自任务的信息学习一个定制的嵌入函数</li>
<li>Task-Invariant Embedding Model：将从其他充足样本中学到的信息直接利用到小样本学习任务中<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110062246351.png" alt="image-20211006224637164"></li>
<li>Matching Nets</li>
<li>Prototypical Networks(ProtoNet)</li>
</ul>
</li>
<li>Hybrid Embedding Model: 前两种方法的结合，使用小样本任务中的task specific信息运用到从先验知识学到的task invariant嵌入模型<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110062249691.png" alt="image-20211006224925493"></li>
</ul>
</li>
</ul>
</li>
<li>3.带有存储的模型，构建键值存储，并优化内存，每个新样本都可以由内存中提取出的内容的加权平均值表示（通过查询相似性），进一步限制假设空间。<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110052104077.png" alt="image-20211005202918521"></li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110052033347.png" alt="image-20211005203314132"></li>
<li>优化表征（representation）</li>
<li>优化参数（parameter）</li>
</ul>
</li>
<li>4.生成模型，对于样本x在先验知识的帮助下可以估计其分布p(x)：假设x的分布可以表示为受$\theta$约束的$p(x;\theta)$，并且通常还存在潜在变量$z \sim p(z;y)$，因此$x \sim \int p(x|z;\theta)p(z;y)dz$，即在先验分布$p(z;y)$的帮助下，可以进一步缩小假设空间的大小.<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110052048660.png" alt="image-20211005204829440"></li>
<li>Decomposable Components：训练可分解组件模型，在不同任务间共享分解组件的信息，最后再找到分解组件的组合方式（模型层面？）</li>
<li>Groupwise Shared Prior：使用无监督学习将数据集分组，对于新类别，首先查询其所属组，再根据其所属组的先验概率建模（相似的任务拥有相似的先验概率）</li>
<li>Parameters of Inference Networks：找到最佳的$\theta$，使得最大化$p(z|x;\theta,\gamma)=\frac{p(x,z;\theta,\gamma)}{p(x;\gamma)}=\frac{p(x|z;\theta)p(z;\gamma)}{\int p(x|z;\theta)p(z;\gamma)dz}$，通常使用从数据中学到的变分分布$q(z;\delta)$来估计$p(z|x;\theta,\gamma)$。（？）</li>
</ul>
</li>
</ul>
</li>
<li>算法：此类方法利用先验知识在假设空间中搜索最优的假设<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110052106876.png" alt="image-20211005210608746"></li>
<li>1.精炼现存参数<ul>
<li>使用预训练模型，通过正则化进行微调<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110052115770.png" alt="image-20211005211532604"></li>
<li>Early-stopping</li>
<li>Selectively updating parameters</li>
<li>Updating related parts of parameters together</li>
<li>Using a model regression network</li>
</ul>
</li>
<li>聚集子任务的参数（参数层面？）<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110052109091.png" alt="image-20211005210954883"></li>
</ul>
</li>
<li>使用新参数微调现有参数：给模型参数扩充一个$\delta$，使其参数为$\theta={\theta_0,\delta}$，然后通过学习$\delta$来微调初始参数$\theta_0$。</li>
</ul>
</li>
<li>2.精炼Meta-Learned参数<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110071533336.png" alt="image-20211007153301984"></li>
</ul>
</li>
<li>3.学习优化器：不使用梯度下降来更新参数，而是通过学习一个优化器来输出参数的更新，即$\Delta{\theta^{i-1}}$<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202110071540903.png" alt="image-20211007154007652"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="3-小样本学习常用数据集"><a href="#3-小样本学习常用数据集" class="headerlink" title="3. 小样本学习常用数据集"></a>3. 小样本学习常用数据集</h2><p>小样本常用Benchmark图像数据集：</p>
<ul>
<li>Omniglot</li>
<li>Mini-Imagenet</li>
<li>CU-Birds</li>
</ul>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>小样本学习</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 | “花书”，Deep Learning笔记</title>
    <url>/posts/43678.html</url>
    <content><![CDATA[<h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><h3 id="第一章-前言"><a href="#第一章-前言" class="headerlink" title="第一章 前言"></a>第一章 前言</h3><p>深度学习(Deep Learning) ∈ 表示学习(Representation Learning) ∈ 机器学习(Machine Learning) ∈ 人工智能(AI)</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201015120220.png"></p>
<p>分类，回归，聚类，降维</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201015120404.png"></p>
<p>神经网络</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/149537710807280383.jpg"></p>
<h2 id="第一部分-应用数学与机器学习基础"><a href="#第一部分-应用数学与机器学习基础" class="headerlink" title="第一部分 应用数学与机器学习基础"></a>第一部分 应用数学与机器学习基础</h2><h3 id="第二章-线性代数"><a href="#第二章-线性代数" class="headerlink" title="第二章 线性代数"></a>第二章 线性代数</h3><h4 id="2-1-标量，向量，矩阵和张量"><a href="#2-1-标量，向量，矩阵和张量" class="headerlink" title="2.1 标量，向量，矩阵和张量"></a>2.1 标量，向量，矩阵和张量</h4><p>1.标量(scalar)是一个单独的数<br>2.向量(vector)是一列数，这些数是有序排列的</p>
<p>$$<br>x = \begin{bmatrix}<br>x_1\<br>x_2\<br>\vdots\<br>x_n\<br>\end{bmatrix}<br>$$</p>
<p>3.矩阵(matrix)是一个二维数组</p>
<p>$$<br>\begin{bmatrix}<br>A_{1,1} &amp; A_{1,2}\<br>B_{2,1} &amp; B_{2,2}\<br>\end{bmatrix}<br>$$</p>
<p>4.张量(tensor)：一般将超过二维的数组称为张量</p>
<ul>
<li>转置：以对角线为轴的镜像</li>
</ul>
<p>$$<br>(A^T)<em>{i,j}=A</em>{j,i}<br>$$</p>
<ul>
<li>广播：将一个向量隐式的复制到每一行生成矩阵（用于运算）的方式</li>
</ul>
<p>$$C=A+b$$<br>$$C_{i,j}=A_{i,j}+b$$<br>$$<br>\begin{bmatrix}<br>C_{1,1} &amp; C_{1,2} &amp; C_{1,3}\<br>C_{2,1} &amp; C_{2,2} &amp; C_{2,3}\<br>C_{3,1} &amp; C_{3,2} &amp; C_{3,3}\<br>\end{bmatrix}=<br>\begin{bmatrix}<br>A_{1,1} &amp; A_{1,2} &amp; A_{1,3}\<br>A_{2,1} &amp; A_{2,2} &amp; A_{2,3}\<br>A_{3,1} &amp; A_{3,2} &amp; A_{3,3}\<br>\end{bmatrix}+<br>\begin{bmatrix}<br>b_{1} &amp; b_{2} &amp; b_{3}\<br>\end{bmatrix}=<br>\begin{bmatrix}<br>A_{1,1} &amp; A_{1,2} &amp; A_{1,3}\<br>A_{2,1} &amp; A_{2,2} &amp; A_{2,3}\<br>A_{3,1} &amp; A_{3,2} &amp; A_{3,3}\<br>\end{bmatrix}+<br>\begin{bmatrix}<br>b_{1} &amp; b_{2} &amp; b_{3}\<br>b_{1} &amp; b_{2} &amp; b_{3}\<br>b_{1} &amp; b_{2} &amp; b_{3}\<br>\end{bmatrix}<br>$$</p>
<h4 id="2-2-矩阵和向量相乘"><a href="#2-2-矩阵和向量相乘" class="headerlink" title="2.2 矩阵和向量相乘"></a>2.2 矩阵和向量相乘</h4><p>如果A的形状是m×n，B的形状是n×p，<code>C=AB</code>，那么C的形状是m×p<br>具体地，该乘法操作定义为：<br>$$C_{i,j}=\sum_kA_{i,k}B_{k,j}$$</p>
<blockquote>
<p>注意区分：存在一种两个矩阵对应元素的乘积，叫<code>Hadamard乘积</code>，记为<code>A⊙B</code></p>
</blockquote>
<p>性质：</p>
<ul>
<li>分配律<br>$$A(B+C)=AB+AC$$</li>
<li>结合律<br>$$A(BC)=(AB)C$$</li>
<li><strong>矩阵乘积不具有交换律</strong>，但是两个向量的点积满足交换律<br>$$x^Ty=y^Tx$$<br>$$(AB)^T=B^TA^T$$</li>
</ul>
<p>对于AX=b，可表示<br>$$A_{1,1}x_1+A_{1,2}x_2+\cdots+A_{1,n}x_n=b_1$$<br>$$A_{2,1}x_1+A_{2,2}x_2+\cdots+A_{2,n}x_n=b_2$$<br>$$\vdots$$<br>$$A_{m,1}x_1+A_{m,2}x_2+\cdots+A_{m,n}x_n=b_m$$<br>即<br>$$<br>\begin{bmatrix}<br>A_{1,1} &amp; A_{1,2} &amp; \cdots &amp; A_{1,n}\<br>A_{2,1} &amp; A_{2,2} &amp; \cdots &amp; A_{2,n}\<br>\vdots\<br>A_{m,1} &amp; A_{m,2} &amp; \cdots &amp; A_{m,n}\<br>\end{bmatrix}<br>\begin{bmatrix}<br>x_{1}\<br>x_{2}\<br>\vdots\<br>x_{n}\<br>\end{bmatrix}=<br>\begin{bmatrix}<br>b_{1}\<br>b_{2}\<br>\vdots\<br>b_{m}\<br>\end{bmatrix}<br>$$</p>
<h4 id="2-3-单位矩阵和逆矩阵"><a href="#2-3-单位矩阵和逆矩阵" class="headerlink" title="2.3 单位矩阵和逆矩阵"></a>2.3 单位矩阵和逆矩阵</h4><p>单位矩阵：任何向量和单位矩阵相乘，都不会改变<br>$${\forall}x{\in}R^n,I_nx=x$$</p>
<p>$$I_3=<br>\begin{bmatrix}<br>1 &amp; 0 &amp; 0\<br>0 &amp; 1 &amp; 0\<br>0 &amp; 0 &amp; 1\<br>\end{bmatrix}<br>$$<br>矩阵逆，记作$$A^{-1}$$，定义<br>$$A^{-1}A=I_n$$</p>
<h4 id="2-4-线性相关和生成子空间"><a href="#2-4-线性相关和生成子空间" class="headerlink" title="2.4 线性相关和生成子空间"></a>2.4 线性相关和生成子空间</h4><p>对于矩阵逆的定义：<br>$$A^{-1}A=I_n$$<br>可以通过以下步骤求解：<br>$$Ax=b$$<br>$$A^{-1}Ax=A^{-1}b$$<br>$$I_nx=A^{-1}b$$<br>$$x=A^{-1}b$$<br>如果能找到一个逆矩阵$A^{-1}$，那么若$s=w_1x_1+w_2x_2+{\cdots}+w_kx_k$。s变量是对变量x的加权线性”混合”。因此，将s定义为变量的线性组合。</p>
<ul>
<li><p>生成子空间：原始向量的一切线性组合生成的子空间</p>
</li>
<li><p>线性无关：一组向量中的任意一个向量都不能表示成其他向量的线性组合，那么这组向量被称为线性无关</p>
</li>
</ul>
<blockquote>
<p>如果数组向量中的某一个或多个向量可以由数组内的其余向量通过加法或数乘表达，则该向量组线性相关，反之则线性无关。</p>
</blockquote>
<ul>
<li>方阵：行列大小相同的矩阵</li>
</ul>
<h4 id="2-5-范数"><a href="#2-5-范数" class="headerlink" title="2.5 范数"></a>2.5 范数</h4><p>为了衡量一个向量的大小，在机器学习中，我们经常使用范数（norm）的函数衡量。形式上，$L^p$范数定义如下：<br>$$<br>\left | x \right | _ p=\left ( \sum_i\left | x_i \right |^p\right )^\frac{1}{p}<br>$$<br>其中$p \in \mathbb{R},p \geqslant 1$</p>
<ul>
<li>范数，是将向量映射到非负值的函数。直观上来说，向量x的范数衡量从原点到点x的距离。更严格的说，范数是满足下列性质的任意函数：<br>$$f\left (x \right )=0\Rightarrow x=0$$<br>$$<br>f\left (x + y \right )\leqslant f \left ( x \right ) + f\left(y \right)<br>$$</li>
</ul>
<p>$$<br>\forall \alpha \in \mathbb{R},f({\alpha}x)=|\alpha|f(x)<br>$$</p>
<ul>
<li><p>当p=2时，$L^2$范数被称为<strong>欧几里得范数</strong>。平方$L^2$范数，也经常用来衡量向量的大小。</p>
</li>
<li><p>$L^1$范数的定义，$||x|| _ 1 = \sum_i|x_i|$</p>
</li>
<li><p>另一个常在机器学习中出现的范数是$L^∞$范数，也被称为<strong>最大范数</strong>。这个范数表示向量中具有最大幅值的元素的绝对值：<br>$$||x|| _ ∞ =\max_i|x_i|$$</p>
</li>
<li><p>Frobenius范数：$$\left |A\right | _ F = \sqrt{\sum _ {i,j}{A^2} _ {i,j}}$$</p>
</li>
</ul>
<p>两个向量的<strong>点积</strong>，可以用范数来表示：<br>$$x^Ty=||x|| _ 2 ||y|| _ 2 \cos \theta $$<br>其中$\theta$，表示x和y之间的夹角</p>
<h4 id="2-6-特殊类型的矩阵和向量"><a href="#2-6-特殊类型的矩阵和向量" class="headerlink" title="2.6 特殊类型的矩阵和向量"></a>2.6 特殊类型的矩阵和向量</h4><p><strong>对角矩阵</strong>:只在主对角线上含有非零元素，其他位置都是零的矩阵。单位矩阵是对角元素都为1的对角矩阵。</p>
<ul>
<li>如果用diag(v)表示一个对角元素由向量v中的元素给定的对角方阵,那么$diag(v)x=v\odot x$，并且计算对角方阵的逆矩阵也很高效，如果对角方阵的逆矩阵存在，当且仅当对角元素都是非零值，这种情况下有，$diag(v)^{-1}=diag([\frac{1}{v_1},\cdots,\frac{1}{v_n}]^T)$</li>
<li>不是所有的对角矩阵都是方阵，非方阵的对角矩阵没有逆矩阵</li>
</ul>
<p><strong>对称矩阵</strong>是转置和自己相等的矩阵<br>$$A=A^T$$</p>
<p><strong>单位向量</strong>是具有<strong>单位范数</strong>的向量<br>$$||x|| _ 2 = 1$$</p>
<p><strong>正交</strong>：如果$x^Ty=0$，那么向量x和向量y互相正交，如果两个向量都有非零范数，那么他们之间的夹角为90度。<br><strong>标准正交</strong>：如果这些向量的不仅互相正交，并且范数都为1，那么我们称他们为标准正交<br><strong>正交矩阵</strong>：指行向量和列向量是分别标准正交的方针<br>$$A^TA=AA^T=I$$<br>$$A^{-1}=A^T$$</p>
<blockquote>
<p>补充关于点乘和叉乘：<br>点乘，也叫数量积，结果是一个向量在另一个向量方向上的投影的长度，是一个标量；<br>$A·B=|A||B|\cos\theta$，点积为0，说明两个向量正交<br>叉乘，也叫向量积，结果是一个和已有两个向量都垂直的向量，向量模长是向量A，B组成平行四边形的面积，即$\left | A×B\right|=\left|A \right|\left|B \right|\sin\theta$；向量方向垂直于向量A,B组成的平面；<br>$$A×B=\begin{vmatrix}<br>i &amp; j &amp; k\<br>a_1 &amp; a_2 &amp; a_3\<br>b_1 &amp; b_2 &amp; b_3<br>\end{vmatrix}=<br>\begin{vmatrix}<br>a_2 &amp; a_3\<br>b_2 &amp; b_3<br>\end{vmatrix}i-<br>\begin{vmatrix}<br>a_1 &amp; a_3\<br>b_1 &amp; b_3<br>\end{vmatrix}j+<br>\begin{vmatrix}<br>a_1 &amp; a_2\<br>b_1 &amp; b_2<br>\end{vmatrix}k$$<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/v2-1bc29eef9c32d93b6b9d6604b0ce65ea_720w.png"></p>
</blockquote>
<h4 id="2-7-特征分解"><a href="#2-7-特征分解" class="headerlink" title="2.7 特征分解"></a>2.7 特征分解</h4><p><strong>特征分解</strong>是使用最广的矩阵分解之一，即我们将矩阵分解成一组特征向量和特征值</p>
<ul>
<li><strong>方阵A</strong>的特征向量是指与A相乘后相当于对该向量进行缩放的非零向量v：$Av=λv$</li>
</ul>
<p>$({\lambda}E-A)v=0$，求特征值$\lambda$，其中$|{\lambda}E-A|$被称为特征多项式</p>
<ul>
<li>标量λ被称为这个特征向量对应的特征值。如果v是A的特征向量，那么任何缩放后的向量sv（s∈R，s≠0）也是A的特征向量。此外sv和v有相同的特征值。</li>
</ul>
<p>假设矩阵A有n个线性无关的特征向量</p>
<p>$$v^{(1)},\cdots,v^{(n)}$$</p>
<p>对应着特征值</p>
<p>$${\lambda} _ 1,\cdots,{\lambda} _ n$$</p>
<p>将特征向量连接成一个矩阵，使得每一列是一个特征向量：</p>
<p>$$V=[v^{(1)},\cdots,v^{(n)}]$$</p>
<p>类似地，将特征值连接成一个向量</p>
<p>$$\lambda =[{\lambda} _ 1,\cdots,{\lambda} _ n]^T$$</p>
<p>因此A的特征分解可以记作：</p>
<p>$$A=Vdiag(\lambda)V^{-1}$$</p>
<ul>
<li>特征分解唯一当且仅当所有的特征值都是唯一的</li>
<li>矩阵是奇异的当且仅当含有零特征值（奇异：非满秩）</li>
<li>正定（所有特征值为正），半正定（所有特征值非负），负定（所有特征值为负），半负定（所有特征值非正）</li>
</ul>
<p>对于每个实对称矩阵，都可以分解成实特征向量和实特征值<br>$$A=QΛQ^T$$<br>其中Ｑ是Ａ的特征向量组成的正交矩阵，Λ是对角矩阵。特征值$Λ_{i,j}$对应的特征向量是矩阵Q的第i列，记作$Q_{:,j}$</p>
<h4 id="2-8-奇异值分解"><a href="#2-8-奇异值分解" class="headerlink" title="2.8 奇异值分解"></a>2.8 奇异值分解</h4><p><a href="https://www.bilibili.com/video/BV1N4411a78K?from=search&seid=2326855606635926731">奇异值分解视频</a></p>
<p>奇异值分解：将矩阵分解为<strong>奇异向量</strong>和<strong>奇异值</strong><br>假设A是一个m×n的矩阵，那么U是一个m×m的矩阵，D是一个m×n的矩阵，V是一个n×n的矩阵，其中U和V是正交矩阵，D是对角矩阵（不一定是方阵）<br>$$A=UDV^T$$<br>对角矩阵D对角线上的元素被称为矩阵A的<strong>奇异值</strong>，矩阵U的列向量被称为<strong>左奇异向量</strong>(是$AA^T$的特征向量)，矩阵V的列向量被称为<strong>右奇异向量</strong>（是$A^TA$的特征向量）。A的非零奇异值是$A^TA$特征值的平方根，也是$AA^T$特征值的平方根</p>
<p>正交-对角-正交：旋转-拉伸-旋转</p>
<p>$$A^TA=(VD^TU^T)(UDV^T)=V(D^TD)V^T$$<br>$$AA^T=(UDV^T)(VD^TU^T)=U(D^TD)U^T$$<br>$$A=<br>\begin{bmatrix}<br>u_1 &amp; u_2<br>\end{bmatrix}<br>\begin{bmatrix}<br>\sigma_1 &amp; \<br> &amp; \sigma_2<br>\end{bmatrix}<br>\begin{bmatrix}<br>v_1^T\<br>v_2^T<br>\end{bmatrix}<br>$$</p>
<p>例子：</p>
<p>$$A=\begin{bmatrix}<br>2 &amp; 2\<br>1 &amp; 1<br>\end{bmatrix}=<br>\begin{bmatrix}<br>\frac{2}{\sqrt{5}} &amp; \frac{1}{\sqrt{5}}\<br>\frac{-1}{\sqrt{5}} &amp; \frac{2}{\sqrt{5}}<br>\end{bmatrix}<br>\begin{bmatrix}<br>\sqrt{10} &amp; \<br> &amp; 0<br>\end{bmatrix}<br>\begin{bmatrix}<br>\frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}}\<br>\frac{1}{\sqrt{2}} &amp; \frac{-1}{\sqrt{2}}<br>\end{bmatrix}<br>$$</p>
<h4 id="2-9-Moore-Penrose伪逆"><a href="#2-9-Moore-Penrose伪逆" class="headerlink" title="2.9 Moore-Penrose伪逆"></a>2.9 Moore-Penrose伪逆</h4><p>对于非方阵，将矩阵A 的伪逆定义为：<br>$$A^+=\lim_{a\rightarrow0}(A^TA+{\alpha}I)^{-1}A^T$$<br>实际计算公式<br>$$A^+=VD^+U^T$$<br>其中，矩阵U，D和V是矩阵A奇异值分解后得到的矩阵，对角矩阵D的伪逆$D^+$是其非零元素取倒数之后再转置得到的</p>
<h4 id="2-10-迹运算"><a href="#2-10-迹运算" class="headerlink" title="2.10 迹运算"></a>2.10 迹运算</h4><p>迹运算返回的是矩阵对角元素的和：<br>$$Tr(A)=\sum_iA_{i,i}$$</p>
<p>迹运算提供了另一种描述矩阵Frobenius范数的方式$$\left|A\right|<em>F=\sqrt{Tr(AA^T)}$$<br>迹运算在转置条件下是不变的<br>$$Tr(A)=Tr(A^T)$$<br>如果多个矩阵相乘交换顺序后仍有定义，那么有<br>$$Tr(ABC)=Tr(CAB)=Tr(BCA)$$<br>$$Tr(\prod</em>{i=1}^{n}F^{(i)})=Tr(F^{(n)}\prod_{i=1}^{n-1}F^{(i)})$$<br>标量的迹运算还是它自己</p>
<h4 id="2-11-行列式"><a href="#2-11-行列式" class="headerlink" title="2.11 行列式"></a>2.11 行列式</h4><p>记作det(A),是一个将方阵A映射到实数的函数。行列式等于矩阵特征值的乘积</p>
<h4 id="2-12-实例：主成分分析"><a href="#2-12-实例：主成分分析" class="headerlink" title="2.12 实例：主成分分析"></a>2.12 实例：主成分分析</h4><p>主成分分析（PCA,Principle component analysis）是一个简单的机器学习算法，可以通过基础的线性代数知识推导。</p>
<p>假设，在$\mathbb{R}^n$空间中我们有m个点，为了对这些点进行有损压缩，可以采取低维表示（线性降维），对于每个点$x^{(i)}\in \mathbb{R}^n$,会有一个对应的编码向量$c^{(i)}\in \mathbb{R}^l$。如果l比n小，那么便实现了压缩。需要设置一个编码函数，根据输入返回编码$f(x)=c$，也希望设置一个解码函数，给定编码重构输入$x≈g(f(x))$，为了简化解码器，使用矩阵乘法将编码映射回$\mathbb{R}^n$，即g(c)=Dc，其中D∈$\mathbb{R}^{n×l}$是定义解码的矩阵</p>
<p>首先，我们需要明确如何根据每一个输入x得到一个最优编码<br>$$c ^ <em>$$<br>一种方法是最小化原始输入向量x和重构向量<br>$$g(c^</em>)$$<br>之间的距离,在PCA中，我们使用L2范数：<br>$$c ^ * =arg\min _ c \left|x-g(c)\right| _ 2$$</p>
<blockquote>
<p>arg min f(x) 是指使得函数 f(x) 取得其最小值的所有自变量 x 的集合。</p>
</blockquote>
<p>当然也可以用平方L2范数来替代L2范数：<br>$$c^*=arg\min_c\left|x-g(c)\right|<em>2^2$$<br>该最小化函数可以简化成：<br>$$(x-g(c))^T(x-g(c))$$<br>$$=x^Tx-x^Tg(c)-g(c)^Tx+g(c)^Tg(c)$$<br>$$=x^Tx-2x^Tg(c)+g(c)^Tg(c)$$<br>因为第一项$x^Tx$不依赖于c所以我们可以忽略它，得到：<br>$$c^*=arg\min_c - 2x^Tg(c)+g(c)^Tg(c)$$<br>代入g(c)的定义：<br>$$c^*=arg\min_c - 2x^TDc+c^TD^TDc=arg\min_c - 2x^TDc+c^TI_lc=arg\min_c - 2x^TDc+c^Tc$$<br>$$\nabla_c(-2x^TDc+c^Tc)=0$$<br>$$-2D^Tx+2c=0$$<br>$$c=D^Tx$$<br>于是，最优编码x只需要一个矩阵-向量乘法操作<br>$$f(x)=D^Tx$$<br>PCA重构操作<br>$$r(x)=g(f(x))=DD^Tx$$<br>接下来需要挑选编码矩阵D，所以我们需要最小化所有维数和所有点上的误差矩阵的Frobenius范数：<br>$$D^*=arg\min_D\sqrt{\sum</em>{i,j}(x_j^{(i)}-r(x^{(i)})_j)^2}\text{ subject to } D^TD=I_l$$<br>先考虑l=1的情况，此时D是一个单一向量d<br>$$d^*=arg\min_d\sum\left|x^{(i)}-dd^Tx^{(i)}\right|_2^2\text{ subject to } \left|d\right|<em>2=1$$<br>将表示个点的向量堆叠成一个矩阵，记为X∈$\mathbb{R}^{m×n}$，其中$X</em>{i,:}=x^{(i)^T}$<br>原问题可以重新表示为：<br>$$d^*=arg\min_d\left|X-Xdd^T\right|_F^2\text{ subject to }d^Td=1$$<br>暂不考虑约束，可以把Frobenius范数简化成<br>$$arg\min_d\left|X-Xdd^T\right|_F^2$$<br>$$=arg\min_dTr((X-Xdd^T)^T(X-Xdd^T))$$<br>$$=arg\min_d-2Tr(X^TXdd^T)+Tr(X^TXdd^Tdd^T)$$<br>再考虑约束条件<br>$$arg\min_d-2Tr(X^TXdd^T)+Tr(X^TXdd^Tdd^T)\text{ subject to } d^td=1$$<br>$$=arg\max_dTr(d^TX^TXd)\text{ subject to }d^Td=1$$<br>即，最优的d是X^TX最大特征值对应的特征向量</p>
<blockquote>
<p>PCA算法两种实现方法：<br>（1）基于特征值分解协方差矩阵实现<br>输入数据集X={x1,x2,x3,…,xn}，需要降到k维。<br>1）去平均值（去中心化），即每一位特征减去各自的平均值<br>2）计算协方差矩阵$\frac{1}{n}XX^T$<br>3）用特征值分解方法求协方差矩阵的特征值和特征向量<br>4）对特征值从大到小排序，选择其中最大的k个，然后将其对应的k个特征向量分别作为行向量组成特征向量矩阵P<br>5）将数据转换到k个特征向量构建的新空间中，即Y=PX<br>(2) 基于SVD分解（奇异值分解）协方差矩阵实现PCA算法</p>
</blockquote>
<h3 id="第三章-概率与信息论"><a href="#第三章-概率与信息论" class="headerlink" title="第三章 概率与信息论"></a>第三章 概率与信息论</h3><p>概率论是用于表示不确定性申明的数学框架</p>
<h4 id="3-1-为什么要使用概率"><a href="#3-1-为什么要使用概率" class="headerlink" title="3.1 为什么要使用概率"></a>3.1 为什么要使用概率</h4><p>几乎所有的活动都需要能够再不确定性存在时进行推理<br>不确定性的三种来源：被建模系统内在的随机性，不完全观测，不完全建模</p>
<h4 id="3-2-随机变量"><a href="#3-2-随机变量" class="headerlink" title="3.2 随机变量"></a>3.2 随机变量</h4><p>随机变量时可以随机地取不同值的变量。</p>
<h4 id="3-3-概率分布"><a href="#3-3-概率分布" class="headerlink" title="3.3 概率分布"></a>3.3 概率分布</h4><p>概率分布用来描述随机变量或一簇随机变量在每一个可能取到的状态的可能性大小</p>
<h5 id="3-3-1-离散型变量和概率质量函数"><a href="#3-3-1-离散型变量和概率质量函数" class="headerlink" title="3.3.1 离散型变量和概率质量函数"></a>3.3.1 离散型变量和概率质量函数</h5><ol>
<li>离散型变量的概率分布可以用概率质量函数(PMF，probability mass function)来描述</li>
<li>联合概率分布是多个变量的概率分布</li>
<li>如果用P表示概率质量函数，则满足以下条件</li>
</ol>
<ul>
<li>P的定义域必须是随机变量x所有可能状态的集合</li>
<li>$\forall x \in X, 0 \leq P(x) \leq 1$，不可能发生的事件概率为0，并且不存在比这概率更低的状态。类似的，一定发生的事件概率为1，且不存在比这概率更高的事件。</li>
<li>$\sum_i P(x)=1$</li>
</ul>
<h5 id="3-3-2-连续型变量和概率密度函数"><a href="#3-3-2-连续型变量和概率密度函数" class="headerlink" title="3.3.2 连续型变量和概率密度函数"></a>3.3.2 连续型变量和概率密度函数</h5><p>对于连续型随机变量，用概率密度函数（PDF，probability density function），如果用p表示概率密度函数，则满足以下条件</p>
<ul>
<li>p的定义域必须是x所有可能状态的集合</li>
<li>$\forall x \in X,p(x) \geq 0$.并不要求p(x)≤1</li>
<li>$\int p(x) \text{d}x = 1$</li>
</ul>
<h4 id="3-4-边缘概率"><a href="#3-4-边缘概率" class="headerlink" title="3.4 边缘概率"></a>3.4 边缘概率</h4><p>边缘概率分布，定义在其中一个子集上的概率分布</p>
<p>$\forall x \in X,P(X=x)=\sum_yP(X=x,Y=y)$<br>$p(x)=\int p(x,y) \text{d}y$</p>
<h4 id="3-5-条件概率"><a href="#3-5-条件概率" class="headerlink" title="3.5 条件概率"></a>3.5 条件概率</h4><p>条件概率，在给定其他事件发生时出现的概率，我们将给定X=x，Y=y发生的条件概率记为P(Y=y|X=x)<br>计算公式如下<br>$$P(Y=y|X=x)=\frac{P(Y=y,X=x)}{P(X=x)}$$</p>
<p>条件概率只在P(X=x)＞0时有定义</p>
<h4 id="3-6-条件概率的链式法则"><a href="#3-6-条件概率的链式法则" class="headerlink" title="3.6 条件概率的链式法则"></a>3.6 条件概率的链式法则</h4><p>任何多维随机变量的联合概率分布，都可以分解成只有一个变量的条件概率相乘的形式<br>$$P(x^{(1)},\cdots,x^{(n)})=P(x^{(1)})\prod_{i=2}^{n}P(x^{(i)}|x^{(1)},\cdots,x^{(i-1)})$$</p>
<p>例如：<br>P(a,b,c)=P(a|b,c)P(b,c)<br>P(b,c)=P(b|c)P(c)<br>P(a,b,c)=P(a|b,c)P(b|c)P(c)</p>
<h4 id="3-7-独立性和条件独立性"><a href="#3-7-独立性和条件独立性" class="headerlink" title="3.7 独立性和条件独立性"></a>3.7 独立性和条件独立性</h4><p><strong>相互独立</strong>：两个随机变量x，y的概率分布可以表示为两个因子的乘积形式，并且一个因子只包含x，另一个只包含y，那么这两个随机变量是相互独立的<br>$$\forall x \in X,y\in Y,p(X=x,Y=y)=p(X=x)p(Y=y)$$</p>
<p><strong>条件独立</strong>：如果关于x和y的条件概率分布对于z的每一个值都可以写成乘积的形式，那么这两个随机变量x和y在给定随机变量z时是条件独立的</p>
<p>$$\forall x \in X,y\in Y,z\in Z,p(X=x,Y=y|Z=z)=p(X=x|Z=z)p(Y=y|Z=z)$$</p>
<h4 id="3-8-期望，方差，协方差"><a href="#3-8-期望，方差，协方差" class="headerlink" title="3.8 期望，方差，协方差"></a>3.8 期望，方差，协方差</h4><p>（1）期望(expected value)<br>函数f(x)关于某分布P(x)的期望或者期望值是指，当x由P产生，f作用到x时，f(x)的平均值</p>
<p>离散型随机变量的期望<br>$$\mathbb{E} _ {x\sim P}[f(x)]=\sum_x P(x)f(x)$$<br>连续型随机变量的期望<br>$$\mathbb{E} _ {x\sim P}[f(x)]=\int p(x)f(x)\text{d}x$$</p>
<p>期望是线性的，假设α和β不依赖于x<br>$$\mathbb{E}_ x[\alpha f(x)+ \beta g(x) ]=\alpha \mathbb{E}_ x[f(x)] +\beta \mathbb{E}_ x[g(x)]$$</p>
<p>（2）方差(variance)<br>$$Var(f(x))=\mathbb{E}[(f(x)-\mathbb{E}[f(x)])^2]$$</p>
<p>方差的平方根被称为标准差</p>
<p>（3）协方差<br>$$Cov(f(x),g(y))=\mathbb{E}[(f(x)-\mathbb{E}[f(x)])(g(y)-\mathbb{E}[g(y)])]$$</p>
<p>两个随机变量独立→协方差为0→没有线性关系<br>但是协方差为0，两个变量不一定独立</p>
<p>协方差矩阵：<br>$$Cov(x)_ {i,j}=Cov(x_i,x_j)$$<br>协方差矩阵的对角元是方差：<br>$$Cov(x_i,x_i)=Var(x_i)$$</p>
<h4 id="3-9-常用概率分布"><a href="#3-9-常用概率分布" class="headerlink" title="3.9 常用概率分布"></a>3.9 常用概率分布</h4><h5 id="3-9-1-Bernoulli分布（伯努利分布）"><a href="#3-9-1-Bernoulli分布（伯努利分布）" class="headerlink" title="3.9.1 Bernoulli分布（伯努利分布）"></a>3.9.1 Bernoulli分布（伯努利分布）</h5><p>单个二值随机变量的分布，又名两点分布，0-1分布</p>
<ul>
<li><p>对于单次随机试验，对于一个随机变量X而言：<br>$$P(X=1)=p$$<br>$$P(X=0)=1-p$$<br>$$P(X=x)=p^x(1-p)^{1-x}$$<br>$$E(X)=p$$<br>$$Var(X)=p(1-p)$$</p>
</li>
<li><p>进行一次伯努利试验，成功(X=1)概率为p(0≤p≤1)，失败(X=0)概率为1-p，则称随机变量X服从伯努利分布。伯努利分布是离散型概率分布，其概率质量函数为：</p>
</li>
</ul>
<p>$$f(x)=p^x(1-p)^{1-x}=\left{\begin{matrix}<br>p \text{ ,if x=1}\<br>1-p \text{ ,if x=0}\<br>0 \text{ ,otherwise}<br>\end{matrix}\right.$$</p>
<h5 id="3-9-2-Multinoulli分布"><a href="#3-9-2-Multinoulli分布" class="headerlink" title="3.9.2 Multinoulli分布"></a>3.9.2 Multinoulli分布</h5><p>Multinoulli分布，或称范畴分布，是指在具有k个不同状态的单个离散型随机变量上的分布，其中k是一个有限值</p>
<blockquote>
<p>Multinoulli分布是多项式分布（Multinomial distribution）的一个特例。多项式分布是${0,…,n}^k$中的向量的分布，用于表示当对Multinoulli分布采样n次时k个类中的每一个被访问的次数。即n=1的多项式分布是Multinoulli分布。</p>
</blockquote>
<p>Multinoulli分布由向量$p∈[0,1]^{k−1}$参数化，其中每一个分量$ p_i $表示第 i 个状态的概率。最后的第k个状态的概率可以通过$1−1^Tp$给出。注意我们必须限制$1^⊤p≤1$。Multinoulli分布经常用来表示对象分类的分布，所以我们很少假设状态 1 具有数值 1 之类的。因此，我们通常不需要去计算 Multinoulli 分布的随机变量的期望和方差。</p>
<p>Bernoulli 分布和 Multinoulli 分布足够用来描述在它们领域内的任意分布。它们能够描述这些分布，不是因为它们特别强大，而是因为它们的领域很简单。它们可以对那些能够将所有的状态进行枚举的离散型随机变量进行建模。当处理的是连续型随机变量时，会有不可数无限多的状态，所以任何通过少量参数描述的概率分布都必须在分布上加以严格的限制。</p>
<h5 id="3-9-3-高斯分布"><a href="#3-9-3-高斯分布" class="headerlink" title="3.9.3 高斯分布"></a>3.9.3 高斯分布</h5><p>高斯分布，也叫正态分布</p>
<p>$$N(x;\mu ,\sigma^2 )=\sqrt{\frac{1}{2\pi \sigma^2}}exp(-\frac{1}{2\sigma^2}(x-\mu)^2)$$<br>$$N(x;\mu ,\sigma^2 )=\sqrt{\frac{1}{2\pi \sigma^2}}e^{(-\frac{1}{2\sigma^2}(x-\mu)^2)}$$</p>
<p>正态分布的概率密度函数的图象的中心峰的x坐标由μ给出，峰的宽度受σ控制<br>标准正态分布：μ=0，σ=1</p>
<p>$$\mathbb{E}(x)=\mu$$<br>$$Var(x)=\sigma^2$$</p>
<p>令β为方差的倒数，来控制分布的精度<br>$$N(x;\mu ,\beta^{-1} )=\sqrt{\frac{\beta}{2\pi}}e^{(-\frac{1}{2}\beta(x-\mu)^2)}$$</p>
<p>正态分布可以推广到$\mathbb{R}^n$空间，这种情况下被称为多维正态分布<br>$$N(x;\mu ,\sum )=\sqrt{\frac{1}{(2\pi)^ndet(\sum)}}e^{(-\frac{1}{2}(x-\mu)^T\sum^{-1}(x-\mu))}$$</p>
<p>参数μ仍然表示分布的均值，只不过现在是向量值。参数∑给出了分布的协方差矩阵，但并不是一个很高效的参数化分布的方式，因为要对∑求逆，因此可以使用一个精度矩阵<strong>β</strong>替换<br>$$N(x;\mu ,\beta^{-1} )=\sqrt{\frac{det(\beta)}{(2\pi)^n}}e^{(-\frac{1}{2}(x-\mu)^T\beta(x-\mu))}$$</p>
<h5 id="3-9-4-指数分布和Laplace分布"><a href="#3-9-4-指数分布和Laplace分布" class="headerlink" title="3.9.4 指数分布和Laplace分布"></a>3.9.4 指数分布和Laplace分布</h5><p>指数分布，可以用来表示事件的时间间隔的概率，可以由泊松分布推导出来</p>
<p>其概率密度函数<br>$$f(x)=\left{\begin{matrix}<br>\lambda e^{-\lambda x} , x &gt;0 \<br>0 , otherwise<br>\end{matrix}\right.$$<br>分布函数<br>$$F(x)=\left{\begin{matrix}<br>1-\lambda e^{-\lambda x} , x \geqslant 0 \<br>0 , x＜0<br>\end{matrix}\right.（\lambda&gt;0）$$</p>
<p>Laplace分布，允许我们在任意一点μ处设置概率质量的峰值<br>$$Laplace(x;\mu , \gamma ) = \frac{1}{2\gamma}exp(-\frac{|x-\mu|}{\gamma})$$</p>
<h5 id="3-9-5-Dirac分布和经验分布"><a href="#3-9-5-Dirac分布和经验分布" class="headerlink" title="3.9.5 Dirac分布和经验分布"></a>3.9.5 Dirac分布和经验分布</h5><p>概率密度函数<br>$$p(x)=\delta(x-\mu)$$</p>
<p>Dirac分布经常作为经验分布的组成部分出现</p>
<h5 id="3-9-6-分布的混合"><a href="#3-9-6-分布的混合" class="headerlink" title="3.9.6 分布的混合"></a>3.9.6 分布的混合</h5><p>潜变量：不能直接观测到的随机变量</p>
<p>高斯混合模型，概率密度的万能近似器</p>
<p>先验概率：在观测到x之前计算的<br>后验概率：在观测到x之后计算的</p>
<h4 id="3-10-常用函数的有用性质"><a href="#3-10-常用函数的有用性质" class="headerlink" title="3.10 常用函数的有用性质"></a>3.10 常用函数的有用性质</h4><p>logistic sigmoid函数,在变量取绝对值很大的正值或负值时出现饱和现象</p>
<p>$$\sigma(x)=\frac{1}{1+e^{-x}}$$</p>
<p>softplus函数,范围（0,∞）</p>
<p>$$\zeta (x)=log(1+e^x)$$</p>
<p>ReLU函数，人工神经网络常用的激活函数</p>
<p>$$f(x)=max(0,x)$$</p>
<h4 id="3-11-贝叶斯规则"><a href="#3-11-贝叶斯规则" class="headerlink" title="3.11 贝叶斯规则"></a>3.11 贝叶斯规则</h4><p>$$P(x|y)=\frac{P(x)P(y|x)}{P(y)}$$</p>
<h4 id="3-12-连续型变量的技术细节"><a href="#3-12-连续型变量的技术细节" class="headerlink" title="3.12 连续型变量的技术细节"></a>3.12 连续型变量的技术细节</h4><p>测度论<br>零测度<br>几乎处处<br>Jacobin矩阵</p>
<h4 id="3-13-信息论"><a href="#3-13-信息论" class="headerlink" title="3.13 信息论"></a>3.13 信息论</h4><p>量化信息</p>
<ul>
<li>非常可能发生的事件信息量要比较少，并且极端情况下，确保能够发生的事件没有信息量</li>
<li>较不可能发生的事件具有更高的信息量</li>
<li>独立事件应具有增量的信息。例如，投掷的硬币两次正面朝上传递的信息量，应该是投掷一次硬币正面朝上信息量的两倍</li>
</ul>
<p>定义一个事件X=x的自信息为<br>$$I(x)=-logP(x)$$<br>log为自然对数，底为e，I(x)单位是奈特，一奈特是以1/e概率观测到一个事件时获得的信息量<br>若以2为底数，单位是比特或者香农</p>
<p>香农熵，一个分布的香农熵时指遵循这个分布的事件所产生的期望信息总量<br>$$H(x)=\mathbb{E}_ {x\sim P}[I(x)]=-\mathbb{E} _ {x \sim P}[logP(x)]$$</p>
<p>当x连续，香农熵被称为微分熵</p>
<p>KL散度，用域衡量两个分布的差异<br>$$D_{KL}(P||Q)=\mathbb{E} _ {x \sim P}[log\frac{P(x)}{Q(x)}]=\mathbb{E} _ {x \sim P}[logP(x)-logQ(x)]$$</p>
<p>交叉熵<br>$$H(P,Q)=-\mathbb{E}_ {x \sim P} logQ(x)$$</p>
<h4 id="3-14-结构化概率模型"><a href="#3-14-结构化概率模型" class="headerlink" title="3.14 结构化概率模型"></a>3.14 结构化概率模型</h4><p>结构化概率模型，又叫图模型</p>
<p>有向<br>无向</p>
<h3 id="第四章-数值计算"><a href="#第四章-数值计算" class="headerlink" title="第四章 数值计算"></a>第四章 数值计算</h3><h4 id="4-1-上溢和下溢"><a href="#4-1-上溢和下溢" class="headerlink" title="4.1 上溢和下溢"></a>4.1 上溢和下溢</h4><p>通过有限数量的位表示无限多的实数，总会引入舍入误差，包括了上溢和下溢<br>对上溢和下溢进行数值稳定的一个例子是softmax函数<br>$$softmax(x) _ i=\frac{exp(x_i)}{\sum_{j=1}^nexp(x_j)}$$</p>
<h4 id="4-2-病态条件"><a href="#4-2-病态条件" class="headerlink" title="4.2 病态条件"></a>4.2 病态条件</h4><p>条件数表征函数相对于输入的微小变化而变化的快慢程度<br>考虑函数$f(x)=A^{-1}x$，当A∈$\mathbb{R}^{n×n}$具有特征分解时，其条件数为<br>$$\max_{i,j}|\frac{\lambda_i}{\lambda_j}|$$</p>
<h4 id="4-3-基于梯度的优化方法"><a href="#4-3-基于梯度的优化方法" class="headerlink" title="4.3 基于梯度的优化方法"></a>4.3 基于梯度的优化方法</h4><p>（1）优化<br>大多数深度学习算法涉及某种形式的优化，包括改变x以最小化或最大化某个函数f(x)。通常以最小化指代大多数最优化问题，最大化可以经由-f(x)来实现</p>
<p>目标函数（准则）：要最小化或最大化的函数<br>代价函数（损失函数/误差函数）：对其进行最小化时也称之为代价函数</p>
<p>梯度下降：将x往导数反方向移动来减小f(x)</p>
<p>$\frac{df(x)}{x}=0$的点称为临界点，驻点<br>有些临界点既不是最大点也不是最小点，被称为鞍点</p>
<p>（2）偏导，梯度，方向导数<br>对于多维输入函数，提出了<strong>偏导数</strong>。偏导数为函数在每个位置处沿着自变量坐标轴方向上的导数（切线斜率）</p>
<p><strong>梯度</strong>，写作$\nabla_xf(x)$，当前位置的梯度方向，为函数在该位置处方向导数最大的方向，也是函数值上升最快的方向，反方向为下降最快的方向。当前位置的梯度长度（模），为最大方向导数的值</p>
<p><strong>方向导数</strong>，如果是方向不是沿着坐标轴方向，而是任意方向，则为方向导数</p>
<h5 id="4-3-1-梯度之上：Jacobin和Hessian矩阵"><a href="#4-3-1-梯度之上：Jacobin和Hessian矩阵" class="headerlink" title="4.3.1 梯度之上：Jacobin和Hessian矩阵"></a>4.3.1 梯度之上：Jacobin和Hessian矩阵</h5><p>1.Jacobin<br>在向量分析中, 雅可比矩阵是一阶偏导数以一定方式排列成的矩阵, 其行列式称为雅可比行列式. 还有, 在代数几何中, 代数曲线的雅可比量表示雅可比簇：伴随该曲线的一个代数群, 曲线可以嵌入其中. </p>
<p>雅可比矩阵的重要性在于它体现了一个可微方程与给出点的最优线性逼近. 因此, 雅可比矩阵类似于多元函数的导数.<br>$$\begin{bmatrix}<br>\frac{\partial y_1}{\partial x_1} &amp;\cdots&amp; \frac{\partial y_1}{\partial x_n} \<br>\vdots &amp; \ddots &amp; \vdots \<br>\frac{\partial y_m}{\partial x_1} &amp;\cdots&amp; \frac{\partial y_m}{\partial x_n}<br>\end{bmatrix}$$</p>
<p>2.Hessian<br>在数学中, 海森矩阵(Hessian matrix或Hessian)是一个自变量为向量的实值函数的二阶偏导数组成的方块矩阵, 此函数如下：<br>$f(x_1,x_2,\cdots,x_n)$，如果f的所有二阶导数都存在，那么<br>$$\begin{bmatrix}<br>\frac{\partial^2 f}{\partial x_1^2} &amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} &amp;\cdots&amp; \frac{\partial^2 f}{\partial x_1 \partial x_n} \<br>\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2} &amp;\cdots&amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \<br>\vdots &amp; \vdots &amp; \ddots &amp;\vdots\<br>\frac{\partial^2 f}{\partial x_n \partial x_1} &amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp;\cdots&amp; \frac{\partial^2 f}{\partial x_n^2}<br>\end{bmatrix}$$</p>
<p>Hessian矩阵等价于梯度的Jacobian矩阵<br>海森矩阵在牛顿法中的应用，牛顿法时一个基于二阶泰勒展开来近似x附近的f(x)的方法</p>
<p>例如：在x0处展开<br>$$f(x)=f(x_0)+(x-x_0)^T\nabla_xf(x_0)+\frac{1}{2}(x-x_0)^TH(f)(x_0)(x-x_0)$$<br>临界点为<br>$$X’=X_0-H(f)(x_0)^{-1}\nabla_xf(x_0)$$</p>
<h4 id="4-4-约束优化"><a href="#4-4-约束优化" class="headerlink" title="4.4 约束优化"></a>4.4 约束优化</h4><p>在x的某些集合S中找f(x)的最大值或最小值，称为约束优化</p>
<p>Karush-Kuhn-Tucker（KKT）方法</p>
<p>广义Lagrangian（广义Lagrange函数）,通过m个函数g和n个函数h描述S，那么S可以表示为$\mathbb{S}={x|\forall i,g^{(i)}(x)=0 and \forall j ,h^{(j)}(x)≤0}$，其中涉及g的等式称为等式约束，涉及h的不等式称为不等式约束，定义如下：<br>$$L(x,\lambda , \alpha)=f(x)+\sum_i\lambda_ig^{(i)}(x)+\sum_j\alpha_jh^{(j)}(x)$$</p>
<h4 id="4-5-实例：线性最小二乘"><a href="#4-5-实例：线性最小二乘" class="headerlink" title="4.5 实例：线性最小二乘"></a>4.5 实例：线性最小二乘</h4><p>假设我们希望最小化下式中的x值：</p>
<p>$$f(x)=\frac{1}{2}\left|Ax-b\right| _ 2 ^ 2$$</p>
<p>首先，计算梯度<br>$$\nabla_xf(x)=A^T(Ax-b)=A^TAx-A^Tb$$</p>
<p>假设希望最小化同样的函数，但受$x^Tx≤1$的约束<br>$$L(x,\lambda)=f(x)+\lambda(x^Tx-1)$$</p>
<p>现在，我们解决以下问题<br>$$\min_x\max_{\lambda , \lambda ≥ 0}L(x,\lambda)$$</p>
<p>我们可以用Moore-Penrose伪逆。<br>关于x对Lagrangian微分，得到<br>$$A^TAx-A^Tb+2\lambda x=0$$</p>
<p>解为：<br>$$x=(A^TA+2\lambda I)^{-1}A^Tb$$</p>
<p>观察<br>$$\frac{\partial}{\partial \lambda}L(x,\lambda)=x^Tx-1$$</p>
<p>当x的范数超过1时，该导数是正的，所以为了跟随导数上坡并相对λ增加Lagrangian，我们需要增加λ。因为$x^Tx$的惩罚系数增加，秋节关于x的线性方程现在将得到具有较小范数的解</p>
<h3 id="第五章-机器学习基础"><a href="#第五章-机器学习基础" class="headerlink" title="第五章 机器学习基础"></a>第五章 机器学习基础</h3><h4 id="5-1-学习算法"><a href="#5-1-学习算法" class="headerlink" title="5.1 学习算法"></a>5.1 学习算法</h4><p>能够从数据中学习的算法</p>
<h5 id="5-1-1-任务T"><a href="#5-1-1-任务T" class="headerlink" title="5.1.1 任务T"></a>5.1.1 任务T</h5><p>通常机器学习任务定义为机器学习系统应该如何处理样本。<br>样本是我们从希望机器学习系统处理的对象或事件中收集到的已经量化的特征的集合</p>
<p>常见任务：分类，输入缺失分类，回归，转录，机器翻译，结构化输出，异常检测，合成和采样，缺失值填补，去噪，密度估计或概率质量函数估计</p>
<h5 id="5-1-2-性能度量P"><a href="#5-1-2-性能度量P" class="headerlink" title="5.1.2 性能度量P"></a>5.1.2 性能度量P</h5><p>为了评估机器学习算法的能力，提出准确率，错误率</p>
<p>使用测试集数据来评估系统性能，将其与训练机器学习系统的训练集数据分开</p>
<h5 id="5-1-3-经验E"><a href="#5-1-3-经验E" class="headerlink" title="5.1.3 经验E"></a>5.1.3 经验E</h5><p>机器学习算法分为无监督算法和监督算法</p>
<h5 id="5-1-4-示例：线性回归"><a href="#5-1-4-示例：线性回归" class="headerlink" title="5.1.4 示例：线性回归"></a>5.1.4 示例：线性回归</h5><h4 id="5-2-容量，过拟合和欠拟合"><a href="#5-2-容量，过拟合和欠拟合" class="headerlink" title="5.2 容量，过拟合和欠拟合"></a>5.2 容量，过拟合和欠拟合</h4><h5 id="5-2-1-没有免费午餐定理"><a href="#5-2-1-没有免费午餐定理" class="headerlink" title="5.2.1 没有免费午餐定理"></a>5.2.1 没有免费午餐定理</h5><h5 id="5-2-2-正则化"><a href="#5-2-2-正则化" class="headerlink" title="5.2.2 正则化"></a>5.2.2 正则化</h5><h4 id="5-3-超参数和验证集"><a href="#5-3-超参数和验证集" class="headerlink" title="5.3 超参数和验证集"></a>5.3 超参数和验证集</h4><h5 id="5-3-1-交叉验证"><a href="#5-3-1-交叉验证" class="headerlink" title="5.3.1 交叉验证"></a>5.3.1 交叉验证</h5><h4 id="5-4-估计，偏差和方差"><a href="#5-4-估计，偏差和方差" class="headerlink" title="5.4 估计，偏差和方差"></a>5.4 估计，偏差和方差</h4><h5 id="5-4-1-点估计"><a href="#5-4-1-点估计" class="headerlink" title="5.4.1 点估计"></a>5.4.1 点估计</h5><h5 id="5-4-2-偏差"><a href="#5-4-2-偏差" class="headerlink" title="5.4.2 偏差"></a>5.4.2 偏差</h5><h5 id="5-4-3-方差和标准差"><a href="#5-4-3-方差和标准差" class="headerlink" title="5.4.3 方差和标准差"></a>5.4.3 方差和标准差</h5><h5 id="5-4-4-权衡偏差和方差以最小化均方误差"><a href="#5-4-4-权衡偏差和方差以最小化均方误差" class="headerlink" title="5.4.4 权衡偏差和方差以最小化均方误差"></a>5.4.4 权衡偏差和方差以最小化均方误差</h5><h5 id="5-4-5-一致性"><a href="#5-4-5-一致性" class="headerlink" title="5.4.5 一致性"></a>5.4.5 一致性</h5><h4 id="5-5-最大似然估计"><a href="#5-5-最大似然估计" class="headerlink" title="5.5 最大似然估计"></a>5.5 最大似然估计</h4>]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测 | 常用数据集标注格式及生成脚本</title>
    <url>/posts/865c56ba.html</url>
    <content><![CDATA[<p>目标检测是计算机视觉任务中的一个重要研究方向，其用于解决对数码图像中特定种类的可视目标实例的检测问题。目标检测作为计算机视觉的根本性问题之一，是其他诸多计算机视觉任务，例如图像描述生成，实例分割和目标跟踪的基础以及前提。而在解决此类问题时，我们常常需要使用自己的脚本或者利用标注工具生成数据集，数据集格式往往会多种多样，因此对于目标检测任务而言，为了更好地兼容训练，大多数目标检测模型框架会默认支持几种常用的数据集标注格式，常见的分别是COCO，Pascal VOC，YOLO等等。本文主要介绍上述几种数据集格式以及我写的Python脚本（一般需要根据实际情况再改改）。</p>
<h1 id="1-COCO"><a href="#1-COCO" class="headerlink" title="1. COCO"></a>1. COCO</h1><h2 id="1-1-COCO数据集格式"><a href="#1-1-COCO数据集格式" class="headerlink" title="1.1 COCO数据集格式"></a>1.1 COCO数据集格式</h2><p>COCO（Common Objects in COtext）数据集，是一个大规模的，适用于目标检测，图像分割，Image Captioning任务的数据集，其标注格式是最常用的几种格式之一。目前使用较多的是COCO2017数据集。其官网为<a href="https://cocodataset.org/">COCO - Common Objects in Context (cocodataset.org)</a>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109111535004.png" alt="image-20210911153516753"></p>
<p>COCO数据集主要包含图像（jpg或者png等等）和标注文件（json），其数据集格式如下(<code>/</code>代表文件夹)：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-coco/</span><br><span class="line">    |-train2017/</span><br><span class="line">    	|-1.jpg</span><br><span class="line">    	|-2.jpg</span><br><span class="line">    |-val2017/</span><br><span class="line">    	|-3.jpg</span><br><span class="line">    	|-4.jpg</span><br><span class="line">    |-test2017/</span><br><span class="line">    	|-5.jpg</span><br><span class="line">    	|-6.jpg</span><br><span class="line">    |-annotations/</span><br><span class="line">    	|-instances_train2017.json</span><br><span class="line">    	|-instances_val2017.json</span><br><span class="line">    	|-*.json</span><br></pre></td></tr></table></figure>

<p><code>train2017</code>以及<code>val2017</code>这两个文件夹中存储的是训练集和验证集的图像，而<code>test2017</code>文件夹中存储的是测试集的信息，可以只是图像，也可以包含标注，一般是单独使用的。</p>
<p><code>annotations</code>文件夹中的文件就是标注文件，如果你有<code>xml</code>文件，通常需要转换成<code>json</code>格式，其格式如下（更详细的可以参考<a href="https://cocodataset.org/#format-data">官网</a>）：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;info&quot;</span>: info, </span><br><span class="line">	<span class="attr">&quot;images&quot;</span>: [image], <span class="comment">//列表</span></span><br><span class="line">	<span class="attr">&quot;annotations&quot;</span>: [annotation], <span class="comment">//列表</span></span><br><span class="line">	<span class="attr">&quot;categories&quot;</span>: [category], <span class="comment">//列表</span></span><br><span class="line">	<span class="attr">&quot;licenses&quot;</span>: [license], <span class="comment">//列表</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中<code>info</code>为整个数据集的信息，包括年份，版本，描述等等信息，如果只是完成训练任务，其实不太重要，如下所示：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="comment">//对于训练，不是那么的重要</span></span><br><span class="line">info&#123;</span><br><span class="line">	<span class="attr">&quot;year&quot;</span>: int, </span><br><span class="line">	<span class="attr">&quot;version&quot;</span>: str, </span><br><span class="line">	<span class="attr">&quot;description&quot;</span>: str, </span><br><span class="line">	<span class="attr">&quot;contributor&quot;</span>: str, </span><br><span class="line">	<span class="attr">&quot;url&quot;</span>: str, </span><br><span class="line">	<span class="attr">&quot;date_created&quot;</span>: datetime,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中的<code>image</code>为图像的基本信息，包括序号，宽高，文件名等等信息，其中的序号（<code>id</code>）需要和后面的<code>annotations</code>中的标注所属图片序号对应如下所示：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">image&#123;</span><br><span class="line">	<span class="attr">&quot;id&quot;</span>: int, <span class="comment">//必要</span></span><br><span class="line">	<span class="attr">&quot;width&quot;</span>: int, <span class="comment">//必要</span></span><br><span class="line">	<span class="attr">&quot;height&quot;</span>: int, <span class="comment">//必要</span></span><br><span class="line">	<span class="attr">&quot;file_name&quot;</span>: str, <span class="comment">//必要</span></span><br><span class="line">	<span class="attr">&quot;license&quot;</span>: int,</span><br><span class="line">	<span class="attr">&quot;flickr_url&quot;</span>: str,</span><br><span class="line">	<span class="attr">&quot;coco_url&quot;</span>: str,</span><br><span class="line">	<span class="attr">&quot;date_captured&quot;</span>: datetime, </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中的<code>annotation</code>是最重要的标注信息，包括序号，所属图像序号，类别序号等等信息，如下所示：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">annotation&#123;</span><br><span class="line">	<span class="attr">&quot;id&quot;</span>: int, <span class="comment">//标注id</span></span><br><span class="line">	<span class="attr">&quot;image_id&quot;</span>: int, <span class="comment">//所属图像id</span></span><br><span class="line">	<span class="attr">&quot;category_id&quot;</span>: int, <span class="comment">//类别id</span></span><br><span class="line">	<span class="attr">&quot;segmentation&quot;</span>: RLE or [polygon], <span class="comment">//图像分割标注</span></span><br><span class="line">	<span class="attr">&quot;area&quot;</span>: float, <span class="comment">//区域面积</span></span><br><span class="line">	<span class="attr">&quot;bbox&quot;</span>: [x,y,width,height], <span class="comment">//目标框左上角坐标以及宽高</span></span><br><span class="line">	<span class="attr">&quot;iscrowd&quot;</span>: <span class="number">0</span> or <span class="number">1</span>, <span class="comment">//是否密集</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中的<code>category</code>代表类别信息，包括父类别，类别序号以及类别名称，如下所示：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">category&#123;</span><br><span class="line">	<span class="attr">&quot;id&quot;</span>: int, <span class="comment">//类别序号</span></span><br><span class="line">	<span class="attr">&quot;name&quot;</span>: str, <span class="comment">//类别名称</span></span><br><span class="line">	<span class="attr">&quot;supercategory&quot;</span>: str, <span class="comment">//父类别</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中的<code>license</code>代表数据集的协议许可信息，包括序号，协议名称以及链接信息，如下所示：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="comment">//对于训练，不重要</span></span><br><span class="line">license&#123;</span><br><span class="line">	<span class="attr">&quot;id&quot;</span>: int, </span><br><span class="line">	<span class="attr">&quot;name&quot;</span>: str, </span><br><span class="line">	<span class="attr">&quot;url&quot;</span>: str,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下来，我们来看一个简单的示例：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">&quot;info&quot;</span>: &#123;略&#125;, <span class="attr">&quot;images&quot;</span>: [&#123;<span class="attr">&quot;id&quot;</span>: <span class="number">1</span>, <span class="attr">&quot;file_name&quot;</span>: <span class="string">&quot;1.jpg&quot;</span>, <span class="attr">&quot;height&quot;</span>: <span class="number">334</span>, <span class="attr">&quot;width&quot;</span>: <span class="number">500</span>&#125;, &#123;<span class="attr">&quot;id&quot;</span>: <span class="number">2</span>, <span class="attr">&quot;file_name&quot;</span>: <span class="string">&quot;2.jpg&quot;</span>, <span class="attr">&quot;height&quot;</span>: <span class="number">445</span>, <span class="attr">&quot;width&quot;</span>: <span class="number">556</span>&#125;], <span class="attr">&quot;annotations&quot;</span>: [&#123;<span class="attr">&quot;id&quot;</span>: <span class="number">1</span>, <span class="attr">&quot;area&quot;</span>: <span class="number">40448</span>, <span class="attr">&quot;iscrowd&quot;</span>: <span class="number">0</span>, <span class="attr">&quot;image_id&quot;</span>: <span class="number">1</span>, <span class="attr">&quot;bbox&quot;</span>: [<span class="number">246</span>, <span class="number">61</span>, <span class="number">128</span>, <span class="number">316</span>], <span class="attr">&quot;category_id&quot;</span>: <span class="number">3</span>, <span class="attr">&quot;segmentation&quot;</span>: []&#125;, &#123;<span class="attr">&quot;id&quot;</span>: <span class="number">2</span>, <span class="attr">&quot;area&quot;</span>: <span class="number">40448</span>, <span class="attr">&quot;iscrowd&quot;</span>: <span class="number">0</span>, <span class="attr">&quot;image_id&quot;</span>: <span class="number">1</span>, <span class="attr">&quot;bbox&quot;</span>: [<span class="number">246</span>, <span class="number">61</span>, <span class="number">128</span>, <span class="number">316</span>], <span class="attr">&quot;category_id&quot;</span>: <span class="number">2</span>, <span class="attr">&quot;segmentation&quot;</span>: []&#125;, &#123;<span class="attr">&quot;id&quot;</span>: <span class="number">3</span>, <span class="attr">&quot;area&quot;</span>: <span class="number">40448</span>, <span class="attr">&quot;iscrowd&quot;</span>: <span class="number">0</span>, <span class="attr">&quot;image_id&quot;</span>: <span class="number">2</span>, <span class="attr">&quot;bbox&quot;</span>: [<span class="number">246</span>, <span class="number">61</span>, <span class="number">128</span>, <span class="number">316</span>], <span class="attr">&quot;category_id&quot;</span>: <span class="number">1</span>, <span class="attr">&quot;segmentation&quot;</span>: []&#125;], <span class="attr">&quot;categories&quot;</span>: [&#123;<span class="attr">&quot;supercategory&quot;</span>: <span class="string">&quot;none&quot;</span>, <span class="attr">&quot;id&quot;</span>: <span class="number">1</span>, <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;liner&quot;</span>&#125;,&#123;<span class="attr">&quot;supercategory&quot;</span>: <span class="string">&quot;none&quot;</span>, <span class="attr">&quot;id&quot;</span>: <span class="number">2</span>, <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;containership&quot;</span>&#125;,&#123;<span class="attr">&quot;supercategory&quot;</span>: <span class="string">&quot;none&quot;</span>, <span class="attr">&quot;id&quot;</span>: <span class="number">3</span>, <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;bulkcarrier&quot;</span>&#125;], <span class="attr">&quot;licenses&quot;</span>: [&#123;略&#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="1-2-COCO转换脚本"><a href="#1-2-COCO转换脚本" class="headerlink" title="1.2 COCO转换脚本"></a>1.2 COCO转换脚本</h2><p><code>Python转换脚本</code>如下所示，需要准备<code>图像</code>和<code>xml</code>标注文件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Author    : justlovesmile</span></span><br><span class="line"><span class="comment"># @Date      : 2021/9/8 15:36</span></span><br><span class="line"><span class="keyword">import</span> os, random, json</span><br><span class="line"><span class="keyword">import</span> shutil <span class="keyword">as</span> sh</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> xmlET</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mkdir</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        os.makedirs(path)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The path (<span class="subst">&#123;path&#125;</span>) already exists.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readxml</span>(<span class="params">file</span>):</span></span><br><span class="line">    tree = xmlET.parse(file)</span><br><span class="line">    <span class="comment">#图片尺寸字段</span></span><br><span class="line">    size = tree.find(<span class="string">&#x27;size&#x27;</span>)</span><br><span class="line">    width = <span class="built_in">int</span>(size.find(<span class="string">&#x27;width&#x27;</span>).text)</span><br><span class="line">    height = <span class="built_in">int</span>(size.find(<span class="string">&#x27;height&#x27;</span>).text)</span><br><span class="line">    <span class="comment">#目标字段</span></span><br><span class="line">    objs = tree.findall(<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">    bndbox = []</span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> objs:</span><br><span class="line">        label = obj.find(<span class="string">&quot;name&quot;</span>).text</span><br><span class="line">        bnd = obj.find(<span class="string">&quot;bndbox&quot;</span>)</span><br><span class="line">        xmin = <span class="built_in">int</span>(bnd.find(<span class="string">&quot;xmin&quot;</span>).text)</span><br><span class="line">        ymin = <span class="built_in">int</span>(bnd.find(<span class="string">&quot;ymin&quot;</span>).text)</span><br><span class="line">        xmax = <span class="built_in">int</span>(bnd.find(<span class="string">&quot;xmax&quot;</span>).text)</span><br><span class="line">        ymax = <span class="built_in">int</span>(bnd.find(<span class="string">&quot;ymax&quot;</span>).text)</span><br><span class="line">        bbox = [xmin, ymin, xmax, ymax, label]</span><br><span class="line">        bndbox.append(bbox)</span><br><span class="line">    <span class="keyword">return</span> [[width, height], bndbox]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tococo</span>(<span class="params">xml_root, image_root, output_root,classes=&#123;&#125;,errorId=[],train_percent=<span class="number">0.9</span></span>):</span></span><br><span class="line">    <span class="comment"># assert</span></span><br><span class="line">    <span class="keyword">assert</span> train_percent&lt;=<span class="number">1</span> <span class="keyword">and</span> <span class="built_in">len</span>(classes)&gt;<span class="number">0</span></span><br><span class="line">    <span class="comment"># define the root path</span></span><br><span class="line">    train_root = os.path.join(output_root, <span class="string">&quot;train2017&quot;</span>)</span><br><span class="line">    val_root = os.path.join(output_root, <span class="string">&quot;val2017&quot;</span>)</span><br><span class="line">    ann_root = os.path.join(output_root, <span class="string">&quot;annotations&quot;</span>)</span><br><span class="line">    <span class="comment"># initialize train and val dict</span></span><br><span class="line">    train_content = &#123;</span><br><span class="line">        <span class="string">&quot;images&quot;</span>: [],  <span class="comment"># &#123;&quot;file_name&quot;: &quot;09780.jpg&quot;, &quot;height&quot;: 334, &quot;width&quot;: 500, &quot;id&quot;: 9780&#125;</span></span><br><span class="line">        <span class="string">&quot;annotations&quot;</span>: [],<span class="comment"># &#123;&quot;area&quot;: 40448, &quot;iscrowd&quot;: 0, &quot;image_id&quot;: 1, &quot;bbox&quot;: [246, 61, 128, 316], &quot;category_id&quot;: 5, &quot;id&quot;: 1, &quot;segmentation&quot;: []&#125;</span></span><br><span class="line">        <span class="string">&quot;categories&quot;</span>: []  <span class="comment"># &#123;&quot;supercategory&quot;: &quot;none&quot;, &quot;id&quot;: 1, &quot;name&quot;: &quot;liner&quot;&#125;</span></span><br><span class="line">    &#125;</span><br><span class="line">    val_content = &#123;</span><br><span class="line">        <span class="string">&quot;images&quot;</span>: [],  <span class="comment"># &#123;&quot;file_name&quot;: &quot;09780.jpg&quot;, &quot;height&quot;: 334, &quot;width&quot;: 500, &quot;id&quot;: 9780&#125;</span></span><br><span class="line">        <span class="string">&quot;annotations&quot;</span>: [],<span class="comment"># &#123;&quot;area&quot;: 40448, &quot;iscrowd&quot;: 0, &quot;image_id&quot;: 1, &quot;bbox&quot;: [246, 61, 128, 316], &quot;category_id&quot;: 5, &quot;id&quot;: 1, &quot;segmentation&quot;: []&#125;</span></span><br><span class="line">        <span class="string">&quot;categories&quot;</span>: []  <span class="comment"># &#123;&quot;supercategory&quot;: &quot;none&quot;, &quot;id&quot;: 1, &quot;name&quot;: &quot;liner&quot;&#125;</span></span><br><span class="line">    &#125;</span><br><span class="line">    train_json = <span class="string">&#x27;instances_train2017.json&#x27;</span></span><br><span class="line">    val_json = <span class="string">&#x27;instances_val2017.json&#x27;</span></span><br><span class="line">    <span class="comment"># divide the trainset and valset</span></span><br><span class="line">    images = os.listdir(image_root)</span><br><span class="line">    total_num = <span class="built_in">len</span>(images)</span><br><span class="line">    train_percent = train_percent</span><br><span class="line">    train_num = <span class="built_in">int</span>(total_num * train_percent)</span><br><span class="line">    train_file = <span class="built_in">sorted</span>(random.sample(images, train_num))</span><br><span class="line">    <span class="keyword">if</span> mkdir(output_root):</span><br><span class="line">        <span class="keyword">if</span> mkdir(train_root) <span class="keyword">and</span> mkdir(val_root) <span class="keyword">and</span> mkdir(ann_root):</span><br><span class="line">            idx1, idx2, dx1, dx2 = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> file <span class="keyword">in</span> tqdm(images):</span><br><span class="line">                name=os.path.splitext(os.path.basename(file))[<span class="number">0</span>]</span><br><span class="line">                <span class="keyword">if</span> name <span class="keyword">not</span> <span class="keyword">in</span> errorId:</span><br><span class="line">                    res = readxml(os.path.join(xml_root, name + <span class="string">&#x27;.xml&#x27;</span>))</span><br><span class="line">                    <span class="keyword">if</span> file <span class="keyword">in</span> train_file:</span><br><span class="line">                        idx1 += <span class="number">1</span></span><br><span class="line">                        sh.copy(os.path.join(image_root, file), train_root)</span><br><span class="line">                        train_content[<span class="string">&#x27;images&#x27;</span>].append(</span><br><span class="line">                            &#123;<span class="string">&quot;file_name&quot;</span>: file, <span class="string">&quot;width&quot;</span>: res[<span class="number">0</span>][<span class="number">0</span>], <span class="string">&quot;height&quot;</span>: res[<span class="number">0</span>][<span class="number">1</span>], <span class="string">&quot;id&quot;</span>: idx1&#125;)</span><br><span class="line">                        <span class="keyword">for</span> b <span class="keyword">in</span> res[<span class="number">1</span>]:</span><br><span class="line">                            dx1 += <span class="number">1</span></span><br><span class="line">                            x = b[<span class="number">0</span>]</span><br><span class="line">                            y = b[<span class="number">1</span>]</span><br><span class="line">                            w = b[<span class="number">2</span>] - b[<span class="number">0</span>]</span><br><span class="line">                            h = b[<span class="number">3</span>] - b[<span class="number">1</span>]</span><br><span class="line">                            train_content[<span class="string">&#x27;annotations&#x27;</span>].append(</span><br><span class="line">                                &#123;<span class="string">&quot;area&quot;</span>: w * h, <span class="string">&quot;iscrowd&quot;</span>: <span class="number">0</span>, <span class="string">&quot;image_id&quot;</span>: idx1, <span class="string">&quot;bbox&quot;</span>: [x, y, w, h],</span><br><span class="line">                                 <span class="string">&quot;category_id&quot;</span>: classes[b[<span class="number">4</span>]], <span class="string">&quot;id&quot;</span>: dx1, <span class="string">&quot;segmentation&quot;</span>: []&#125;)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        idx2 += <span class="number">1</span></span><br><span class="line">                        sh.copy(os.path.join(image_root, file), val_root)</span><br><span class="line">                        val_content[<span class="string">&#x27;images&#x27;</span>].append(</span><br><span class="line">                            &#123;<span class="string">&quot;file_name&quot;</span>: file, <span class="string">&quot;width&quot;</span>: res[<span class="number">0</span>][<span class="number">0</span>], <span class="string">&quot;height&quot;</span>: res[<span class="number">0</span>][<span class="number">1</span>], <span class="string">&quot;id&quot;</span>: idx2&#125;)</span><br><span class="line">                        <span class="keyword">for</span> b <span class="keyword">in</span> res[<span class="number">1</span>]:</span><br><span class="line">                            dx2 += <span class="number">1</span></span><br><span class="line">                            x = b[<span class="number">0</span>]</span><br><span class="line">                            y = b[<span class="number">1</span>]</span><br><span class="line">                            w = b[<span class="number">2</span>] - b[<span class="number">0</span>]</span><br><span class="line">                            h = b[<span class="number">3</span>] - b[<span class="number">1</span>]</span><br><span class="line">                            val_content[<span class="string">&#x27;annotations&#x27;</span>].append(</span><br><span class="line">                                &#123;<span class="string">&quot;area&quot;</span>: w * h, <span class="string">&quot;iscrowd&quot;</span>: <span class="number">0</span>, <span class="string">&quot;image_id&quot;</span>: idx2, <span class="string">&quot;bbox&quot;</span>: [x, y, w, h],</span><br><span class="line">                                 <span class="string">&quot;category_id&quot;</span>: classes[b[<span class="number">4</span>]], <span class="string">&quot;id&quot;</span>: dx2, <span class="string">&quot;segmentation&quot;</span>: []&#125;)</span><br><span class="line">            <span class="keyword">for</span> i, j <span class="keyword">in</span> classes.items():</span><br><span class="line">                train_content[<span class="string">&#x27;categories&#x27;</span>].append(&#123;<span class="string">&quot;supercategory&quot;</span>: <span class="string">&quot;none&quot;</span>, <span class="string">&quot;id&quot;</span>: j, <span class="string">&quot;name&quot;</span>: i&#125;)</span><br><span class="line">                val_content[<span class="string">&#x27;categories&#x27;</span>].append(&#123;<span class="string">&quot;supercategory&quot;</span>: <span class="string">&quot;none&quot;</span>, <span class="string">&quot;id&quot;</span>: j, <span class="string">&quot;name&quot;</span>: i&#125;)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(ann_root, train_json), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                json.dump(train_content, f)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(ann_root, val_json), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                json.dump(val_content, f)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Number of Train Images:&quot;</span>, <span class="built_in">len</span>(os.listdir(train_root)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Number of Val Images:&quot;</span>, <span class="built_in">len</span>(os.listdir(val_root)))</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    box_root = <span class="string">&quot;E:/MyProject/Dataset/hwtest/annotations&quot;</span> <span class="comment">#xml文件夹</span></span><br><span class="line">    image_root = <span class="string">&quot;E:/MyProject/Dataset/hwtest/images&quot;</span> <span class="comment">#image文件夹</span></span><br><span class="line">    output_root = <span class="string">&quot;E:/MyProject/Dataset/coco&quot;</span> <span class="comment">#输出文件夹</span></span><br><span class="line">    classes = &#123;<span class="string">&quot;liner&quot;</span>: <span class="number">0</span>,<span class="string">&quot;bulk carrier&quot;</span>: <span class="number">1</span>,<span class="string">&quot;warship&quot;</span>: <span class="number">2</span>,<span class="string">&quot;sailboat&quot;</span>: <span class="number">3</span>,<span class="string">&quot;canoe&quot;</span>: <span class="number">4</span>,<span class="string">&quot;container ship&quot;</span>: <span class="number">5</span>,<span class="string">&quot;fishing boat&quot;</span>: <span class="number">6</span>&#125; <span class="comment">#类别字典</span></span><br><span class="line">    errorId = [] <span class="comment">#脏数据id</span></span><br><span class="line">    train_percent = <span class="number">0.9</span> <span class="comment">#训练集和验证集比例</span></span><br><span class="line">    tococo(box_root, image_root, output_root,classes=classes,errorId=errorId,train_percent=train_percent)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    test()</span><br></pre></td></tr></table></figure>

<h1 id="2-VOC"><a href="#2-VOC" class="headerlink" title="2. VOC"></a>2. VOC</h1><h2 id="2-1-VOC数据集格式"><a href="#2-1-VOC数据集格式" class="headerlink" title="2.1 VOC数据集格式"></a>2.1 VOC数据集格式</h2><p>VOC（Visual Object Classes）数据集来源于PASCAL VOC挑战赛，其主要任务有<code>Object Classification</code> 、<code>Object Detection</code>、<code>Object Segmentation</code>、<code>Human Layout</code>、<code>Action Classification</code>。其官网为<a href="http://host.robots.ox.ac.uk/pascal/VOC/">The PASCAL Visual Object Classes Homepage (ox.ac.uk)</a>。其主要数据集有VOC2007以及VOC2012。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109111939729.png" alt="image-20210911193933398"></p>
<p>VOC数据集主要包含图像（jpg或者png等等）和标注文件（xml），其数据集格式如下(<code>/</code>代表文件夹)：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-VOC/</span><br><span class="line">	|-JPEGImages/</span><br><span class="line">		|-1.jpg</span><br><span class="line">		|-2.jpg</span><br><span class="line">	|-Annotations/</span><br><span class="line">		|-1.xml</span><br><span class="line">		|-2.xml</span><br><span class="line">	|-ImageSets/</span><br><span class="line">		|-Layout/</span><br><span class="line">			|-*.txt</span><br><span class="line">		|-Main/</span><br><span class="line">			|-train.txt</span><br><span class="line">			|-val.txt</span><br><span class="line">			|-trainval.txt</span><br><span class="line">			|-test.txt</span><br><span class="line">		|-Segmentation/</span><br><span class="line">			|-*.txt</span><br><span class="line">		|-Action/</span><br><span class="line">			|-*.txt</span><br><span class="line">	|-SegmentationClass/</span><br><span class="line">	|-SegmentationObject/</span><br></pre></td></tr></table></figure>

<p>其中对于目标检测任务而言，最常用的以及必须的文件夹包括：<code>JPEGImages</code>，<code>Annotations</code>，<code>ImageSets/Main</code>。</p>
<p><code>JPEGImages</code>里存放的是图像，而<code>Annotations</code>里存放的是<code>xml</code>标注文件，文件内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;annotation&gt;</span><br><span class="line">	&lt;folder&gt;VOC&lt;/folder&gt;            # 图像所在文件夹</span><br><span class="line">	&lt;filename&gt;000032.jpg&lt;/filename&gt; # 图像文件名</span><br><span class="line">	&lt;source&gt;                        # 图像源</span><br><span class="line">		&lt;database&gt;The VOC Database&lt;/database&gt;</span><br><span class="line">		&lt;annotation&gt;PASCAL VOC&lt;/annotation&gt;</span><br><span class="line">		&lt;image&gt;flickr&lt;/image&gt;</span><br><span class="line">	&lt;/source&gt;</span><br><span class="line">	&lt;size&gt;                          # 图像尺寸信息</span><br><span class="line">		&lt;width&gt;500&lt;/width&gt;    # 图像宽度</span><br><span class="line">		&lt;height&gt;281&lt;/height&gt;  # 图像高度</span><br><span class="line">		&lt;depth&gt;3&lt;/depth&gt;      # 图像通道数</span><br><span class="line">	&lt;/size&gt;</span><br><span class="line">	&lt;segmented&gt;0&lt;/segmented&gt;  # 图像是否用于分割，0代表不适用，对目标检测而言没关系</span><br><span class="line">	&lt;object&gt;                  # 一个目标对象的信息</span><br><span class="line">		&lt;name&gt;aeroplane&lt;/name&gt;    # 目标的类别名</span><br><span class="line">		&lt;pose&gt;Frontal&lt;/pose&gt;      # 拍摄角度，若无一般为Unspecified</span><br><span class="line">		&lt;truncated&gt;0&lt;/truncated&gt;  # 是否被截断，0表示完整未截断</span><br><span class="line">		&lt;difficult&gt;0&lt;/difficult&gt;  # 是否难以识别，0表示不难识别</span><br><span class="line">		&lt;bndbox&gt;            # 边界框信息</span><br><span class="line">			&lt;xmin&gt;104&lt;/xmin&gt;  # 左上角x</span><br><span class="line">			&lt;ymin&gt;78&lt;/ymin&gt;   # 左上角y</span><br><span class="line">			&lt;xmax&gt;375&lt;/xmax&gt;  # 右下角x</span><br><span class="line">			&lt;ymax&gt;183&lt;/ymax&gt;  # 右下角y</span><br><span class="line">		&lt;/bndbox&gt;</span><br><span class="line">	&lt;/object&gt;</span><br><span class="line">    # 下面是其他目标的信息，这里略掉</span><br><span class="line">	&lt;object&gt;</span><br><span class="line">        其他object信息，这里省略</span><br><span class="line">	&lt;/object&gt;</span><br><span class="line">&lt;/annotation&gt;</span><br></pre></td></tr></table></figure>

<h2 id="2-2-VOC转换脚本"><a href="#2-2-VOC转换脚本" class="headerlink" title="2.2 VOC转换脚本"></a>2.2 VOC转换脚本</h2><p>下面这个脚本，只适用于有图像和xml文件的情况下，coco转voc格式以后有需要再写：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Author    : justlovesmile</span></span><br><span class="line"><span class="comment"># @Date      : 2021/9/8 21:01</span></span><br><span class="line"><span class="keyword">import</span> os,random</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> shutil <span class="keyword">as</span> sh</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mkdir</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        os.mkdir(path)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The path (<span class="subst">&#123;path&#125;</span>) already exists.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tovoc</span>(<span class="params">xmlroot,imgroot,saveroot,errorId=[],classes=&#123;&#125;,tvp=<span class="number">1.0</span>,trp=<span class="number">0.9</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        root：数据集存放根目录</span></span><br><span class="line"><span class="string">    功能：</span></span><br><span class="line"><span class="string">        加载数据，并保存为VOC格式</span></span><br><span class="line"><span class="string">    加载后的格式：</span></span><br><span class="line"><span class="string">    VOC/</span></span><br><span class="line"><span class="string">      Annotations/</span></span><br><span class="line"><span class="string">        - **.xml</span></span><br><span class="line"><span class="string">      JPEGImages/</span></span><br><span class="line"><span class="string">        - **.jpg</span></span><br><span class="line"><span class="string">      ImageSets/</span></span><br><span class="line"><span class="string">        Main/</span></span><br><span class="line"><span class="string">          - train.txt</span></span><br><span class="line"><span class="string">          - test.txt</span></span><br><span class="line"><span class="string">          - val.txt</span></span><br><span class="line"><span class="string">          - trainval.txt</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># assert</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(classes)&gt;<span class="number">0</span></span><br><span class="line">    <span class="comment"># init path</span></span><br><span class="line">    VOC = saveroot</span><br><span class="line">    ann_path = os.path.join(VOC, <span class="string">&#x27;Annotations&#x27;</span>)</span><br><span class="line">    img_path = os.path.join(VOC,<span class="string">&#x27;JPEGImages&#x27;</span>)</span><br><span class="line">    set_path = os.path.join(VOC,<span class="string">&#x27;ImageSets&#x27;</span>)</span><br><span class="line">    txt_path = os.path.join(set_path,<span class="string">&#x27;Main&#x27;</span>)</span><br><span class="line">    <span class="comment"># mkdirs </span></span><br><span class="line">    <span class="keyword">if</span> mkdir(VOC):</span><br><span class="line">        <span class="keyword">if</span> mkdir(ann_path) <span class="keyword">and</span> mkdir(img_path) <span class="keyword">and</span> mkdir(set_path):</span><br><span class="line">            mkdir(txt_path)</span><br><span class="line"></span><br><span class="line">    images = os.listdir(imgroot)</span><br><span class="line">    list_index = <span class="built_in">range</span>(<span class="built_in">len</span>(images))</span><br><span class="line">    <span class="comment">#test and trainval set</span></span><br><span class="line">    trainval_percent = tvp</span><br><span class="line">    train_percent = trp</span><br><span class="line">    val_percent = <span class="number">1</span> - train_percent <span class="keyword">if</span> train_percent&lt;<span class="number">1</span> <span class="keyword">else</span> <span class="number">0.1</span></span><br><span class="line">    total_num = <span class="built_in">len</span>(images)</span><br><span class="line">    trainval_num = <span class="built_in">int</span>(total_num*trainval_percent)</span><br><span class="line">    train_num = <span class="built_in">int</span>(trainval_num*train_percent)</span><br><span class="line">    val_num = <span class="built_in">int</span>(trainval_num*val_percent) <span class="keyword">if</span> train_percent&lt;<span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    trainval = random.sample(list_index,trainval_num)</span><br><span class="line">    train = random.sample(list_index,train_num)</span><br><span class="line">    val = random.sample(list_index,val_num)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(list_index):</span><br><span class="line">        imgfile = images[i]</span><br><span class="line">        img_id = os.path.splitext(os.path.basename(imgfile))[<span class="number">0</span>]</span><br><span class="line">        xmlfile = img_id+<span class="string">&quot;.xml&quot;</span></span><br><span class="line">        sh.copy(os.path.join(imgroot,imgfile),os.path.join(img_path,imgfile))</span><br><span class="line">        sh.copy(os.path.join(xmlroot,xmlfile),os.path.join(ann_path,xmlfile))</span><br><span class="line">        <span class="keyword">if</span> img_id <span class="keyword">not</span> <span class="keyword">in</span> errorId:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> trainval:</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(txt_path,<span class="string">&#x27;trainval.txt&#x27;</span>),<span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    f.write(img_id+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> i <span class="keyword">in</span> train:</span><br><span class="line">                    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(txt_path,<span class="string">&#x27;train.txt&#x27;</span>),<span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                        f.write(img_id+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(txt_path,<span class="string">&#x27;val.txt&#x27;</span>),<span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                        f.write(img_id+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> train_percent==<span class="number">1</span> <span class="keyword">and</span> i <span class="keyword">in</span> val:</span><br><span class="line">                    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(txt_path,<span class="string">&#x27;val.txt&#x27;</span>),<span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                        f.write(img_id+<span class="string">&#x27;\n&#x27;</span>)          </span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(txt_path,<span class="string">&#x27;test.txt&#x27;</span>),<span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    f.write(img_id+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># end</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Dataset to VOC format finished!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    box_root = <span class="string">&quot;E:/MyProject/Dataset/hwtest/annotations&quot;</span></span><br><span class="line">    image_root = <span class="string">&quot;E:/MyProject/Dataset/hwtest/images&quot;</span></span><br><span class="line">    output_root = <span class="string">&quot;E:/MyProject/Dataset/voc&quot;</span></span><br><span class="line">    classes = &#123;<span class="string">&quot;liner&quot;</span>: <span class="number">0</span>,<span class="string">&quot;bulk carrier&quot;</span>: <span class="number">1</span>,<span class="string">&quot;warship&quot;</span>: <span class="number">2</span>,<span class="string">&quot;sailboat&quot;</span>: <span class="number">3</span>,<span class="string">&quot;canoe&quot;</span>: <span class="number">4</span>,<span class="string">&quot;container ship&quot;</span>: <span class="number">5</span>,<span class="string">&quot;fishing boat&quot;</span>: <span class="number">6</span>&#125;</span><br><span class="line">    errorId = []</span><br><span class="line">    train_percent = <span class="number">0.9</span></span><br><span class="line">    tovoc(box_root,image_root,output_root,errorId,classes,trp=train_percent)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    test()</span><br></pre></td></tr></table></figure>

<h1 id="3-YOLO"><a href="#3-YOLO" class="headerlink" title="3. YOLO"></a>3. YOLO</h1><h2 id="3-1-YOLO数据集格式"><a href="#3-1-YOLO数据集格式" class="headerlink" title="3.1 YOLO数据集格式"></a>3.1 YOLO数据集格式</h2><p><code>YOLO</code>数据集格式的出现主要是为了训练<code>YOLO</code>模型，其文件格式没有固定的要求，因为可以通过修改模型的配置文件进行数据加载，唯一需要注意的是<code>YOLO</code>数据集的标注格式是将目标框的位置信息进行归一化处理（此处归一化指的是除以图片宽和高），如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;目标类别&#125; &#123;归一化后的目标中心点x坐标&#125; &#123;归一化后的目标中心点y坐标&#125; &#123;归一化后的目标框宽度w&#125; &#123;归一化后的目标框高度h&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-2-YOLO转换脚本"><a href="#3-2-YOLO转换脚本" class="headerlink" title="3.2 YOLO转换脚本"></a>3.2 YOLO转换脚本</h2><p><code>Python</code>转换脚本如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Author    : justlovesmile</span></span><br><span class="line"><span class="comment"># @Date      : 2021/9/8 20:28</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> shutil <span class="keyword">as</span> sh</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> xml.etree.cElementTree <span class="keyword">as</span> et</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> et</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mkdir</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        os.makedirs(path)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The path (<span class="subst">&#123;path&#125;</span>) already exists.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span>  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xml2yolo</span>(<span class="params">xmlpath,savepath,classes=&#123;&#125;</span>):</span></span><br><span class="line">    namemap = classes</span><br><span class="line">    <span class="comment">#try:</span></span><br><span class="line">    <span class="comment">#    with open(&#x27;classes_yolo.json&#x27;,&#x27;r&#x27;) as f:</span></span><br><span class="line">    <span class="comment">#        namemap=json.load(f)</span></span><br><span class="line">    <span class="comment">#except:</span></span><br><span class="line">    <span class="comment">#    pass</span></span><br><span class="line">    rt = et.parse(xmlpath).getroot()</span><br><span class="line">    w = <span class="built_in">int</span>(rt.find(<span class="string">&quot;size&quot;</span>).find(<span class="string">&quot;width&quot;</span>).text)</span><br><span class="line">    h = <span class="built_in">int</span>(rt.find(<span class="string">&quot;size&quot;</span>).find(<span class="string">&quot;height&quot;</span>).text)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(savepath, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> obj <span class="keyword">in</span> rt.findall(<span class="string">&quot;object&quot;</span>):</span><br><span class="line">            name = obj.find(<span class="string">&quot;name&quot;</span>).text</span><br><span class="line">            xmin = <span class="built_in">int</span>(obj.find(<span class="string">&quot;bndbox&quot;</span>).find(<span class="string">&quot;xmin&quot;</span>).text)</span><br><span class="line">            ymin = <span class="built_in">int</span>(obj.find(<span class="string">&quot;bndbox&quot;</span>).find(<span class="string">&quot;ymin&quot;</span>).text)</span><br><span class="line">            xmax = <span class="built_in">int</span>(obj.find(<span class="string">&quot;bndbox&quot;</span>).find(<span class="string">&quot;xmax&quot;</span>).text)</span><br><span class="line">            ymax = <span class="built_in">int</span>(obj.find(<span class="string">&quot;bndbox&quot;</span>).find(<span class="string">&quot;ymax&quot;</span>).text)</span><br><span class="line">            f.write(</span><br><span class="line">                <span class="string">f&quot;<span class="subst">&#123;namemap[name]&#125;</span> <span class="subst">&#123;(xmin+xmax)/w/<span class="number">2.</span>&#125;</span> <span class="subst">&#123;(ymin+ymax)/h/<span class="number">2.</span>&#125;</span> <span class="subst">&#123;(xmax-xmin)/w&#125;</span> <span class="subst">&#123;(ymax-ymin)/h&#125;</span>&quot;</span></span><br><span class="line">                + <span class="string">&quot;\n&quot;</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainval</span>(<span class="params">xmlroot,imgroot,saveroot,errorId=[],classes=&#123;&#125;,tvp=<span class="number">1.0</span>,trp=<span class="number">0.9</span></span>):</span></span><br><span class="line">    <span class="comment"># assert</span></span><br><span class="line">    <span class="keyword">assert</span> tvp&lt;=<span class="number">1.0</span> <span class="keyword">and</span> trp &lt;=<span class="number">1.0</span> <span class="keyword">and</span> <span class="built_in">len</span>(classes)&gt;<span class="number">0</span></span><br><span class="line">    <span class="comment"># create dirs</span></span><br><span class="line">    imglabel = [<span class="string">&#x27;images&#x27;</span>,<span class="string">&#x27;labels&#x27;</span>]</span><br><span class="line">    trainvaltest = [<span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;val&#x27;</span>,<span class="string">&#x27;test&#x27;</span>]</span><br><span class="line">    mkdir(saveroot)</span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> imglabel:</span><br><span class="line">        mkdir(os.path.join(saveroot,r))</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> trainvaltest:</span><br><span class="line">            mkdir(os.path.join(saveroot,r,s))</span><br><span class="line">    <span class="comment">#train / val</span></span><br><span class="line">    trainval_percent = tvp</span><br><span class="line">    train_percent = trp</span><br><span class="line">    val_percent = <span class="number">1</span> - train_percent <span class="keyword">if</span> train_percent&lt;<span class="number">1.0</span> <span class="keyword">else</span> <span class="number">0.15</span></span><br><span class="line">    </span><br><span class="line">    total_img = os.listdir(imgroot)</span><br><span class="line">    num = <span class="built_in">len</span>(total_img)</span><br><span class="line">    list_index = <span class="built_in">range</span>(num)</span><br><span class="line">    tv = <span class="built_in">int</span>(num * trainval_percent)</span><br><span class="line">    tr = <span class="built_in">int</span>(tv * train_percent)</span><br><span class="line">    va = <span class="built_in">int</span>(tv * val_percent)</span><br><span class="line">    trainval = random.sample(list_index, tv) <span class="comment"># trainset and valset</span></span><br><span class="line">    train = random.sample(trainval, tr) <span class="comment"># trainset</span></span><br><span class="line">    val = random.sample(trainval, va) <span class="comment">#valset, use it only when train_percent = 1 </span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;trainval_percent:<span class="subst">&#123;trainval_percent&#125;</span>,train_percent:<span class="subst">&#123;train_percent&#125;</span>,val_percent:<span class="subst">&#123;val_percent&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(list_index):</span><br><span class="line">        name = total_img[i]</span><br><span class="line">        op = os.path.join(imgroot,name)</span><br><span class="line">        file_id = os.path.splitext(os.path.basename(name))[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> file_id <span class="keyword">not</span> <span class="keyword">in</span> errorId:</span><br><span class="line">            xmlp = os.path.join(xmlroot,file_id+<span class="string">&#x27;.xml&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> trainval:</span><br><span class="line">                <span class="comment"># trainset and valset</span></span><br><span class="line">                <span class="keyword">if</span> i <span class="keyword">in</span> train:</span><br><span class="line">                    sp = os.path.join(saveroot,<span class="string">&quot;images&quot;</span>,<span class="string">&quot;train&quot;</span>,name)</span><br><span class="line">                    xml2yolo(xmlp,os.path.join(saveroot,<span class="string">&quot;labels&quot;</span>,<span class="string">&quot;train&quot;</span>,file_id+<span class="string">&#x27;.txt&#x27;</span>),classes)</span><br><span class="line">                    sh.copy(op,sp)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    sp = os.path.join(saveroot,<span class="string">&quot;images&quot;</span>,<span class="string">&quot;val&quot;</span>,name)</span><br><span class="line">                    xml2yolo(xmlp,os.path.join(saveroot,<span class="string">&quot;labels&quot;</span>,<span class="string">&quot;val&quot;</span>,file_id+<span class="string">&#x27;.txt&#x27;</span>),classes)</span><br><span class="line">                    sh.copy(op,sp)</span><br><span class="line">                <span class="keyword">if</span> (train_percent==<span class="number">1.0</span> <span class="keyword">and</span> i <span class="keyword">in</span> val):</span><br><span class="line">                    sp = os.path.join(saveroot,<span class="string">&quot;images&quot;</span>,<span class="string">&quot;val&quot;</span>,name)</span><br><span class="line">                    xml2yolo(xmlp,os.path.join(saveroot,<span class="string">&quot;labels&quot;</span>,<span class="string">&quot;val&quot;</span>,file_id+<span class="string">&#x27;.txt&#x27;</span>),classes)</span><br><span class="line">                    sh.copy(op,sp)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># testset</span></span><br><span class="line">                sp = os.path.join(saveroot,<span class="string">&quot;images&quot;</span>,<span class="string">&quot;test&quot;</span>,name)</span><br><span class="line">                xml2yolo(xmlp,os.path.join(saveroot,<span class="string">&quot;labels&quot;</span>,<span class="string">&quot;test&quot;</span>,file_id+<span class="string">&#x27;.txt&#x27;</span>),classes)</span><br><span class="line">                sh.copy(op,sp)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maketxt</span>(<span class="params"><span class="built_in">dir</span>,saveroot,filename</span>):</span></span><br><span class="line">    savetxt = os.path.join(saveroot,filename)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(savetxt,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(os.listdir(<span class="built_in">dir</span>)):</span><br><span class="line">            f.write(os.path.join(<span class="built_in">dir</span>,i)+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">                           </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">toyolo</span>(<span class="params">xmlroot,imgroot,saveroot,errorId=[],classes=&#123;&#125;,tvp=<span class="number">1</span>,train_percent=<span class="number">0.9</span></span>):</span></span><br><span class="line">    <span class="comment"># toyolo main function</span></span><br><span class="line">    trainval(xmlroot,imgroot,saveroot,errorId,classes,tvp,train_percent)</span><br><span class="line">    maketxt(os.path.join(saveroot,<span class="string">&quot;images&quot;</span>,<span class="string">&quot;train&quot;</span>),saveroot,<span class="string">&quot;train.txt&quot;</span>)</span><br><span class="line">    maketxt(os.path.join(saveroot,<span class="string">&quot;images&quot;</span>,<span class="string">&quot;val&quot;</span>),saveroot,<span class="string">&quot;val.txt&quot;</span>)</span><br><span class="line">    maketxt(os.path.join(saveroot,<span class="string">&quot;images&quot;</span>,<span class="string">&quot;test&quot;</span>),saveroot,<span class="string">&quot;test.txt&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Dataset to yolo format success.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    box_root = <span class="string">&quot;E:/MyProject/Dataset/hwtest/annotations&quot;</span></span><br><span class="line">    image_root = <span class="string">&quot;E:/MyProject/Dataset/hwtest/images&quot;</span></span><br><span class="line">    output_root = <span class="string">&quot;E:/MyProject/Dataset/yolo&quot;</span></span><br><span class="line">    classes = &#123;<span class="string">&quot;liner&quot;</span>: <span class="number">0</span>,<span class="string">&quot;bulk carrier&quot;</span>: <span class="number">1</span>,<span class="string">&quot;warship&quot;</span>: <span class="number">2</span>,<span class="string">&quot;sailboat&quot;</span>: <span class="number">3</span>,<span class="string">&quot;canoe&quot;</span>: <span class="number">4</span>,<span class="string">&quot;container ship&quot;</span>: <span class="number">5</span>,<span class="string">&quot;fishing boat&quot;</span>: <span class="number">6</span>&#125;</span><br><span class="line">    errorId = []</span><br><span class="line">    train_percent = <span class="number">0.9</span></span><br><span class="line">    toyolo(box_root,image_root,output_root,errorId,classes,train_percent=train_percent)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    test()</span><br></pre></td></tr></table></figure>

<p>按照此脚本，将会在输出文件夹中生成以下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-yolo/</span><br><span class="line">	|-images/</span><br><span class="line">		|-train/</span><br><span class="line">			|-1.jpg</span><br><span class="line">			|-2.jpg</span><br><span class="line">		|-test/</span><br><span class="line">			|-3.jpg</span><br><span class="line">			|-4.jpg</span><br><span class="line">		|-val/</span><br><span class="line">			|-5.jpg</span><br><span class="line">			|-6.jpg</span><br><span class="line">	|-labels/</span><br><span class="line">		|-train/</span><br><span class="line">			|-1.txt</span><br><span class="line">			|-2.txt</span><br><span class="line">		|-test/</span><br><span class="line">			|-3.txt</span><br><span class="line">			|-4.txt</span><br><span class="line">		|-val/</span><br><span class="line">			|-5.txt</span><br><span class="line">			|-6.txt</span><br><span class="line">	|-train.txt</span><br><span class="line">	|-test.txt</span><br><span class="line">	|-val.txt</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>目标检测</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python工具 | pdf转excel的python方法</title>
    <url>/posts/10294.html</url>
    <content><![CDATA[<p>最近不知道写什么了，正好昨天整理了几学期的年级排名，需要pdf转excel，所以百度学习了一下python的pdfplumber库</p>
<span id="more"></span>
<p>但是pdfplumber只能解析规整的完美的表格，那种乱七八糟的格式的表格，就不太行了，好在成绩单除了标题外，还算规整.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber  <span class="comment"># pip install pdfplumber</span></span><br><span class="line"><span class="keyword">from</span> openpyxl <span class="keyword">import</span> Workbook <span class="comment">#pip install openpyxl</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">wb = Workbook()  <span class="comment"># 创建文件对象</span></span><br><span class="line">ws = wb.active  <span class="comment"># 获取第一个sheet</span></span><br><span class="line">path=os.getcwd()+<span class="string">&quot;/2.pdf&quot;</span> <span class="comment">#当前路径下的pdf文件</span></span><br><span class="line">pdf = pdfplumber.<span class="built_in">open</span>(path) <span class="comment">#打开pdf文件</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;开始读取数据&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"><span class="comment">#第一页第一行标题，解析只对规整的表格有用，凸(艹皿艹 )</span></span><br><span class="line"><span class="comment">#ws.append(pdf.pages[0].extract_tables()[0][0])</span></span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> pdf.pages:</span><br><span class="line">    <span class="comment"># 获取当前页面的全部文本信息，包括表格中的文字</span></span><br><span class="line">    <span class="comment">#print(page.extract_text())</span></span><br><span class="line">    <span class="keyword">for</span> table <span class="keyword">in</span> page.extract_tables():</span><br><span class="line">        <span class="comment"># print(table)</span></span><br><span class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> table:</span><br><span class="line">            <span class="comment"># print(row)</span></span><br><span class="line">            <span class="comment">#把列表拆了</span></span><br><span class="line">            rowlist=<span class="built_in">str</span>(row).replace(<span class="string">&quot;[&quot;</span>,<span class="string">&quot;&quot;</span>,).replace(<span class="string">&quot;]&quot;</span>,<span class="string">&quot;&quot;</span>).replace(<span class="string">&quot;&#x27;&quot;</span>,<span class="string">&quot;&quot;</span>).replace(<span class="string">&quot;\\n&quot;</span>,<span class="string">&quot;&quot;</span>).split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">            <span class="comment">#print(rowlist)</span></span><br><span class="line">            ws.append(rowlist)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;---------- 分割线 ----------&#x27;</span>)</span><br><span class="line">pdf.close()</span><br><span class="line"><span class="comment"># 保存Excel表到22.xlsx,直接替换,注意保存</span></span><br><span class="line">endfile=<span class="string">&#x27;22.xlsx&#x27;</span></span><br><span class="line">wb.save(endfile)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;写入excel成功&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;保存位置：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(os.getcwd()+<span class="string">&quot;/&quot;</span>+endfile)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>代码编程</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pdf</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title>Python爬虫 | 如何快速获取LOL英雄皮肤高清图片</title>
    <url>/posts/5271.html</url>
    <content><![CDATA[<ul>
<li>编写爬虫获取英雄联盟所有英雄的全部皮肤<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/lol2019.jpg"><span id="more"></span></li>
</ul>
<blockquote>
<ul>
<li>需要库：<ul>
<li>requests</li>
<li>re</li>
<li>json</li>
<li>os</li>
</ul>
</li>
</ul>
</blockquote>
<ul>
<li>效果：在该代码文件目录下生成n个Hero文件夹保存皮肤图片。<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200722173251.png"></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Date: 2019.11.7</span></span><br><span class="line"><span class="string">Author: Justlovesmile</span></span><br><span class="line"><span class="string">Language: python3</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHtml</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r=requests.get(url)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding=r.apparent_encoding</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(url+<span class="string">&quot;爬取失败！&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        response = r.text</span><br><span class="line">        getInfo(response)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getInfo</span>(<span class="params">res</span>):</span></span><br><span class="line">    lists=re.findall(<span class="string">r&#x27;&quot;keys&quot;:(.*?),&quot;data&quot;&#x27;</span>,res)</span><br><span class="line">    <span class="comment">#print(lists)</span></span><br><span class="line">    hero_id=json.loads(lists[<span class="number">0</span>])</span><br><span class="line">    <span class="comment">#print(hero_id)</span></span><br><span class="line">    <span class="keyword">for</span> hero <span class="keyword">in</span> hero_id.values():</span><br><span class="line">        getSkin(hero)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getSkin</span>(<span class="params">hero</span>):</span></span><br><span class="line">    url=<span class="string">&#x27;https://lol.qq.com/biz/hero/&#x27;</span>+hero+<span class="string">&#x27;.js&#x27;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r=requests.get(url)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding=r.apparent_encoding</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(url+<span class="string">&quot;爬取失败！&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        html=r.text</span><br><span class="line">        num=re.findall(<span class="string">r&#x27;&quot;id&quot;:&quot;(\d&#123;4,6&#125;)&quot;,&quot;num&quot;&#x27;</span>,html)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(num)):</span><br><span class="line">            img_url=<span class="string">&#x27;https://game.gtimg.cn/images/lol/act/img/skin/big&#x27;</span> + num[i] + <span class="string">&#x27;.jpg&#x27;</span></span><br><span class="line">            save_img(hero,img_url)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_img</span>(<span class="params">hero,img_url</span>):</span></span><br><span class="line">    root=hero+<span class="string">&quot;\\&quot;</span></span><br><span class="line">    path=root+img_url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(root):</span><br><span class="line">            os.mkdir(root)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">            r=requests.get(img_url)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(path,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(r.content)</span><br><span class="line">                f.close()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;文件保存成功！&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;文件已存在！&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;爬取失败！&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(img_url+<span class="string">&quot;已下载&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    url=<span class="string">&quot;https://lol.qq.com/biz/hero/champion.js&quot;</span></span><br><span class="line">    getHtml(url)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>代码编程</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>Python爬虫 | 如何获取网易云音乐评论</title>
    <url>/posts/52305.html</url>
    <content><![CDATA[<p>今天看了知乎上的一个问答，关于如何爬取网易云音乐的评论</p>
<span id="more"></span>
<p><a href="https://www.zhihu.com/question/36081767">关于如何爬网易云音乐的评论</a><br>我发现，第一位大佬写的方法，嗯，确实看不懂（虽然不妨碍白嫖），然后我自己试了试，params和encSecKey直接F12+ctrlC/V复制的😂</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">不按照大佬写的加密方法，只能获取第一页的评论/(ㄒoㄒ)/~~</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_song_html</span>(<span class="params">url</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;获取网页HTML&quot;&quot;&quot;</span></span><br><span class="line">        headers=&#123;</span><br><span class="line">                <span class="string">&quot;User-Agent&quot;</span>:<span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36&quot;</span>,</span><br><span class="line">                <span class="string">&quot;Host&quot;</span>:<span class="string">&quot;music.163.com&quot;</span>,</span><br><span class="line">                <span class="string">&quot;Upgrade-Insecure-Requests&quot;</span>:<span class="string">&#x27;1&#x27;</span></span><br><span class="line">        &#125;</span><br><span class="line">        data=&#123;</span><br><span class="line">                <span class="string">&quot;params&quot;</span>: <span class="string">&quot;wFDYU3SUWyoCUekCRy6S6oPwnDHv/2Cvd8zMLZ1TCZexhtvcOGdiZdCw+UC7Y5QKC+7KdMMOZqc2eHjTDFfqVEPwuajKbFwywKKBuxe2gfkYBTNiC02rbZM5OxMM22qhVrZRPZMzAxWZz3t213Ts8A==&quot;</span>,</span><br><span class="line">                <span class="string">&quot;encSecKey&quot;</span>: <span class="string">&quot;b6c67b2c848ef79a5cc0bc0261b6b88b75209276f9f1050091d64731398809b2e0d03081618d9c1a3d442ae1367e7e1a1f54224a6e94fed8eddc3bb337017d0b9f3bb8a274fbf58e8142020b7cbd909f9addf68c674f0232811fa18bf7a1dd90030a5f607ff2c488f20e2aab37dbab1bedff5cfa6684f6e49b69bfc727e943c1&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        song_id=url.split(<span class="string">&quot;=&quot;</span>)[<span class="number">1</span>]</span><br><span class="line">        <span class="string">&quot;&quot;&quot;已知的网易云音乐网页链接&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment">#歌曲</span></span><br><span class="line">        url_so=<span class="string">&quot;http://music.163.com/weapi/v1/resource/comments/R_SO_4_&#123;&#125;?csrf_token=&quot;</span>.<span class="built_in">format</span>(song_id)</span><br><span class="line">        <span class="comment">#专辑</span></span><br><span class="line">        url_al=<span class="string">&quot;https://music.163.com/weapi/v1/resource/comments/R_AL_3_&#123;&#125;?csrf_token=&quot;</span>.<span class="built_in">format</span>(song_id)</span><br><span class="line">        <span class="comment">#电台</span></span><br><span class="line">        url_dj=<span class="string">&quot;https://music.163.com/weapi/v1/resource/comments/A_DJ_1_&#123;&#125;?csrf_token=&quot;</span>.<span class="built_in">format</span>(song_id)</span><br><span class="line">        urls=[url_so,url_al,url_dj]<span class="comment">#常用三个url</span></span><br><span class="line">        answer=<span class="built_in">input</span>(<span class="string">&quot;获取热门评论：1\n获取全部评论：2\n请输入： &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> answer==<span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">                <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">                        <span class="keyword">try</span>:</span><br><span class="line">                                html=requests.post(url,headers=headers,data=data)</span><br><span class="line">                                html.raise_for_status()</span><br><span class="line">                        <span class="keyword">except</span>:</span><br><span class="line">                                <span class="keyword">return</span> <span class="string">&quot;爬取失败！&quot;</span></span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                                get_song_hot_comments(html)</span><br><span class="line">        <span class="keyword">elif</span> answer==<span class="string">&#x27;2&#x27;</span>:</span><br><span class="line">                <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">                        <span class="keyword">try</span>:</span><br><span class="line">                                html=requests.post(url,headers=headers,data=data)</span><br><span class="line">                                html.raise_for_status()</span><br><span class="line">                        <span class="keyword">except</span>:</span><br><span class="line">                                <span class="keyword">return</span> <span class="string">&quot;爬取失败！&quot;</span></span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                                get_song_comments(html)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;输入错误！&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_song_hot_comments</span>(<span class="params">html</span>):</span></span><br><span class="line">        comments = json.loads(html.text)</span><br><span class="line">        hot_comments = comments[<span class="string">&#x27;hotComments&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> hot_comments:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;网易云音乐热门评论.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                                <span class="keyword">for</span> C_list <span class="keyword">in</span> hot_comments:</span><br><span class="line">                                        f.write(<span class="string">&quot;User: &quot;</span>+C_list[<span class="string">&#x27;user&#x27;</span>][<span class="string">&#x27;nickname&#x27;</span>]+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">                                        f.write(<span class="string">&quot;Comment: \n&quot;</span>+C_list[<span class="string">&#x27;content&#x27;</span>]+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">                                        f.write(<span class="string">&quot;\n&quot;</span>+<span class="string">&quot;-&quot;</span>*<span class="number">30</span>+<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;保存热门评论失败！&quot;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;保存热门评论成功！&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_song_comments</span>(<span class="params">html</span>):</span></span><br><span class="line">        comments = json.loads(html.text)</span><br><span class="line">        comments = comments[<span class="string">&#x27;comments&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> comments:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;网易云音乐评论.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                                <span class="keyword">for</span> C_list <span class="keyword">in</span> comments:</span><br><span class="line">                                        f.write(<span class="string">&quot;User: &quot;</span>+C_list[<span class="string">&#x27;user&#x27;</span>][<span class="string">&#x27;nickname&#x27;</span>]+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">                                        f.write(<span class="string">&quot;Comment: \n&quot;</span>+C_list[<span class="string">&#x27;content&#x27;</span>]+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">                                        f.write(<span class="string">&quot;\n&quot;</span>+<span class="string">&quot;-&quot;</span>*<span class="number">30</span>+<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;保存全部评论失败！&quot;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;保存全部评论成功！&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">        url=<span class="built_in">input</span>(<span class="string">&quot;请输入需要获取的音乐网址（仅网易云音乐）: &quot;</span>)</span><br><span class="line">        get_song_html(url)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">        main()</span><br></pre></td></tr></table></figure>

<p>这样好像也可以获取评论，但是只有第一页的评论<br><img src="https://s1.ax1x.com/2020/03/15/88uadI.png" alt="88uadI.png"></p>
<p>之后又看了第二个的评论，发现有没有加密的api<br>，于是在尝试了多个各种评论后发现👇：</p>
<h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#单曲&#123;id&#125;&#123;limit&#125;&#123;offset&#125;</span></span><br><span class="line">url_so=<span class="string">&quot;http://music.163.com/api/v1/resource/comments/R_SO_4_&#123;&#125;?limit=&#123;&#125;&amp;offset=&#123;&#125;&quot;</span></span><br><span class="line"><span class="comment">#专辑</span></span><br><span class="line">url_al=<span class="string">&quot;http://music.163.com/api/v1/resource/comments/R_AL_3_&#123;&#125;?limit=&#123;&#125;&amp;offset=&#123;&#125;&quot;</span></span><br><span class="line"><span class="comment">#电台</span></span><br><span class="line">url_dj=<span class="string">&quot;http://music.163.com/api/v1/resource/comments/A_DJ_1_&#123;&#125;?limit=&#123;&#125;&amp;offset=&#123;&#125;&quot;</span></span><br><span class="line"><span class="comment">#视频</span></span><br><span class="line">url_vi=<span class="string">&quot;http://music.163.com/api/v1/resource/comments/R_VI_62_&#123;&#125;?limit=&#123;&#125;&amp;offset=&#123;&#125;&quot;</span></span><br><span class="line"><span class="comment">#MV</span></span><br><span class="line">url_mv=<span class="string">&quot;http://music.163.com/api/v1/resource/comments/R_MV_5_&#123;&#125;?limit=&#123;&#125;&amp;offset=&#123;&#125;&quot;</span></span><br><span class="line"><span class="comment">#歌单</span></span><br><span class="line">url_pl<span class="string">&quot;http://music.163.com/api/v1/resource/comments/A_PL_0_&#123;&#125;?limit=&#123;&#125;&amp;offset=&#123;&#125;&quot;</span></span><br><span class="line"><span class="comment">#事件（这个好像比较特殊，有id和uid）</span></span><br><span class="line">url_ev=<span class="string">&quot;http://music.163.com/api/v1/resource/comments/A_EV_2_&#123;&#125;_&#123;&#125;?limit=&#123;&#125;&amp;offset=&#123;&#125;&quot;</span></span><br></pre></td></tr></table></figure>
<p>这些url对应都是评论，limit是一页的数量，offset就是偏移量=（评论页数-1） * limit<br><img src="https://s1.ax1x.com/2020/03/15/88l2cT.png" alt="88l2cT.png"></p>
<p>如何爬网易云音乐的评论数？ - 知乎<br><a href="https://www.zhihu.com/question/36081767">https://www.zhihu.com/question/36081767</a></p>
]]></content>
      <categories>
        <category>代码编程</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客 | 如何让Butterfly主题导航栏居中</title>
    <url>/posts/56b0563d.html</url>
    <content><![CDATA[<p>最近有很多小伙伴留言问我ButterFly主题的<strong>导航栏是怎么居中的</strong>，说实话我的博客样式其实都是一点一点从其他博主的博客那模仿来的（如果我没记错的话，导航栏应该是看的<a href="https://blog.zhheo.com/">Heo大佬</a>的），所以样式修改的时间跨度有点长，我自己也不太清楚具体改了哪些地方，但是鉴于问的小伙伴太多，我决定把导航栏文件全部展示出来，至于CSS可以参考我的<a href="/css/justlovesmile.css">css文件</a>第168到434行（当前时间2022/3/15，不排除之后我又改了）……</p>
<h2 id="主题模板文件"><a href="#主题模板文件" class="headerlink" title="主题模板文件"></a>主题模板文件</h2><h3 id="index-pug"><a href="#index-pug" class="headerlink" title="index.pug"></a>index.pug</h3><p><code>themes\butterfly\layout\includes\header\index.pug</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if !theme.disable_top_img &amp;&amp; page.top_img !== false</span><br><span class="line">  if is_post()</span><br><span class="line">    - var top_img = page.top_img || page.cover || page.randomcover</span><br><span class="line">  else if is_page()</span><br><span class="line">    - var top_img = page.top_img || theme.default_top_img</span><br><span class="line">  else if is_tag()</span><br><span class="line">    - var top_img = theme.tag_per_img &amp;&amp; theme.tag_per_img[page.tag] </span><br><span class="line">    - top_img = top_img ? top_img : (theme.tag_img !== false ? theme.tag_img || theme.default_top_img : false)</span><br><span class="line">  else if is_category()</span><br><span class="line">    - var top_img = theme.category_per_img &amp;&amp; theme.category_per_img[page.category]</span><br><span class="line">    - top_img = top_img ? top_img : (theme.category_img !== false ? theme.category_img || theme.default_top_img : false)</span><br><span class="line">  else if is_home()</span><br><span class="line">    - var top_img = theme.index_img !== false ? theme.index_img || theme.default_top_img : false</span><br><span class="line">  else if is_archive()</span><br><span class="line">    - var top_img = theme.archive_img !== false ? theme.archive_img || theme.default_top_img : false</span><br><span class="line">  else</span><br><span class="line">    - var top_img = page.top_img || theme.default_top_img</span><br><span class="line"></span><br><span class="line">  if top_img !== false</span><br><span class="line">    - var imgSource = top_img &amp;&amp; top_img.indexOf(&#x27;/&#x27;) !== -1 ? `background-image: url(&#x27;$&#123;url_for(top_img)&#125;&#x27;)` : `background: $&#123;top_img&#125;`</span><br><span class="line">    - var bg_img = top_img ? imgSource : &#x27;&#x27;</span><br><span class="line">    - var site_title = is_archive() ? fragment_cache(&#x27;findArchivesTitle&#x27;, function()&#123;return findArchivesTitle(theme.menu);&#125;) : page.title || page.tag || page.category || config.title</span><br><span class="line">    - var isHomeClass = is_home() ? &#x27;full_page&#x27; : &#x27;not-home-page&#x27;</span><br><span class="line">    - is_post() ? isHomeClass = &#x27;post-bg&#x27; : isHomeClass</span><br><span class="line">  else</span><br><span class="line">    - var isHomeClass = &#x27;not-top-img&#x27;</span><br><span class="line">else</span><br><span class="line">  - var top_img = false</span><br><span class="line">  - var isHomeClass = &#x27;not-top-img&#x27;</span><br><span class="line"></span><br><span class="line">header#page-header(class=isHomeClass style=bg_img)</span><br><span class="line">  !=partial(&#x27;includes/header/nav&#x27;, &#123;&#125;, &#123;cache: true&#125;)</span><br><span class="line">  if top_img !== false</span><br><span class="line">    if is_post()</span><br><span class="line">      #coverdiv.coverdiv</span><br><span class="line">        img#post-cover.cover.entered.loading(alt=&#x27;cover&#x27; src=`$&#123;top_img&#125;`)</span><br><span class="line">      include ./post-info.pug</span><br><span class="line">    else if is_home() </span><br><span class="line">      #site-info</span><br><span class="line">        h1#site-title=site_title</span><br><span class="line">        if theme.subtitle.enable</span><br><span class="line">          - var loadSubJs = true</span><br><span class="line">          #site-subtitle</span><br><span class="line">            span#subtitle</span><br><span class="line">        if(theme.social)</span><br><span class="line">          #site_social_icons</span><br><span class="line">            !=fragment_cache(&#x27;social&#x27;, function()&#123;return partial(&#x27;includes/header/social&#x27;)&#125;)</span><br><span class="line">      #scroll-down</span><br><span class="line">        i.fas.fa-angle-down.scroll-down-effects</span><br><span class="line">    else</span><br><span class="line">      #coverdiv.coverdiv</span><br><span class="line">        img#post-cover.cover.entered.loading(alt=&#x27;cover&#x27; src=`$&#123;top_img&#125;`)</span><br><span class="line">      #page-site-info</span><br><span class="line">        h1#site-title=site_title</span><br></pre></td></tr></table></figure>

<h3 id="nav-pug"><a href="#nav-pug" class="headerlink" title="nav.pug"></a>nav.pug</h3><p><code>themes\butterfly\layout\includes\header\nav.pug</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nav#nav</span><br><span class="line">  #nav-group</span><br><span class="line">    #blog_name</span><br><span class="line">      a#site-name(href=url_for(&#x27;/&#x27;)) #[=config.author]</span><br><span class="line"></span><br><span class="line">    #menus</span><br><span class="line">      !=partial(&#x27;includes/header/menu_item&#x27;, &#123;&#125;, &#123;cache: true&#125;)</span><br><span class="line"></span><br><span class="line">    #nav-right</span><br><span class="line">      if (theme.algolia_search.enable || theme.local_search.enable)</span><br><span class="line">        #search-button</span><br><span class="line">          a.nav-rightbutton.site-page.social-icon.search</span><br><span class="line">            i.fas.fa-search.fa-fw</span><br><span class="line">      #darkmode_navswitch</span><br><span class="line">        a.nav-rightbutton.site-page.darkmode_switchbutton(onclick=&quot;switchDarkMode()&quot;)</span><br><span class="line">          i.fas.fa-adjust</span><br><span class="line">      #toggle-menu</span><br><span class="line">        a.nav-rightbutton.site-page</span><br><span class="line">          i.fas.fa-bars.fa-fw</span><br></pre></td></tr></table></figure>

<p>上面提到的<code>switchDarkMode()</code></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">switchDarkMode</span>(<span class="params"></span>) </span>&#123; <span class="comment">// Switch Between Light And Dark Mode</span></span><br><span class="line">      <span class="keyword">const</span> nowMode = <span class="built_in">document</span>.documentElement.getAttribute(<span class="string">&#x27;data-theme&#x27;</span>) === <span class="string">&#x27;dark&#x27;</span> ? <span class="string">&#x27;dark&#x27;</span> : <span class="string">&#x27;light&#x27;</span></span><br><span class="line">      <span class="keyword">if</span> (nowMode === <span class="string">&#x27;light&#x27;</span>) &#123;</span><br><span class="line">        activateDarkMode()</span><br><span class="line">        saveToLocal.set(<span class="string">&#x27;theme&#x27;</span>, <span class="string">&#x27;dark&#x27;</span>, <span class="number">2</span>)</span><br><span class="line">        GLOBAL_CONFIG.Snackbar !== <span class="literal">undefined</span> &amp;&amp; btf.snackbarShow(GLOBAL_CONFIG.Snackbar.day_to_night)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        activateLightMode()</span><br><span class="line">        saveToLocal.set(<span class="string">&#x27;theme&#x27;</span>, <span class="string">&#x27;light&#x27;</span>, <span class="number">2</span>)</span><br><span class="line">        GLOBAL_CONFIG.Snackbar !== <span class="literal">undefined</span> &amp;&amp; btf.snackbarShow(GLOBAL_CONFIG.Snackbar.night_to_day)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// handle some cases</span></span><br><span class="line">      <span class="keyword">typeof</span> utterancesTheme === <span class="string">&#x27;function&#x27;</span> &amp;&amp; utterancesTheme()</span><br><span class="line">      <span class="keyword">typeof</span> FB === <span class="string">&#x27;object&#x27;</span> &amp;&amp; <span class="built_in">window</span>.loadFBComment()</span><br><span class="line">      <span class="built_in">window</span>.DISQUS &amp;&amp; <span class="built_in">document</span>.getElementById(<span class="string">&#x27;disqus_thread&#x27;</span>).children.length &amp;&amp; <span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> <span class="built_in">window</span>.disqusReset(), <span class="number">200</span>)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h2 id="CSS"><a href="#CSS" class="headerlink" title="CSS"></a>CSS</h2><p>请自行F12查看，截至目前（2022/3/15）导航栏相关css样式是在<a href="/css/justlovesmile.css">/css/justlovesmile.css</a>第168到434行….</p>
<p>其他的之后再补充，有问题的欢迎留言提问</p>
]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>Python工具 | 用python把excel成绩单拼起来</title>
    <url>/posts/18326.html</url>
    <content><![CDATA[<p>接上一篇，昨天除了把pdf转word，还得把几次成绩单拼起来，又去百度了openpyxl的用法，😂</p>
<span id="more"></span>
<p>由于我是一个菜鸟，如果成绩单里有人少了一次成绩，那个人的信息就错位了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> openpyxl <span class="keyword">import</span> Workbook   <span class="comment">#pip install openpyxl</span></span><br><span class="line"><span class="keyword">from</span> openpyxl <span class="keyword">import</span> load_workbook</span><br><span class="line"></span><br><span class="line">ex=&#123;&#125;<span class="comment">#字典</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readexcel</span>(<span class="params">file</span>):</span></span><br><span class="line">	wb=load_workbook(file)<span class="comment">#读取excel</span></span><br><span class="line">	sheet=wb.get_sheet_by_name(wb.get_sheet_names()[<span class="number">0</span>])<span class="comment">#读第一个sheet表单</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;正在打开&quot;</span>+file+<span class="string">&quot;的&quot;</span>+sheet.title)</span><br><span class="line">	ws=wb.active<span class="comment">#激活</span></span><br><span class="line">	<span class="comment">#找一找学号在第几列</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">		nav=[]</span><br><span class="line">		<span class="keyword">for</span> cell <span class="keyword">in</span> <span class="built_in">list</span>(sheet.rows)[i]:</span><br><span class="line">			nav.append(cell.value)</span><br><span class="line">			<span class="comment">#print(nav)</span></span><br><span class="line">		<span class="keyword">if</span> <span class="string">&quot;学号&quot;</span> <span class="keyword">in</span> nav:<span class="comment">#！！！确保键值存在，且前后没有空格</span></span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		index=nav.index(<span class="string">&quot;学号&quot;</span>)</span><br><span class="line">	<span class="keyword">except</span>:</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;Not find key!&quot;</span>)</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	<span class="comment">#读数据</span></span><br><span class="line">	<span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">list</span>(sheet.rows)[i:]:</span><br><span class="line">		rr=[]</span><br><span class="line">		<span class="keyword">for</span> cell <span class="keyword">in</span> row:</span><br><span class="line">			rr.append(cell.value)</span><br><span class="line">		<span class="keyword">if</span> rr[index] <span class="keyword">in</span> ex.keys():</span><br><span class="line">			ex[rr[index]].extend(rr)</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			ex[rr[index]]=rr</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">savefile</span>(<span class="params">f</span>):</span></span><br><span class="line">	path=os.getcwd()+<span class="string">&#x27;/&#x27;</span>+f</span><br><span class="line">	<span class="keyword">if</span>(os.path.exists(path)):</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;Error!File exists.Please delete it!&quot;</span>)</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	wb=Workbook()</span><br><span class="line">	ws = wb.active  <span class="comment"># 默认第一个sheet</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> ex:</span><br><span class="line">		ws.append(ex[i])</span><br><span class="line">	wb.save(f)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">	contents=[]</span><br><span class="line">	<span class="comment">#文件名，不要路径</span></span><br><span class="line">	files=[<span class="string">&#x27;1.xlsx&#x27;</span>,<span class="string">&#x27;2.xlsx&#x27;</span>,<span class="string">&#x27;3.xlsx&#x27;</span>]</span><br><span class="line">	<span class="keyword">for</span> f <span class="keyword">in</span> files:</span><br><span class="line">		readexcel(f)</span><br><span class="line">	<span class="comment">#print(ex)</span></span><br><span class="line">	endfile=<span class="string">&quot;总结.xlsx&quot;</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;正在保存到:&quot;</span>+os.getcwd()+<span class="string">&quot;/&quot;</span>+endfile)</span><br><span class="line">	savefile(endfile)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">	main()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>代码编程</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title>前端利器 | CodePen.io全球百万前端设计师的灵感社区</title>
    <url>/posts/11952.html</url>
    <content><![CDATA[<p>今天发现了一个神仙前端开源网站CodePen,对于我来说,里面的开源项目简直厉害的不要不要的。</p>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gif/twopeople.gif"></p>
<h4 id="CodePen"><a href="#CodePen" class="headerlink" title="CodePen"></a>CodePen</h4><ul>
<li>CodePen是一个完全免费的前端代码托管服务。它的首页每天都会放上很多有趣的好看的项目。😍</li>
<li><a href="https://codepen.io/">官网入口https://codepen.io/</a></li>
<li>引用我在百度上看到的描述：👇</li>
</ul>
<blockquote>
<ul>
<li>与 GitHub Pages 相比，它最重要的优势有：<ul>
<li>即时预览。你甚至可以本地修改并即时预览别人的作品。</li>
<li>支持多种主流预处理器。你从不需要手写生产级别的代码，无论是 Jade 、 LESS 、 Sass ，还是 CoffeeScript 、 es6+（ Babel ），都能尽情使用。</li>
<li>快速添加外部资源文件。只需在输入框里输入库名， CodePen 就会从 cdnjs 上寻找匹配的 css 或 js 库。</li>
<li>免费用户支持创建三个模板，不是每个作品都需要从白板开始。</li>
<li>优秀的外嵌体验，且支持 oEmbed 。在 WordPress 或 Reddit 等支持 oEmbed 的平台上，只要简单地把链接贴入编辑框，发布后会自动转为嵌入作品。<br>当然，它不是 Git ，不能记录提交历史。不过有 fork 功能，通常出于“备份他人优秀作品，防止未来该作品消失了或者变了样子”的目的而使用。</li>
</ul>
</li>
</ul>
</blockquote>
<ul>
<li>希望自己有一天也能写出这么好看的前端🙃！</li>
</ul>
]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>CodePen</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习 | 《深度学习入门之PyTorch》阅读笔记</title>
    <url>/posts/bfa4054.html</url>
    <content><![CDATA[<h1 id="深度学习入门之PyTorch"><a href="#深度学习入门之PyTorch" class="headerlink" title="深度学习入门之PyTorch"></a>深度学习入门之PyTorch</h1><h2 id="第一章-深度学习介绍"><a href="#第一章-深度学习介绍" class="headerlink" title="第一章 深度学习介绍"></a>第一章 深度学习介绍</h2><h3 id="1-1-人工智能"><a href="#1-1-人工智能" class="headerlink" title="1.1 人工智能"></a>1.1 人工智能</h3><ol>
<li>Artificial Intelligence，人工智能，也称机器智能。</li>
<li>人工智能分为三大类<br>（1）弱人工智能：擅长单方面<br>（2）强人工智能：类似人类等级<br>（3）超人工智能：全方面胜过人类</li>
</ol>
<h3 id="1-2-数据挖掘，机器学习和深度学习"><a href="#1-2-数据挖掘，机器学习和深度学习" class="headerlink" title="1.2 数据挖掘，机器学习和深度学习"></a>1.2 数据挖掘，机器学习和深度学习</h3><h4 id="1-2-1-数据挖掘"><a href="#1-2-1-数据挖掘" class="headerlink" title="1.2.1 数据挖掘"></a>1.2.1 数据挖掘</h4><p>KDD（knowledge discovery in database），从数据中获取有意义的信息</p>
<h4 id="1-2-2-机器学习"><a href="#1-2-2-机器学习" class="headerlink" title="1.2.2 机器学习"></a>1.2.2 机器学习</h4><ol>
<li>机器学习是实现人工智能的一种途径，涉及多门学科</li>
<li>大致分为五个大类<br>（1）监督学习：从给定的训练数据集中学习出一个函数，训练集中的目标是由人标注的，常见算法包括回归和分类<br>（2）无监督学习：训练集没有人为标注，常见算法如聚类<br>（3）半监督学习：介于两者之间<br>（4）迁移学习：将已经训练好的模型参数迁移到新的模型来帮助新模型训练数据集<br>（5）增强学习：通过观察周围环境来学习</li>
</ol>
<h4 id="1-2-3-深度学习"><a href="#1-2-3-深度学习" class="headerlink" title="1.2.3 深度学习"></a>1.2.3 深度学习</h4><ol>
<li>机器学习的一个分支，通过模拟人脑来实现数据特征的提取</li>
<li>常见网络结构：DNN，CNN，RNN，GAN等等</li>
</ol>
<h2 id="第二章-深度学习框架"><a href="#第二章-深度学习框架" class="headerlink" title="第二章 深度学习框架"></a>第二章 深度学习框架</h2><h3 id="2-1-深度学习框架介绍"><a href="#2-1-深度学习框架介绍" class="headerlink" title="2.1 深度学习框架介绍"></a>2.1 深度学习框架介绍</h3><ol>
<li>Tensorflow<br>Google开源的基于C++开发的数学计算软件</li>
<li>Caffe</li>
<li>Theano</li>
<li>Torch<br>支持动态图</li>
<li>MXNet</li>
</ol>
<h3 id="2-2-PyTorch介绍"><a href="#2-2-PyTorch介绍" class="headerlink" title="2.2 PyTorch介绍"></a>2.2 PyTorch介绍</h3><h4 id="2-2-1-什么是PyTorch"><a href="#2-2-1-什么是PyTorch" class="headerlink" title="2.2.1 什么是PyTorch"></a>2.2.1 什么是PyTorch</h4><p>Python优先的深度学习框架，支持GPU加速和动态神经网络</p>
<h4 id="2-2-2-为什么使用PyTorch"><a href="#2-2-2-为什么使用PyTorch" class="headerlink" title="2.2.2 为什么使用PyTorch"></a>2.2.2 为什么使用PyTorch</h4><p>1.多学习一个框架准没错<br>2.PyTorch通过一种反向自动求导的技术，可以让你零延迟地改变神经网络<br>3.线性，直观，易于使用<br>4.代码简洁直观，底层代码友好</p>
<h3 id="2-3-配置PyTorch深度学习环境"><a href="#2-3-配置PyTorch深度学习环境" class="headerlink" title="2.3 配置PyTorch深度学习环境"></a>2.3 配置PyTorch深度学习环境</h3><h4 id="2-3-1-操作系统"><a href="#2-3-1-操作系统" class="headerlink" title="2.3.1 操作系统"></a>2.3.1 操作系统</h4><p>Windows，Linux，Mac</p>
<h4 id="2-3-2-Python开发环境的安装"><a href="#2-3-2-Python开发环境的安装" class="headerlink" title="2.3.2 Python开发环境的安装"></a>2.3.2 Python开发环境的安装</h4><p>Anaconda</p>
<h4 id="2-3-3-PyTorch安装"><a href="#2-3-3-PyTorch安装" class="headerlink" title="2.3.3 PyTorch安装"></a>2.3.3 PyTorch安装</h4><p>官网或者anaconda</p>
<p>CPU或GPU</p>
<p>CUDA，CuDnn</p>
<h2 id="第三章-多层全连接神经网络"><a href="#第三章-多层全连接神经网络" class="headerlink" title="第三章 多层全连接神经网络"></a>第三章 多层全连接神经网络</h2><h3 id="3-1-PyTorch基础"><a href="#3-1-PyTorch基础" class="headerlink" title="3.1 PyTorch基础"></a>3.1 PyTorch基础</h3><h4 id="3-1-1-Tensor张量"><a href="#3-1-1-Tensor张量" class="headerlink" title="3.1.1 Tensor张量"></a>3.1.1 Tensor张量</h4><p>Tensor相当于多维的矩阵</p>
<p>Tensor的数据类型有：(32位浮点型)torch.FloatTensor，（64位浮点型）torch.DoubleTensor，（16位整型）torch.ShortTensor,（32位整型）torch.IntTensor，（64位整型）torch.LongTensor</p>
<p><strong>导入pytorch</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>

<p><strong>创建一个没有初始化的5×3矩阵</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=torch.empty(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<p><strong>创建一个随机初始化矩阵</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#均匀分布[0,1],rand</span></span><br><span class="line">x=torch.rand(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">#正态分布，randn</span></span><br><span class="line">x=torch.randn(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<p><strong>构造一个0矩阵，且数据类型为long</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=torch.zeros(<span class="number">5</span>,<span class="number">3</span>,dtype=torch.long)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<p><strong>直接根据数据构造张量</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=torch.tensor([<span class="number">5.5</span>,<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<p><strong>创建一个全为1的矩阵，且数据类型为double</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=torch.ones(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line">x=x.new_ones(<span class="number">5</span>,<span class="number">3</span>,dtype=torch.double)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<p><strong>根据已有tensor建立新的tensor，且除非提供新值，将重用所给张量属性</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=x.new_ones(<span class="number">5</span>,<span class="number">3</span>,dtype=torch.double)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line">x=torch.randn_like(x,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<p><strong>获取张量的形状</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(x.size())</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>注意</strong><br><code>torch.Size</code>本质上还是tuple，所以支持tuple的一切操作</p>
</blockquote>
<p><strong>和numpy的相互转换</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line">numpy_x = x.numpy()</span><br><span class="line"><span class="built_in">print</span>(numpy_x)</span><br><span class="line">torch_x = torch.from_numpy(numpy_x)</span><br><span class="line"><span class="built_in">print</span>(torch_x)</span><br></pre></td></tr></table></figure>

<p><strong>绝对值</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=torch.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line">b=torch.<span class="built_in">abs</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br></pre></td></tr></table></figure>

<p><strong>运算</strong>，例如加法</p>
<p><strong>形式一</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y=torch.rand(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x+y)</span><br></pre></td></tr></table></figure>

<p><strong>形式二</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(torch.add(x,y))</span><br></pre></td></tr></table></figure>

<p><strong>形式三</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result=torch.empty(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">torch.add(x,y,out=result)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<p><strong>形式四</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y.add_(x)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>注意：</strong><br>任何一个in-place改变张量的操作后面都固定一个_。例如x.copy_(y)、x.t_()将更改x</p>
</blockquote>
<p><strong>剪裁</strong>:如果在上下边界内则不变，否则大于上边界值，则改为上边界值，小于下边界值，则改为下边界值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=torch.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line">b=torch.clamp(a,-<span class="number">0.1</span>,<span class="number">0.1</span>)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br></pre></td></tr></table></figure>

<p><strong>除法</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=torch.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b=torch.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">c=torch.div(a,b)</span><br><span class="line">d=torch.div(c,<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="built_in">print</span>(d)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>加法</strong>add，<strong>乘积</strong>mul，<strong>除法</strong>div，<strong>求幂</strong>pow，<strong>矩阵乘法</strong>mm，<strong>矩阵向量乘法</strong>mv</p>
</blockquote>
<p><strong>改变张量形状</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=torch.randn(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">y=x.view(<span class="number">16</span>)</span><br><span class="line">z=x.view(-<span class="number">1</span>,<span class="number">8</span>) <span class="comment"># -1将会自动取值</span></span><br><span class="line"><span class="built_in">print</span>(x.size(),y.size(),z.size())</span><br></pre></td></tr></table></figure>

<p><strong>对于只含一个元素的tensor，可以使用<code>.item()</code>来得到数值</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=torch.randn(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x.item())</span><br></pre></td></tr></table></figure>

<p><strong>使用GPU</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">    y = torch.ones_like(x, device=device)</span><br><span class="line">    x = x.to(device)</span><br><span class="line">    z = x+y</span><br><span class="line">    <span class="built_in">print</span>(z)</span><br><span class="line">    <span class="built_in">print</span>(z.to(<span class="string">&quot;CPU&quot;</span>,torch.double))</span><br></pre></td></tr></table></figure>

<h4 id="3-1-2-Variable（变量）"><a href="#3-1-2-Variable（变量）" class="headerlink" title="3.1.2 Variable（变量）"></a>3.1.2 Variable（变量）</h4><p><strong>1. Autograd：自动求导</strong></p>
<p><strong>创建一个张量并设置requires_grad=True用来追踪其计算历史</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=torch.ones(<span class="number">2</span>,<span class="number">2</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<p><strong>对这个张量做一次运算</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y=x+<span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="comment"># y是计算结果，所以他有grad_fn属性</span></span><br><span class="line"><span class="built_in">print</span>(y.grad_fn)</span><br><span class="line"><span class="comment"># 对y进行更多操作</span></span><br><span class="line">z=y*y*<span class="number">3</span></span><br><span class="line">out=z.mean()</span><br><span class="line"><span class="built_in">print</span>(z,out)</span><br></pre></td></tr></table></figure>

<p>.requires_grad_(…) 改变了现有张量的 requires_grad 标志。如果没有指定的话，默认输入的这个标志是 False。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">a = ((a * <span class="number">3</span>) / (a - <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(a.requires_grad)</span><br><span class="line">a.requires_grad_(<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(a.requires_grad)</span><br><span class="line">b = (a * a).<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(b.grad_fn)</span><br></pre></td></tr></table></figure>

<p><strong>2. 梯度</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=torch.ones(<span class="number">2</span>,<span class="number">2</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">y=x+<span class="number">2</span></span><br><span class="line">z=y*y*<span class="number">3</span></span><br><span class="line">out=z.mean()</span><br><span class="line"><span class="comment"># 现在开始反向传播，因为out是一个标量，则out.backward()和out.backward(torch.tensor(1.))等价</span></span><br><span class="line">out.backward()</span><br><span class="line"><span class="comment">#输出导数d(out)/dx</span></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br></pre></td></tr></table></figure>

<p>即</p>
<p>$$out=\frac{1}{4}\sum_iz_i$$</p>
<p>$$z_i=3(x_i+2)^2$$</p>
<p>并且$ z _ i| _ {x_i=1}=27$，因此，有</p>
<p>$$\frac{\partial_{out}}{\partial_{x_i}}=\frac{3}{2}(x_i+2)$$<br>因此<br>$$\frac{\partial _ {out}}{\partial_ {x_i}}|_ {x_i=1}=\frac{9}{2}=4.5$$</p>
<p><strong>雅可比矩阵</strong></p>
<p>数学上，若有向量值函数y=f(x)，那么y相当于对x的梯度是一个雅可比矩阵（下面是一个latex数学公式）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">J=\begin&#123;bmatrix&#125;</span><br><span class="line">\frac&#123;\partial y_1&#125;&#123;\partial x_1&#125; &amp;\cdots&amp; \frac&#123;\partial y_1&#125;&#123;\partial x_n&#125; \\</span><br><span class="line">\vdots &amp; \ddots &amp; \vdots \\</span><br><span class="line">\frac&#123;\partial y_m&#125;&#123;\partial x_1&#125; &amp;\cdots&amp; \frac&#123;\partial y_m&#125;&#123;\partial x_n&#125;</span><br><span class="line">\end&#123;bmatrix&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211125183936512.png" alt="image-20211125183936512"></p>
<p>通常来说，torch.autograd是计算雅可比向量积的一个引擎。也就是说，给定任意向量v，计算乘积$v^TJ$.如果v恰好是一个标量函数l=g(y)的导数，即$v=(\frac{\partial l}{\partial y_1} \cdots \frac{\partial l}{\partial y_m}^T)$，那么根据链式法则，雅可比向量积应该是l对x的导数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">J^T·v=\begin&#123;bmatrix&#125;</span><br><span class="line">\frac&#123;\partial y_1&#125;&#123;\partial x_1&#125; &amp;\cdots&amp; \frac&#123;\partial y_m&#125;&#123;\partial x_1&#125; \\</span><br><span class="line">\vdots &amp; \ddots &amp; \vdots \\</span><br><span class="line">\frac&#123;\partial y_1&#125;&#123;\partial x_n&#125; &amp;\cdots&amp; \frac&#123;\partial y_m&#125;&#123;\partial x_n&#125;</span><br><span class="line">\end&#123;bmatrix&#125;</span><br><span class="line">\begin&#123;bmatrix&#125;</span><br><span class="line">\frac&#123;\partial l&#125;&#123;\partial y_1&#125;\\</span><br><span class="line">\cdots\\</span><br><span class="line">\frac&#123;\partial l&#125;&#123;\partial y_m&#125;</span><br><span class="line">\end&#123;bmatrix&#125;=</span><br><span class="line">\begin&#123;bmatrix&#125;</span><br><span class="line">\frac&#123;\partial l&#125;&#123;\partial x_1&#125;\\</span><br><span class="line">\cdots\\</span><br><span class="line">\frac&#123;\partial l&#125;&#123;\partial x_n&#125;</span><br><span class="line">\end&#123;bmatrix&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211125184143947.png" alt="image-20211125184143947"></p>
<p>(注意：行向量的$v^T⋅J$也可以被视作列向量的$J^T⋅v$)</p>
<p>雅可比向量积的这一特性使得将外部梯度输入到具有非标量输出的模型中变得非常方便。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=torch.randn(<span class="number">3</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">y=x*<span class="number">2</span></span><br><span class="line"><span class="keyword">while</span> y.data.norm() &lt;<span class="number">1000</span>:</span><br><span class="line">    y=y*<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure>

<p>在这种情况下，y 不再是标量。torch.autograd 不能直接计算完整的雅可比矩阵，但是如果我们只想要雅可比向量积，只需将这个向量作为参数传给 backward</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">v = torch.tensor([<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">0.0001</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">y.backward(v)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br></pre></td></tr></table></figure>

<p>也可以通过将代码块包装在 with torch.no_grad(): 中，来阻止autograd跟踪设置了 .requires_grad=True 的张量的历史记录。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(x.requires_grad)</span><br><span class="line"><span class="built_in">print</span>((x ** <span class="number">2</span>).requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="built_in">print</span>((x ** <span class="number">2</span>).requires_grad)</span><br></pre></td></tr></table></figure>

<p><strong>3. Variable</strong></p>
<p>Variable和Tensor的区别，Variable会被放入计算图中，然后进行前向传播，反向传播，自动求导</p>
<p>Variable是在torch.autograd.Variable中</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line">x=Variable(torch.Tensor([<span class="number">1</span>]),requires_grad=<span class="literal">True</span>)</span><br><span class="line">w=Variable(torch.Tensor([<span class="number">2</span>]),requires_grad=<span class="literal">True</span>)</span><br><span class="line">b=Variable(torch.Tensor([<span class="number">3</span>]),requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y=w*x+b</span><br><span class="line"></span><br><span class="line">y.backward()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"><span class="built_in">print</span>(w.grad)</span><br><span class="line"><span class="built_in">print</span>(b.grad)</span><br></pre></td></tr></table></figure>

<p><strong>搭建一个简单的神经网络</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch_n = <span class="number">100</span> <span class="comment"># 一个批次中输入数据的数量</span></span><br><span class="line">hidden_layer = <span class="number">100</span> <span class="comment"># 经过隐藏层后保留的数据特征的个数</span></span><br><span class="line">input_data = <span class="number">1000</span> <span class="comment"># 每个数据包含的数据量</span></span><br><span class="line">output_data = <span class="number">10</span> <span class="comment"># 每个输出的数据包含的数据量</span></span><br><span class="line"></span><br><span class="line">x=torch.randn(batch_n,input_data) <span class="comment">#100*1000</span></span><br><span class="line">y=torch.randn(batch_n,output_data) <span class="comment">#100*10</span></span><br><span class="line"></span><br><span class="line">w1=torch.randn(input_data,hidden_layer) <span class="comment">#1000*100</span></span><br><span class="line">w2=torch.randn(hidden_layer,output_data) <span class="comment"># 100*10</span></span><br><span class="line"></span><br><span class="line">epoch_n = <span class="number">20</span> <span class="comment">#训练的次数</span></span><br><span class="line">learning_rate = <span class="number">1e-6</span> <span class="comment">#学习率</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epoch_n):</span><br><span class="line">    h1=x.mm(w1)<span class="comment">#100*100</span></span><br><span class="line">    h1=h1.clamp(<span class="built_in">min</span>=<span class="number">0</span>) <span class="comment"># if x&lt;0 ,x=0</span></span><br><span class="line">    y_pred=h1.mm(w2) <span class="comment">#100*10，前向传播预测结果</span></span><br><span class="line">    </span><br><span class="line">    loss = (y_pred - y).<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>() <span class="comment">#损失函数，即均方误差</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Epoch:&#123;&#125;, Loss:&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(epoch,loss))</span><br><span class="line">    grad_y_pred = <span class="number">2</span>*(y_pred-y) <span class="comment">#dloss/dy</span></span><br><span class="line">    grad_w2 = h1.t().mm(grad_y_pred) <span class="comment">#dloss/dy * dy/dw2</span></span><br><span class="line">    </span><br><span class="line">    grad_h = grad_y_pred.clone() <span class="comment">#复制</span></span><br><span class="line">    grad_h = grad_h.mm(w2.t()) <span class="comment">#dloss/dy * dy/dh1</span></span><br><span class="line">    grad_h.clamp_(<span class="built_in">min</span>=<span class="number">0</span>) <span class="comment"># if x&lt;0 ,x=0</span></span><br><span class="line">    grad_w1 = x.t().mm(grad_h) </span><br><span class="line">    </span><br><span class="line">    w1 -= learning_rate*grad_w1 <span class="comment">#梯度下降</span></span><br><span class="line">    w2 -= learning_rate*grad_w2</span><br></pre></td></tr></table></figure>

<p><strong>使用Variable搭建一个自动计算梯度的神经网络</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line">batch_n = <span class="number">100</span> <span class="comment"># 一个批次中输入数据的数量</span></span><br><span class="line">hidden_layer = <span class="number">100</span> <span class="comment"># 经过隐藏层后保留的数据特征的个数</span></span><br><span class="line">input_data = <span class="number">1000</span> <span class="comment"># 每个数据包含的数据量</span></span><br><span class="line">output_data = <span class="number">10</span> <span class="comment"># 每个输出的数据包含的数据量</span></span><br><span class="line"></span><br><span class="line">x=Variable(torch.randn(batch_n,input_data),requires_grad = <span class="literal">False</span>) <span class="comment">#requires_grad = False不保留梯度</span></span><br><span class="line">y=Variable(torch.randn(batch_n,output_data),requires_grad = <span class="literal">False</span>)</span><br><span class="line">w1=Variable(torch.randn(input_data,hidden_layer),requires_grad = <span class="literal">True</span>) <span class="comment">#requires_grad = True自动保留梯度</span></span><br><span class="line">w2=Variable(torch.randn(hidden_layer,output_data),requires_grad = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">epoch_n = <span class="number">20</span></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epoch_n):</span><br><span class="line">    y_pred = x.mm(w1).clamp(<span class="built_in">min</span> = <span class="number">0</span>).mm(w2) <span class="comment">#y_pred=w2*(w1*x)</span></span><br><span class="line">    loss = (y_pred-y).<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>() <span class="comment">#损失函数</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Epoch:&#123;&#125;,Loss:&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(epoch,loss))</span><br><span class="line">    </span><br><span class="line">    loss.backward() <span class="comment">#后向传播计算</span></span><br><span class="line">    </span><br><span class="line">    w1.data -= learning_rate*w1.grad.data</span><br><span class="line">    w2.data -=learning_rate*w2.grad.data</span><br><span class="line">    </span><br><span class="line">    w1.grad.data.zero_() <span class="comment">#置0</span></span><br><span class="line">    w2.grad.data.zero_()</span><br></pre></td></tr></table></figure>

<p><strong>使用nn.Module自定义传播函数来搭建神经网络</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line">batch_n = <span class="number">100</span></span><br><span class="line">hidden_layer = <span class="number">100</span></span><br><span class="line">input_data = <span class="number">1000</span></span><br><span class="line">output_data = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Model,self).__init__()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,input_n,w1,w2</span>):</span></span><br><span class="line">        x = torch.mm(input_n,w1)</span><br><span class="line">        x = torch.clamp(x,<span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line">        x = torch.mm(x,w2)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">model = Model()</span><br><span class="line"></span><br><span class="line">x=Variable(torch.randn(batch_n,input_data),requires_grad = <span class="literal">False</span>) <span class="comment">#requires_grad = False不保留梯度</span></span><br><span class="line">y=Variable(torch.randn(batch_n,output_data),requires_grad = <span class="literal">False</span>)</span><br><span class="line">w1=Variable(torch.randn(input_data,hidden_layer),requires_grad = <span class="literal">True</span>) <span class="comment">#requires_grad = True自动保留梯度</span></span><br><span class="line">w2=Variable(torch.randn(hidden_layer,output_data),requires_grad = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">epoch_n = <span class="number">20</span></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epoch_n):</span><br><span class="line">    y_pred = model(x,w1,w2)</span><br><span class="line">    loss = (y_pred-y).<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Epoch:&#123;&#125;,Loss:&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(epoch,loss))</span><br><span class="line">    loss.backward() <span class="comment">#后向传播计算</span></span><br><span class="line">    </span><br><span class="line">    w1.data -= learning_rate*w1.grad.data</span><br><span class="line">    w2.data -=learning_rate*w2.grad.data</span><br><span class="line">    </span><br><span class="line">    w1.grad.data.zero_() <span class="comment">#置0</span></span><br><span class="line">    w2.grad.data.zero_()</span><br></pre></td></tr></table></figure>

<h4 id="3-1-3-Dataset-数据集"><a href="#3-1-3-Dataset-数据集" class="headerlink" title="3.1.3 Dataset(数据集)"></a>3.1.3 Dataset(数据集)</h4><p>torch.utils.data.Dataset是代表这一数据的抽象类，可以自己定义数据类继承和重写这个抽象类，只需要定义<code>__len__</code>和<code>__getitem__</code>函数即可</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, csv_file, txt_file, root_dir, other_file</span>):</span></span><br><span class="line">        self.csv_data = pd.read_csv(csv_file)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(txt_file, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            data_list=f.readlines()</span><br><span class="line">        self.txt_data = data_list</span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.csv_data)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self,idx</span>):</span></span><br><span class="line">        data = (self.csv_data[idx],self.txt_data[idx])</span><br><span class="line">        <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>

<p>通过上面的方式，可以定义需要的数据类，可以通过迭代的方法取得每一个数据，但是这样很难实现取batch，shuffle或者多线程去读取数据，所以Pytorch中提供了torch.utils.data.DataLoader来定义一个新迭代器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line">dataiter = DataLoader(myDataset,batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure>

<h4 id="3-1-4-nn-Module-模组"><a href="#3-1-4-nn-Module-模组" class="headerlink" title="3.1.4 nn.Module(模组)"></a>3.1.4 nn.Module(模组)</h4><p>所有的层结构和损失函数来自torch.nn</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">net_name</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,other_arguments</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(net_name, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels,out_channels, kernel_size)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p>一个神经网络的典型训练过程如下：</p>
<ul>
<li>定义包含一些可学习参数(或者叫权重）的神经网络</li>
<li>在输入数据集上迭代</li>
<li>通过网络处理输入</li>
<li>计算loss(输出和正确答案的距离）</li>
<li>将梯度反向传播给网络的参数</li>
<li>更新网络的权重，一般使用一个简单的规则：weight = weight - learning_rate * gradient</li>
</ul>
<p><strong>使用torch.nn内的序列容器Sequential</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch_n = <span class="number">100</span></span><br><span class="line">hidden_layer = <span class="number">100</span></span><br><span class="line">input_data = <span class="number">1000</span></span><br><span class="line">output_data = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一种方式</span></span><br><span class="line">models_1 = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(input_data,hidden_layer),</span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(hidden_layer,output_data)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种方式</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">models_2 = torch.nn.Sequential(OrderedDict([</span><br><span class="line">    (<span class="string">&quot;Line1&quot;</span>,torch.nn.Linear(input_data,hidden_layer)),</span><br><span class="line">    (<span class="string">&quot;ReLU1&quot;</span>,torch.nn.ReLU()),</span><br><span class="line">    (<span class="string">&quot;Line2&quot;</span>,torch.nn.Linear(hidden_layer,output_data))])    </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(models_1)</span><br><span class="line"><span class="built_in">print</span>(models_2)</span><br></pre></td></tr></table></figure>

<p><strong>使用nn.Module定义一个神经网络</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        <span class="comment"># 输入图像channel：1；输出channel：6；5x5卷积核</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># an affine operation: y = Wx + b</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 2x2 Max pooling</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># 如果是方阵,则可以只使用一个数字进行定义</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.num_flat_features(x))</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:]  <span class="comment"># 除去批处理维度的其他所有维度</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>

<h4 id="3-1-5-torch-optim-优化"><a href="#3-1-5-torch-optim-优化" class="headerlink" title="3.1.5 torch.optim(优化)"></a>3.1.5 torch.optim(优化)</h4><p>优化算法分为两大类：</p>
<p>（1）一阶优化算法<br>使用各个参数的梯度值来更新参数，最常用的是梯度下降。梯度下降的功能是通过寻找最小值，控制方差，更新模型参数，最终使模型收敛，网络的参数更新公式<br>$$\theta = \theta - \eta × \frac{\partial J(\theta)}{\partial \theta}$$<br>其中$\eta$是学习率，$\frac{\partial J(\theta)}{\partial \theta}$是函数的梯度</p>
<p>（2）二阶优化算法<br>二阶优化算法使用了二阶导数（Hessian方法）来最小化或最大化损失函数，主要是基于牛顿法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer=torch.optim.SGD(model.parameters(),lr=<span class="number">0.01</span>,momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>

<h4 id="3-1-6-模型的保存和加载"><a href="#3-1-6-模型的保存和加载" class="headerlink" title="3.1.6 模型的保存和加载"></a>3.1.6 模型的保存和加载</h4><p>1.保存</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#保存模型</span></span><br><span class="line">torch.save(model,path)</span><br><span class="line"><span class="comment">#保存模型的状态</span></span><br><span class="line">torch.save(model.state_dict(),path)</span><br></pre></td></tr></table></figure>

<p>2.加载</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载完整的模型</span></span><br><span class="line">load_model = torch.load(path)</span><br><span class="line"><span class="comment">#加载模型参数，需要先导入模型的结构</span></span><br><span class="line">model.load_state_dic(torch.load(path))</span><br></pre></td></tr></table></figure>

<h3 id="3-2-线性模型"><a href="#3-2-线性模型" class="headerlink" title="3.2 线性模型"></a>3.2 线性模型</h3><h4 id="3-2-1-介绍"><a href="#3-2-1-介绍" class="headerlink" title="3.2.1 介绍"></a>3.2.1 介绍</h4><p>f(x)=wx+b</p>
<p>f(x)=w1x1+w2x2+…+wdxd+b</p>
<p>w和b都是需要学习的参数</p>
<h4 id="3-2-2-一维线性回归"><a href="#3-2-2-一维线性回归" class="headerlink" title="3.2.2 一维线性回归"></a>3.2.2 一维线性回归</h4><p>给定数据集D={(x1,y1),(x2,y2),…,(xm,ym)}，线性回归希望得到一个f(x)=wx+b能够很好的拟合y</p>
<p>方法是利用$Loss=\sum_{i=1}^m(f(x_i)-y_i)^2$来衡量误差，即均方误差，那么<br>$$(w^*,b^*)=arg\min_{w,b}\sum_{i=1}^m(f(x_i)-y_i)^2=arg\min_{w,b}\sum_{i=1}^m(y_i-wx_i-b)^2$$</p>
<p>求解办法：求它的偏导数,并让其为0来估计参数<br>$$\frac{\partial Loss_{(w,b)}}{\partial w} = 2(w\sum_{i=1}^{m}x_i^2-\sum_{i=1}^{m}(y_i-b)x_i)=0$$<br>$$\frac{\partial Loss_{(w,b)}}{\partial b} = 2(mb-\sum_{i=1}^{m}(y_i-wx_i))=0$$<br>得到w和b的最优解<br>$$w=\frac{\sum_{i=1}^{m}y_i(x_i- \bar x)}{\sum_{i=1}^{m}x_i^2-\frac{1}{m}(\sum_{i=1}^{m}x_i)^2}$$<br>$$b=\frac{1}{m}\sum_{i=1}^{m}(y_i-wx_i)$$<br>其中$\bar x$是x的均值<br>$$\bar x = \frac{1}{m}\sum_{i=1}^{m}x_i$$</p>
<h4 id="3-2-3-多维线性回归"><a href="#3-2-3-多维线性回归" class="headerlink" title="3.2.3 多维线性回归"></a>3.2.3 多维线性回归</h4><p>$$f(x_i)=w^Tx_i+b$$<br>为使得$\sum_{i=1}^{m}(f(x_i)-y_i)^2$最小，这也称为“多元线性回归”，使用最小二乘法对w和b进行估计，假设有d个属性，将w和d写入同一个矩`阵，将数据集D表示成一个m×(d+1)的矩阵X，即</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">X=\begin&#123;bmatrix&#125;</span><br><span class="line">x_&#123;11&#125; &amp; x_&#123;12&#125; &amp; \cdots &amp; x_&#123;1d&#125; &amp; 1 \\</span><br><span class="line">x_&#123;21&#125; &amp; x_&#123;22&#125; &amp; \cdots &amp; x_&#123;2d&#125; &amp; 1 \\</span><br><span class="line">\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\</span><br><span class="line">x_&#123;m1&#125; &amp; x_&#123;m2&#125; &amp; \cdots &amp; x_&#123;md&#125; &amp; 1</span><br><span class="line">\end&#123;bmatrix&#125;=</span><br><span class="line">\begin&#123;bmatrix&#125;</span><br><span class="line">x_1^T &amp; 1\\</span><br><span class="line">x_2^T &amp; 1\\</span><br><span class="line">\vdots &amp; \vdots\\</span><br><span class="line">x_m^T &amp; 1</span><br><span class="line">\end&#123;bmatrix&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211125184508266.png" alt="image-20211125184508266"></p>
<p>将目标y也写成乘向量的形式y=(y1,y2,…,ym),那么可得<br>$$w^* = arg \min_w(y-Xw)^T(y-Xw)$$<br>对其求导，令它为0<br>$$\frac{\partial Loss_w}{\partial w}=2X^T(Xw-y)=0$$</p>
<blockquote>
<p>上面涉及到矩阵的逆运算，所以需要$X^TX$是一个满秩矩阵或者正定矩阵</p>
</blockquote>
<p>可以得到:<br>$$w ^ * =(X^TX)^{-1}X^Ty$$<br>故回归模型可以写成：<br>$$f(x _ i)=x _ i^T(X^TX)^{-1}X^Ty$$</p>
<h4 id="3-2-4-一维线性回归的代码实现"><a href="#3-2-4-一维线性回归的代码实现" class="headerlink" title="3.2.4 一维线性回归的代码实现"></a>3.2.4 一维线性回归的代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x_train = np.array([[<span class="number">3.3</span>],[<span class="number">4.4</span>],[<span class="number">5.5</span>],[<span class="number">6.71</span>],[<span class="number">6.93</span>],[<span class="number">4.168</span>],[<span class="number">9.779</span>],[<span class="number">6.182</span>],[<span class="number">7.59</span>],[<span class="number">2.167</span>],[<span class="number">7.042</span>],[<span class="number">10.791</span>],[<span class="number">5.313</span>],[<span class="number">7.997</span>],[<span class="number">3.1</span>]],dtype=np.float32)</span><br><span class="line">y_train = np.array([[<span class="number">1.7</span>],[<span class="number">2.76</span>],[<span class="number">2.09</span>],[<span class="number">3.19</span>],[<span class="number">1.694</span>],[<span class="number">1.573</span>],[<span class="number">3.366</span>],[<span class="number">2.596</span>],[<span class="number">2.53</span>],[<span class="number">1.221</span>],[<span class="number">2.827</span>],[<span class="number">3.465</span>],[<span class="number">1.65</span>],[<span class="number">2.904</span>],[<span class="number">1.3</span>]],dtype=np.float32)</span><br><span class="line"></span><br><span class="line">x_train = torch.from_numpy(x_train)</span><br><span class="line">y_train = torch.from_numpy(y_train)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearRegression</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LinearRegression,self).__init__() <span class="comment">#继承父类</span></span><br><span class="line">        self.linear = nn.Linear(<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># 1*1</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        out=self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    model = LinearRegression().cuda()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    model = LinearRegression()</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.MSELoss() <span class="comment"># 均方误差</span></span><br><span class="line"><span class="comment">#优化函数，model.parameters()为该实例中可优化的参数，lr为参数优化的选项（学习率等）</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=<span class="number">1e-3</span>) <span class="comment">#梯度下降</span></span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        inputs = Variable(x_train).cuda()</span><br><span class="line">        target = Variable(y_train).cuda()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        inputs = Variable(x_train)</span><br><span class="line">        target = Variable(y_train)</span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    out = model(inputs)</span><br><span class="line">    loss = criterion(out,target) <span class="comment">#均方误差</span></span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    optimizer.zero_grad() <span class="comment">#置0</span></span><br><span class="line">    loss.backward() <span class="comment">#求梯度</span></span><br><span class="line">    optimizer.step() <span class="comment">#更新所有的参数，梯度下降</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(epoch+<span class="number">1</span>)%<span class="number">50</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch[&#123;&#125;/&#123;&#125;],Loss:&#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>,num_epochs,loss))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>() <span class="comment">#将模型变成测试模式</span></span><br><span class="line">predict = model(Variable(x_train))</span><br><span class="line">predict = predict.data.numpy()</span><br><span class="line"><span class="comment">#画图</span></span><br><span class="line"><span class="comment">#plt.plot(x_train.numpy(),y_train.numpy(),&#x27;ro&#x27;,label=&#x27;Original data&#x27;)</span></span><br><span class="line"><span class="comment">#plt.plot(x_train.numpy(),predict,label=&quot;Fitting Line&quot;)</span></span><br><span class="line"><span class="comment">#plt.show()</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201022195143.png"></p>
<h4 id="3-2-5-多项式回归"><a href="#3-2-5-多项式回归" class="headerlink" title="3.2.5 多项式回归"></a>3.2.5 多项式回归</h4><p>对于$y=b+w_1×x+w_2×x^2+w_3×x^3$，预处理数据，变成矩阵形式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">X=\begin&#123;bmatrix&#125;</span><br><span class="line">x_1 &amp; x_1^2 &amp; x_1^3 \\</span><br><span class="line">x_2 &amp; x_2^2 &amp; x_2^3 \\</span><br><span class="line">\vdots &amp; \ddots &amp; \vdots \\</span><br><span class="line">x_n &amp; x_n^2 &amp; x_n^3</span><br><span class="line">\end&#123;bmatrix&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211125184611404.png" alt="image-20211125184611404"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_features</span>(<span class="params">x</span>):</span></span><br><span class="line">    x=x.unsqueeze(<span class="number">1</span>)  <span class="comment"># 在第1维（从0开始）增加一维</span></span><br><span class="line">    <span class="keyword">return</span> torch.cat([x ** i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">4</span>)],<span class="number">1</span>) <span class="comment">#1代表横着拼接x,x^2,x^3</span></span><br><span class="line"></span><br><span class="line">w_target = torch.FloatTensor([<span class="number">0.5</span>,<span class="number">3</span>,<span class="number">2.4</span>]).unsqueeze(<span class="number">1</span>) <span class="comment"># 在第1维（从0开始）加一层</span></span><br><span class="line">b_target = torch.FloatTensor([<span class="number">0.9</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="comment">#定义∑wix^i+b</span></span><br><span class="line">    <span class="keyword">return</span> x.mm(w_target) + b_target[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_batch</span>(<span class="params">batch_size=<span class="number">32</span></span>):</span></span><br><span class="line">    <span class="comment">#产生数据</span></span><br><span class="line">    random = torch.randn(batch_size)</span><br><span class="line">    x = make_features(random)</span><br><span class="line">    y = f(x)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        <span class="keyword">return</span> Variable(x).cuda(),Variable(y).cuda()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> Variable(x),Variable(y)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">poly_model</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(poly_model,self).__init__()</span><br><span class="line">        self.poly = nn.Linear(<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        out = self.poly(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    model = poly_model().cuda()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    model = poly_model()</span><br><span class="line">    </span><br><span class="line">criterion = nn.MSELoss() <span class="comment"># 均方误差</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=<span class="number">1e-3</span>)<span class="comment">#梯度下降</span></span><br><span class="line"></span><br><span class="line">epoch = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    batch_x,batch_y = get_batch()</span><br><span class="line">    <span class="comment">#前向传播</span></span><br><span class="line">    output = model(batch_x)</span><br><span class="line">    loss = criterion(output,batch_y)</span><br><span class="line">    epoch+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">50</span> ==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Epoch:&#123;&#125;,Loss:&#123;:.6f&#125;&quot;</span>.<span class="built_in">format</span>(epoch,loss.data.item()))</span><br><span class="line">    optimizer.zero_grad() <span class="comment">#置0</span></span><br><span class="line">    loss.backward() <span class="comment">#后向传播</span></span><br><span class="line">    optimizer.step() <span class="comment">#优化参数</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> loss &lt;<span class="number">1e-2</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：<br><code>torch.nn</code>只支持小批量处理<code>(mini-batches）</code>。整个<code>torch.nn</code>包只支持小批量样本的输入，不支持单个样本的输入。<br>比如，<code>nn.Conv2d</code> 接受一个4维的张量，即<code>nSamples x nChannels x Height x Width</code>.<br>如果是一个单独的样本，只需要使用<code>input.unsqueeze(0)</code>来添加一个“假的”批大小维度。</p>
</blockquote>
<h3 id="3-3-分类问题"><a href="#3-3-分类问题" class="headerlink" title="3.3 分类问题"></a>3.3 分类问题</h3><h4 id="3-3-1-问题介绍"><a href="#3-3-1-问题介绍" class="headerlink" title="3.3.1 问题介绍"></a>3.3.1 问题介绍</h4><p>机器学习中的监督学习主要分为回归问题和分类问题，对于回归问题，希望预测的结果是连续的，对于分类问题所预测的结果是离散的。</p>
<p>监督学习从数据中学习一个分类模型或者分类决策函数，被称为分类器</p>
<h4 id="3-3-2-Logistic起源"><a href="#3-3-2-Logistic起源" class="headerlink" title="3.3.2 Logistic起源"></a>3.3.2 Logistic起源</h4><p>著名的二分类算法，Logistic回归。起源于对人口数量增长情况的研究</p>
<h4 id="3-3-3-Logistic分布"><a href="#3-3-3-Logistic分布" class="headerlink" title="3.3.3 Logistic分布"></a>3.3.3 Logistic分布</h4><p>设x是连续的随机变量，服从Logistic分布是指X的分布函数和密度函数是如下<br>$$F(x)=P(X≤x)=\frac{1}{1+e^{-(x-\mu)/\gamma}}$$<br>$$f(x)=\frac{e^{-(x-\mu)/\gamma}}{\gamma (1+e^{-(x-\mu)/\gamma})^2}$$<br>其中μ影响中心对称点的位置，γ越小中心点附件的增长速度越快<br>Sigmoid函数是Logistic分布函数中γ=1，μ=0的特殊形式，表达式如下：$$p(x)=\frac{1}{1+e^{-x}}$$</p>
<h4 id="3-3-4-二分类的Logistic回归"><a href="#3-3-4-二分类的Logistic回归" class="headerlink" title="3.3.4 二分类的Logistic回归"></a>3.3.4 二分类的Logistic回归</h4><p>假设输入的数据的特征向量$x∈R^n$，那么决策边界可以表示为$\sum_{i=1}^{n}w_ix_i+b=0$，建设存在一个样本点使得$h_w(x)=\sum_{i=1}^{n}w_ix_i+b&gt;0$，那么判定它的类别是1，如果&lt;0，判定其类别是0.<br>Logistic回归通过找到分类概率P(Y=1)与输入变量x的直接关系，然后通过比较概率值来判断类别，简单来说就是通过计算下面两个概率分布<br>$$P(Y=0|x)=\frac{1}{1+e^{wx+b}}$$<br>$$P(Y=1|x)=\frac{e^{wx+b}}{1+e^{wx+b}}$$<br>其中w是权重，b是偏置</p>
<blockquote>
<p>一个事件发生的几率（odds）是指该事件发生的概率（p）与不发生的概率的比值（1-p），该事件的对数几率或logit函数是：$logit(p)=log\frac{p}{1-p}$</p>
</blockquote>
<p>对于Logistic回归而言，可以得到：<br>$$log \frac{P(Y=1|x)}{1-P(Y=1|x)}=wx+b$$</p>
<h4 id="3-3-5-模型的参数估计"><a href="#3-3-5-模型的参数估计" class="headerlink" title="3.3.5 模型的参数估计"></a>3.3.5 模型的参数估计</h4><p>对于给定的训练集数据T={(x1,y1),(x2,y2),…,(xn,yn)}，其中$x_i \in R^n,y_i \in ${0,1}，假设P(Y=1|x)=Π(x)，那么P(Y=0|x)=1-Π(x)，所以似然函数为：<br>$$\prod_{i=1}^{n}[\pi (x_i)]^{y_1}[1-\pi (x_i)]^{1-y_i}$$<br>取对数后的对数似然函数：<br>$$L(w)=\sum_{i=1}^{n}[y_i(wx_i+b)-log(1+e^{wx_i+b})]$$<br>用L(w)对w求导：<br>$$\frac{\partial L(w)}{\partial w}=\sum_{i=1}^{n}y_ix_i-\sum_{i=1}^{n}\frac{e^{wx_i+b}}{1+e^{wx_i+b}}x_i=\sum_{i=1}^{n}(y_i-logit(wx_i))x_i$$<br>$$\frac{\partial L(w)}{\partial b}=\sum_{i=1}^{n}y_i-\sum_{i=1}^{n}\frac{e^{wx_i+b}}{1+e^{wx_i+b}}=\sum_{i=1}^{n}(y_i-logit(wx_i))$$</p>
<h4 id="3-3-6-Logistic回归的代码实现"><a href="#3-3-6-Logistic回归的代码实现" class="headerlink" title="3.3.6 Logistic回归的代码实现"></a>3.3.6 Logistic回归的代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取数据</span></span><br><span class="line">url=<span class="string">&quot;https://cdn.jsdelivr.net/gh/Justlovesmile/code-of-learn-deep-learning-with-pytorch/chapter3_NN/logistic-regression/data.txt&quot;</span></span><br><span class="line">data = requests.get(url)</span><br><span class="line">data_list=data.text.split(<span class="string">&#x27;\n&#x27;</span>)[:-<span class="number">1</span>]</span><br><span class="line">data_list=[i.split(<span class="string">&#x27;,&#x27;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> data_list]</span><br><span class="line">data = [(<span class="built_in">float</span>(i[<span class="number">0</span>]),<span class="built_in">float</span>(i[<span class="number">1</span>]),<span class="built_in">float</span>(i[<span class="number">2</span>])) <span class="keyword">for</span> i <span class="keyword">in</span> data_list]</span><br><span class="line"></span><br><span class="line">np_data = np.array(data, dtype=<span class="string">&#x27;float32&#x27;</span>) <span class="comment"># 转换成 numpy array</span></span><br><span class="line">x_data = torch.from_numpy(np_data[:, <span class="number">0</span>:<span class="number">2</span>]) <span class="comment"># 转换成 Tensor, 大小是 [100, 2]</span></span><br><span class="line">y_data = torch.from_numpy(np_data[:, -<span class="number">1</span>]).unsqueeze(<span class="number">1</span>) <span class="comment"># 转换成 Tensor，大小是 [100, 1]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#print(x_data,y_data)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#画数据的散点图</span></span><br><span class="line">x0=<span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x:x[-<span class="number">1</span>]==<span class="number">0.0</span>,data))</span><br><span class="line">x1=<span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x:x[-<span class="number">1</span>]==<span class="number">1.0</span>,data))</span><br><span class="line">plot_x0_0 = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> x0]</span><br><span class="line">plot_x0_1 = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> x0]</span><br><span class="line">plot_x1_0 = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> x1]</span><br><span class="line">plot_x1_1 = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> x1]</span><br><span class="line"></span><br><span class="line">plt.plot(plot_x0_0,plot_x0_1,<span class="string">&#x27;ro&#x27;</span>,label=<span class="string">&quot;x_0&quot;</span>) <span class="comment">#0类用红色</span></span><br><span class="line">plt.plot(plot_x1_0,plot_x1_1,<span class="string">&#x27;bo&#x27;</span>,label=<span class="string">&quot;x_1&quot;</span>) <span class="comment">#1类用蓝色</span></span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>) <span class="comment">#图例的位置</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#分类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegression</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LogisticRegression,self).__init__() <span class="comment">#继承</span></span><br><span class="line">        self.lr = nn.Linear(<span class="number">2</span>,<span class="number">1</span>) <span class="comment">#2*1</span></span><br><span class="line">        self.sm = nn.Sigmoid() <span class="comment">#sigmoid函数</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x=self.lr(x)</span><br><span class="line">        x=self.sm(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">logistic_model = LogisticRegression()</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    logistic_model.cuda()</span><br><span class="line"></span><br><span class="line">criterion = nn.BCELoss() <span class="comment">#二分类的损失函数</span></span><br><span class="line"><span class="comment">#随机梯度下降优化，parameters是可优化参数，lr是学习率，momentum是动量因子</span></span><br><span class="line">optimizer = torch.optim.SGD(logistic_model.parameters(),lr=<span class="number">1e-3</span>,momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20000</span>):</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        x=Variable(x_data).cuda()</span><br><span class="line">        y=Variable(y_data).cuda()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x=Variable(x_data)</span><br><span class="line">        y=Variable(y_data)</span><br><span class="line">    <span class="comment">#forward</span></span><br><span class="line">    out = logistic_model(x)</span><br><span class="line">    loss = criterion(out,y)</span><br><span class="line">    mask = out.ge(<span class="number">0.5</span>).<span class="built_in">float</span>() <span class="comment">#if out&gt;0.5,out=1,else out=0</span></span><br><span class="line">    acc = <span class="built_in">float</span>((mask == y_data).<span class="built_in">sum</span>().item()) / y_data.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment">#backward</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="keyword">if</span>(epoch+<span class="number">1</span>)%<span class="number">2000</span> ==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span>*<span class="number">10</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125;,Loss: &#123;:.4f&#125;,Acc: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>,loss,acc))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画线w1x+w2y+b=0</span></span><br><span class="line">w0,w1 = logistic_model.lr.weight[<span class="number">0</span>]</span><br><span class="line">b = logistic_model.lr.bias.data[<span class="number">0</span>]</span><br><span class="line">plot_x = np.arange(<span class="number">30</span>,<span class="number">100</span>,<span class="number">0.1</span>)</span><br><span class="line">w0=w0.data</span><br><span class="line">w1=w1.data</span><br><span class="line">plot_y = (-w0*plot_x-b) /w1</span><br><span class="line">plt.plot(plot_x,plot_y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201023124844.png"></p>
<h3 id="3-4-简单多层全连接前向网络"><a href="#3-4-简单多层全连接前向网络" class="headerlink" title="3.4 简单多层全连接前向网络"></a>3.4 简单多层全连接前向网络</h3><h4 id="3-4-1-模拟神经元"><a href="#3-4-1-模拟神经元" class="headerlink" title="3.4.1 模拟神经元"></a>3.4.1 模拟神经元</h4><p>神经网络就是受到了模拟脑神经元的启发</p>
<h4 id="3-4-2-单层神经网络的分类器"><a href="#3-4-2-单层神经网络的分类器" class="headerlink" title="3.4.2 单层神经网络的分类器"></a>3.4.2 单层神经网络的分类器</h4><p>例如之前的Logistic回归，是使用了sigmoid函数作为激活函数的一层神经网络</p>
<h4 id="3-4-3-激活函数"><a href="#3-4-3-激活函数" class="headerlink" title="3.4.3 激活函数"></a>3.4.3 激活函数</h4><p>1.Sigmoid函数</p>
<p>$$\sigma (x)=\frac{1}{1+e^{-x}}$$</p>
<p>缺点：<br>（1）造成梯度消失。在靠近0，1两端，梯度几乎为0，导致没有信息来更新参数<br>（2）输出不是以0为均值。</p>
<p>2.Tanh</p>
<p>$$tanh(x)=2\sigma(2x)-1$$</p>
<p>Tanh激活函数是sigmoid函数的变形，将输入的数据转化到-1到1之间，解决了sigmoid函数第二个问题，但仍存在梯度消失的问题</p>
<p>3.ReLU</p>
<p>ReLU的数学表达式为$f(x)=max(0,x)$</p>
<p>优点：<br>（1）相比较sigmoid和tanh，ReLU可以极大地加速随机梯度下降法的收敛速度，因为是线性的，不存在梯度消失<br>（2）计算方法更简单</p>
<p>缺点：<br>训练的时候很脆弱，一个很大的梯度经过ReLU激活函数，更新参数之后，会使得这个神经元不会对任何数据有激活现象，之后再经过ReLU的梯度都是0，参数无法更新。可以通过设置较小的学习率来避免这个问题</p>
<p>4.Leaky ReLU</p>
<p>ReLU的变式，为了修复ReLU脆弱的缺点，将x&lt;0的部分变成一个很小的负的斜率，但是效果时好时不好</p>
<p>5.Maxout</p>
<p>$$f(x)=max(w_1x+b_1,w_2x+b_2)$$<br>ReLU只是Maxout中w1=0，b1=0的特殊形式</p>
<p>优点：包含ReLU的优点，避免了ReLU的脆弱性<br>缺点：参数存储变大</p>
<h4 id="3-4-4-神经网络的结构"><a href="#3-4-4-神经网络的结构" class="headerlink" title="3.4.4 神经网络的结构"></a>3.4.4 神经网络的结构</h4><p>神经网络是一个由神经元组成的无环图</p>
<p>nn.Linear(in,out，bias=False)是全连接神经网络层的函数</p>
<h4 id="3-4-5-模型的表示能力与容量"><a href="#3-4-5-模型的表示能力与容量" class="headerlink" title="3.4.5 模型的表示能力与容量"></a>3.4.5 模型的表示能力与容量</h4><p>在实际中，我们可能发现一个三层的全连接神经网络比一个两层的全连接神经网络表现更好，但是更深的网络结构对全连接神经网络效果提升表现不大。<br>我们需要注意的是，增大网络的层数和每层的节点数，相当于在增大网络的容量，容量的增大意味着网络有着更大的潜在表现能力。</p>
<p>但是当我们在做一个二分类问题时，更复杂的模型或许有着更复杂的形状，能将测试用例完美的分类，但是却忽略了潜在的数学关系，将噪声的干扰放大，这种效果被称为过拟合</p>
<h3 id="3-5-深度学习的基石：反向传播算法"><a href="#3-5-深度学习的基石：反向传播算法" class="headerlink" title="3.5 深度学习的基石：反向传播算法"></a>3.5 深度学习的基石：反向传播算法</h3><h4 id="3-5-1-链式法则"><a href="#3-5-1-链式法则" class="headerlink" title="3.5.1 链式法则"></a>3.5.1 链式法则</h4><p>求导的链式法则（高数知识）</p>
<h4 id="3-5-2-反向传播算法"><a href="#3-5-2-反向传播算法" class="headerlink" title="3.5.2 反向传播算法"></a>3.5.2 反向传播算法</h4><p>是链式求导法则的应用</p>
<p>局部求导，不断迭代传播</p>
<h3 id="3-6-各种优化算法的变式"><a href="#3-6-各种优化算法的变式" class="headerlink" title="3.6 各种优化算法的变式"></a>3.6 各种优化算法的变式</h3><h4 id="3-6-1-梯度下降法"><a href="#3-6-1-梯度下降法" class="headerlink" title="3.6.1 梯度下降法"></a>3.6.1 梯度下降法</h4><p>梯度下降的更新公式<br>$$x^i=x^{i-1}-\eta \nabla L(x^{i-1})$$</p>
<h4 id="3-6-2-梯度下降法的变式"><a href="#3-6-2-梯度下降法的变式" class="headerlink" title="3.6.2 梯度下降法的变式"></a>3.6.2 梯度下降法的变式</h4><p>1.SGD<br>随机梯度下降法，每次使用一批（batch）数据进行梯度的计算，而不是全部数据的梯度</p>
<p>2.Momentum<br>在随机梯度下降的同时，增加动量（momentum），帮助跳出一些鞍点或局部极小值点</p>
<p>3.Adagrad<br>自适应学习率的方法，公式是<br>$$w^{t+1}←w^{t}-\frac{\eta}{\sqrt{\sum_{i=0}^{t}(g^i)^2}+\varepsilon }$$</p>
<p>学习率在不断变小，但是在某些情况下会导致学习过早停止</p>
<p>4.RMSprop<br>一种非常有效的自适应学习率的改进方法，公式是<br>$$cache^t=\alpha * cache^{t-1}+(1-\alpha)(g^t)^2$$<br>$$w^{t+1}←w^{t}-\frac{\eta}{\sqrt{cache^t+\varepsilon}}g^t$$<br>其中α是衰减率，能有效避免Adagrad学习率一直递减太多的问题，能够更快地收敛</p>
<p>5.Adam<br>一种综合型学习方法，可以看成RMSprop加上momentum的学习方法</p>
<h3 id="3-7-处理数据和训练模型的技巧"><a href="#3-7-处理数据和训练模型的技巧" class="headerlink" title="3.7 处理数据和训练模型的技巧"></a>3.7 处理数据和训练模型的技巧</h3><h4 id="3-7-1-数据预处理"><a href="#3-7-1-数据预处理" class="headerlink" title="3.7.1 数据预处理"></a>3.7.1 数据预处理</h4><p>1.中心化<br>变成0均值</p>
<p>2.标准化<br>使得每个特征维度的最大值和最小值按比例缩放到-1到1之间</p>
<p>3.PCA（主成分分析）<br>将数据去相关性，将其投影到一个特征空间，取一些较大的，主要的特征向量来降低数据的维度</p>
<p>4.白噪声<br>将数据投影到一个特征空间，然后每个维度除以特征值来标准化这些数据</p>
<h4 id="3-7-2-权重初始化"><a href="#3-7-2-权重初始化" class="headerlink" title="3.7.2 权重初始化"></a>3.7.2 权重初始化</h4><p>1.全0初始化<br>不应该采用这种策略</p>
<p>2.随机初始化<br>包括了高斯随机化，均匀随机化</p>
<p>3.稀疏初始化</p>
<p>4.初始化偏置</p>
<p>5.批标准化</p>
<h4 id="3-7-3-防止过拟合"><a href="#3-7-3-防止过拟合" class="headerlink" title="3.7.3 防止过拟合"></a>3.7.3 防止过拟合</h4><p>1.正则化<br>2.Dropout</p>
<h3 id="3-8-多层全连接神经网络实现MNIST手写数字分类"><a href="#3-8-多层全连接神经网络实现MNIST手写数字分类" class="headerlink" title="3.8 多层全连接神经网络实现MNIST手写数字分类"></a>3.8 多层全连接神经网络实现MNIST手写数字分类</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn,optim</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets,transforms</span><br><span class="line"></span><br><span class="line"><span class="comment">#带有批标准化和激活函数的三层全连接神经网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Batch_Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,in_dim,n_hidden_1,n_hidden_2,out_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Batch_Net,self).__init__()</span><br><span class="line">        self.layer1 = nn.Sequential(nn.Linear(in_dim,n_hidden_1),nn.BatchNorm1d(n_hidden_1),nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1,n_hidden_2),nn.BatchNorm1d(n_hidden_2),nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2,out_dim))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x=self.layer1(x)</span><br><span class="line">        x=self.layer2(x)</span><br><span class="line">        x=self.layer3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line">num_epoch = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#transforms.ToTensor()将图片转换成PyTorch中从处理的对象，并自动将图片标准化了，即范围0到1</span></span><br><span class="line"><span class="comment">#transforms.Normalize(均值，方差)，处理：减均值，除以方差</span></span><br><span class="line"><span class="comment">#图片为灰度图，只有一个通道，如果是三通道则为transforms.Normalize([a,b,c],[d,e,f])</span></span><br><span class="line">data_tf = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),transforms.Normalize([<span class="number">0.5</span>],[<span class="number">0.5</span>])]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据集</span></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">True</span>,transform=data_tf,download=<span class="literal">True</span>)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">False</span>,transform=data_tf)</span><br><span class="line"><span class="comment"># 数据迭代器，传入数据集和batch_size，通过shuffle=True来表示是否将数据打乱</span></span><br><span class="line">train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">model = Batch_Net(<span class="number">28</span>*<span class="number">28</span>,<span class="number">300</span>,<span class="number">100</span>,<span class="number">10</span>)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    model = model.cuda()</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss() <span class="comment">#交叉熵</span></span><br><span class="line"><span class="comment"># 优化</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    eval_loss = <span class="number">0</span></span><br><span class="line">    eval_acc = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_loader:</span><br><span class="line">        img,label=data</span><br><span class="line">        img = img.view(img.size(<span class="number">0</span>),-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            img = Variable(img).cuda()</span><br><span class="line">            label = Variable(label).cuda()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            img = Variable(img)</span><br><span class="line">            label = Variable(label)</span><br><span class="line">        out=model(img)</span><br><span class="line">        loss = criterion(out,label)</span><br><span class="line">        <span class="comment"># backward</span></span><br><span class="line">        optimizer.zero_grad() <span class="comment">#置0</span></span><br><span class="line">        loss.backward() <span class="comment">#求梯度</span></span><br><span class="line">        optimizer.step() <span class="comment">#更新所有的参数，梯度下降</span></span><br><span class="line">        <span class="comment">#acc</span></span><br><span class="line">        eval_loss +=loss*label.size(<span class="number">0</span>)</span><br><span class="line">        _,pred = torch.<span class="built_in">max</span>(out,<span class="number">1</span>)</span><br><span class="line">        num_correct = (pred == label).<span class="built_in">sum</span>()</span><br><span class="line">        eval_acc +=num_correct</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch:&#123;&#125;,Loss: &#123;:.6f&#125;,Acc:&#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch,eval_loss/(<span class="built_in">len</span>(train_dataset)),<span class="built_in">float</span>(eval_acc)/(<span class="built_in">len</span>(train_dataset))))</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"><span class="comment">#测试</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">eval_loss = <span class="number">0</span></span><br><span class="line">eval_acc = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">    img,label=data</span><br><span class="line">    img = img.view(img.size(<span class="number">0</span>),-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        img = Variable(img).cuda()</span><br><span class="line">        label = Variable(label).cuda()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        img = Variable(img)</span><br><span class="line">        label = Variable(label)</span><br><span class="line">    out=model(img)</span><br><span class="line">    loss = criterion(out,label)</span><br><span class="line">    eval_loss +=loss.data*label.size(<span class="number">0</span>)</span><br><span class="line">    _,pred = torch.<span class="built_in">max</span>(out,<span class="number">1</span>)</span><br><span class="line">    num_correct = (pred == label).<span class="built_in">sum</span>()</span><br><span class="line">    eval_acc +=num_correct.data</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Test Loss: &#123;:.6f&#125;,Acc:&#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(eval_loss/(<span class="built_in">len</span>(test_dataset)),<span class="built_in">float</span>(eval_acc)/(<span class="built_in">len</span>(test_dataset))))</span><br></pre></td></tr></table></figure>

<h2 id="第四章-卷积神经网络"><a href="#第四章-卷积神经网络" class="headerlink" title="第四章 卷积神经网络"></a>第四章 卷积神经网络</h2><p>1998年由Yann Lecun提出，2012年Alex Krizhecsky凭借它赢得了ImageNet挑战赛</p>
<h3 id="4-1-主要任务及起源"><a href="#4-1-主要任务及起源" class="headerlink" title="4.1 主要任务及起源"></a>4.1 主要任务及起源</h3><p>对于计算机视觉，主要用提取图像中的特征</p>
<h3 id="4-2-卷积神经网络的原理和结构"><a href="#4-2-卷积神经网络的原理和结构" class="headerlink" title="4.2 卷积神经网络的原理和结构"></a>4.2 卷积神经网络的原理和结构</h3><p>一，卷积神经网络的三种思想</p>
<p>1.局部性</p>
<p>对于图片而言，需要检测图片中的特征来决定图片的类别，通常情况下这些特征都不是由整张图片决定的，而是由一些局部的区域决定的</p>
<p>2.相同性</p>
<p>对不同图片，如果具有同样的特征，这些特征会出现在不同位置，但特征检测所作的操作几乎一样</p>
<p>3.不变性</p>
<p>对于一张大图片，如果进行下采样，那么图片的性质基本保持不变</p>
<p>二，卷积神经网络的层结构</p>
<p>对于全连接神经网络，其由一系列隐藏层构成，每个隐藏层由若干个神经元构成，其中每个神经元都和前一层的所有神经元相关联，但是每一层中的神经元是相互独立的。全连接神经网络在处理图片时，比如在minist数据集上，图片大小是28×28，那么每层的单个神经元的权重数目就是28×28=784，但这知识一张小图片，且只有一个通道，如果是大图片，那么就会导致参数增长特别快，所以全连接神经网络在处理图像并不是好的选择</p>
<p>而卷积神经网络是一个3D容量的神经元，每个神经元由三个维度排列：宽带，高度和深度。如果输入的图片是32×32×3，那么这张图片的宽度就是32，高度也是32，深度是3</p>
<p>卷积神经网络的主要层结构有三个：卷积层，池化层，全连接层，通过堆叠这些层结构形成了一个完整的卷积神经网络结构，其中一些层包含参数（如：卷积层，全连接层），一些层不包含参数（如：激活层，池化层）。</p>
<h4 id="4-2-1-卷积层"><a href="#4-2-1-卷积层" class="headerlink" title="4.2.1 卷积层"></a>4.2.1 卷积层</h4><p>卷积层是卷积神经网络的核心</p>
<p>1.概述</p>
<p>卷积神经网络的参数，是由一些可学习的滤波器集合构成，每个滤波器在空间上（宽度和高度）都比较小，但深度和输入数据的深度保持一致。在前向传播时，让每个滤波器都在输入数据的宽度和高度上滑动（卷积），然后计算整个滤波器和输入数据任意一处的内积。<br>当滤波器沿着输入数据的宽度和高度滑动时，会生成一个二维的激活图。每个卷积层上，会有一整个集合的滤波器，这样会形成多个二维的不同的激活图，将这些激活图在深度方向堆叠起来形成卷积层的输出</p>
<p>2.局部连接</p>
<p>与神经元连接的空间大小叫做神经元的感受野，其大小是一个人为设置的超参数，其实是滤波器的宽和高</p>
<p>3.空间排列</p>
<p>卷积层的输出深度是一个超参数，与使用的滤波器数量一致，并且在滑动滤波器的时候必须指定步长</p>
<p>4.边界填充</p>
<p>可以将输入数据用0在边界进行填充，用来控制输出数据在空间上的尺寸，输出的尺寸可以用一个公式来计算，$\frac{W-F+2P}{S}+1$，其中W是输入的数据大小，F表示卷积层中神经元的感受野尺寸，S表示步长，P表示边界填充0的数量</p>
<p>5.步长的限制</p>
<p>步长的选择是有所限制的。当输入尺寸W是10时，如果不使用0填充，即P=0，滤波器尺寸F=3，这样步长S=2就行不通，因为(10-3+0)/2+1=4.5，不是一个整数，说明神经元不能整齐对称地滑过输入数据体，这样的超参数是无效的</p>
<p>6.参数共享</p>
<p>输出体数据在深度切片上所有的权重都使用同一个权重向量，那么卷积层在向前传播的过程中每个深度切片都可以看成是神经元的权重对输入数据体做卷积，这也就是为什么把这些3D的权重集合称为滤波器或者卷积核</p>
<p>7.总结</p>
<p>卷积层的性质</p>
<ul>
<li>（1）输入数据体尺寸是W1×H1×D1</li>
<li>（2）4个超参数：卷积核数量K，卷积核空间尺寸F，滑动步长S，零填充的数量P</li>
<li>（3）输出数据体的尺寸为W2×H2×D2，其中$W_2=\frac{W_1-F+2P}{S}+1$,$H_2=\frac{H_1-F+2P}{S}+1$,D2=K</li>
<li>（4）由于参数共享，每个卷积核包含的权重数目为F×F×D1，卷积层一共有F×F×D1×K个权重和K个偏置</li>
<li>（5）在输出体数据中，第d个深度切片（空间尺寸是W2×H2），用第d个卷积器和输入数据进行有效卷积运算的结果，再加上第d个偏置</li>
</ul>
<p>对于卷积神经网络的一些超参数，常见的设置是F=3，S=1，P=1</p>
<h4 id="4-2-2-池化层"><a href="#4-2-2-池化层" class="headerlink" title="4.2.2 池化层"></a>4.2.2 池化层</h4><p>通常或者卷积层之间周期性插入一个池化层，作用是逐渐减低数据体的空间尺寸，这样能减少网络中参数的数量，减少计算资源耗费，同时也能有效地控制过拟合</p>
<p>步骤：设定一个空间窗口，不断滑动窗口，取这些窗口中的最大值作为输出结果</p>
<p>池化层之所有有效，是因为之前介绍的图片特征具有不变性，也就是通过下采样不会丢失图片拥有的特征</p>
<p>常用的池化层形式是尺寸为2×2的窗口，滑动步长是2，对图像进行下采样，将其中75%的激活信息都丢掉，选择其中最大的保留，池化层很少引入零填充</p>
<p>除最大值池化外，还有平均池化，或者L2范数池化，实际证明，最大池化效果最好，平均池化一般放在卷积神经网络最后一层</p>
<h4 id="4-2-3-全连接层"><a href="#4-2-3-全连接层" class="headerlink" title="4.2.3 全连接层"></a>4.2.3 全连接层</h4><p>全连接层的每个神经元与前一层所有的神经元全部连接，在这个过程中为了防止过拟合会引入<code>Dropout</code>。在进入全连接层之前，使用全局平均池化能够有效地降低过拟合</p>
<h4 id="4-2-4-卷积神经网络的基本形式"><a href="#4-2-4-卷积神经网络的基本形式" class="headerlink" title="4.2.4 卷积神经网络的基本形式"></a>4.2.4 卷积神经网络的基本形式</h4><p>卷积神经网络最常见的形式就是将一些卷积层和<code>ReLU</code>层放在一起，有可能在<code>ReLU</code>层前面加上批标准化层，随后紧跟池化层，再不断重复，直到图像被缩小到一个足够小的尺寸，然后将特征图展开，连接几层全连接层，最后输出结果</p>
<p>1.小滤波器的有效性</p>
<p>2.网络的尺寸</p>
<p>经验<br>（1）输入层：一般而言，输入层的大小应该能够被2整除很多次，常用的数字包括32，44，96，224<br>（2）卷积层：卷积层应该尽可能使用小尺寸，比如3×3或5×5，滑动步长取1。7×7通常用在第一个面对原始图像的卷积层上<br>（3）池化层：池化层负责对输入的数据空间维度进行下采样，常用的设置使用2×2的感受野做最大值池化，步长取2<br>（4）零填充：零填充的使用可以让卷积层的输入和输出在空间上的维度保持一致</p>
<h3 id="4-3-Pytorch卷积模块"><a href="#4-3-Pytorch卷积模块" class="headerlink" title="4.3 Pytorch卷积模块"></a>4.3 Pytorch卷积模块</h3><h4 id="4-3-1-卷积层"><a href="#4-3-1-卷积层" class="headerlink" title="4.3.1 卷积层"></a>4.3.1 卷积层</h4><p><code>nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,dilation,groups,bias)</code><br>其中</p>
<ul>
<li><code>in_channels</code>对应输入数据体的深度</li>
<li><code>out_channels</code>对应输出数据体的深度</li>
<li><code>kernel_size</code>表示滤波器（卷积核）的大小，例如：<code>kernel_size=3</code>或<code>kernel_size=(3,2)</code></li>
<li><code>stride</code>表示滑动步长，默认<code>1</code></li>
<li><code>padding=0</code>表示四周不进行零填充，<code>padding=1</code>表示四周进行<code>1</code>个像素点的零填充，默认<code>0</code></li>
<li><code>bias</code>是一个布尔值，默认为<code>True</code>，表示使用偏置</li>
<li><code>groups</code>表示输出数据体深度上的联系，默认<code>groups=1</code>，即所有的输出和输入都是相关联的，如果<code>groups=2</code>表示输入的深度被分割成两份，输出的深度也被分割成两份，他们之间分别对应起来，所以要求输出和输入都必须要能被<code>groups</code>整除</li>
<li><code>dilation</code>表示卷积对于输入数据体的空间间隔，默认为<code>1</code></li>
</ul>
<h4 id="4-3-2-池化层"><a href="#4-3-2-池化层" class="headerlink" title="4.3.2 池化层"></a>4.3.2 池化层</h4><p><code>nn.MaxPool2d(kernel_size,stride,padding,dilation,return_indices,ceil_model)</code><br>其中</p>
<ul>
<li><code>kernel_size</code>,<code>stride</code>,<code>padding</code>,<code>dilation</code>和卷积层相同</li>
<li><code>return_indices</code>表示是否返回最大值所处的下标，默认为<code>False</code></li>
<li><code>ceil_mode</code>表示使用一些方格代替层结构，默认<code>False</code></li>
</ul>
<p><code>nn.AvgPool2d()</code>表示均值池化，里面的参数和MaxPool2d类似，但多一个参数<code>count_include_pad</code>表示计算均值的时候是否包含零填充，默认为<code>True</code></p>
<p>其他还有<code>nn.LPPool2d()</code>,<code>nn.AdaptiveMaxPool2d()</code></p>
<p><strong>下面是一个简单的多层卷积神经网络</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleCNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SimpleCNN,self).__init__()</span><br><span class="line">        layer1 = nn.Sequential()</span><br><span class="line">        layer1.add_module(<span class="string">&#x27;conv1&#x27;</span>,nn.Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">3</span>,<span class="number">1</span>,padding=<span class="number">1</span>))</span><br><span class="line">        layer1.add_module(<span class="string">&#x27;relu1&#x27;</span>,nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        layer1.add_module(<span class="string">&#x27;pool1&#x27;</span>,nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">        self.layer1=layer1</span><br><span class="line"></span><br><span class="line">        layer2 = nn.Sequential()</span><br><span class="line">        layer2.add_module(<span class="string">&#x27;conv2&#x27;</span>,nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">3</span>,<span class="number">1</span>,padding=<span class="number">1</span>))</span><br><span class="line">        layer2.add_module(<span class="string">&#x27;relu2&#x27;</span>,nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        layer2.add_module(<span class="string">&#x27;pool2&#x27;</span>,nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">        self.layer2=layer2</span><br><span class="line">        </span><br><span class="line">        layer3 = nn.Sequential()</span><br><span class="line">        layer3.add_module(<span class="string">&#x27;conv3&#x27;</span>,nn.Conv2d(<span class="number">64</span>,<span class="number">128</span>,<span class="number">3</span>,<span class="number">1</span>,padding=<span class="number">1</span>))</span><br><span class="line">        layer3.add_module(<span class="string">&#x27;relu3&#x27;</span>,nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        layer3.add_module(<span class="string">&#x27;pool3&#x27;</span>,nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">        self.layer3=layer3</span><br><span class="line"></span><br><span class="line">        layer4 = nn.Sequential()</span><br><span class="line">        layer4.add_module(<span class="string">&#x27;fc1&#x27;</span>,nn.Linear(<span class="number">2048</span>,<span class="number">512</span>))</span><br><span class="line">        layer4.add_module(<span class="string">&#x27;fc_relu1&#x27;</span>,nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        layer4.add_module(<span class="string">&#x27;fc2&#x27;</span>,nn.Linear(<span class="number">512</span>,<span class="number">64</span>))</span><br><span class="line">        layer4.add_module(<span class="string">&#x27;fc_relu2&#x27;</span>,nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        layer4.add_module(<span class="string">&#x27;fc3&#x27;</span>,nn.Linear(<span class="number">64</span>,<span class="number">10</span>))</span><br><span class="line">        self.layer4=layer4</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        conv1 = self.layer1(x)</span><br><span class="line">        conv2 = self.layer2(conv1)</span><br><span class="line">        conv3 = self.layer3(conv2)</span><br><span class="line">        fc_input = conv3.view(conv3.size(<span class="number">0</span>),-<span class="number">1</span>)</span><br><span class="line">        fc_out = slef.layer4(fc_input)</span><br><span class="line">        <span class="keyword">return</span> fc_out</span><br><span class="line"></span><br><span class="line">model = SimpleCNN()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure>

<h4 id="4-3-3-提取层结构"><a href="#4-3-3-提取层结构" class="headerlink" title="4.3.3 提取层结构"></a>4.3.3 提取层结构</h4><p>nn.Module具有几个重要属性</p>
<ul>
<li><code>children()</code>，会返回下一级模块的迭代器，比如上面这个模型，直会返回在<code>self.layer1</code>,<code>slef.layer2</code>,<code>slef.layer3</code>以及<code>self.layer4</code>上的迭代器，不会返回他们内部的东西</li>
<li><code>modules()</code>，会返回模型中所有模块的迭代器，这样就有了一个好处，即它能够访问到最内层，比如<code>self.layer1.conv1</code>这个模块</li>
<li><code>named_children()</code>和<code>named_modules()</code>不仅会返回模块的迭代器，还会返回网络层的名字</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#提取前面两层</span></span><br><span class="line"><span class="built_in">print</span>(nn.Sequential(*<span class="built_in">list</span>(model.children())[:<span class="number">2</span>]))</span><br></pre></td></tr></table></figure>

<p><strong>提取所有的卷积层</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conv_model = nn.Sequential()</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> model.named_modules():</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(layer[<span class="number">1</span>],nn.Conv2d):</span><br><span class="line">        conv_model.add_module(layer[<span class="number">0</span>].split(<span class="string">&#x27;.&#x27;</span>)[-<span class="number">1</span>],layer[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(conv_model)</span><br></pre></td></tr></table></figure>

<h4 id="4-3-4-提取参数及自定义初始化"><a href="#4-3-4-提取参数及自定义初始化" class="headerlink" title="4.3.4 提取参数及自定义初始化"></a>4.3.4 提取参数及自定义初始化</h4><p><code>nn.Module</code>关于参数的属性</p>
<ul>
<li><code>named_parameters()</code>，给出网络层的名字和参数的迭代器</li>
<li><code>parameters()</code>，给出一个网络的全部参数的迭代器</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(param[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<p><strong>对权重初始化</strong>，因为权重是Variable，只需要取出data属性就能处理</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> model.modules():</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m,nn.Conv2d):</span><br><span class="line">        nn.init.normal(m.weight.data)</span><br><span class="line">        nn.init.xavier_normal(m.weight.data)</span><br><span class="line">        nn.init.kaiming_normal(m.weight.data)<span class="comment">#卷积层参数初始化</span></span><br><span class="line">        m.bias.data.fill_(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m,nn.Linear):</span><br><span class="line">        m.weight.data.normal_()<span class="comment">#全连接层参数初始化</span></span><br></pre></td></tr></table></figure>

<h3 id="4-4-卷积神经网络案例分析"><a href="#4-4-卷积神经网络案例分析" class="headerlink" title="4.4 卷积神经网络案例分析"></a>4.4 卷积神经网络案例分析</h3><h4 id="4-4-1-LeNet"><a href="#4-4-1-LeNet" class="headerlink" title="4.4.1 LeNet"></a>4.4.1 LeNet</h4><p>LeNet是整个卷积神经网络的开山之作，共有7层，其中2层卷积和2层池化层交替出现，最后输出3层全连接层得到整体的效果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Lenet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Lenet,self).__init__()</span><br><span class="line">        layer1 = nn.Sequential()</span><br><span class="line">        layer1.add_module(<span class="string">&#x27;conv1&#x27;</span>,nn.Conv2d(<span class="number">1</span>,<span class="number">6</span>,<span class="number">3</span>,padding=<span class="number">1</span>))</span><br><span class="line">        layer1.add_module(<span class="string">&#x27;pool1&#x27;</span>,nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">        self.layer1 = layer1</span><br><span class="line">        </span><br><span class="line">        layer2 = nn.Sequential()</span><br><span class="line">        layer2.add_module(<span class="string">&#x27;conv2&#x27;</span>,nn.Conv2d(<span class="number">6</span>,<span class="number">16</span>,<span class="number">5</span>))</span><br><span class="line">        layer2.add_module(<span class="string">&#x27;pool2&#x27;</span>,nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">        self.layer2 = layer2</span><br><span class="line">        </span><br><span class="line">        layer3 = nn.Sequential()</span><br><span class="line">        layer3.add_module(<span class="string">&#x27;fc1&#x27;</span>,nn.Linear(<span class="number">400</span>,<span class="number">120</span>))</span><br><span class="line">        layer3.add_module(<span class="string">&#x27;fc2&#x27;</span>,nn.Linear(<span class="number">120</span>,<span class="number">84</span>))</span><br><span class="line">        layer3.add_module(<span class="string">&#x27;fc3&#x27;</span>,nn.Linear(<span class="number">84</span>,<span class="number">10</span>))</span><br><span class="line">        self.layer3 = layer3</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>),-<span class="number">1</span>) <span class="comment"># 将第二次卷积的输出拉伸为一行</span></span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<h4 id="4-4-2-AlexNet"><a href="#4-4-2-AlexNet" class="headerlink" title="4.4.2 AlexNet"></a>4.4.2 AlexNet</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlexNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,num_classes</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(AlexNet,self).__init__()</span><br><span class="line">        self.features = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">64</span>,kernel_size=<span class="number">11</span>,stride=<span class="number">4</span>,padding=<span class="number">2</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>,stride=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>,<span class="number">192</span>,kernel_size=<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>,stride=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">192</span>,<span class="number">384</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>,<span class="number">256</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>,<span class="number">256</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>,stride=<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>*<span class="number">6</span>*<span class="number">6</span>,<span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>,<span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>,num_classes),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>),<span class="number">256</span>*<span class="number">6</span>*<span class="number">6</span>)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<h4 id="4-4-3-VGGNet"><a href="#4-4-3-VGGNet" class="headerlink" title="4.4.3 VGGNet"></a>4.4.3 VGGNet</h4><p>使用了更小的滤波器，同时使用了更深的结构</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGG</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,num_classes</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(VGG,self).__init__()</span><br><span class="line">        self.features = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">64</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>,<span class="number">64</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>,<span class="number">128</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>,<span class="number">128</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>,<span class="number">256</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>,<span class="number">256</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>,<span class="number">256</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>,<span class="number">512</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>,<span class="number">512</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>,<span class="number">512</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>,<span class="number">512</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>,<span class="number">512</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>,<span class="number">512</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">512</span>*<span class="number">7</span>*<span class="number">7</span>,<span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>,<span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>,num_classes),</span><br><span class="line">        )</span><br><span class="line">        self._initialize_weights()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>),-<span class="number">1</span>)</span><br><span class="line">        x = self.classifier(x)</span><br></pre></td></tr></table></figure>

<h4 id="4-4-4-GoogleNet"><a href="#4-4-4-GoogleNet" class="headerlink" title="4.4.4 GoogleNet"></a>4.4.4 GoogleNet</h4><p>也叫InceptionNet，采用了比VGG更深的网络结构，一共22层，但是参数却比AlexNet少了12倍，同时有很高的计算效率，因为它采用了一种很有效的Inception模块，而且没有全连接层。</p>
<p><strong>Inception模块</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicConv2d</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,in_channels,out_channels,**kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(BasicConv2d,self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_channels,out_channels,bias=<span class="literal">False</span>,**kwargs)</span><br><span class="line">        self.bn = nn.BatchNorm2d(out_channels,eps=<span class="number">0.001</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = self.bn(x)</span><br><span class="line">        <span class="keyword">return</span> F.relu(x,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Inception</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,in_channels,pool_features</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Inception,self).__init__()</span><br><span class="line">        self.branch1x1 = BasicConv2d(in_channels,<span class="number">64</span>,kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch5x5_1 = BasicConv2d(in_channels,<span class="number">48</span>,kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch5x5_2 = BasicConv2d(<span class="number">48</span>,<span class="number">64</span>,kernel_size=<span class="number">5</span>,padding=<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        self.branch3x3db1_1 = BasicConv2d(in_channels,<span class="number">64</span>,kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch3x3db1_2 = BasicConv2d(<span class="number">64</span>,<span class="number">96</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line">        self.branch3x3db1_3 = BasicConv2d(<span class="number">96</span>,<span class="number">96</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.branch_pool = BasicConv2d(in_channels,pool_features,kernel_size=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        branch1x1 = self.branch1x1(x)</span><br><span class="line">        </span><br><span class="line">        branch5x5 = self.branch5x5_1(x)</span><br><span class="line">        branch5x5 = self.branch5x5_2(branch5x5)</span><br><span class="line">        </span><br><span class="line">        branch3x3db1 = self.branch3x3db1_1(x)</span><br><span class="line">        branch3x3db1 = self.branch3x3db1_2(branch3x3db1)</span><br><span class="line">        branch3x3db1 = self.branch3x3db1_3(branch3x3db1)</span><br><span class="line">        </span><br><span class="line">        branch_pool = F.avg_pool2d(x,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line">        branch_pool = self.branch_pool(branch_pool)</span><br><span class="line">        </span><br><span class="line">        outputs = [branch1x1,branch5x5,branch3x3db1,branch_pool]</span><br><span class="line">        <span class="keyword">return</span> torch.cat(outputs,<span class="number">1</span>) <span class="comment">#按深度拼接</span></span><br></pre></td></tr></table></figure>

<h4 id="4-4-5-ResNet"><a href="#4-4-5-ResNet" class="headerlink" title="4.4.5 ResNet"></a>4.4.5 ResNet</h4><p>由微软研究院提出，通过残差模块能够成功地训练高达152层深的神经网络</p>
<p>ResNet 最初的设计灵感来自这个问题:在不断加深神经网络的时候，会出现一个Degradation ，即准确率会先上升然后达到饱和，再持续增加深度则会导致模型准确率下降。</p>
<p>这并不是过拟合的问题，因为不仅在验证集上误差增加，训练集本身误差也会增加，假设一个比较浅的网络达到了饱和的准确率，那么在后面加上几个恒等映射层，误差不会增加，也就说更深的模型起码不会使得模型效果下降。</p>
<p>这里提到的使用恒等映射直接将前一层输出传到后面的思想，就是 ResNet 的灵感来源。假设某个神经网络的输入是x， 期望输出是 H(x)，如果直接把输入x传到输出作为初始结果，那么此时需要学习的目标就是 F(x) = H (x) - x<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/20201027143439.png"><br>左边是一个普通的网络，右边是一个 ResNet 的残差学习 单元， ResNet 相当于将学习目 标改变了.不再是学习一个完整的输出H ( x ) ， 而是学习输出和输入的差别H (x) - x，即残差。</p>
<p>除了这些比较出名的以外还有很多。并且并不需要重复造轮子，PyTorch内为我们实现了以上网络，都在<code>torchvision.model</code>里面，并且大部分网络都有预训练好的参数</p>
<h3 id="4-5-再实现MNIST手写数字分类"><a href="#4-5-再实现MNIST手写数字分类" class="headerlink" title="4.5 再实现MNIST手写数字分类"></a>4.5 再实现MNIST手写数字分类</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn,optim</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets,transforms</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CNN,self).__init__()</span><br><span class="line">        self.layer1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>,<span class="number">16</span>,kernel_size=<span class="number">3</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">16</span>),<span class="comment"># 归一化处理，使得数据分布一致，避免梯度消失或梯度爆炸</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.layer2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">16</span>,<span class="number">32</span>,kernel_size=<span class="number">3</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.layer3 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,kernel_size=<span class="number">3</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.layer4 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>,<span class="number">128</span>,kernel_size=<span class="number">3</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">128</span>*<span class="number">4</span>*<span class="number">4</span>,<span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>,<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">128</span>,<span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x  = self.layer1(x)</span><br><span class="line">        x  = self.layer2(x)</span><br><span class="line">        x  = self.layer3(x)</span><br><span class="line">        x  = self.layer4(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>),-<span class="number">1</span>)</span><br><span class="line">        x  = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line">num_epoch = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">data_tf = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),transforms.Normalize([<span class="number">0.5</span>],[<span class="number">0.5</span>])]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据集</span></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">True</span>,transform=data_tf,download=<span class="literal">True</span>)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">False</span>,transform=data_tf)</span><br><span class="line"><span class="comment"># 数据迭代器，传入数据集和batch_size，通过shuffle=True来表示是否将数据打乱</span></span><br><span class="line">train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">model = CNN()</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    model = model.cuda()</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    eval_loss = <span class="number">0.0</span></span><br><span class="line">    eval_acc = <span class="number">0.0</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Epoch &#123;&#125;/&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch,num_epoch))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">20</span>)</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_loader:</span><br><span class="line">        img,label=data</span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            img = Variable(img).cuda()</span><br><span class="line">            label = Variable(label).cuda()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            img = Variable(img)</span><br><span class="line">            label = Variable(label)</span><br><span class="line">        out=model(img)</span><br><span class="line">        loss = criterion(out,label)</span><br><span class="line">        <span class="comment"># backward</span></span><br><span class="line">        optimizer.zero_grad() <span class="comment">#置0</span></span><br><span class="line">        loss.backward() <span class="comment">#求梯度</span></span><br><span class="line">        optimizer.step() <span class="comment">#更新所有的参数，梯度下降</span></span><br><span class="line">        <span class="comment">#acc</span></span><br><span class="line">        eval_loss += loss.data</span><br><span class="line">        _,pred = torch.<span class="built_in">max</span>(out,<span class="number">1</span>)</span><br><span class="line">        eval_acc += (pred == label).<span class="built_in">sum</span>()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch:&#123;&#125;,Loss: &#123;:.4f&#125;,Acc:&#123;:.4f&#125;%&#x27;</span>.<span class="built_in">format</span>(epoch,eval_loss/(<span class="built_in">len</span>(train_dataset)),<span class="number">100</span>*<span class="built_in">float</span>(eval_acc)/(<span class="built_in">len</span>(train_dataset))))</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">PATH=<span class="string">&#x27;./minist_net.pth&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Train finished!&quot;</span>)</span><br><span class="line">torch.save(model.state_dict(), PATH)</span><br></pre></td></tr></table></figure>

<h3 id="4-6-图像增强的方法"><a href="#4-6-图像增强的方法" class="headerlink" title="4.6 图像增强的方法"></a>4.6 图像增强的方法</h3><p>torchvision.transforms包括所有图像增强的方法</p>
<ul>
<li>Scale，对图片的尺寸进行缩小和放大</li>
<li>CenterCrop，对图像正中心进行给定大小的随机裁剪</li>
<li>RandomCrop，对图片进行给定大小的随机裁剪</li>
<li>RandomHorizaontalFlip，对图像进行概率为0.5的随机水平翻转</li>
<li>RandomSizedCrop，首先对图片进行随机尺寸的裁剪，然后对裁剪图片进行一个随即比例的缩放，最后将图片变成给定的大小</li>
<li>Pad，对图片进行边界零填充</li>
</ul>
<p>除此之外，还可以使用OpenCV或者PIL等第三方图形库来实现</p>
<h3 id="4-7-实现cifar10分类"><a href="#4-7-实现cifar10分类" class="headerlink" title="4.7 实现cifar10分类"></a>4.7 实现cifar10分类</h3><p>cifar10数据集中有60000张图片，每张图片的大小都是32×32的三通道彩色图</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据处理</span></span><br><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.Scale(<span class="number">40</span>),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.RandomCrop(<span class="number">32</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">test_transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据集获取</span></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=train_transform)</span><br><span class="line">train_data = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=test_transform)</span><br><span class="line">test_data = torch.utils.data.DataLoader(test_set, batch_size=<span class="number">32</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"><span class="comment">#3×3卷积层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv3x3</span>(<span class="params">in_channel, out_channel, stride=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> nn.Conv2d(in_channel, out_channel, <span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">residual_block</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channel, out_channel, same_shape=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(residual_block, self).__init__()</span><br><span class="line">        self.same_shape = same_shape</span><br><span class="line">        stride = <span class="number">1</span> <span class="keyword">if</span> self.same_shape <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">          </span><br><span class="line">        self.conv1 = conv3x3(in_channel, out_channel, stride=stride)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(out_channel)</span><br><span class="line">          </span><br><span class="line">        self.conv2 = conv3x3(out_channel, out_channel)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_channel)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.same_shape:</span><br><span class="line">            self.conv3 = nn.Conv2d(in_channel, out_channel, <span class="number">1</span>, stride=stride)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = F.relu(self.bn1(out), <span class="literal">True</span>)</span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = F.relu(self.bn2(out), <span class="literal">True</span>)</span><br><span class="line">          </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.same_shape:</span><br><span class="line">            x = self.conv3(x)</span><br><span class="line">        <span class="keyword">return</span> F.relu(x+out, <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">resnet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channel, num_classes</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(resnet, self).__init__()</span><br><span class="line">        self.block1 = nn.Conv2d(in_channel, <span class="number">64</span>, <span class="number">7</span>, <span class="number">2</span>,<span class="number">3</span>) <span class="comment"># 32-7+2*3/2+1=16</span></span><br><span class="line">        self.block2 = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">            residual_block(<span class="number">64</span>, <span class="number">64</span>),</span><br><span class="line">            residual_block(<span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">        )</span><br><span class="line">        self.block3 = nn.Sequential(</span><br><span class="line">            residual_block(<span class="number">64</span>, <span class="number">128</span>, <span class="literal">False</span>),</span><br><span class="line">            residual_block(<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">        )</span><br><span class="line">        self.block4 = nn.Sequential(</span><br><span class="line">            residual_block(<span class="number">128</span>, <span class="number">256</span>, <span class="literal">False</span>),</span><br><span class="line">            residual_block(<span class="number">256</span>, <span class="number">256</span>)</span><br><span class="line">        )</span><br><span class="line">        self.block5 = nn.Sequential(</span><br><span class="line">            residual_block(<span class="number">256</span>, <span class="number">512</span>, <span class="literal">False</span>),</span><br><span class="line">            residual_block(<span class="number">512</span>, <span class="number">512</span>)</span><br><span class="line">        )</span><br><span class="line">        self.avg_pool = nn.AvgPool2d(<span class="number">2</span>)</span><br><span class="line">        self.classifier = nn.Linear(<span class="number">512</span>, num_classes)</span><br><span class="line">          </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.block1(x)</span><br><span class="line">        <span class="comment">#print(x.shape)</span></span><br><span class="line">        x = self.block2(x)</span><br><span class="line">        <span class="comment">#print(x.shape)</span></span><br><span class="line">        x = self.block3(x)</span><br><span class="line">        <span class="comment">#print(x.shape)</span></span><br><span class="line">        x = self.block4(x)</span><br><span class="line">        <span class="comment">#print(x.shape)</span></span><br><span class="line">        x = self.block5(x)</span><br><span class="line">        <span class="comment">#print(x.shape)</span></span><br><span class="line">        x = self.avg_pool(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">PATH = <span class="string">&#x27;./cifar_net.pth&#x27;</span></span><br><span class="line">net = resnet(<span class="number">3</span>, <span class="number">10</span>)</span><br><span class="line"><span class="comment">#if os.path.exists(PATH):</span></span><br><span class="line"><span class="comment">#    net.load_state_dict(torch.load(PATH))</span></span><br><span class="line">criterion = nn.CrossEntropyLoss() <span class="comment">#交叉熵</span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.01</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算正确率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_acc</span>(<span class="params">output, label</span>):</span></span><br><span class="line">    total = output.shape[<span class="number">0</span>]</span><br><span class="line">    _, pred_label = output.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">    num_correct = (pred_label == label).<span class="built_in">sum</span>().data</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(num_correct) / total</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">net, train_data, valid_data, num_epochs, optimizer, criterion</span>):</span></span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        net = net.cuda()</span><br><span class="line">    <span class="comment">#计时</span></span><br><span class="line">    prev_time = datetime.now()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;*&quot;</span>*<span class="number">10</span>)</span><br><span class="line">        train_loss = <span class="number">0.0</span></span><br><span class="line">        train_acc = <span class="number">0.0</span></span><br><span class="line">        net = net.train() <span class="comment">#训练模式</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> train_data:</span><br><span class="line">            im,label = data</span><br><span class="line">            <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">                im = Variable(im.cuda())</span><br><span class="line">                label = Variable(label.cuda())</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                im = Variable(im)</span><br><span class="line">                label = Variable(label)</span><br><span class="line">            <span class="comment">#forward</span></span><br><span class="line">            output = net(im)</span><br><span class="line">            loss = criterion(output, label)</span><br><span class="line">            <span class="comment">#forward</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">               </span><br><span class="line">            train_loss += loss.data</span><br><span class="line">            train_acc += get_acc(output, label)</span><br><span class="line">        <span class="comment">#计时</span></span><br><span class="line">        cur_time = datetime.now()</span><br><span class="line">        h, remainder = <span class="built_in">divmod</span>((cur_time-prev_time).seconds, <span class="number">3600</span>)</span><br><span class="line">        m, s = <span class="built_in">divmod</span>(remainder, <span class="number">60</span>)</span><br><span class="line">        time_str = <span class="string">&quot;Time %02d:%02d:%02d&quot;</span> % (h, m, s)</span><br><span class="line">        <span class="comment">#测试</span></span><br><span class="line">        <span class="keyword">if</span> valid_data <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            valid_loss = <span class="number">0.0</span></span><br><span class="line">            valid_acc = <span class="number">0.0</span></span><br><span class="line">            net = net.<span class="built_in">eval</span>() <span class="comment"># 切换测试模式</span></span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> valid_data:</span><br><span class="line">                im, label = data</span><br><span class="line">                <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">                    im = Variable(im.cuda())</span><br><span class="line">                    label = Variable(label.cuda())</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    im = Variable(im)</span><br><span class="line">                    label = Variable(label)</span><br><span class="line">                output = net(im)</span><br><span class="line">                loss = criterion(output, label)</span><br><span class="line">                valid_loss += loss.item()</span><br><span class="line">                valid_acc += get_acc(output, label)</span><br><span class="line">            epoch_str = (</span><br><span class="line">                <span class="string">&quot;Epoch %d. Train Loss: %f, Train Acc: %f, Valid Loss: %f, Valid Acc: %f, &quot;</span></span><br><span class="line">                % (epoch, train_loss / <span class="built_in">len</span>(train_data),</span><br><span class="line">                   train_acc / <span class="built_in">len</span>(train_data), valid_loss / <span class="built_in">len</span>(valid_data),</span><br><span class="line">                   valid_acc / <span class="built_in">len</span>(valid_data)))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            epoch_str = (<span class="string">&quot;Epoch %d. Train Loss: %f, Train Acc: %f, &quot;</span> %</span><br><span class="line">                         (epoch, train_loss / <span class="built_in">len</span>(train_data),</span><br><span class="line">                          train_acc / <span class="built_in">len</span>(train_data)))</span><br><span class="line">               </span><br><span class="line">        prev_time = cur_time</span><br><span class="line">        <span class="built_in">print</span>(epoch_str + time_str)</span><br><span class="line"></span><br><span class="line">train(net, train_data, test_data, <span class="number">10</span>, optimizer, criterion) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line">torch.save(net.state_dict(), PATH)</span><br></pre></td></tr></table></figure>

<p><strong>测试</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=test_transform)</span><br><span class="line">test_data = torch.utils.data.DataLoader(test_set, batch_size=<span class="number">4</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出图像的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span>(<span class="params">img</span>):</span></span><br><span class="line">    img = img / <span class="number">2</span> + <span class="number">0.5</span>     <span class="comment"># unnormalize</span></span><br><span class="line">    npimg = img.numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">dataiter = <span class="built_in">iter</span>(test_data)</span><br><span class="line">images, labels = dataiter.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">#print(images.shape)</span></span><br><span class="line"><span class="comment"># 输出图片</span></span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;GroundTruth: &#x27;</span>, <span class="string">&#x27; &#x27;</span>.join(<span class="string">&#x27;%5s&#x27;</span> % classes[labels[j]] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)))</span><br><span class="line"></span><br><span class="line">PATH = <span class="string">&#x27;./cifar_net.pth&#x27;</span></span><br><span class="line">net.load_state_dict(torch.load(PATH))</span><br><span class="line"></span><br><span class="line">outputs = net(images)</span><br><span class="line"></span><br><span class="line">_, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Predicted: &#x27;</span>, <span class="string">&#x27; &#x27;</span>.join(<span class="string">&#x27;%5s&#x27;</span> % classes[predicted[j]] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)))</span><br><span class="line"></span><br><span class="line">class_correct = <span class="built_in">list</span>(<span class="number">0.</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line">class_total = <span class="built_in">list</span>(<span class="number">0.</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_data:</span><br><span class="line">        images, labels = data</span><br><span class="line">        outputs = net(images)</span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">        c = (predicted == labels).squeeze()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            label = labels[i]</span><br><span class="line">            class_correct[label] += c[i].item()</span><br><span class="line">            class_total[label] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy of %5s : %2d %%&#x27;</span> % (</span><br><span class="line">        classes[i], <span class="number">100</span> * class_correct[i] / class_total[i]))</span><br></pre></td></tr></table></figure>

<h2 id="第五章-循环神经网络"><a href="#第五章-循环神经网络" class="headerlink" title="第五章 循环神经网络"></a>第五章 循环神经网络</h2><p>RNN，在序列问题和自然语言处理等领域取得很大的成功</p>
<h3 id="5-1-循环神经网络"><a href="#5-1-循环神经网络" class="headerlink" title="5.1 循环神经网络"></a>5.1 循环神经网络</h3><p>卷积神经网络相当于人类的视觉，但是它没有记忆能力，所以它只能处理一种特定的视觉任务，没办法根据以前的记忆来处理新的任务。</p>
<p>循环神经网络的提出便是居于记忆模型的想法，期望网络能够记住前面出现的特征，并依据特征推断后面的结果，而且整体的网络结构不断循环，因而得名循环神经网络</p>
<p>比如：某一个单词的意思会因为上文提到的内容不同而有不同的含义，RNN可以很好的解决这类问题</p>
<h4 id="5-1-1-问题介绍"><a href="#5-1-1-问题介绍" class="headerlink" title="5.1.1 问题介绍"></a>5.1.1 问题介绍</h4><p>对于下面两句话</p>
<ul>
<li>arrive beijing on November 2nd</li>
<li>leave beijing on November 2nd</li>
</ul>
<p>第一句话表达到达，第二句话表示离开，如果网络能构记忆“beijing”前面的词，就会预测出不同的结果。</p>
<h4 id="5-1-2-循环神经网络的基本结构"><a href="#5-1-2-循环神经网络的基本结构" class="headerlink" title="5.1.2 循环神经网络的基本结构"></a>5.1.2 循环神经网络的基本结构</h4><p>将网络的输出保存在一个记忆单元中，这个记忆单元和下一次的输入一起进入神经网络中。因此，输入序列（sequences）的顺序改变，会改变网络的输出结果。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/v2-206db7ba9d32a80ff56b6cc988a62440_r.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/v2-b0175ebd3419f9a11a3d0d8b00e28675_r.jpg"></p>
<p>这个网络在t时刻接收到输入$x_t$之后，隐藏层的值是$S_t$，输出值是$O_t$。关键一点是，$S_t$的值不仅仅取决于$x_t$，还取决于$S_{t-1}$。我们可以用下面的公式来表示循环神经网络的计算方法：</p>
<p>$$O _ t = g(VS_t)$$<br>$$S _ t = f(UX_t+WS_{t-1})$$</p>
<h4 id="5-1-3-存在的问题"><a href="#5-1-3-存在的问题" class="headerlink" title="5.1.3 存在的问题"></a>5.1.3 存在的问题</h4><p>循环神经网络具有很好的记忆特性，能够将记忆内容应用到当前情景下，但是记忆最大的问题在于遗忘性</p>
<h3 id="5-2-循环神经网络的变式：LSTM和GRU"><a href="#5-2-循环神经网络的变式：LSTM和GRU" class="headerlink" title="5.2 循环神经网络的变式：LSTM和GRU"></a>5.2 循环神经网络的变式：LSTM和GRU</h3><h4 id="5-2-1-LSTM"><a href="#5-2-1-LSTM" class="headerlink" title="5.2.1 LSTM"></a>5.2.1 LSTM</h4><p>LSTM是Long Short Term Memory Networks的缩写，是一种链式循环的网络结构，在网络内部有着更复杂的结构，主要为了解决长序列训练过程中的梯度下降和梯度爆炸问题。</p>
<p>LSTM由三个门来控制，分别是输入门，遗忘门和输出门。顾名思义，输入门控制着网络的输入，遗忘门控制着记忆单元，输出门控制着网络的输出。这其中最重要的就是遗忘门，遗忘门的作用是决定之前的哪些记忆及那个被保留，那些记忆将被去掉，正是由于遗忘门的作用，使得LSTM具有了长时记忆的功能</p>
<h4 id="5-2-2-GRU"><a href="#5-2-2-GRU" class="headerlink" title="5.2.2 GRU"></a>5.2.2 GRU</h4><p>GRU是Gated Recurrent Unit的缩写，由Cho于2014年提出，GRU和LSTM最大的不同在于GRU将遗忘门和输入门合成了一个“更新门”，同时网络不再额外给出记忆状态Ct，而是将输出结果ht作为记忆状态不断向后循环传递，网络的输出和出入变得简单</p>
<h4 id="5-2-3-收敛性问题"><a href="#5-2-3-收敛性问题" class="headerlink" title="5.2.3 收敛性问题"></a>5.2.3 收敛性问题</h4><p>如果写了一个简单的LSTM网络去训练数据，会发现loss并不会按照想象的方式下降，而是在乱跳，这是因为RNN的误差曲面粗糙不平导致的，而解决方法是梯度裁剪（gradient clipping）</p>
<h3 id="5-3-循环神经网络的PyTorch实现"><a href="#5-3-循环神经网络的PyTorch实现" class="headerlink" title="5.3 循环神经网络的PyTorch实现"></a>5.3 循环神经网络的PyTorch实现</h3><h4 id="5-3-1-PyTorch的循环网络模块"><a href="#5-3-1-PyTorch的循环网络模块" class="headerlink" title="5.3.1 PyTorch的循环网络模块"></a>5.3.1 PyTorch的循环网络模块</h4><p><strong>1.标准RNN</strong></p>
<p><code>nn.RNN()</code><br><strong>参数</strong></p>
<ul>
<li><code>input_size</code>表示输入$x_t$的维度</li>
<li><code>hidden_size</code>表示输出$h_t$的维度</li>
<li><code>num_layers</code>表示网络层数，默认为1层</li>
<li><code>nonlinearity</code>表示非线性激活函数，默认为tanh，可选relu</li>
<li><code>bias</code>表示是否使用偏置，默认为True</li>
<li><code>batch_first</code>决定网络输入的维度顺序，默认输入顺序（seq,batch,feature），如果设置为True，则顺序为（batch，seq，feature）</li>
<li><code>dropout</code>，接受一个0到1的数值，并在除最后一层的其他输出层加上dropout层</li>
<li><code>bidirectional</code>默认是False，如果设置为True，就是双向循环神经网络的结构</li>
</ul>
<p><strong>网络接受的输入</strong></p>
<ul>
<li>序列输入$x_t$：$x_t$的维度是（seq，batch，feature），分别表示序列长度，批量和输入的特征维度</li>
<li>记忆输入$h_0$：$h_0$也叫隐藏状态，它的维度是（layers×direction，batch，hidden），分别表示层数乘方向（单向1，双向2），批量和输出的维度</li>
</ul>
<p><strong>网络的输出</strong></p>
<ul>
<li>output，表示网络实际的输出，维度是（seq，batch，hidden×direction），分别表示序列长度，批量和输出维度乘方向</li>
<li>$h_n$表示记忆单元，维度是（layer×direction，batch，hidden）分别表示层数乘方向，批量，输出维度</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">basic_rnn = nn.RNN(input_size=<span class="number">20</span>,hidden_size=<span class="number">50</span>,num_layers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">toy_input = Variable(torch.randn(<span class="number">100</span>,<span class="number">32</span>,<span class="number">20</span>)) <span class="comment"># seq,batch,input_size</span></span><br><span class="line">h_0 = Variable(torch.rand(<span class="number">2</span>,<span class="number">32</span>,<span class="number">50</span>)) <span class="comment"># layer * direction,batch,hidden_size</span></span><br><span class="line"></span><br><span class="line">toy_output,h_n = basic_rnn(toy_input,h_0)</span><br></pre></td></tr></table></figure>

<p><strong>2.LSTM</strong></p>
<p><code>nn.LSTM()</code><br>参数和标准RNN一样</p>
<p>LSTM与RNN不同的地方：</p>
<ul>
<li>LSTM的参数比标准RNN多，是标准RNN维度的4倍，但是访问的方式仍然是相同的</li>
<li>LSTM的输入还多了一个$C_0$，它们合在一起称为网络的隐藏状态，即（layer×direction，batch，hidden），当然输出也会有$h_0$,$C_0$</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lstm = nn.LSTM(input_size=<span class="number">20</span>,hidden_size=<span class="number">50</span>,num_layers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">lstm_input = Variable(torch.randn(<span class="number">10</span>, <span class="number">3</span>, <span class="number">20</span>))</span><br><span class="line">out, (h, c) = lstm(lstm_input)</span><br></pre></td></tr></table></figure>

<p><strong>3.GRU</strong></p>
<p>GRU本质上和LSTM一样</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gru_seq = nn.GRU(<span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line">gru_input = Variable(torch.randn(<span class="number">3</span>, <span class="number">32</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">out, h = gru_seq(gru_input)</span><br></pre></td></tr></table></figure>

<p>它和LSTM不同的地方：</p>
<ul>
<li>参数是标准RNN的三倍</li>
<li>网络的隐藏状态只有h0</li>
</ul>
<h4 id="5-3-2-实例介绍"><a href="#5-3-2-实例介绍" class="headerlink" title="5.3.2 实例介绍"></a>5.3.2 实例介绍</h4><p>序列预测</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment">#希望通过前两个月的流量来预测当月的流量</span></span><br><span class="line"><span class="comment">#将前两个月的流量当做输入，当月的流量当做输出</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span>(<span class="params">dataset,look_back=<span class="number">2</span></span>):</span></span><br><span class="line">    dataX,dataY = [],[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dataset)-look_back):</span><br><span class="line">        a = dataset[i:(i+look_back)]</span><br><span class="line">        dataX.append(a)</span><br><span class="line">        dataY.append(dataset[i+look_back])</span><br><span class="line">    <span class="keyword">return</span> np.array(dataX),np.array(dataY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">lstm_reg</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size, hidden_size, output_size=<span class="number">1</span>, num_layers=<span class="number">2</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(lstm_reg, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.rnn = nn.LSTM(input_size, hidden_size, num_layers) <span class="comment"># rnn</span></span><br><span class="line">        self.reg = nn.Linear(hidden_size, output_size) <span class="comment"># 回归</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x, _ = self.rnn(x) <span class="comment"># (seq, batch, hidden)</span></span><br><span class="line">        s, b, h = x.shape</span><br><span class="line">        x = x.view(s*b, h) <span class="comment"># 转换成线性层的输入格式</span></span><br><span class="line">        x = self.reg(x)</span><br><span class="line">        x = x.view(s, b, -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取数据</span></span><br><span class="line">data_csv = pd.read_csv(<span class="string">&#x27;./data.csv&#x27;</span>, usecols=[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预处理，将数据中na的数据去掉，然后将数据标准化到0~1之间</span></span><br><span class="line">data_csv = data_csv.dropna()</span><br><span class="line">dataset = data_csv.values</span><br><span class="line">dataset = dataset.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">max_value = np.<span class="built_in">max</span>(dataset)</span><br><span class="line">min_value = np.<span class="built_in">min</span>(dataset)</span><br><span class="line">scalar = max_value - min_value</span><br><span class="line">dataset = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x / scalar, dataset))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建好输入输出</span></span><br><span class="line">data_X, data_Y = create_dataset(dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集，70% 作为训练集</span></span><br><span class="line">train_size = <span class="built_in">int</span>(<span class="built_in">len</span>(data_X) * <span class="number">0.7</span>)</span><br><span class="line">test_size = <span class="built_in">len</span>(data_X) - train_size</span><br><span class="line">train_X = data_X[:train_size]</span><br><span class="line">train_Y = data_Y[:train_size]</span><br><span class="line">test_X = data_X[train_size:]</span><br><span class="line">test_Y = data_Y[train_size:]</span><br><span class="line"></span><br><span class="line"><span class="comment">#将数据改变一下形状 (seq, batch, feature)</span></span><br><span class="line"><span class="comment">#只有一个序列，所以 batch 是 1</span></span><br><span class="line"><span class="comment">#输入的feature是希望依据的几个月份，这里定的是两个月份，feature=2.</span></span><br><span class="line">train_X = train_X.reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">train_Y = train_Y.reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">test_X = test_X.reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">train_x = torch.from_numpy(train_X)</span><br><span class="line">train_y = torch.from_numpy(train_Y)</span><br><span class="line">test_x = torch.from_numpy(test_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失和优化</span></span><br><span class="line">net = lstm_reg(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=<span class="number">1e-2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    var_x = Variable(train_x)</span><br><span class="line">    var_y = Variable(train_y)</span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    out = net(var_x)</span><br><span class="line">    loss = criterion(out, var_y)</span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="keyword">if</span> (e + <span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>: <span class="comment"># 每 100 次输出结果</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125;, Loss: &#123;:.5f&#125;&#x27;</span>.<span class="built_in">format</span>(e + <span class="number">1</span>, loss.data))</span><br><span class="line">        </span><br><span class="line"><span class="comment">#测试</span></span><br><span class="line">net = net.<span class="built_in">eval</span>() <span class="comment"># 转换成测试模式</span></span><br><span class="line">data_X = data_X.reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">data_X = torch.from_numpy(data_X)</span><br><span class="line">var_data = Variable(data_X)</span><br><span class="line">pred_test = net(var_data) <span class="comment"># 测试集的预测结果</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 改变输出的格式</span></span><br><span class="line">pred_test = pred_test.view(-<span class="number">1</span>).data.numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画出实际结果和预测的结果</span></span><br><span class="line">plt.plot(pred_test, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;prediction&#x27;</span>)</span><br><span class="line">plt.plot(dataset, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;real&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201102181225.png"></p>
<h3 id="5-4-自然语言处理的应用"><a href="#5-4-自然语言处理的应用" class="headerlink" title="5.4 自然语言处理的应用"></a>5.4 自然语言处理的应用</h3><h4 id="5-4-1-词嵌入"><a href="#5-4-1-词嵌入" class="headerlink" title="5.4.1 词嵌入"></a>5.4.1 词嵌入</h4><p>词嵌入（word embedding），也称为词向量，即对于每个词，可以使用一个高维向量去表示它</p>
<p>例如：</p>
<ul>
<li>(1)The cat likes playing ball</li>
<li>(2)The kitty likes playing wool</li>
<li>(3)The dog likes playing ball</li>
<li>(4)The boy doesn’t like playing ball</li>
</ul>
<p>对于这四句话里的四个词，cat，kitty，dog，boy，如果用one-hot编码，那么cat可以是（1，0，0，0），kitty可以是（0，1，0，0），但是cat和kitty都是小猫，所以这两个词实际语义是接近的，但是one-hot不能体现这个特点，于是可以用词嵌入的方式表示这四个词。</p>
<p>假设使用一个二维向量（a，b）来表示一个词，其中a代表是否喜欢玩球，b代表是否喜欢玩毛线，且数值越大代表越喜欢，那么对于cat可以表示（-1，4），对于kitty可以表示为（-2，5），对于dog可以表示为（3，-2），对于boy可以表示为（-2，-3）</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201102190952.png"></p>
<p>可以发现kitty和cat的夹角更小，所以它们更加相似</p>
<h4 id="5-4-2-词嵌入的PyTorch实现"><a href="#5-4-2-词嵌入的PyTorch实现" class="headerlink" title="5.4.2 词嵌入的PyTorch实现"></a>5.4.2 词嵌入的PyTorch实现</h4><p>PyTorch中的词嵌入是通过函数<code>nn.Embedding(m,n)</code>来实现的，其中m表示所有的单词数目，n表示词嵌入的维度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">word_to_ix = &#123;<span class="string">&#x27;hello&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;world&#x27;</span>:<span class="number">1</span>&#125;</span><br><span class="line">embeds = nn.Embeding(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">hello_idx = torch.LongTensor([word_to_ix[<span class="string">&#x27;hello&#x27;</span>]])</span><br><span class="line">hello_idx = Variable(hello_idx)</span><br><span class="line">hello_embed = embeds(hello_idx)</span><br><span class="line"><span class="built_in">print</span>(hello_embed)</span><br></pre></td></tr></table></figure>

<h4 id="5-4-3-N-Gram模型"><a href="#5-4-3-N-Gram模型" class="headerlink" title="5.4.3 N Gram模型"></a>5.4.3 N Gram模型</h4><p>对于一句话，单词的排列顺序是非常重要的，所以我们能否由前面的几个词来预测后面的几个单词呢，比如 ‘I lived in France for 10 years, I can speak _ ‘ 这句话中，我们能够预测出最后一个词是 French。</p>
<p>对于一句话T，它由w1，w2,…,wn这n个词构成，可以得到下面的公式<br>$$<br>P(T) = P(w_1)P(w_2 | w_1)P(w_3 |w_2 w_1) \cdots P(w_n |w_{n-1} w_{n-2}\cdots w_2w_1)<br>$$<br>但是该模型存在如参数空间过大等缺陷，因此引入了马尔科夫假设，也就是说这个单词只与前面的几个词有关系。</p>
<p>对于这个条件概率，传统的方式是统计语料中每个单词出现的频率，据此来估计这个条件概率，这里使用词嵌入的办法，直接在语料中计算这个条件概率，然后最大化条件概率从而优化词向量，据此进行预测</p>
<h4 id="5-4-4-单词预测的PyTorch实现"><a href="#5-4-4-单词预测的PyTorch实现" class="headerlink" title="5.4.4 单词预测的PyTorch实现"></a>5.4.4 单词预测的PyTorch实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line">CONTEXT_SIZE = <span class="number">2</span> <span class="comment"># 依据的单词数</span></span><br><span class="line">EMBEDDING_DIM = <span class="number">10</span> <span class="comment"># 词向量的维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">n_gram</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, context_size=CONTEXT_SIZE, n_dim=EMBEDDING_DIM</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(n_gram, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.embed = nn.Embedding(vocab_size, n_dim)</span><br><span class="line">        self.classify = nn.Sequential(</span><br><span class="line">            nn.Linear(context_size * n_dim, <span class="number">128</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">128</span>, vocab_size)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        voc_embed = self.embed(x) <span class="comment"># 得到词嵌入</span></span><br><span class="line">        voc_embed = voc_embed.view(<span class="number">1</span>, -<span class="number">1</span>) <span class="comment"># 将两个词向量拼在一起</span></span><br><span class="line">        out = self.classify(voc_embed)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们使用莎士比亚的诗</span></span><br><span class="line">test_sentence = <span class="string">&quot;&quot;&quot;When forty winters shall besiege thy brow,</span></span><br><span class="line"><span class="string">And dig deep trenches in thy beauty&#x27;s field,</span></span><br><span class="line"><span class="string">Thy youth&#x27;s proud livery so gazed on now,</span></span><br><span class="line"><span class="string">Will be a totter&#x27;d weed of small worth held:</span></span><br><span class="line"><span class="string">Then being asked, where all thy beauty lies,</span></span><br><span class="line"><span class="string">Where all the treasure of thy lusty days;</span></span><br><span class="line"><span class="string">To say, within thine own deep sunken eyes,</span></span><br><span class="line"><span class="string">Were an all-eating shame, and thriftless praise.</span></span><br><span class="line"><span class="string">How much more praise deserv&#x27;d thy beauty&#x27;s use,</span></span><br><span class="line"><span class="string">If thou couldst answer &#x27;This fair child of mine</span></span><br><span class="line"><span class="string">Shall sum my count, and make my old excuse,&#x27;</span></span><br><span class="line"><span class="string">Proving his beauty by succession thine!</span></span><br><span class="line"><span class="string">This were to be new made when thou art old,</span></span><br><span class="line"><span class="string">And see thy blood warm when thou feel&#x27;st it cold.&quot;&quot;&quot;</span>.split()</span><br><span class="line"></span><br><span class="line">trigram = [((test_sentence[i], test_sentence[i+<span class="number">1</span>]), test_sentence[i+<span class="number">2</span>]) </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(test_sentence)-<span class="number">2</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立每个词与数字的编码，据此构建词嵌入</span></span><br><span class="line">vocb = <span class="built_in">set</span>(test_sentence) <span class="comment"># 使用 set 将重复的元素去掉</span></span><br><span class="line">word_to_idx = &#123;word: i <span class="keyword">for</span> i, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(vocb)&#125;</span><br><span class="line">idx_to_word = &#123;word_to_idx[word]: word <span class="keyword">for</span> word <span class="keyword">in</span> word_to_idx&#125;</span><br><span class="line"></span><br><span class="line">net = n_gram(<span class="built_in">len</span>(word_to_idx))</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">1e-2</span>, weight_decay=<span class="number">1e-5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> word, label <span class="keyword">in</span> trigram: <span class="comment"># 使用前 100 个作为训练集</span></span><br><span class="line">        word = Variable(torch.LongTensor([word_to_idx[i] <span class="keyword">for</span> i <span class="keyword">in</span> word])) <span class="comment"># 将两个词作为输入</span></span><br><span class="line">        label = Variable(torch.LongTensor([word_to_idx[label]]))</span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        out = net(word)</span><br><span class="line">        loss = criterion(out, label)</span><br><span class="line">        train_loss += loss.data</span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    <span class="keyword">if</span> (e + <span class="number">1</span>) % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch: &#123;&#125;, Loss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(e + <span class="number">1</span>, train_loss / <span class="built_in">len</span>(trigram)))</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 测试</span></span><br><span class="line">word, label = trigram[<span class="number">19</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;input: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(word))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;label: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(label))</span><br><span class="line"></span><br><span class="line">word = Variable(torch.LongTensor([word_to_idx[i] <span class="keyword">for</span> i <span class="keyword">in</span> word]))</span><br><span class="line">out = net(word)</span><br><span class="line">pred_label_idx = out.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>].item()</span><br><span class="line">predict_word = idx_to_word[pred_label_idx]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;real word is &#123;&#125;, predicted word is &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(label, predict_word))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">epoch: 20, Loss: 0.873597</span><br><span class="line">epoch: 40, Loss: 0.153170</span><br><span class="line">epoch: 60, Loss: 0.090456</span><br><span class="line">epoch: 80, Loss: 0.071410</span><br><span class="line">epoch: 100, Loss: 0.061979</span><br><span class="line">input: (&#x27;so&#x27;, &#x27;gazed&#x27;)</span><br><span class="line">label: on</span><br><span class="line"></span><br><span class="line">real word is on, predicted word is on</span><br></pre></td></tr></table></figure>

<h4 id="5-4-5-词性判断"><a href="#5-4-5-词性判断" class="headerlink" title="5.4.5 词性判断"></a>5.4.5 词性判断</h4><p><strong>1.LSTM做词性判断的基本原理</strong></p>
<p>同构LSTM，根据它记忆的特性，能够通过这个单词前面记忆的一些词语来对它做一个判断，比如前面的单词如果是my，那么紧跟的词很可能是一个名词，这样就能充分利用上文来处理这个问题</p>
<p><strong>2.字符增强</strong></p>
<p>通过引入字符来增强表达，比如有些单词存在前缀或者后缀，比如<code>-ly</code>这种后缀很有可能是副词，这样我们就能在字符水平对词性进一步判断，把两种方法集成起来，能够得到一个更好的结果</p>
<h4 id="5-4-6-词性判断的PyTorch实现"><a href="#5-4-6-词性判断的PyTorch实现" class="headerlink" title="5.4.6 词性判断的PyTorch实现"></a>5.4.6 词性判断的PyTorch实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line">training_data = [(<span class="string">&quot;The dog ate the apple&quot;</span>.split(),</span><br><span class="line">                  [<span class="string">&quot;DET&quot;</span>, <span class="string">&quot;NN&quot;</span>, <span class="string">&quot;V&quot;</span>, <span class="string">&quot;DET&quot;</span>, <span class="string">&quot;NN&quot;</span>]),</span><br><span class="line">                 (<span class="string">&quot;Everybody read that book&quot;</span>.split(), </span><br><span class="line">                  [<span class="string">&quot;NN&quot;</span>, <span class="string">&quot;V&quot;</span>, <span class="string">&quot;DET&quot;</span>, <span class="string">&quot;NN&quot;</span>])]</span><br><span class="line"></span><br><span class="line"><span class="comment">#对单词和标签进行编码</span></span><br><span class="line">word_to_idx = &#123;&#125;</span><br><span class="line">tag_to_idx = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> context, tag <span class="keyword">in</span> training_data:</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> context:</span><br><span class="line">        <span class="keyword">if</span> word.lower() <span class="keyword">not</span> <span class="keyword">in</span> word_to_idx:</span><br><span class="line">            word_to_idx[word.lower()] = <span class="built_in">len</span>(word_to_idx)</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> tag:</span><br><span class="line">        <span class="keyword">if</span> label.lower() <span class="keyword">not</span> <span class="keyword">in</span> tag_to_idx:</span><br><span class="line">            tag_to_idx[label.lower()] = <span class="built_in">len</span>(tag_to_idx)</span><br><span class="line"></span><br><span class="line"><span class="comment">#对字母编码</span></span><br><span class="line">alphabet = <span class="string">&#x27;abcdefghijklmnopqrstuvwxyz&#x27;</span></span><br><span class="line">char_to_idx = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(alphabet)):</span><br><span class="line">    char_to_idx[alphabet[i]] = i</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_sequence</span>(<span class="params">x, dic</span>):</span> <span class="comment"># 字符编码</span></span><br><span class="line">    idx = [dic[i.lower()] <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">    idx = torch.LongTensor(idx)</span><br><span class="line">    <span class="keyword">return</span> idx</span><br><span class="line"></span><br><span class="line"><span class="comment">#构建单个字符的lstm模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">char_lstm</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_char, char_dim, char_hidden</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(char_lstm, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.char_embed = nn.Embedding(n_char, char_dim)</span><br><span class="line">        self.lstm = nn.LSTM(char_dim, char_hidden)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.char_embed(x)</span><br><span class="line">        out, _ = self.lstm(x)</span><br><span class="line">        <span class="keyword">return</span> out[-<span class="number">1</span>] <span class="comment"># (batch, hidden)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#构建词性分类的lstm模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">lstm_tagger</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_word, n_char, char_dim, word_dim, </span></span></span><br><span class="line"><span class="params"><span class="function">                 char_hidden, word_hidden, n_tag</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(lstm_tagger, self).__init__()</span><br><span class="line">        self.word_embed = nn.Embedding(n_word, word_dim)</span><br><span class="line">        self.char_lstm = char_lstm(n_char, char_dim, char_hidden)</span><br><span class="line">        self.word_lstm = nn.LSTM(word_dim + char_hidden, word_hidden)</span><br><span class="line">        self.classify = nn.Linear(word_hidden, n_tag)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, word</span>):</span></span><br><span class="line">        char = []</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> word: <span class="comment"># 对于每个单词做字符的 lstm</span></span><br><span class="line">            char_list = make_sequence(w, char_to_idx)</span><br><span class="line">            char_list = char_list.unsqueeze(<span class="number">1</span>) <span class="comment"># (seq, batch, feature) 满足 lstm 输入条件</span></span><br><span class="line">            char_infor = self.char_lstm(Variable(char_list)) <span class="comment"># (batch, char_hidden)</span></span><br><span class="line">            char.append(char_infor)</span><br><span class="line">        char = torch.stack(char, dim=<span class="number">0</span>) <span class="comment"># (seq, batch, feature)</span></span><br><span class="line">        </span><br><span class="line">        x = self.word_embed(x) <span class="comment"># (batch, seq, word_dim)</span></span><br><span class="line">        x = x.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>) <span class="comment"># 改变顺序</span></span><br><span class="line">        x = torch.cat((x, char), dim=<span class="number">2</span>) <span class="comment"># 沿着特征通道将每个词的词嵌入和字符 lstm 输出的结果拼接在一起</span></span><br><span class="line">        x, _ = self.word_lstm(x)</span><br><span class="line">        </span><br><span class="line">        s, b, h = x.shape</span><br><span class="line">        x = x.view(-<span class="number">1</span>, h) <span class="comment"># 重新 reshape 进行分类线性层</span></span><br><span class="line">        out = self.classify(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">net = lstm_tagger(<span class="built_in">len</span>(word_to_idx), <span class="built_in">len</span>(char_to_idx), <span class="number">10</span>, <span class="number">100</span>, <span class="number">50</span>, <span class="number">128</span>, <span class="built_in">len</span>(tag_to_idx))</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">1e-2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">300</span>):</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> word, tag <span class="keyword">in</span> training_data:</span><br><span class="line">        word_list = make_sequence(word, word_to_idx).unsqueeze(<span class="number">0</span>) <span class="comment"># 添加第一维 batch</span></span><br><span class="line">        tag = make_sequence(tag, tag_to_idx)</span><br><span class="line">        word_list = Variable(word_list)</span><br><span class="line">        tag = Variable(tag)</span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        out = net(word_list, word)</span><br><span class="line">        loss = criterion(out, tag)</span><br><span class="line">        train_loss += loss.data</span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    <span class="keyword">if</span> (e + <span class="number">1</span>) % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125;, Loss: &#123;:.5f&#125;&#x27;</span>.<span class="built_in">format</span>(e + <span class="number">1</span>, train_loss / <span class="built_in">len</span>(training_data)))</span><br><span class="line"></span><br><span class="line"><span class="comment">#测试</span></span><br><span class="line">net = net.<span class="built_in">eval</span>()</span><br><span class="line">test_sent = <span class="string">&#x27;Everybody ate the apple&#x27;</span></span><br><span class="line">test = make_sequence(test_sent.split(), word_to_idx).unsqueeze(<span class="number">0</span>)</span><br><span class="line">out = net(Variable(test), test_sent.split())</span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="built_in">print</span>(tag_to_idx)</span><br></pre></td></tr></table></figure>

<h3 id="5-5-循环神经网络的更多应用"><a href="#5-5-循环神经网络的更多应用" class="headerlink" title="5.5 循环神经网络的更多应用"></a>5.5 循环神经网络的更多应用</h3><h4 id="5-5-1-Many-to-one"><a href="#5-5-1-Many-to-one" class="headerlink" title="5.5.1 Many to one"></a>5.5.1 Many to one</h4><p>循环神经网络不仅能够输入序列，输出序列，还能后输入序列，输出单个向量。只需要再输出的序列里面取其中一个就可以，通常是取最后一个。这样的结构被称为Many to one。</p>
<p>Many to one的结构可以用来执行什么任务：</p>
<ul>
<li>情感分析</li>
<li>关键字提取</li>
</ul>
<h4 id="5-5-2-Many-to-Many-shorter"><a href="#5-5-2-Many-to-Many-shorter" class="headerlink" title="5.5.2 Many to Many (shorter)"></a>5.5.2 Many to Many (shorter)</h4><p>这种结构是输入和输出都是序列，但是输出的序列比输入的序列短。这种类型的结构通常在语音识别中遇到，因为一段话如果用语言表达往往会比这段话更长。这种情况需要使用CTC算法解决重复的问题，CTC就是将输出的所有可能列举出来，然后通过去重复，去空格的方式来选择最大的概率。</p>
<h4 id="5-5-3-Seq2seq"><a href="#5-5-3-Seq2seq" class="headerlink" title="5.5.3 Seq2seq"></a>5.5.3 Seq2seq</h4><p>这种情况是输出的长度不确定，一般是在机器翻译的任务中出现。</p>
<h4 id="5-5-4-CNN-RNN"><a href="#5-5-4-CNN-RNN" class="headerlink" title="5.5.4 CNN+RNN"></a>5.5.4 CNN+RNN</h4><p>RNN和CNN可以联合在一起完成图像描述任务，简而言之，就是通过预训练的卷积神经网络提取图片特征，接着通过循环网络将特征变成文字描述</p>
<h2 id="第6章-生成对抗网络"><a href="#第6章-生成对抗网络" class="headerlink" title="第6章 生成对抗网络"></a>第6章 生成对抗网络</h2><p>2014年，lan Goodfellow提出的生成对抗网络（Generative Adversarial Networks，GANs）推进了整个无监督学习的发展进程，让机器实现一些创造性工作，如画画，写诗，创作歌词等成为可能…</p>
<h3 id="6-1-生成模型"><a href="#6-1-生成模型" class="headerlink" title="6.1 生成模型"></a>6.1 生成模型</h3><p>生成模型(Generative Model)这一概念属于概率统计和机器学习,是指一系列用于随机生成可观测数据的模型.简而言之,就是”生成”的样本和”真实”的样本尽可能地相似.</p>
<p>生成模型的两个主要功能就是学习一个概率分布$P_{model}(x)$和生成数据</p>
<h4 id="6-1-1-自动编码器"><a href="#6-1-1-自动编码器" class="headerlink" title="6.1.1 自动编码器"></a>6.1.1 自动编码器</h4><p>自动编码器(AutoEncoder)最开始作为一种数据的压缩方法,其特点有:</p>
<ul>
<li>和数据相关程度很高</li>
<li>压缩后数据是有损的</li>
</ul>
<p>所以现在自动编码器主要应用在几个方面:</p>
<ul>
<li>数据去噪</li>
<li>可视化降维</li>
<li>生成数据</li>
</ul>
<p>自动编码器的一般结构</p>
<ul>
<li>编码器(Encoder)</li>
<li>解码器(Decoder)</li>
</ul>
<p>编码器和解码器可以是任意的模型,通常使用神经网络模型作为编码器和解码器.输入的数据经过神经网络降维到一个编码(code),接着又通过另一个神经网络去解码得到一个与输入原数据一模一样的生成数据,然后通过比较这两个数据,最小化它们之间的差异来训练这个网络中编码器和解码器的参数.当这个过程训练完之后,拿出这个解码器,随机传入一个编码,通过解码器能够生成一个和原数据差不多的数据</p>
<p>下面我们使用 mnist 数据集来说明一个如何构建一个简单的自动编码器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms <span class="keyword">as</span> tfs</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"></span><br><span class="line"><span class="comment">#进行数据预处理和迭代器的构建</span></span><br><span class="line">im_tfs = tfs.Compose([</span><br><span class="line">    tfs.ToTensor(),</span><br><span class="line">    tfs.Normalize([<span class="number">0.5</span>], [<span class="number">0.5</span>]) <span class="comment"># 标准化</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">train_set = MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,transform=im_tfs,download=<span class="literal">True</span>)</span><br><span class="line">train_data = DataLoader(train_set, batch_size=<span class="number">128</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">autoencoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(autoencoder,self).__init__()</span><br><span class="line">        self.encoder = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">28</span>*<span class="number">28</span>,<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">128</span>,<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>,<span class="number">12</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">12</span>,<span class="number">3</span>) <span class="comment"># 输出的 code 是 3 维，便于可视化</span></span><br><span class="line">        )</span><br><span class="line">        self.decoder = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">3</span>,<span class="number">12</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">12</span>,<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>,<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">128</span>,<span class="number">28</span>*<span class="number">28</span>),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        encode = self.encoder(x)</span><br><span class="line">        decode = self.decoder(encode)</span><br><span class="line">        <span class="keyword">return</span> encode,decode</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">这里定义的编码器和解码器都是 4 层神经网络作为模型，</span></span><br><span class="line"><span class="string">中间使用 relu 激活函数，最后输出的 code 是三维，</span></span><br><span class="line"><span class="string">注意解码器最后我们使用tanh作为激活函数，</span></span><br><span class="line"><span class="string">因为输入图片标准化在 -1 ~ 1 之间，</span></span><br><span class="line"><span class="string">所以输出也要在 -1 ~ 1 这个范围内</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">net = autoencoder()</span><br><span class="line">criterion = nn.MSELoss(size_average=<span class="literal">False</span>)</span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_img</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="comment"># 定义一个函数将最后的结果转换回图片</span></span><br><span class="line">    x = <span class="number">0.5</span> * (x + <span class="number">1.</span>)</span><br><span class="line">    x = x.clamp(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    x = x.view(x.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练自动编码器</span></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">for</span> im, _ <span class="keyword">in</span> train_data:</span><br><span class="line">        im = im.view(im.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">        im = Variable(im)</span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        _, output = net(im)</span><br><span class="line">        loss = criterion(output, im) / im.shape[<span class="number">0</span>] <span class="comment"># 平均</span></span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (e+<span class="number">1</span>) % <span class="number">20</span> == <span class="number">0</span>: <span class="comment"># 每 20 次，将生成的图片保存一下</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch: &#123;&#125;, Loss: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(e + <span class="number">1</span>, loss.data))</span><br><span class="line">        pic = to_img(output.cpu().data)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;./simple_autoencoder&#x27;</span>):</span><br><span class="line">            os.mkdir(<span class="string">&#x27;./simple_autoencoder&#x27;</span>)</span><br><span class="line">        save_image(pic, <span class="string">&#x27;./simple_autoencoder/image_&#123;&#125;.png&#x27;</span>.<span class="built_in">format</span>(e + <span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<p>训练完成之后看看效果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> cm</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化结果</span></span><br><span class="line">view_data = Variable((train_set.train_data[:<span class="number">200</span>].<span class="built_in">type</span>(torch.FloatTensor).view(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>) / <span class="number">255.</span> - <span class="number">0.5</span>) / <span class="number">0.5</span>)</span><br><span class="line">encode, _ = net(view_data)    <span class="comment"># 提取压缩的特征值</span></span><br><span class="line">fig = plt.figure(<span class="number">2</span>)</span><br><span class="line">ax = Axes3D(fig)    <span class="comment"># 3D 图</span></span><br><span class="line"><span class="comment"># x, y, z 的数据值</span></span><br><span class="line">X = encode.data[:, <span class="number">0</span>].numpy()</span><br><span class="line">Y = encode.data[:, <span class="number">1</span>].numpy()</span><br><span class="line">Z = encode.data[:, <span class="number">2</span>].numpy()</span><br><span class="line">values = train_set.train_labels[:<span class="number">200</span>].numpy()  <span class="comment"># 标签值</span></span><br><span class="line"><span class="keyword">for</span> x, y, z, s <span class="keyword">in</span> <span class="built_in">zip</span>(X, Y, Z, values):</span><br><span class="line">    c = cm.rainbow(<span class="built_in">int</span>(<span class="number">255</span>*s/<span class="number">9</span>))    <span class="comment"># 上色</span></span><br><span class="line">    ax.text(x, y, z, s, backgroundcolor=c)  <span class="comment"># 标位子</span></span><br><span class="line">ax.set_xlim(X.<span class="built_in">min</span>(), X.<span class="built_in">max</span>())</span><br><span class="line">ax.set_ylim(Y.<span class="built_in">min</span>(), Y.<span class="built_in">max</span>())</span><br><span class="line">ax.set_zlim(Z.<span class="built_in">min</span>(), Z.<span class="built_in">max</span>())</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/untitled.png"><br>可以看到，不同种类的图片进入自动编码器之后会被编码得不同，而相同类型的图片经过自动编码之后的编码在几何示意图上距离较近，在训练好自动编码器之后，我们可以给一个随机的 code，通过 decoder 生成图片</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">code = Variable(torch.FloatTensor([[-<span class="number">20.19</span>, <span class="number">10.36</span>, -<span class="number">0.06</span>]])) <span class="comment"># 给一个 code</span></span><br><span class="line">decode = net.decoder(code)</span><br><span class="line">decode_img = to_img(decode).squeeze()</span><br><span class="line">decode_img = decode_img.data.numpy() * <span class="number">255</span></span><br><span class="line">plt.imshow(decode_img.astype(<span class="string">&#x27;uint8&#x27;</span>), cmap=<span class="string">&#x27;gray&#x27;</span>) </span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201104180838.png"><br>这里我们仅仅使用多层神经网络定义了一个自动编码器，当然你会想到，为什么不使用效果更好的卷积神经网络呢？我们当然可以使用卷积神经网络来定义，下面我们就重新定义一个卷积神经网络来进行 autoencoder</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">conv_autoencoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(conv_autoencoder, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.encoder = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">16</span>, <span class="number">3</span>, stride=<span class="number">3</span>, padding=<span class="number">1</span>),  <span class="comment"># (b, 16, 10, 10)</span></span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),  <span class="comment"># (b, 16, 5, 5)</span></span><br><span class="line">            nn.Conv2d(<span class="number">16</span>, <span class="number">8</span>, <span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),  <span class="comment"># (b, 8, 3, 3)</span></span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">1</span>)  <span class="comment"># (b, 8, 2, 2)</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.decoder = nn.Sequential(</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">8</span>, <span class="number">16</span>, <span class="number">3</span>, stride=<span class="number">2</span>),  <span class="comment"># (b, 16, 5, 5)</span></span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">16</span>, <span class="number">8</span>, <span class="number">5</span>, stride=<span class="number">3</span>, padding=<span class="number">1</span>),  <span class="comment"># (b, 8, 15, 15)</span></span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">8</span>, <span class="number">1</span>, <span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),  <span class="comment"># (b, 1, 28, 28)</span></span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        encode = self.encoder(x)</span><br><span class="line">        decode = self.decoder(encode)</span><br><span class="line">        <span class="keyword">return</span> encode, decode</span><br><span class="line"></span><br><span class="line">conv_net = conv_autoencoder()</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    conv_net = conv_net.cuda()</span><br><span class="line">optimizer = torch.optim.Adam(conv_net.parameters(), lr=<span class="number">1e-3</span>, weight_decay=<span class="number">1e-5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练自动编码器</span></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">40</span>):</span><br><span class="line">    <span class="keyword">for</span> im, _ <span class="keyword">in</span> train_data:</span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            im = im.cuda()</span><br><span class="line">            <span class="built_in">print</span>(torch.device(<span class="string">&quot;cuda&quot;</span>))</span><br><span class="line">        im = Variable(im)</span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        _, output = conv_net(im)</span><br><span class="line">        loss = criterion(output, im) / im.shape[<span class="number">0</span>] <span class="comment"># 平均</span></span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (e+<span class="number">1</span>) % <span class="number">20</span> == <span class="number">0</span>: <span class="comment"># 每 20 次，将生成的图片保存一下</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch: &#123;&#125;, Loss: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(e+<span class="number">1</span>, loss.data))</span><br><span class="line">        pic = to_img(output.cpu().data)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;./conv_autoencoder&#x27;</span>):</span><br><span class="line">            os.mkdir(<span class="string">&#x27;./conv_autoencoder&#x27;</span>)</span><br><span class="line">        save_image(pic, <span class="string">&#x27;./conv_autoencoder/image_&#123;&#125;.png&#x27;</span>.<span class="built_in">format</span>(e+<span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<p>为了时间更短，只跑 40 次，如果有条件可以再 gpu 上跑跑.这里我们展示了简单的自动编码器，也用了多层神经网络和卷积神经网络作为例子，但是自动编码器存在一个问题，我们并不能任意生成我们想要的数据，因为我们并不知道 encode 之后的编码到底是什么样的概率分布，所以有一个改进的版本变分自动编码器，其能够解决这个问题</p>
<h4 id="6-1-2-变分自动编码器"><a href="#6-1-2-变分自动编码器" class="headerlink" title="6.1.2 变分自动编码器"></a>6.1.2 变分自动编码器</h4><p>变分自动编码器（Variational Auto Encoder, VAE）是自动编码器的升级版本，它的结构和自动编码器相似，也是由编码器和解码器构成的。</p>
<p>自动编码器不能任意生成数据，因为没办法自己去构造隐藏向量，需要通过数据输入编码才知道得到的隐含向量是什么，这个时候变分自动编码器就可以解决这个问题</p>
<p>它的原理是，在编码过程给他增加一些限制，迫使他生成的隐含向量能够粗略地遵循一个标准正态分布。</p>
<p>这样我们生成一张新图片就很简单了，我们只需要给它一个标准正态分布的随机隐含向量，这样通过解码器就能够生成我们想要的图片，而不需要给它一张原始图片先编码。</p>
<p>一般来讲，我们通过 encoder 得到的隐含向量并不是一个标准的正态分布，为了衡量两种分布的相似程度，我们使用 KL divergence，利用其来表示隐含向量与标准正态分布之间差异的 loss，另外一个 loss 仍然使用生成图片与原图片的均方误差来表示。</p>
<p>KL divergence 的公式如下<br>$$<br>D_{KL} (P || Q) =  \sum_{i} p(i) \log \frac{P(i)}{Q(i)}<br>$$</p>
<p>$$<br>D_{KL} (P || Q) =  \int_{-\infty}^{\infty} p(x) \log \frac{p(x)}{q(x)} dx<br>$$</p>
<p><strong>重参数</strong></p>
<p>为了避免计算 KL divergence 中的积分，我们使用重参数的技巧，不是每次产生一个隐含向量，而是生成两个向量，一个表示均值，一个表示标准差，这里我们默认编码之后的隐含向量服从一个正态分布的之后，就可以用一个标准正态分布先乘上标准差再加上均值来合成这个正态分布，最后 loss 就是希望这个生成的正态分布能够符合一个标准正态分布，也就是希望均值为 0，方差为 1</p>
<p><a href="https://arxiv.org/pdf/1606.05908.pdf">详细内容见https://arxiv.org/pdf/1606.05908.pdf</a></p>
<p>所以最后我们可以将我们的 loss 定义为下面的函数，由均方误差和 KL divergence 求和得到一个总的 loss</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">reconstruction_funtion = nn.BCELoss(size_average=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_function</span>(<span class="params">recon_x, x, mu, logvar</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    recon_x: generating images</span></span><br><span class="line"><span class="string">    x: origin images</span></span><br><span class="line"><span class="string">    mu: latent mean</span></span><br><span class="line"><span class="string">    logvar: latent log variance</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    MSE = reconstruction_function(recon_x, x)</span><br><span class="line">    <span class="comment"># loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)</span></span><br><span class="line">    KLD_element = mu.<span class="built_in">pow</span>(<span class="number">2</span>).add_(logvar.exp()).mul_(-<span class="number">1</span>).add_(<span class="number">1</span>).add_(logvar)</span><br><span class="line">    KLD = torch.<span class="built_in">sum</span>(KLD_element).mul_(-<span class="number">0.5</span>)</span><br><span class="line">    <span class="comment"># KL divergence</span></span><br><span class="line">    <span class="keyword">return</span> MSE + KLD</span><br></pre></td></tr></table></figure>

<p>下面我们用 mnist 数据集来简单说明一下变分自动编码器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms <span class="keyword">as</span> tfs</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"></span><br><span class="line">im_tfs = tfs.Compose([</span><br><span class="line">    tfs.ToTensor(),</span><br><span class="line">    tfs.Normalize([<span class="number">0.5</span>], [<span class="number">0.5</span>]) <span class="comment"># 标准化</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">train_set = MNIST(<span class="string">&#x27;./data&#x27;</span>, transform=im_tfs)</span><br><span class="line">train_data = DataLoader(train_set, batch_size=<span class="number">128</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VAE</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(VAE, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">784</span>, <span class="number">400</span>)</span><br><span class="line">        self.fc21 = nn.Linear(<span class="number">400</span>, <span class="number">20</span>) <span class="comment"># mean</span></span><br><span class="line">        self.fc22 = nn.Linear(<span class="number">400</span>, <span class="number">20</span>) <span class="comment"># var</span></span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">20</span>, <span class="number">400</span>)</span><br><span class="line">        self.fc4 = nn.Linear(<span class="number">400</span>, <span class="number">784</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">encode</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        h1 = F.relu(self.fc1(x))</span><br><span class="line">        <span class="keyword">return</span> self.fc21(h1), self.fc22(h1)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reparametrize</span>(<span class="params">self, mu, logvar</span>):</span></span><br><span class="line">        std = logvar.mul(<span class="number">0.5</span>).exp_()</span><br><span class="line">        eps = torch.FloatTensor(std.size()).normal_()</span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            eps = Variable(eps.cuda())</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            eps = Variable(eps)</span><br><span class="line">        <span class="keyword">return</span> eps.mul(std).add_(mu)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decode</span>(<span class="params">self, z</span>):</span></span><br><span class="line">        h3 = F.relu(self.fc3(z))</span><br><span class="line">        <span class="keyword">return</span> F.tanh(self.fc4(h3))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        mu, logvar = self.encode(x) <span class="comment"># 编码</span></span><br><span class="line">        z = self.reparametrize(mu, logvar) <span class="comment"># 重新参数化成正态分布</span></span><br><span class="line">        <span class="keyword">return</span> self.decode(z), mu, logvar <span class="comment"># 解码，同时输出均值方差</span></span><br><span class="line"></span><br><span class="line">net = VAE() <span class="comment"># 实例化网络</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    net = net.cuda()</span><br><span class="line"></span><br><span class="line">reconstruction_function = nn.MSELoss(size_average=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_function</span>(<span class="params">recon_x, x, mu, logvar</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    recon_x: generating images</span></span><br><span class="line"><span class="string">    x: origin images</span></span><br><span class="line"><span class="string">    mu: latent mean</span></span><br><span class="line"><span class="string">    logvar: latent log variance</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    MSE = reconstruction_function(recon_x, x)</span><br><span class="line">    <span class="comment"># loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)</span></span><br><span class="line">    KLD_element = mu.<span class="built_in">pow</span>(<span class="number">2</span>).add_(logvar.exp()).mul_(-<span class="number">1</span>).add_(<span class="number">1</span>).add_(logvar)</span><br><span class="line">    KLD = torch.<span class="built_in">sum</span>(KLD_element).mul_(-<span class="number">0.5</span>)</span><br><span class="line">    <span class="comment"># KL divergence</span></span><br><span class="line">    <span class="keyword">return</span> MSE + KLD</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_img</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="comment">#定义一个函数将最后的结果转换回图片</span></span><br><span class="line">    x = <span class="number">0.5</span> * (x + <span class="number">1.</span>)</span><br><span class="line">    x = x.clamp(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    x = x.view(x.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">for</span> im, _ <span class="keyword">in</span> train_data:</span><br><span class="line">        im = im.view(im.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">        im = Variable(im)</span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            im = im.cuda()</span><br><span class="line">            <span class="built_in">print</span>(torch.device(<span class="string">&quot;cuda&quot;</span>))</span><br><span class="line">        recon_im, mu, logvar = net(im)</span><br><span class="line">        loss = loss_function(recon_im, im, mu, logvar) / im.shape[<span class="number">0</span>] <span class="comment"># 将 loss 平均</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (e + <span class="number">1</span>) % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch: &#123;&#125;, Loss: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(e + <span class="number">1</span>, loss.data[<span class="number">0</span>]))</span><br><span class="line">        save = to_img(recon_im.cpu().data)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;./vae_img&#x27;</span>):</span><br><span class="line">            os.mkdir(<span class="string">&#x27;./vae_img&#x27;</span>)</span><br><span class="line">        save_image(save, <span class="string">&#x27;./vae_img/image_&#123;&#125;.png&#x27;</span>.<span class="built_in">format</span>(e + <span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<p>可以看看使用变分自动编码器得到的结果，可以发现效果比一般的编码器要好很多</p>
<h3 id="6-2-生成对抗网络"><a href="#6-2-生成对抗网络" class="headerlink" title="6.2 生成对抗网络"></a>6.2 生成对抗网络</h3><p>前面我们讲了自动编码器和变分自动编码器，不管是哪一个，都是通过计算生成图像和输入图像在每个像素点的误差来生成 loss，这一点是特别不好的，因为不同的像素点可能造成不同的视觉结果，但是可能他们的 loss 是相同的，所以通过单个像素点来得到 loss 是不准确的，这个时候我们需要一种全新的 loss 定义方式，就是通过对抗进行学习。</p>
<h4 id="6-2-1-什么是生成对抗网络"><a href="#6-2-1-什么是生成对抗网络" class="headerlink" title="6.2.1 什么是生成对抗网络"></a>6.2.1 什么是生成对抗网络</h4><p>这种训练方式定义了一种全新的网络结构，就是生成对抗网络，也就是 GANs。</p>
<p>根据这个名字就可以知道这个网络是由两部分组成的，第一部分是生成，第二部分是对抗。简单来说，就是有一个生成网络和一个判别网络，通过训练让两个网络相互竞争，生成网络来生成假的数据，对抗网络通过判别器去判别真伪，最后希望生成器生成的数据能够以假乱真。</p>
<p><strong>对抗：Discriminator Network</strong></p>
<p>首先我们来讲一下对抗过程，因为这个过程更加简单。</p>
<p>对抗过程简单来说就是一个判断真假的判别器，相当于一个二分类问题，我们输入一张真的图片希望判别器输出的结果是1，输入一张假的图片希望判别器输出的结果是0。这其实已经和原图片的 label 没有关系了，不管原图片到底是一个多少类别的图片，他们都统一称为真的图片，label 是 1 表示真实的；而生成的假的图片的 label 是 0 表示假的。</p>
<p>我们训练的过程就是希望这个判别器能够正确的判出真的图片和假的图片，这其实就是一个简单的二分类问题，对于这个问题可以用我们前面讲过的很多方法去处理，比如 logistic 回归，深层网络，卷积神经网络，循环神经网络都可以。</p>
<p><strong>生成：Generator Network</strong></p>
<p>接着我们看看生成网络如何生成一张假的图片。首先给出一个简单的高维的正态分布的噪声向量，这个时候我们可以通过仿射变换，也就是 xw+b 将其映射到一个更高的维度，然后将他重新排列成一个矩形，这样看着更像一张图片，接着进行一些卷积、转置卷积、池化、激活函数等进行处理，最后得到了一个与我们输入图片大小一模一样的噪音矩阵，这就是我们所说的假的图片。</p>
<p>这个时候我们如何去训练这个生成器呢？这就需要通过对抗学习，增大判别器判别这个结果为真的概率，通过这个步骤不断调整生成器的参数，希望生成的图片越来越像真的，而在这一步中我们不会更新判别器的参数，因为如果判别器不断被优化，可能生成器无论生成什么样的图片都无法骗过判别器。</p>
<p>关于生成对抗网络，出现了很多变形，比如 WGAN，LS-GAN 等等，这里我们只使用 mnist 举一些简单的例子来说明，更复杂的网络结构可以在 github 上找到相应的实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> tfs</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, sampler</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> MNIST</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10.0</span>, <span class="number">8.0</span>) <span class="comment"># 设置画图的尺寸</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;image.interpolation&#x27;</span>] = <span class="string">&#x27;nearest&#x27;</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;image.cmap&#x27;</span>] = <span class="string">&#x27;gray&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_images</span>(<span class="params">images</span>):</span> <span class="comment"># 定义画图工具</span></span><br><span class="line">    images = np.reshape(images, [images.shape[<span class="number">0</span>], -<span class="number">1</span>])</span><br><span class="line">    sqrtn = <span class="built_in">int</span>(np.ceil(np.sqrt(images.shape[<span class="number">0</span>])))</span><br><span class="line">    sqrtimg = <span class="built_in">int</span>(np.ceil(np.sqrt(images.shape[<span class="number">1</span>])))</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(figsize=(sqrtn, sqrtn))</span><br><span class="line">    gs = gridspec.GridSpec(sqrtn, sqrtn)</span><br><span class="line">    gs.update(wspace=<span class="number">0.05</span>, hspace=<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, img <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">        ax = plt.subplot(gs[i])</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        ax.set_xticklabels([])</span><br><span class="line">        ax.set_yticklabels([])</span><br><span class="line">        ax.set_aspect(<span class="string">&#x27;equal&#x27;</span>)</span><br><span class="line">        plt.imshow(img.reshape([sqrtimg,sqrtimg]))</span><br><span class="line">    <span class="keyword">return</span> </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_img</span>(<span class="params">x</span>):</span></span><br><span class="line">    x = tfs.ToTensor()(x)</span><br><span class="line">    <span class="keyword">return</span> (x - <span class="number">0.5</span>) / <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deprocess_img</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (x + <span class="number">1.0</span>) / <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChunkSampler</span>(<span class="params">sampler.Sampler</span>):</span> <span class="comment"># 定义一个取样的函数</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Samples elements sequentially from some offset. </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        num_samples: # of desired datapoints</span></span><br><span class="line"><span class="string">        start: offset where we should start selecting from</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_samples, start=<span class="number">0</span></span>):</span></span><br><span class="line">        self.num_samples = num_samples</span><br><span class="line">        self.start = start</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">iter</span>(<span class="built_in">range</span>(self.start, self.start + self.num_samples))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.num_samples</span><br><span class="line"></span><br><span class="line">NUM_TRAIN = <span class="number">50000</span></span><br><span class="line">NUM_VAL = <span class="number">5000</span></span><br><span class="line"></span><br><span class="line">NOISE_DIM = <span class="number">96</span></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line"></span><br><span class="line">train_set = MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=preprocess_img)</span><br><span class="line"></span><br><span class="line">train_data = DataLoader(train_set, batch_size=batch_size, sampler=ChunkSampler(NUM_TRAIN, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">val_set = MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=preprocess_img)</span><br><span class="line"></span><br><span class="line">val_data = DataLoader(val_set, batch_size=batch_size, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))</span><br><span class="line"></span><br><span class="line">imgs = deprocess_img(train_data.__iter__().<span class="built_in">next</span>()[<span class="number">0</span>].view(batch_size, <span class="number">784</span>)).numpy().squeeze() <span class="comment"># 可视化图片效果</span></span><br><span class="line">show_images(imgs)</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201105142821.png"></p>
<p><strong>简单版本的生成对抗网络</strong></p>
<p>通过前面我们知道生成对抗网络有两个部分构成，一个是生成网络，一个是对抗网络，我们首先写一个简单版本的网络结构，生成网络和对抗网络都是简单的多层神经网络</p>
<p><strong>判别网络</strong></p>
<p>判别网络的结构非常简单，就是一个二分类器，结构如下:</p>
<ul>
<li>全连接(784 -&gt; 256)</li>
<li>leakyrelu,  $\alpha$ 是 0.2</li>
<li>全连接(256 -&gt; 256)</li>
<li>leakyrelu, $\alpha$ 是 0.2</li>
<li>全连接(256 -&gt; 1)</li>
</ul>
<p>其中 leakyrelu 是指 f(x) = max($\alpha$ x, x)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span>():</span></span><br><span class="line">    net = nn.Sequential(        </span><br><span class="line">            nn.Linear(<span class="number">784</span>, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">return</span> net</span><br></pre></td></tr></table></figure>

<p><strong>生成网络</strong></p>
<p>接下来我们看看生成网络，生成网络的结构也很简单，就是根据一个随机噪声生成一个和数据维度一样的张量，结构如下：</p>
<ul>
<li>全连接(噪音维度 -&gt; 1024)</li>
<li>relu</li>
<li>全连接(1024 -&gt; 1024)</li>
<li>relu</li>
<li>全连接(1024 -&gt; 784)</li>
<li>tanh 将数据裁剪到 -1 ~ 1 之间</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span>(<span class="params">noise_dim=NOISE_DIM</span>):</span>   </span><br><span class="line">    net = nn.Sequential(</span><br><span class="line">        nn.Linear(noise_dim, <span class="number">1024</span>),</span><br><span class="line">        nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">        nn.Linear(<span class="number">1024</span>, <span class="number">1024</span>),</span><br><span class="line">        nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">        nn.Linear(<span class="number">1024</span>, <span class="number">784</span>),</span><br><span class="line">        nn.Tanh()</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> net</span><br></pre></td></tr></table></figure>

<p>接下来我们需要定义生成对抗网络的 loss，通过前面的讲解我们知道，对于对抗网络，相当于二分类问题，将真的判别为真的，假的判别为假的，作为辅助，可以参考一下论文中公式</p>
<p>$$ \ell_D = \mathbb{E}_{x \sim p_\text{data}}\left[\log D(x)\right] + \mathbb{E} _ {z \sim p(z)}\left[\log \left(1-D(G(z))\right)\right]$$</p>
<p>而对于生成网络，需要去骗过对抗网络，也就是将假的也判断为真的，作为辅助，可以参考一下论文中公式</p>
<p>$$\ell_G  =  \mathbb{E} _ {z \sim p(z)}\left[\log D(G(z))\right]$$</p>
<p>如果你还记得前面的二分类 loss，那么你就会发现上面这两个公式就是二分类 loss</p>
<p>$$ bce(s, y) = y * \log(s) + (1 - y) * \log(1 - s) $$</p>
<p>如果我们把 D(x) 看成真实数据的分类得分，那么 D(G(z)) 就是假数据的分类得分，所以上面判别器的 loss 就是将真实数据的得分判断为 1，假的数据的得分判断为 0，而生成器的 loss 就是将假的数据判断为 1</p>
<p>下面我们来实现一下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> tfs</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, sampler</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> MNIST</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">NUM_TRAIN = <span class="number">50000</span></span><br><span class="line">NUM_VAL = <span class="number">5000</span></span><br><span class="line"></span><br><span class="line">NOISE_DIM = <span class="number">96</span></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span>():</span></span><br><span class="line">    net = nn.Sequential(        </span><br><span class="line">            nn.Linear(<span class="number">784</span>, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span>(<span class="params">noise_dim=NOISE_DIM</span>):</span>   </span><br><span class="line">    net = nn.Sequential(</span><br><span class="line">        nn.Linear(noise_dim, <span class="number">1024</span>),</span><br><span class="line">        nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">        nn.Linear(<span class="number">1024</span>, <span class="number">1024</span>),</span><br><span class="line">        nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">        nn.Linear(<span class="number">1024</span>, <span class="number">784</span>),</span><br><span class="line">        nn.Tanh()</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line">bce_loss = nn.BCEWithLogitsLoss()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator_loss</span>(<span class="params">logits_real, logits_fake</span>):</span> <span class="comment"># 判别器的 loss</span></span><br><span class="line">    size = logits_real.shape[<span class="number">0</span>]</span><br><span class="line">    true_labels = Variable(torch.ones(size, <span class="number">1</span>)).<span class="built_in">float</span>().cuda()</span><br><span class="line">    false_labels = Variable(torch.zeros(size, <span class="number">1</span>)).<span class="built_in">float</span>().cuda()</span><br><span class="line">    loss = bce_loss(logits_real, true_labels) + bce_loss(logits_fake, false_labels)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator_loss</span>(<span class="params">logits_fake</span>):</span> <span class="comment"># 生成器的 loss  </span></span><br><span class="line">    size = logits_fake.shape[<span class="number">0</span>]</span><br><span class="line">    true_labels = Variable(torch.ones(size, <span class="number">1</span>)).<span class="built_in">float</span>().cuda()</span><br><span class="line">    loss = bce_loss(logits_fake, true_labels)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 adam 来进行训练，学习率是 3e-4, beta1 是 0.5, beta2 是 0.999</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_optimizer</span>(<span class="params">net</span>):</span></span><br><span class="line">    optimizer = torch.optim.Adam(net.parameters(), lr=<span class="number">3e-4</span>, betas=(<span class="number">0.5</span>, <span class="number">0.999</span>))</span><br><span class="line">    <span class="keyword">return</span> optimizer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_img</span>(<span class="params">x</span>):</span></span><br><span class="line">    x = tfs.ToTensor()(x)</span><br><span class="line">    <span class="keyword">return</span> (x - <span class="number">0.5</span>) / <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deprocess_img</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (x + <span class="number">1.0</span>) / <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChunkSampler</span>(<span class="params">sampler.Sampler</span>):</span> <span class="comment"># 定义一个取样的函数</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Samples elements sequentially from some offset. </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        num_samples: # of desired datapoints</span></span><br><span class="line"><span class="string">        start: offset where we should start selecting from</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_samples, start=<span class="number">0</span></span>):</span></span><br><span class="line">        self.num_samples = num_samples</span><br><span class="line">        self.start = start</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">iter</span>(<span class="built_in">range</span>(self.start, self.start + self.num_samples))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.num_samples</span><br><span class="line"></span><br><span class="line">train_set = MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=preprocess_img)</span><br><span class="line"></span><br><span class="line">train_data = DataLoader(train_set, batch_size=batch_size, sampler=ChunkSampler(NUM_TRAIN, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">val_set = MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=preprocess_img)</span><br><span class="line"></span><br><span class="line">val_data = DataLoader(val_set, batch_size=batch_size, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))</span><br><span class="line"></span><br><span class="line"><span class="comment">#下面我们开始训练一个这个简单的生成对抗网络</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_a_gan</span>(<span class="params">D_net, G_net, D_optimizer, G_optimizer, discriminator_loss, generator_loss, show_every=<span class="number">250</span>, </span></span></span><br><span class="line"><span class="params"><span class="function">                noise_size=<span class="number">96</span>, num_epochs=<span class="number">10</span></span>):</span></span><br><span class="line">    iter_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="keyword">for</span> x, _ <span class="keyword">in</span> train_data:</span><br><span class="line">            bs = x.shape[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># 判别网络</span></span><br><span class="line">            real_data = Variable(x).view(bs, -<span class="number">1</span>).cuda() <span class="comment"># 真实数据</span></span><br><span class="line">            logits_real = D_net(real_data) <span class="comment"># 判别网络得分</span></span><br><span class="line">            </span><br><span class="line">            sample_noise = (torch.rand(bs, noise_size) - <span class="number">0.5</span>) / <span class="number">0.5</span> <span class="comment"># -1 ~ 1 的均匀分布</span></span><br><span class="line">            g_fake_seed = Variable(sample_noise).cuda()</span><br><span class="line">            fake_images = G_net(g_fake_seed) <span class="comment"># 生成的假的数据</span></span><br><span class="line">            logits_fake = D_net(fake_images) <span class="comment"># 判别网络得分</span></span><br><span class="line"></span><br><span class="line">            d_total_error = discriminator_loss(logits_real, logits_fake) <span class="comment"># 判别器的 loss</span></span><br><span class="line">            D_optimizer.zero_grad()</span><br><span class="line">            d_total_error.backward()</span><br><span class="line">            D_optimizer.step() <span class="comment"># 优化判别网络</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 生成网络</span></span><br><span class="line">            g_fake_seed = Variable(sample_noise).cuda()</span><br><span class="line">            fake_images = G_net(g_fake_seed) <span class="comment"># 生成的假的数据</span></span><br><span class="line"></span><br><span class="line">            gen_logits_fake = D_net(fake_images)</span><br><span class="line">            g_error = generator_loss(gen_logits_fake) <span class="comment"># 生成网络的 loss</span></span><br><span class="line">            G_optimizer.zero_grad()</span><br><span class="line">            g_error.backward()</span><br><span class="line">            G_optimizer.step() <span class="comment"># 优化生成网络</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (iter_count % show_every == <span class="number">0</span>):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Iter: &#123;&#125;, D: &#123;:.4&#125;, G:&#123;:.4&#125;&#x27;</span>.<span class="built_in">format</span>(iter_count, d_total_error.data, g_error.data))</span><br><span class="line">                imgs_numpy = deprocess_img(fake_images.data.cpu().numpy())</span><br><span class="line">                show_images(imgs_numpy[<span class="number">0</span>:<span class="number">16</span>])</span><br><span class="line">                plt.show()</span><br><span class="line">                <span class="built_in">print</span>()</span><br><span class="line">            iter_count += <span class="number">1</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">D = discriminator().cuda()</span><br><span class="line">G = generator().cuda()</span><br><span class="line"></span><br><span class="line">D_optim = get_optimizer(D)</span><br><span class="line">G_optim = get_optimizer(G)</span><br><span class="line"></span><br><span class="line">train_a_gan(D, G, D_optim, G_optim, discriminator_loss, generator_loss)</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201105174301-min.gif"></p>
<p>我们已经完成了一个简单的生成对抗网络，是不是非常容易呢。但是可以看到效果并不是特别好，生成的数字也不是特别完整，因为我们仅仅使用了简单的多层全连接网络。</p>
<p>除了这种最基本的生成对抗网络之外，还有很多生成对抗网络的变式，有结构上的变式，也有 loss 上的变式，我们先讲一讲其中一种在 loss 上的变式，Least Squares GAN</p>
<p><strong>Least Squares GAN</strong></p>
<p><a href="https://arxiv.org/abs/1611.04076">Least Squares GAN</a> 比最原始的 GANs 的 loss 更加稳定，通过名字我们也能够看出这种 GAN 是通过最小平方误差来进行估计，而不是通过二分类的损失函数，下面我们看看 loss 的计算公式</p>
<p>$$\ell_G  =  \frac{1}{2}\mathbb{E} _ {z \sim p(z)}\left[\left(D(G(z))-1\right)^2\right]$$</p>
<p>$$ \ell_D = \frac{1}{2}\mathbb{E}_{x \sim p_\text{data}}\left[\left(D(x)-1\right)^2\right] + \frac{1}{2}\mathbb{E} _ {z \sim p(z)}\left[ \left(D(G(z))\right)^2\right]$$</p>
<p>可以看到 Least Squares GAN 通过最小二乘代替了二分类的 loss，下面我们定义一下 loss 函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ls_discriminator_loss</span>(<span class="params">scores_real, scores_fake</span>):</span></span><br><span class="line">    loss = <span class="number">0.5</span> * ((scores_real - <span class="number">1</span>) ** <span class="number">2</span>).mean() + <span class="number">0.5</span> * (scores_fake ** <span class="number">2</span>).mean()</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ls_generator_loss</span>(<span class="params">scores_fake</span>):</span></span><br><span class="line">    loss = <span class="number">0.5</span> * ((scores_fake - <span class="number">1</span>) ** <span class="number">2</span>).mean()</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">D = discriminator().cuda()</span><br><span class="line">G = generator().cuda()</span><br><span class="line"></span><br><span class="line">D_optim = get_optimizer(D)</span><br><span class="line">G_optim = get_optimizer(G)</span><br><span class="line"></span><br><span class="line">train_a_gan(D, G, D_optim, G_optim, ls_discriminator_loss, ls_generator_loss)</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201105174302-min.gif"></p>
<p>上面我们讲了 最基本的 GAN 和 least squares GAN，最后我们讲一讲使用卷积网络的 GAN，叫做深度卷积生成对抗网络</p>
<p><strong>Deep Convolutional GANs</strong></p>
<p>深度卷积生成对抗网络特别简单，就是将生成网络和对抗网络都改成了卷积网络的形式，下面我们来实现一下</p>
<p>卷积判别网络就是一个一般的卷积网络，结构如下</p>
<ul>
<li>32 Filters, 5x5, Stride 1, Leaky ReLU(alpha=0.01)</li>
<li>Max Pool 2x2, Stride 2</li>
<li>64 Filters, 5x5, Stride 1, Leaky ReLU(alpha=0.01)</li>
<li>Max Pool 2x2, Stride 2</li>
<li>Fully Connected size 4 x 4 x 64, Leaky ReLU(alpha=0.01)</li>
<li>Fully Connected size 1</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">build_dc_classifier</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(build_dc_classifier, self).__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.01</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, <span class="number">1</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.01</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.01</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = x.view(x.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p>卷积生成网络需要将一个低维的噪声向量变成一个图片数据，结构如下</p>
<ul>
<li>Fully connected of size 1024, ReLU</li>
<li>BatchNorm</li>
<li>Fully connected of size 7 x 7 x 128, ReLU</li>
<li>BatchNorm</li>
<li>Reshape into Image Tensor</li>
<li>64 conv2d^T filters of 4x4, stride 2, padding 1, ReLU</li>
<li>BatchNorm</li>
<li>1 conv2d^T filter of 4x4, stride 2, padding 1, TanH</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">build_dc_generator</span>(<span class="params">nn.Module</span>):</span> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, noise_dim=NOISE_DIM</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(build_dc_generator, self).__init__()</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(noise_dim, <span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">1024</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">7</span> * <span class="number">7</span> * <span class="number">128</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">7</span> * <span class="number">7</span> * <span class="number">128</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">128</span>, <span class="number">64</span>, <span class="number">4</span>, <span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">64</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        x = x.view(x.shape[<span class="number">0</span>], <span class="number">128</span>, <span class="number">7</span>, <span class="number">7</span>) <span class="comment"># reshape 通道是 128，大小是 7x7</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_dc_gan</span>(<span class="params">D_net, G_net, D_optimizer, G_optimizer, discriminator_loss, generator_loss, show_every=<span class="number">250</span>, </span></span></span><br><span class="line"><span class="params"><span class="function">                noise_size=<span class="number">96</span>, num_epochs=<span class="number">10</span></span>):</span></span><br><span class="line">    iter_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="keyword">for</span> x, _ <span class="keyword">in</span> train_data:</span><br><span class="line">            bs = x.shape[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># 判别网络</span></span><br><span class="line">            real_data = Variable(x).cuda() <span class="comment"># 真实数据</span></span><br><span class="line">            logits_real = D_net(real_data) <span class="comment"># 判别网络得分</span></span><br><span class="line">            </span><br><span class="line">            sample_noise = (torch.rand(bs, noise_size) - <span class="number">0.5</span>) / <span class="number">0.5</span> <span class="comment"># -1 ~ 1 的均匀分布</span></span><br><span class="line">            g_fake_seed = Variable(sample_noise).cuda()</span><br><span class="line">            fake_images = G_net(g_fake_seed) <span class="comment"># 生成的假的数据</span></span><br><span class="line">            logits_fake = D_net(fake_images) <span class="comment"># 判别网络得分</span></span><br><span class="line"></span><br><span class="line">            d_total_error = discriminator_loss(logits_real, logits_fake) <span class="comment"># 判别器的 loss</span></span><br><span class="line">            D_optimizer.zero_grad()</span><br><span class="line">            d_total_error.backward()</span><br><span class="line">            D_optimizer.step() <span class="comment"># 优化判别网络</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 生成网络</span></span><br><span class="line">            g_fake_seed = Variable(sample_noise).cuda()</span><br><span class="line">            fake_images = G_net(g_fake_seed) <span class="comment"># 生成的假的数据</span></span><br><span class="line"></span><br><span class="line">            gen_logits_fake = D_net(fake_images)</span><br><span class="line">            g_error = generator_loss(gen_logits_fake) <span class="comment"># 生成网络的 loss</span></span><br><span class="line">            G_optimizer.zero_grad()</span><br><span class="line">            g_error.backward()</span><br><span class="line">            G_optimizer.step() <span class="comment"># 优化生成网络</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (iter_count % show_every == <span class="number">0</span>):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Iter: &#123;&#125;, D: &#123;:.4&#125;, G:&#123;:.4&#125;&#x27;</span>.<span class="built_in">format</span>(iter_count, d_total_error.data, g_error.data))</span><br><span class="line">                imgs_numpy = deprocess_img(fake_images.data.cpu().numpy())</span><br><span class="line">                show_images(imgs_numpy[<span class="number">0</span>:<span class="number">16</span>])</span><br><span class="line">                plt.show()</span><br><span class="line">                <span class="built_in">print</span>()</span><br><span class="line">            iter_count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">D_DC = build_dc_classifier().cuda()</span><br><span class="line">G_DC = build_dc_generator().cuda()</span><br><span class="line"></span><br><span class="line">D_DC_optim = get_optimizer(D_DC)</span><br><span class="line">G_DC_optim = get_optimizer(G_DC)</span><br><span class="line"></span><br><span class="line">train_dc_gan(D_DC, G_DC, D_DC_optim, G_DC_optim, discriminator_loss, generator_loss, num_epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201105174303-min.gif"><br>可以看到，通过 DCGANs 能够得到更加清楚的结果</p>
<h3 id="6-3-Improving-GAN"><a href="#6-3-Improving-GAN" class="headerlink" title="6.3 Improving GAN"></a>6.3 Improving GAN</h3><h4 id="6-3-1-Wasserstein-GAN"><a href="#6-3-1-Wasserstein-GAN" class="headerlink" title="6.3.1 Wasserstein GAN"></a>6.3.1 Wasserstein GAN</h4><p>Wasserstein GAN是GAN的一种变式，WGAN的出现解决了下面这些难点</p>
<ul>
<li>彻底解决了训练不稳定的问题</li>
<li>基本解决了coolapse mode 的问题，确保了生成样本的多样性</li>
<li>训练中有一个向交叉熵，准确率的数值指标来衡量训练的进程，数值越小代表GAN训练得越好，同时也代表着生成的图片质量越高</li>
<li>不需要精心设计网络结构也能取得较好的效果</li>
</ul>
<h3 id="6-4-应用介绍"><a href="#6-4-应用介绍" class="headerlink" title="6.4 应用介绍"></a>6.4 应用介绍</h3><h4 id="6-4-1-Conditional-GAN"><a href="#6-4-1-Conditional-GAN" class="headerlink" title="6.4.1 Conditional GAN"></a>6.4.1 Conditional GAN</h4><p>Conditional GAN的一个应用是文字生成图片</p>
<h4 id="6-4-2-Cycle-GAN"><a href="#6-4-2-Cycle-GAN" class="headerlink" title="6.4.2 Cycle GAN"></a>6.4.2 Cycle GAN</h4><p>根据一个人的作品，想象他完成其他场景会是什么样</p>
<h2 id="第七章-深度学习实战"><a href="#第七章-深度学习实战" class="headerlink" title="第七章 深度学习实战"></a>第七章 深度学习实战</h2><h3 id="7-1-实例一，猫狗大战：运用预训练卷积神经网络进行特征提取与预训"><a href="#7-1-实例一，猫狗大战：运用预训练卷积神经网络进行特征提取与预训" class="headerlink" title="7.1 实例一，猫狗大战：运用预训练卷积神经网络进行特征提取与预训"></a>7.1 实例一，猫狗大战：运用预训练卷积神经网络进行特征提取与预训</h3><h4 id="7-1-1-背景介绍"><a href="#7-1-1-背景介绍" class="headerlink" title="7.1.1 背景介绍"></a>7.1.1 背景介绍</h4><p>Asirra是一个图像识别机制的验证码，其有很多不同猫狗的照片（三百万张），可以用他的子集当作训练集</p>
<h4 id="7-1-2-原理分析"><a href="#7-1-2-原理分析" class="headerlink" title="7.1.2 原理分析"></a>7.1.2 原理分析</h4><p>对于这个问题，简单的网络模型可能效果并不好，这个时候，使用一些成熟的模型，比如VggNet，GoogleNet，ResNet等可以帮助我们解决问题，为了节省计算资源和时间，可以通过迁移学习实现。</p>
<p><strong>迁移学习</strong></p>
<p>对于一个特定任务，如果没有来自该任务足够的数据集，传统的监督学习无法支持，而迁移学习允许通过借用已经存在的一些相关任务的标签数据来处理这些场景，把解决相关任务时获得的知识存储下来，并将它应用到我们感兴趣的目标任务中。</p>
<p>卷积神经网络可以理解为两个部分：前面的<strong>卷积</strong>部分和后面的<strong>分类</strong>部分，卷积部分主要用于提取图片特征，而预训练的网络对于特征提取效果已经非常好。我们可以直接用预训练的网络卷积部分来提取我们自己的图片特征，而对于自己的任务，比如猫狗二分类，就用自己的分类全连接层即可。</p>
<p>当然，迁移学习并不是任何时候都能使用，需要它们<strong>完成的任务是相关的</strong>，所以迁移学习在相似数据集上的应用效果才是良好的。</p>
<p><strong>实现方法</strong></p>
<ol>
<li>第一种方法：导入预训练的卷积网络，将最后的全连接层改成我们自己设计的全连接层，然后更新整个网络，最后能特别快地达到收敛</li>
<li>第二种方法：锁定前面卷积层的参数，让网络训练只更新最后全连接层的参数，可以使训练时间大大减少</li>
<li>第三种方法：使用多个预训练好的网络，将它们并联在一起，图片经过每个网络都会得到特征图，我们将这些特征图拼接在一起进入最后的全连接层</li>
</ol>
<h4 id="7-1-3-代码实现"><a href="#7-1-3-代码实现" class="headerlink" title="7.1.3 代码实现"></a>7.1.3 代码实现</h4><p>1.数据预处理</p>
<p>数据集可以去 <a href="https://www.kaggle.com/c/dogs-vs-cats/data">https://www.kaggle.com/c/dogs-vs-cats/data</a> 下载</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line">train_root = <span class="string">&#x27;./data/dogs-vs-cats/train/&#x27;</span></span><br><span class="line">val_root = <span class="string">&#x27;./data/dogs-vs-cats/val/&#x27;</span></span><br><span class="line">data_file=os.listdir(train_root)</span><br><span class="line"><span class="comment">#print(data_file)</span></span><br><span class="line">dog_file = <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x:x.split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>]==<span class="string">&#x27;dog&#x27;</span><span class="keyword">and</span> x!=<span class="string">&quot;dog&quot;</span>,data_file))</span><br><span class="line">cat_file = <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x:x.split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>]==<span class="string">&#x27;cat&#x27;</span><span class="keyword">and</span> x!=<span class="string">&quot;cat&quot;</span>,data_file))</span><br><span class="line"></span><br><span class="line">root = <span class="string">&#x27;./data/dogs-vs-cats/&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(train_root+<span class="string">&#x27;dog/&#x27;</span>):</span><br><span class="line">    os.makedirs(train_root+<span class="string">&#x27;dog/&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(train_root+<span class="string">&#x27;cat/&#x27;</span>):</span><br><span class="line">    os.makedirs(train_root+<span class="string">&#x27;cat/&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(val_root+<span class="string">&#x27;dog/&#x27;</span>):</span><br><span class="line">    os.makedirs(val_root+<span class="string">&#x27;dog/&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(val_root+<span class="string">&#x27;cat/&#x27;</span>):</span><br><span class="line">    os.makedirs(val_root+<span class="string">&#x27;cat/&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dog_file)):</span><br><span class="line">    pic_path = root+<span class="string">&#x27;train/&#x27;</span>+dog_file[i]</span><br><span class="line">    <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(dog_file)*<span class="number">0.9</span>:</span><br><span class="line">        obj_path = train_root+<span class="string">&#x27;dog/&#x27;</span>+dog_file[i]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        obj_path = val_root+<span class="string">&#x27;dog/&#x27;</span>+dog_file[i]</span><br><span class="line">    shutil.move(pic_path,obj_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(cat_file)):</span><br><span class="line">    pic_path = root+<span class="string">&#x27;train/&#x27;</span>+cat_file[i]</span><br><span class="line">    <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(cat_file)*<span class="number">0.9</span>:</span><br><span class="line">        obj_path = train_root+<span class="string">&#x27;cat/&#x27;</span>+cat_file[i]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        obj_path = val_root+<span class="string">&#x27;cat/&#x27;</span>+cat_file[i]</span><br><span class="line">    shutil.move(pic_path,obj_path)</span><br></pre></td></tr></table></figure>

<p>上面的操作实现了，将猫狗照片分别移动到训练集和验证集，其中90%的数据作为训练集，10%的图片作为验证集，使用<code>shutil.move()</code>来移动图片</p>
<p>2.迁移学习模型训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models,transforms,datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">img_classes=<span class="number">2</span></span><br><span class="line">epoch_num = <span class="number">2</span></span><br><span class="line">path = <span class="string">&quot;./data/dogs-vs-cats/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#数据</span></span><br><span class="line">data_transform = transforms.Compose([</span><br><span class="line">    transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>],[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ImageFOLDER 返回的是一个list，这里的写法是字典的形式</span></span><br><span class="line">data_image = &#123;x: datasets.ImageFolder(root=os.path.join(path, x),transform=data_transform) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&quot;train&quot;</span>, <span class="string">&quot;val&quot;</span>]&#125;</span><br><span class="line">data_loader_image = &#123;x: DataLoader(dataset=data_image[x],batch_size=<span class="number">4</span>,shuffle=<span class="literal">True</span>) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&quot;train&quot;</span>, <span class="string">&quot;val&quot;</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分类</span></span><br><span class="line">classes = data_image[<span class="string">&quot;train&quot;</span>].classes <span class="comment"># 按文件夹名字分类</span></span><br><span class="line">classes_index = data_image[<span class="string">&quot;train&quot;</span>].class_to_idx <span class="comment"># 文件夹类名所对应的链值</span></span><br><span class="line"><span class="comment"># 打印类别</span></span><br><span class="line"><span class="built_in">print</span>(classes) </span><br><span class="line"><span class="built_in">print</span>(classes_index)</span><br><span class="line"><span class="comment"># 打印训练集，验证集大小</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train data set:&quot;</span>, <span class="built_in">len</span>(data_image[<span class="string">&quot;train&quot;</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;val data set:&quot;</span>, <span class="built_in">len</span>(data_image[<span class="string">&quot;val&quot;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment">#导入预训练的网络，并修改全连接层</span></span><br><span class="line">model = models.resnet18(pretrained=<span class="literal">True</span>) <span class="comment"># 18层的残差网络</span></span><br><span class="line"><span class="comment">#print(model)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> parma <span class="keyword">in</span> model.parameters():</span><br><span class="line">    parma.requires_grad = <span class="literal">False</span>  <span class="comment"># 不进行梯度更新</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 改变模型的全连接层，本项目只需要输出2类</span></span><br><span class="line">model.fc = nn.Sequential(nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">                                       nn.ReLU(),</span><br><span class="line">                                       nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">                                       nn.Linear(<span class="number">256</span>, <span class="number">256</span>),</span><br><span class="line">                                       nn.ReLU(),</span><br><span class="line">                                       nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">                                       nn.Linear(<span class="number">256</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index, parma <span class="keyword">in</span> <span class="built_in">enumerate</span>(model.fc.parameters()):</span><br><span class="line">    parma.requires_grad = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否有GPU</span></span><br><span class="line">use_gpu = torch.cuda.is_available()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Find GPU: &quot;</span>,use_gpu)</span><br><span class="line"><span class="keyword">if</span> use_gpu:</span><br><span class="line">    model = model.cuda()</span><br><span class="line"><span class="comment">#print(model)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义代价函数</span></span><br><span class="line">cost = torch.nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">optimizer = torch.optim.Adam(model.fc.parameters(),lr=<span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>():</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epoch_num):</span><br><span class="line">        since = time.time()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Epoch&#123;&#125;/&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>, epoch_num))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">10</span>)</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> [<span class="string">&quot;train&quot;</span>, <span class="string">&quot;val&quot;</span>]:</span><br><span class="line">            <span class="keyword">if</span> param == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">                model.train = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                model.train = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            running_correct = <span class="number">0</span></span><br><span class="line">            batch = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> data_loader_image[param]:</span><br><span class="line">                batch += <span class="number">1</span></span><br><span class="line">                X, y = data</span><br><span class="line">                <span class="keyword">if</span> use_gpu:</span><br><span class="line">                    X, y = Variable(X.cuda()), Variable(y.cuda())</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    X, y = Variable(X), Variable(y)</span><br><span class="line"></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">                y_pred = model(X)</span><br><span class="line">                _, pred = torch.<span class="built_in">max</span>(y_pred.data, <span class="number">1</span>)</span><br><span class="line">                loss = cost(y_pred,y)</span><br><span class="line">                <span class="keyword">if</span> param == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">                    loss.backward()</span><br><span class="line">                    optimizer.step()</span><br><span class="line">                running_loss += loss.item()</span><br><span class="line">                <span class="comment"># running_loss += loss.data</span></span><br><span class="line">                running_correct += torch.<span class="built_in">sum</span>(pred == y.data)</span><br><span class="line">                <span class="keyword">if</span> batch % <span class="number">5</span> == <span class="number">0</span> <span class="keyword">and</span> param == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;Batch &#123;&#125;, Train Loss:&#123;:.4f&#125;, Train ACC:&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                        batch, running_loss / (<span class="number">4</span> * batch), <span class="number">100</span> * running_correct / (<span class="number">4</span> * batch)))</span><br><span class="line"></span><br><span class="line">            epoch_loss = running_loss / <span class="built_in">len</span>(data_image[param])</span><br><span class="line">            epoch_correct = <span class="number">100</span> * running_correct / <span class="built_in">len</span>(data_image[param])</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; Loss:&#123;:.4f&#125;, Correct:&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(param, epoch_loss, epoch_correct))</span><br><span class="line">        now_time = time.time() - since</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Training time is:&#123;:.0f&#125;m &#123;:.0f&#125;s&quot;</span>.<span class="built_in">format</span>(now_time // <span class="number">60</span>, now_time % <span class="number">60</span>))</span><br><span class="line"></span><br><span class="line">train()</span><br><span class="line">torch.save(model, <span class="string">&#x27;dogsvscats.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>测试</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms, models</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">model = torch.load(<span class="string">&#x27;dogsvscats.pth&#x27;</span>)</span><br><span class="line">path = <span class="string">&quot;./data/dogs-vs-cats&quot;</span></span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">                                transforms.ToTensor(),</span><br><span class="line">                                transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])])</span><br><span class="line"></span><br><span class="line">data_test_img = datasets.ImageFolder(root=path+<span class="string">&quot;/val/&quot;</span>, transform = transform) </span><br><span class="line"></span><br><span class="line">data_loader_test_img = torch.utils.data.DataLoader(dataset=data_test_img,</span><br><span class="line">                                                  batch_size = <span class="number">16</span>,shuffle=<span class="literal">True</span>) <span class="comment">#载入测试数据集，并随机打乱</span></span><br><span class="line">classes = data_test_img.classes   <span class="comment">##class</span></span><br><span class="line"></span><br><span class="line">image, label = <span class="built_in">next</span>(<span class="built_in">iter</span>(data_loader_test_img))</span><br><span class="line">images = Variable(image).cuda()</span><br><span class="line">y_pred = model(images)</span><br><span class="line">_,pred = torch.<span class="built_in">max</span>(y_pred.data, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(pred)</span><br><span class="line"><span class="built_in">print</span>(label)</span><br><span class="line"></span><br><span class="line">img = torchvision.utils.make_grid(image)</span><br><span class="line">img = img.numpy().transpose(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)</span><br><span class="line">mean = [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>]</span><br><span class="line">std = [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>]</span><br><span class="line">img = img * std + mean</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Pred Label:&quot;</span>, [classes[i] <span class="keyword">for</span> i <span class="keyword">in</span> pred])</span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h3 id="7-2-实例二，Deep-Dream：探索卷积神经网络眼中的世界"><a href="#7-2-实例二，Deep-Dream：探索卷积神经网络眼中的世界" class="headerlink" title="7.2 实例二，Deep Dream：探索卷积神经网络眼中的世界"></a>7.2 实例二，Deep Dream：探索卷积神经网络眼中的世界</h3><p>2015年，Google发布了一个有意思的东西，叫做Deep Dream</p>
<h4 id="7-2-1-原理介绍"><a href="#7-2-1-原理介绍" class="headerlink" title="7.2.1 原理介绍"></a>7.2.1 原理介绍</h4><p><strong>1.反向神经网络</strong></p>
<p>我们知道经过训练之后，每一层网络足部提取越来越高级的图像特征，知道最后一层将这些特征比较做出分类的结果。比如前面几层也许在寻找边缘和拐角的特征，中间几层分析整体的轮廓特征，这样不断的增加层数就可以发展出越来越多的复杂特征，最后几层将这些特征要素组合起来形成完整的解释，这样到最后网络就会对非常复杂的东西，比如小猫，树叶等图片有所反应</p>
<p><strong>2.Deep Dream</strong></p>
<p>如果我们将算法反复地应用到自身的输出上，不断迭代，并在每次迭代后应用一些缩放，就能不断地激活特征，得到无尽的新效果。</p>
<h4 id="7-2-2-代码实现"><a href="#7-2-2-代码实现" class="headerlink" title="7.2.2 代码实现"></a>7.2.2 代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, utils</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="comment"># PIL.ImageFilter是Python中的图像滤波，主要对图像进行平滑、锐化、边界增强等滤波处理</span></span><br><span class="line"><span class="comment"># PIL.ImageChops模块包含一些算术图形操作，叫做channel operations（“chops”）。这些操作可用于诸多目的，比如图像特效，图像组合，算法绘图等等</span></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageFilter, ImageChops</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载图像并显示</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_image</span>(<span class="params">path</span>):</span></span><br><span class="line">    image = Image.<span class="built_in">open</span>(path)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.title(<span class="string">&quot;Image loaded successfully&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对数据集的标准化设置——减去均值再除以标准差</span></span><br><span class="line">normalise = transforms.Normalize(</span><br><span class="line">    mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">    std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集的预处理，包括缩放、转换成Tensor、标准化</span></span><br><span class="line">preprocess = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">224</span>,<span class="number">224</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    normalise</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 逆向处理过程，逆标准化，图像乘以标准差再加上均值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deprocess</span>(<span class="params">image</span>):</span></span><br><span class="line">    <span class="keyword">return</span> image * torch.Tensor([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]).cuda()  + torch.Tensor([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]).cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载vgg16的预训练模型，传到GPU上，输出网络结构</span></span><br><span class="line">vgg = models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line">vgg = vgg.cuda()</span><br><span class="line">modulelist = <span class="built_in">list</span>(vgg.features.modules())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这是deep dream的实际代码，特定层的梯度被设置为等于该层的响应，这导致了该层响应最大化。换句话说，我们正在增强一层检测到的特征，对输入图像（octaves）应用梯度上升算法。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dd_helper</span>(<span class="params">image, layer, iterations, lr</span>):</span>        </span><br><span class="line">    <span class="comment"># 一开始的输入是图像经过预处理、在正数第一个维度上增加一个维度以匹配神经网络的输入、传到GPU上</span></span><br><span class="line">    <span class="built_in">input</span> = Variable(preprocess(image).unsqueeze(<span class="number">0</span>).cuda(), requires_grad=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># vgg梯度清零</span></span><br><span class="line">    vgg.zero_grad()</span><br><span class="line">    <span class="comment"># 开始迭代</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">        <span class="comment"># 一层一层传递输入</span></span><br><span class="line">        out = <span class="built_in">input</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(layer):</span><br><span class="line">            out = modulelist[j+<span class="number">1</span>](out)</span><br><span class="line">        <span class="comment"># 损失是输出的范数</span></span><br><span class="line">        loss = out.norm()</span><br><span class="line">        <span class="comment"># 损失反向传播</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># 输入的数据是上次迭代时的输入数据+学习率×输入的梯度</span></span><br><span class="line">        <span class="built_in">input</span>.data = <span class="built_in">input</span>.data + lr * <span class="built_in">input</span>.grad.data</span><br><span class="line">    <span class="comment"># 将从网络结构中取出的输入数据的第一个维度去掉</span></span><br><span class="line">    <span class="built_in">input</span> = <span class="built_in">input</span>.data.squeeze()</span><br><span class="line">    <span class="comment"># 矩阵转置</span></span><br><span class="line">    <span class="built_in">input</span>.transpose_(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">input</span>.transpose_(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 将输入逆标准化后强制截断在0到1的范围内</span></span><br><span class="line">    <span class="built_in">input</span> = np.clip(deprocess(<span class="built_in">input</span>), <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 得到像素值为0到255的图像</span></span><br><span class="line">    im = Image.fromarray(np.uint8(<span class="built_in">input</span>*<span class="number">255</span>))</span><br><span class="line">    <span class="keyword">return</span> im</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这是一个递归函数，用于创建octaves，并且将由一次递归调用生成的图像与由上一级递归调用生成的图像相融合</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deep_dream_vgg</span>(<span class="params">image, layer, iterations, lr, octave_scale, num_octaves</span>):</span></span><br><span class="line">    <span class="comment"># 若octave序号大于0，即还未到达最底层的octave时，一层一层递归</span></span><br><span class="line">    <span class="keyword">if</span> num_octaves&gt;<span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 对图像进行高斯滤波（高斯模糊）</span></span><br><span class="line">        image1 = image.<span class="built_in">filter</span>(ImageFilter.GaussianBlur(<span class="number">2</span>))</span><br><span class="line">        <span class="comment"># 判断是否缩放</span></span><br><span class="line">        <span class="keyword">if</span>(image1.size[<span class="number">0</span>]/octave_scale &lt; <span class="number">1</span> <span class="keyword">or</span> image1.size[<span class="number">1</span>]/octave_scale&lt;<span class="number">1</span>):</span><br><span class="line">            size = image1.size</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            size = (<span class="built_in">int</span>(image1.size[<span class="number">0</span>]/octave_scale), <span class="built_in">int</span>(image1.size[<span class="number">1</span>]/octave_scale))</span><br><span class="line">        <span class="comment"># 图像缩放    </span></span><br><span class="line">        image1 = image1.resize(size,Image.ANTIALIAS)</span><br><span class="line">        <span class="comment"># 递归调用，直至num_octave==0</span></span><br><span class="line">        image1 = deep_dream_vgg(image1, layer, iterations, lr, octave_scale, num_octaves-<span class="number">1</span>)</span><br><span class="line">        size = (image.size[<span class="number">0</span>], image.size[<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># 将图像缩放到最初输入图像的大小</span></span><br><span class="line">        image1 = image1.resize(size,Image.ANTIALIAS)</span><br><span class="line">        <span class="comment"># 将最初输入的图像与合成的相同尺寸大小的图像融合</span></span><br><span class="line">        image = ImageChops.blend(image, image1, <span class="number">0.6</span>)</span><br><span class="line"><span class="comment">#     print(&quot;-------------- Recursive level: &quot;, num_octaves, &#x27;--------------&#x27;)</span></span><br><span class="line">    <span class="comment"># 按照dd_helper中的流程生成图像</span></span><br><span class="line">    img_result = dd_helper(image, layer, iterations, lr)</span><br><span class="line">    <span class="comment"># 图像缩放并显示</span></span><br><span class="line">    img_result = img_result.resize(image.size)</span><br><span class="line">    plt.imshow(img_result)</span><br><span class="line">    <span class="keyword">return</span> img_result</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 加载图像(原始图像)</span></span><br><span class="line">sky = load_image(<span class="string">&#x27;1.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于vgg16最后一个卷积层conv5_3,迭代5次，学习率为0.2,octave缩放比例为2,octave从第20层开始</span></span><br><span class="line">sky_28 = deep_dream_vgg(sky, <span class="number">28</span>, <span class="number">5</span>, <span class="number">0.2</span>, <span class="number">2</span>, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>python</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo主题 | Hexo-yilia的配置</title>
    <url>/posts/48052.html</url>
    <content><![CDATA[<p>我在使用yilia这个主题时用到的一些设置</p>
<h1 id="获取Yilia主题"><a href="#获取Yilia主题" class="headerlink" title="获取Yilia主题"></a>获取Yilia主题</h1><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">$ cd /hexo</span><br><span class="line">$ git clone https:<span class="regexp">//gi</span>thub.com<span class="regexp">/litten/</span>hexo-theme-yilia.git themes/yilia</span><br></pre></td></tr></table></figure>

<p><img src="https://s2.ax1x.com/2019/09/06/nMNdc4.png" alt="nMNdc4.png"></p>
<ul>
<li>其中/languages存放语言包，/layout存放主题布局文件，/source存放静态文件，如图片，图标等，/source-src存放外部引用资源</li>
</ul>
<h1 id="添加新页面"><a href="#添加新页面" class="headerlink" title="添加新页面"></a>添加新页面</h1><p><img src="https://s2.ax1x.com/2019/09/06/nMUhGT.png" alt="nMUhGT.png"></p>
<ul>
<li>打开<code>/hexo/theme/yilia/_config.yml</code>文件，在menu处修改为：</li>
</ul>
<figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line">menu:</span><br><span class="line">  主页: /</span><br><span class="line">  分类: <span class="string">/categories</span></span><br><span class="line">  标签: <span class="string">/tag</span></span><br></pre></td></tr></table></figure>

<ul>
<li>新建页面</li>
</ul>
<figure class="highlight haxe"><table><tr><td class="code"><pre><span class="line">hexo <span class="keyword">new</span> <span class="type">page</span> categories</span><br></pre></td></tr></table></figure>

<ul>
<li>其会在/hexo/source下生成一个categories文件夹，其下有index.md文件，修改categories/index.md：</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">文章分类</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2019-07-10 18:52:02</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">&quot;categories&quot;</span></span><br><span class="line"><span class="attr">layout:</span> <span class="string">&quot;categories&quot;</span></span><br><span class="line"><span class="attr">comments:</span> <span class="literal">false</span></span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></table></figure>

<ul>
<li>在hexo/theme/yilia/source/main.0cf68a.css文件中添加内容：</li>
</ul>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">category-all-page &#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">30px</span> <span class="number">40px</span> <span class="number">30px</span> <span class="number">40px</span>;</span><br><span class="line">    <span class="attribute">position</span>: relative;</span><br><span class="line">    <span class="attribute">min-height</span>: <span class="number">70vh</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-class">.category-all-page</span> <span class="selector-tag">h2</span> &#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">20px</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-class">.category-all-page</span> <span class="selector-class">.category-all-title</span> &#123;</span><br><span class="line">    <span class="attribute">text-align</span>: center;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-class">.category-all-page</span> <span class="selector-class">.category-all</span> &#123;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">20px</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-class">.category-all-page</span> <span class="selector-class">.category-list</span> &#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">list-style</span>: none;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-class">.category-all-page</span> <span class="selector-class">.category-list-item-list-item</span> &#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">10px</span> <span class="number">15px</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-class">.category-all-page</span> <span class="selector-class">.category-list-item-list-count</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: <span class="variable">$grey</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-class">.category-all-page</span> <span class="selector-class">.category-list-item-list-count</span>:before &#123;</span><br><span class="line">    <span class="attribute">display</span>: inline;</span><br><span class="line">    <span class="attribute">content</span>: <span class="string">&quot; (&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-class">.category-all-page</span> <span class="selector-class">.category-list-item-list-count</span>:after &#123;</span><br><span class="line">    <span class="attribute">display</span>: inline;</span><br><span class="line">    <span class="attribute">content</span>: <span class="string">&quot;) &quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-class">.category-all-page</span> <span class="selector-class">.category-list-item</span> &#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">10px</span> <span class="number">10px</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-class">.category-all-page</span> <span class="selector-class">.category-list-count</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: <span class="variable">$grey</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-class">.category-all-page</span> <span class="selector-class">.category-list-count</span>:before &#123;</span><br><span class="line">    <span class="attribute">display</span>: inline;</span><br><span class="line">    <span class="attribute">content</span>: <span class="string">&quot; (&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-class">.category-all-page</span> <span class="selector-class">.category-list-count</span>:after &#123;</span><br><span class="line">    <span class="attribute">display</span>: inline;</span><br><span class="line">    <span class="attribute">content</span>: <span class="string">&quot;) &quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-class">.category-all-page</span> <span class="selector-class">.category-list-child</span> &#123;</span><br><span class="line">    <span class="attribute">padding-left</span>: <span class="number">10px</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>新建/hexo/theme/yilia/layout/categories.ejs文件，输入：</li>
</ul>
<figure class="highlight erb"><table><tr><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">article</span> <span class="attr">class</span>=<span class="string">&quot;article article-type-post show&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">header</span> <span class="attr">class</span>=<span class="string">&quot;article-header&quot;</span> <span class="attr">style</span>=<span class="string">&quot;border-bottom: 1px solid #ccc&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">h1</span> <span class="attr">class</span>=<span class="string">&quot;article-title&quot;</span> <span class="attr">itemprop</span>=<span class="string">&quot;name&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">    &lt;%=</span><span class="ruby"> page.title </span><span class="xml">%&gt;</span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;/<span class="name">header</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">  &lt;%</span><span class="ruby"> <span class="keyword">if</span> (site.categories.length)&#123; </span><span class="xml">%&gt;</span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;category-all-page&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">h2</span>&gt;</span>共计<span class="symbol">&amp;nbsp;</span>&lt;%=</span><span class="ruby"> site.categories.length </span><span class="xml">%&gt;<span class="symbol">&amp;nbsp;</span>个分类<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span></span><br><span class="line"><span class="xml">    &lt;%-</span><span class="ruby"> list_categories(site.categories, &#123;</span></span><br><span class="line"><span class="ruby">      <span class="symbol">show_count:</span> <span class="literal">true</span>,</span></span><br><span class="line"><span class="ruby">      <span class="class"><span class="keyword">class</span>: &#x27;<span class="title">category</span>-<span class="title">list</span>-<span class="title">item</span>&#x27;,</span></span></span><br><span class="line"><span class="ruby">      <span class="symbol">style:</span> <span class="string">&#x27;list&#x27;</span>,</span></span><br><span class="line"><span class="ruby">      <span class="symbol">depth:</span> <span class="number">2</span>,</span></span><br><span class="line"><span class="ruby">      <span class="symbol">separator:</span> <span class="string">&#x27;&#x27;</span></span></span><br><span class="line"><span class="ruby">    &#125;) </span><span class="xml">%&gt;</span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="xml">  &lt;%</span><span class="ruby"> &#125; </span><span class="xml">%&gt;</span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">article</span>&gt;</span></span></span><br></pre></td></tr></table></figure>

<ul>
<li>在写文章时加入：</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">hexo-yilia的配置</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2019-09-06 17:53:09</span></span><br><span class="line"><span class="attr">tags:</span> [<span class="string">hexo</span>,<span class="string">学习笔记</span>]</span><br><span class="line"><span class="attr">categories:</span> [<span class="string">hexo</span>,<span class="string">学习笔记</span>]</span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></table></figure>

<h1 id="设置打赏"><a href="#设置打赏" class="headerlink" title="设置打赏"></a>设置打赏</h1><ul>
<li>将二维码图片放到/yilia/source/img中</li>
<li>打开主题目录下的_config.yml文件，在reward_wording处修改</li>
</ul>
<figure class="highlight vala"><table><tr><td class="code"><pre><span class="line"><span class="meta"># 打赏</span></span><br><span class="line"><span class="meta"># 打赏type设定：0-关闭打赏； 1-文章对应的md文件里有reward:true属性，才有打赏； 2-所有文章均有打赏</span></span><br><span class="line">reward_type: <span class="number">1</span></span><br><span class="line"><span class="meta"># 打赏wording</span></span><br><span class="line">reward_wording: <span class="string">&#x27;给作者点一杯奶茶吧&#x27;</span></span><br><span class="line"><span class="meta"># 支付宝二维码图片地址，跟你设置头像的方式一样。比如：/assets/img/alipay.jpg</span></span><br><span class="line">alipay: /img/alipay.png</span><br><span class="line"><span class="meta"># 微信二维码图片地址</span></span><br><span class="line">weixin: /img/weixinpay.png</span><br></pre></td></tr></table></figure>

<ul>
<li>在需要的文章添加：</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">hexo-yilia的配置</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2019-09-06 17:53:09</span></span><br><span class="line"><span class="attr">tags:</span> [<span class="string">hexo</span>,<span class="string">学习笔记</span>]</span><br><span class="line"><span class="attr">categories:</span> [<span class="string">hexo</span>,<span class="string">学习笔记</span>]</span><br><span class="line"><span class="attr">reward:</span> <span class="literal">true</span></span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></table></figure>

<h1 id="点击所有文章提示缺失模块"><a href="#点击所有文章提示缺失模块" class="headerlink" title="点击所有文章提示缺失模块"></a>点击所有文章提示缺失模块</h1><ul>
<li>确保 node 版本大于 6.2</li>
<li>在博客根目录/hexo执行以下命令：<code>npm install hexo-generator-json-content --save</code></li>
<li>在 hexo博客根目录<code>_config.yml</code> 里添加配置，关掉 <code>hexo s</code> 之后执行 <code>hexo g</code> 重新生成：</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">jsonContent:</span></span><br><span class="line">  <span class="attr">meta:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">pages:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">posts:</span></span><br><span class="line">    <span class="attr">title:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">date:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">path:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">text:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">raw:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">content:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">slug:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">updated:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">comments:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">link:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">permalink:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">excerpt:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">categories:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">tags:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h1 id="配置智能菜单"><a href="#配置智能菜单" class="headerlink" title="配置智能菜单"></a>配置智能菜单</h1><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"># 智能菜单</span><br><span class="line"># 如不需要，将该对应项置为false</span><br><span class="line"># 比如</span><br><span class="line">#smart_menu:</span><br><span class="line">#  friend<span class="variable">s:</span> false</span><br><span class="line">smart_menu:</span><br><span class="line">  innerArchive: <span class="string">&#x27;所有文章&#x27;</span></span><br><span class="line">  friend<span class="variable">s:</span> false</span><br><span class="line">  aboutme: <span class="string">&#x27;关于我&#x27;</span></span><br><span class="line"></span><br><span class="line">friend<span class="variable">s:</span></span><br><span class="line">  #HEXO: http<span class="variable">s:</span>//hexo.io/zh-<span class="keyword">cn</span>/<span class="built_in">index</span>.html</span><br><span class="line">  #LIVE2d: http<span class="variable">s:</span>//www.npmjs.<span class="keyword">com</span>/package/hexo-helper-live2d</span><br><span class="line">  #Python: http<span class="variable">s:</span>//www.<span class="keyword">python</span>.org/</span><br><span class="line">  #Bootstrap: http<span class="variable">s:</span>//www.bootcss.<span class="keyword">com</span>/</span><br><span class="line">  #我的githu<span class="variable">b:</span> http<span class="variable">s:</span>//github.<span class="keyword">com</span>/Justlovesmile</span><br><span class="line">  #我的微博: http<span class="variable">s:</span>//www.weibo.<span class="keyword">com</span>/<span class="number">5252319712</span>/<span class="keyword">profile</span>?topnav=<span class="number">1</span>&amp;wvr=<span class="number">6</span></span><br><span class="line"></span><br><span class="line">aboutme: 孜孜不倦<span class="symbol">&lt;br&gt;</span>认真且怂<span class="symbol">&lt;br&gt;</span>正在努力提升自己</span><br></pre></td></tr></table></figure>

<h1 id="设置主页展示截断"><a href="#设置主页展示截断" class="headerlink" title="设置主页展示截断"></a>设置主页展示截断</h1><ul>
<li>在md文件中添加内容<code>&lt;!-- more --&gt;</code>：</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">xxx</span></span><br><span class="line"><span class="attr">data:</span> <span class="string">xxxx</span></span><br><span class="line"><span class="attr">tag:</span> <span class="string">XXX</span></span><br><span class="line"><span class="attr">categories:</span> <span class="string">xxx</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="string">简短介绍</span></span><br><span class="line"><span class="string">&lt;!--</span> <span class="string">more</span> <span class="string">--&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>可在<code>/yilia/_config.yml</code>中修改：</li>
</ul>
<figure class="highlight vala"><table><tr><td class="code"><pre><span class="line"><span class="meta"># 文章太长，截断按钮文字</span></span><br><span class="line">excerpt_link: more</span><br><span class="line"><span class="meta"># 文章卡片右下角常驻链接，不需要请设置为false</span></span><br><span class="line">show_all_link: <span class="string">&#x27;展开全文&#x27;</span></span><br></pre></td></tr></table></figure>

<h1 id="添加live2d模型"><a href="#添加live2d模型" class="headerlink" title="添加live2d模型"></a>添加live2d模型</h1><p><img src="https://s2.ax1x.com/2019/09/06/nMBBuD.png" alt="nMBBuD.png"></p>
<ul>
<li>live2d的<a href="https://www.npmjs.com/package/hexo-helper-live2d">官网</a></li>
<li>首先，安装npm包：</li>
</ul>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">npm install <span class="comment">--save hexo-helper-live2d</span></span><br></pre></td></tr></table></figure>
<ul>
<li>所有模型列表如下：</li>
</ul>
<figure class="highlight gams"><table><tr><td class="code"><pre><span class="line">live2d-widget-<span class="keyword">model</span>-chitose</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-epsilon2_1</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-gf</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-haru/<span class="number">01</span> (use npm install --save live2d-widget-<span class="keyword">model</span>-haru)</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-haru/<span class="number">02</span> (use npm install --save live2d-widget-<span class="keyword">model</span>-haru)</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-haruto</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-hibiki</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-hijiki</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-izumi</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-koharu</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-miku</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-ni-j</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-nico</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-nietzsche</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-nipsilon</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-nito</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-shizuku</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-tororo</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-tsumiki</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-unitychan</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-wanko</span><br><span class="line">live2d-widget-<span class="keyword">model</span>-z16</span><br></pre></td></tr></table></figure>
<ul>
<li>然后下载模型</li>
</ul>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">npm</span> install live<span class="number">2</span>d-widget-model-koharu</span><br></pre></td></tr></table></figure>

<ul>
<li>然后在hexo的配置文件_config.yml中添加如下配置，详细配置可以参考官网文档：</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 添加萌妹子效果</span></span><br><span class="line"><span class="attr">live2d:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">scriptFrom:</span> <span class="string">local</span></span><br><span class="line">  <span class="attr">model:</span></span><br><span class="line">    <span class="attr">use:</span> <span class="string">live2d-widget-model-koharu</span></span><br><span class="line">    <span class="attr">scale:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">hHeadPos:</span> <span class="number">0.5</span></span><br><span class="line">    <span class="attr">vHeadPos:</span> <span class="number">0.618</span></span><br><span class="line">  <span class="attr">display:</span></span><br><span class="line">    <span class="attr">superSample:</span> <span class="number">2</span></span><br><span class="line">    <span class="attr">position:</span> <span class="string">left</span></span><br><span class="line">    <span class="attr">width:</span> <span class="number">112.5</span></span><br><span class="line">    <span class="attr">height:</span> <span class="number">225</span></span><br><span class="line">    <span class="attr">hOffset:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">vOffset:</span> <span class="number">-20</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">mobile:</span></span><br><span class="line">    <span class="attr">show:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">scale:</span> <span class="number">0.5</span></span><br><span class="line">  <span class="attr">react:</span></span><br><span class="line">    <span class="attr">opacityDefault:</span> <span class="number">0.7</span></span><br><span class="line">    <span class="attr">opacityOnHover:</span> <span class="number">0.2</span></span><br></pre></td></tr></table></figure>

<ul>
<li>主要是配置model.use使用的模型名称，mobile是移动端效果</li>
</ul>
<h1 id="左侧导航栏设置背景图片"><a href="#左侧导航栏设置背景图片" class="headerlink" title="左侧导航栏设置背景图片"></a>左侧导航栏设置背景图片</h1><p><img src="https://s2.ax1x.com/2019/09/06/nMDbee.png" alt="nMDbee.png"></p>
<ul>
<li>找到<code>/yilia/layout/_partial/left-col.ejs</code>文件,修改为：</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&lt;% <span class="keyword">var</span> defaultBg = <span class="string">&#x27;#4d4d4d&#x27;</span>; %&gt;</span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;overlay&quot;</span> <span class="attr">style</span>=<span class="string">&quot;background: &lt;%= theme.style &amp;&amp; theme.style.header ? theme.style.header : defaultBg %&gt;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">&lt;% if (theme.leftimg)&#123; %&gt;</span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;&lt;%=theme.leftimg%&gt;&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;background.jpg&quot;</span> <span class="attr">border</span>=<span class="string">&quot;0&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml">      &lt;% &#125; %&gt;</span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;intrude-less&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">	<span class="tag">&lt;<span class="name">header</span> <span class="attr">id</span>=<span class="string">&quot;header&quot;</span> <span class="attr">class</span>=<span class="string">&quot;inner&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">		<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;&lt;%=theme.root%&gt;&quot;</span> <span class="attr">class</span>=<span class="string">&quot;profilepic&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">			<span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;&lt;%=theme.avatar%&gt;&quot;</span> <span class="attr">class</span>=<span class="string">&quot;js-avatar&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">		<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span></span><br><span class="line"><span class="xml">		<span class="tag">&lt;<span class="name">hgroup</span>&gt;</span></span></span><br><span class="line"><span class="xml">		  <span class="tag">&lt;<span class="name">h1</span> <span class="attr">class</span>=<span class="string">&quot;header-author&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;&lt;%=theme.root%&gt;&quot;</span>&gt;</span>&lt;%=theme.author%&gt;<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span></span><br><span class="line"><span class="xml">		<span class="tag">&lt;/<span class="name">hgroup</span>&gt;</span></span></span><br><span class="line"><span class="xml">		&lt;% if (theme.subtitle)&#123; %&gt;</span></span><br><span class="line"><span class="xml">		<span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;header-subtitle&quot;</span>&gt;</span>&lt;%=theme.subtitle%&gt;<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span></span><br><span class="line"><span class="xml">		&lt;%&#125;%&gt;</span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">		<span class="tag">&lt;<span class="name">nav</span> <span class="attr">class</span>=<span class="string">&quot;header-menu&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">			<span class="tag">&lt;<span class="name">ul</span>&gt;</span></span></span><br><span class="line"><span class="xml">			&lt;% for (var i in theme.menu)&#123; %&gt;</span></span><br><span class="line"><span class="xml">				<span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;&lt;%- url_for(theme.menu[i]) %&gt;&quot;</span>&gt;</span>&lt;%= i %&gt;<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span></span><br><span class="line"><span class="xml">	        &lt;%&#125;%&gt;</span></span><br><span class="line"><span class="xml">			<span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span></span><br><span class="line"><span class="xml">		<span class="tag">&lt;/<span class="name">nav</span>&gt;</span></span></span><br><span class="line"><span class="xml">		<span class="tag">&lt;<span class="name">nav</span> <span class="attr">class</span>=<span class="string">&quot;header-smart-menu&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">    		&lt;% for (var i in theme.smart_menu)&#123; %&gt;</span></span><br><span class="line"><span class="xml">    			&lt;% if(theme.smart_menu[i])&#123; %&gt;</span></span><br><span class="line"><span class="xml">    			<span class="tag">&lt;<span class="name">a</span> <span class="attr">q-on</span>=<span class="string">&quot;click: openSlider(e, &#x27;&lt;%-i%&gt;&#x27;)&quot;</span> <span class="attr">href</span>=<span class="string">&quot;javascript:void(0)&quot;</span>&gt;</span>&lt;%= theme.smart_menu[i] %&gt;<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span></span><br><span class="line"><span class="xml">    			&lt;% &#125; %&gt;</span></span><br><span class="line"><span class="xml">            &lt;%&#125;%&gt;</span></span><br><span class="line"><span class="xml">		<span class="tag">&lt;/<span class="name">nav</span>&gt;</span></span></span><br><span class="line"><span class="xml">		<span class="tag">&lt;<span class="name">nav</span> <span class="attr">class</span>=<span class="string">&quot;header-nav&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">			<span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;social&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">				&lt;% for (var i in theme.subnav)&#123; %&gt;</span></span><br><span class="line"><span class="xml">					<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;&lt;%= i %&gt;&quot;</span> <span class="attr">target</span>=<span class="string">&quot;_blank&quot;</span> <span class="attr">href</span>=<span class="string">&quot;&lt;%- url_for(theme.subnav[i]) %&gt;&quot;</span> <span class="attr">title</span>=<span class="string">&quot;&lt;%= i %&gt;&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;icon-&lt;%= i %&gt;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span></span><br><span class="line"><span class="xml">		        &lt;%&#125;%&gt;</span></span><br><span class="line"><span class="xml">			<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="xml">		<span class="tag">&lt;/<span class="name">nav</span>&gt;</span></span></span><br><span class="line"><span class="xml">	<span class="tag">&lt;/<span class="name">header</span>&gt;</span>		</span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br></pre></td></tr></table></figure>
<ul>
<li>在<code>/yilia/_config.yml</code>中添加：</li>
</ul>
<figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">leftimg:</span> 图片的链接，不加引号即可</span><br></pre></td></tr></table></figure>

<h1 id="最后给大家推荐几个博主"><a href="#最后给大家推荐几个博主" class="headerlink" title="最后给大家推荐几个博主"></a>最后给大家推荐几个博主</h1><p>一个主题可以添加或修改很多东西，但是逐步让它变成自己的东西是一门技术活。<br>由于可以加的东西很多，给大家推荐几个博主，他们写的文章给我提供了很大的帮助，希望也能帮到更多人</p>
<ul>
<li><a href="https://tding.top/archives/9a232bbe.html">小丁的个人博客</a></li>
<li><a href="http://tigerliu.site/2017/06/hexo-1/">Tigerliu的博客</a></li>
</ul>
]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客 | 第一次搭建BLOG</title>
    <url>/posts/33244.html</url>
    <content><![CDATA[<p>这是我写的第一个blog，关于我怎么搭建这个blog</p>
<h1 id="第一次使用hexo搭建个人博客的步骤"><a href="#第一次使用hexo搭建个人博客的步骤" class="headerlink" title="第一次使用hexo搭建个人博客的步骤"></a>第一次使用hexo搭建个人博客的步骤</h1><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1 准备工作"></a>1 准备工作</h2><ul>
<li>注册了github的账号</li>
<li>安装了node.js和npm</li>
<li>安装并配置了git</li>
</ul>
<h2 id="2-创建仓库"><a href="#2-创建仓库" class="headerlink" title="2 创建仓库"></a>2 创建仓库</h2><ul>
<li>在github中创建了一个‘username.github.io’的仓库</li>
</ul>
<h2 id="3-使用hexo"><a href="#3-使用hexo" class="headerlink" title="3 使用hexo"></a>3 使用hexo</h2><ul>
<li><p>安装hexo： $ npm install -g hexo</p>
</li>
<li><p>初始化一个文件夹： </p>
<ul>
<li>$ cd /e/hexo/</li>
<li>$ hexo init</li>
</ul>
</li>
<li><p>生成服务：$ hexo g</p>
</li>
<li><p>启动服务：$ hexo s</p>
<ul>
<li>默认是localhost:4000</li>
</ul>
</li>
<li><p>因为自带的主题不好看，所以：</p>
<ul>
<li> $ cd /f/Workspaces/hexo/</li>
<li>$ git clone <a href="https://github.com/litten/hexo-theme-yilia.git">https://github.com/litten/hexo-theme-yilia.git</a> themes/yilia</li>
<li>修改hexo根目录下的<code>_config.yml</code>中的    <code>theme: landscape</code>改成<code>theme： yilia</code> ,(注意冒号：后面有一个空格),然后重新执行 hexo g</li>
</ul>
</li>
<li><p>修改hexo根目录下的文件<code>_config.yml</code>中的deploy：</p>
<ul>
<li>deploy:<br>  type： git<br>  repository： <a href="mailto:&#103;&#105;&#x74;&#x40;&#x67;&#x69;&#116;&#104;&#117;&#x62;&#x2e;&#99;&#111;&#109;">&#103;&#105;&#x74;&#x40;&#x67;&#x69;&#116;&#104;&#117;&#x62;&#x2e;&#99;&#111;&#109;</a>:username/username.github.io.git<br>  branch: master</li>
</ul>
</li>
<li><p>上传到github：$ hexo d -g</p>
</li>
<li><p>查看blog: <a href="https://username.github.io/">https://username.github.io</a></p>
</li>
</ul>
<h2 id="写博客"><a href="#写博客" class="headerlink" title="写博客"></a>写博客</h2><ul>
<li>hexo new ‘first-blog’</li>
<li>hexo自动生成一个md文件，修改md内容<ul>
<li>头部如：</li>
</ul>
</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">postName</span> <span class="comment">#文章页面上的显示名称</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2013-12-02 15:30:16</span> <span class="comment">#文章生成时间，一般不改，当然也可以任意修改</span></span><br><span class="line"><span class="attr">categories:</span> <span class="string">默认分类</span> <span class="comment">#分类</span></span><br><span class="line"><span class="attr">tags:</span> [<span class="string">tag1</span>,<span class="string">tag2</span>,<span class="string">tag3</span>] <span class="comment">#文章标签，可空，多标签请用格式，注意冒号:后面有个空格</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">摘要</span></span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></table></figure>
<pre><code>    - 如果没有categories：$ hexo new page categories 然后修改生成的 index.md文件，添加`type: &quot;categories&quot;`
    - 如果没有tags同理
</code></pre>
]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>必看 | Hexo博客搭建超级指南</title>
    <url>/posts/c8972b63.html</url>
    <content><![CDATA[<h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h1><p>不知不觉，我的博客已经在风雨飘摇中运行超过一年时间了，回想这一年的博客维护以及魔改经历，我觉得有必要详细记录一下博客搭建的过程，以防我不小心搞崩了博客…</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715162057.png"></p>
<h1 id="2-环境部署工作"><a href="#2-环境部署工作" class="headerlink" title="2. 环境部署工作"></a>2. 环境部署工作</h1><h2 id="2-1-安装Node-js"><a href="#2-1-安装Node-js" class="headerlink" title="2.1 安装Node.js"></a>2.1 安装Node.js</h2><p>1.进入官网选择对应的系统下载：<br>官网：<a href="https://nodejs.org/en/download/">https://nodejs.org/en/download/</a><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715163331.png"><br>2.安装<br>选好路径，完成安装<br>3.检查<br>打开<code>cmd</code>或者<code>powershell</code>,输入:</p>
<figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line"><span class="keyword">node</span> <span class="title">-v</span></span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure>

<p>显示版本号，即安装无误</p>
<blockquote>
<p>npm为Node.js的包管理工具</p>
</blockquote>
<h2 id="2-2-安装Git"><a href="#2-2-安装Git" class="headerlink" title="2.2 安装Git"></a>2.2 安装Git</h2><p>1.进入官网下载<br>官网：<a href="https://git-scm.com/downloads">https://git-scm.com/downloads</a><br>2.安装<br>选好路径，完成安装<br>3.检查<br>打开git bash，输入：</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">git <span class="comment">--version</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715170132.png"></p>
<h2 id="2-3-注册Github账号"><a href="#2-3-注册Github账号" class="headerlink" title="2.3 注册Github账号"></a>2.3 注册Github账号</h2><p>1.Github官网<a href="https://github.com/">https://github.com</a>,注册账号<br>2.新建项目</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715171105.png"></p>
<p>项目名字为<code>你的昵称.github.io</code>，例如：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="comment">//我的昵称是Justlovesmile</span></span><br><span class="line">所以我的项目名称为<span class="module-access"><span class="module"><span class="identifier">Justlovesmile</span>.</span></span>github.io</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715170812.png"></p>
<p>3.代码库设置</p>
<p>创建好之后，保存<code>&lt;&gt;code</code>内的SSH，即：</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">git@github<span class="selector-class">.com</span>:XXXXXXXXX/XXXXXXXXX<span class="selector-class">.github</span><span class="selector-class">.io</span>.git</span><br></pre></td></tr></table></figure>

<p>点击右侧的<code>Settings</code></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715171759.png"></p>
<p>向下找到<code>Gihub pages</code>,点击<code>Launch automatic page generator</code>，<code>Github</code>将会自动替你创建出一个<code>pages</code>的页面。 如果配置没有问题，大约几分钟之后，<code>yourname.github.io</code>这个网址就可以正常访问了</p>
<p>5.推荐开启强制使用https</p>
<h2 id="2-4-安装Hexo"><a href="#2-4-安装Hexo" class="headerlink" title="2.4 安装Hexo"></a>2.4 安装Hexo</h2><p>1.在合适的位置，如<code>E:/hexo</code>，安装<code>hexo-cli</code>,输入：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">cd <span class="regexp">/e/</span>hexo/</span><br><span class="line">npm install hexo-cli -g</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715172419.png"></p>
<p>再安装<code>hexo</code></p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">npm install hexo <span class="comment">--save</span></span><br></pre></td></tr></table></figure>

<p>安装完成后，检查</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">hexo -v</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715172614.png"></p>
<p>2.初始化一个文件夹： </p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">cd <span class="regexp">/e/</span>hexo/</span><br><span class="line">hexo init</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure>

<p>3.生成Hexo页面：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">hexo g</span></span><br></pre></td></tr></table></figure>

<p>4.启动服务：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">hexo s</span></span><br></pre></td></tr></table></figure>

<p>默认是<code>localhost:4000</code>，打开浏览器输入即可</p>
<h2 id="2-5-推送到Github"><a href="#2-5-推送到Github" class="headerlink" title="2.5 推送到Github"></a>2.5 推送到Github</h2><p>1.配置个人信息</p>
<figure class="highlight verilog"><table><tr><td class="code"><pre><span class="line">git <span class="keyword">config</span> --<span class="keyword">global</span> user<span class="variable">.name</span> <span class="string">&quot;XXXX&quot;</span></span><br><span class="line">git <span class="keyword">config</span> --<span class="keyword">global</span> user<span class="variable">.email</span> <span class="string">&quot;XXXXXXXXX@XXX.com&quot;</span></span><br></pre></td></tr></table></figure>

<p>2.生成密钥</p>
<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">ssh-keygen -<span class="built_in">t</span> rsa -C <span class="string">&quot;XXXXXXXXX@XXX.com&quot;</span></span><br></pre></td></tr></table></figure>

<p>3.查看<code>id_rsa.pub</code>文件，并整个复制</p>
<figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line">cat ~<span class="regexp">/.ssh/i</span>d_rsa.pub</span><br></pre></td></tr></table></figure>

<p>4.然后再在<code>Github</code>中添加<code>ssh key</code></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715173551.png"></p>
<p>5.修改hexo根目录下的文件<code>_config.yml</code>中的deploy，添加之前保存的ssh：</p>
<figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="symbol">deploy:</span></span><br><span class="line"><span class="symbol">  type:</span> git</span><br><span class="line"><span class="symbol">  repository:</span> </span><br><span class="line"><span class="symbol">	github:</span> git@github.com:Justlovesmile/Justlovesmile.github.io.git</span><br><span class="line"><span class="symbol">  branch:</span> master</span><br></pre></td></tr></table></figure>

<p>6.上传到github：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">hexo d -g</span></span><br></pre></td></tr></table></figure>

<p>如果没有hexo-deployer-git，安装</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git <span class="comment">--save</span></span><br></pre></td></tr></table></figure>

<p>7.查看blog,<code>https://username.github.io</code></p>
<h1 id="3-Hexo基础"><a href="#3-Hexo基础" class="headerlink" title="3. Hexo基础"></a>3. Hexo基础</h1><h2 id="3-1-写博客"><a href="#3-1-写博客" class="headerlink" title="3.1 写博客"></a>3.1 写博客</h2><p>1.新建文章</p>
<figure class="highlight haxe"><table><tr><td class="code"><pre><span class="line">hexo <span class="keyword">new</span> <span class="type">post</span> <span class="string">&#x27;我的第一篇文章&#x27;</span></span><br></pre></td></tr></table></figure>

<p>2.hexo自动生成一个md文件，修改md内容<br>头部如：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">postName</span> <span class="comment">#文章页面上的显示名称</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2020-03-10 12:30:16</span> <span class="comment">#文章生成时间，一般不改，当然也可以任意修改</span></span><br><span class="line"><span class="attr">categories:</span> <span class="string">默认分类</span> <span class="comment">#分类</span></span><br><span class="line"><span class="attr">tags:</span> [<span class="string">tag1</span>,<span class="string">tag2</span>,<span class="string">tag3</span>] <span class="comment">#文章标签，可空，多标签请用格式，注意冒号:后面有个空格</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">摘要</span></span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></table></figure>

<p>3.在头部下面即可写文章内容</p>
<blockquote>
<p>markdown，支持html和其自带的语法。Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。</p>
</blockquote>
<h2 id="3-2-新建页面"><a href="#3-2-新建页面" class="headerlink" title="3.2 新建页面"></a>3.2 新建页面</h2><figure class="highlight haxe"><table><tr><td class="code"><pre><span class="line">hexo <span class="keyword">new</span> <span class="type">page</span> <span class="string">&quot;music&quot;</span></span><br></pre></td></tr></table></figure>

<p>会在source文件夹中生成music文件夹，其内的index.md为页面内容</p>
<h2 id="3-3-常用基本命令"><a href="#3-3-常用基本命令" class="headerlink" title="3.3 常用基本命令"></a>3.3 常用基本命令</h2><figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">hexo <span class="built_in">new</span> <span class="string">&quot;文章&quot;</span></span><br><span class="line">hexo <span class="built_in">new</span> <span class="built_in">post</span> <span class="string">&quot;文章&quot;</span></span><br><span class="line">hexo <span class="built_in">new</span> page <span class="string">&quot;页面&quot;</span></span><br><span class="line"></span><br><span class="line">hexo clean <span class="comment">#清除缓存，每次重新部署时最好执行</span></span><br><span class="line">hexo g <span class="comment">#生成静态页面</span></span><br><span class="line">hexo s <span class="comment">#本地端口，默认4000运行</span></span><br><span class="line">hexo s -p <span class="number">5000</span> <span class="comment"># 端口5000</span></span><br><span class="line">hexo d <span class="comment">#部署</span></span><br><span class="line">hexo deploy <span class="comment">#部署</span></span><br></pre></td></tr></table></figure>

<figure class="highlight 1c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#为了方便，每次准备推送时,可以👇</span></span><br><span class="line">hexo cl <span class="meta">&amp;&amp; hexo g &amp;&amp; hexo d</span></span><br></pre></td></tr></table></figure>

<h1 id="4-Hexo进阶"><a href="#4-Hexo进阶" class="headerlink" title="4. Hexo进阶"></a>4. Hexo进阶</h1><h2 id="4-1-推荐编辑器"><a href="#4-1-推荐编辑器" class="headerlink" title="4.1 推荐编辑器"></a>4.1 推荐编辑器</h2><p>方便后续魔改内容</p>
<ol>
<li>VSCode <a href="https://code.visualstudio.com/">https://code.visualstudio.com/</a></li>
<li>Sublime Text <a href="http://www.sublimetext.com/">http://www.sublimetext.com/</a></li>
</ol>
<h2 id="4-2-更换主题"><a href="#4-2-更换主题" class="headerlink" title="4.2 更换主题"></a>4.2 更换主题</h2><p>1.因为自带的主题并不好看，所以可以更换主题，常见主题的很多，例如butterfly</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">cd <span class="regexp">/e/</span>hexo/</span><br><span class="line">git clone -b master https:<span class="regexp">//gi</span>thub.com<span class="regexp">/jerryc127/</span>hexo-theme-butterfly.git themes/butterfly</span><br></pre></td></tr></table></figure>

<p>2.修改hexo根目录下的<code>_config.yml</code>中的    <code>theme: landscape</code>改成<code>theme： butterfly</code> ,(注意冒号：后面有一个空格)</p>
<h2 id="4-3-注册Coding账号"><a href="#4-3-注册Coding账号" class="headerlink" title="4.3 注册Coding账号"></a>4.3 注册Coding账号</h2><p>1.由于国内访问github的速度较慢，因此可以通过双部署同时部署到Coding<a href="https://coding.net/">https://coding.net/</a>，同样注册账号，新建项目，项目名随意<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715175443.png"><br>2.创建好后，同样记住<code>SSH</code><br>3.修改hexo根目录下的文件<code>_config.yml</code>中的deploy，添加之前保存的ssh：<br>例如我的：</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: </span><br><span class="line">    github: git@github<span class="selector-class">.com</span>:Justlovesmile/Justlovesmile<span class="selector-class">.github</span><span class="selector-class">.io</span><span class="selector-class">.git</span></span><br><span class="line">    coding: git@e<span class="selector-class">.coding</span><span class="selector-class">.net</span>:justlovesmile/justlovesmile<span class="selector-class">.top</span><span class="selector-class">.git</span></span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure>
<p>4.在Coding中保存你的密钥，方法同Github</p>
<figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line">cat ~<span class="regexp">/.ssh/i</span>d_rsa.pub</span><br></pre></td></tr></table></figure>

<p>5.下次<code>hexo d -g</code>部署后,开启<code>静态网站</code>，然后可以通过其提供的<code>//xxxxxxx.coding-pages.com</code>访问。（第一次记得点，<code>立即部署</code>）</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715180119.png"></p>
<p>6.推荐开启强制使用https</p>
<h2 id="4-4-注册Gitee账号"><a href="#4-4-注册Gitee账号" class="headerlink" title="4.4 注册Gitee账号"></a>4.4 注册Gitee账号</h2><p>1.除了Coding外，网内访问速度较快的还有码云<a href="https://gitee.com/">https://gitee.com/</a>，同样注册账号，新建项目<code>yourname</code><br>2.创建好后，同样记住<code>SSH</code><br>3.修改hexo根目录下的文件<code>_config.yml</code>中的deploy，添加之前保存的ssh：<br>例如我的：</p>
<figure class="highlight less"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: </span><br><span class="line">    gitee: git@gitee.com:justlovesmile/justlovesmile.git</span><br><span class="line">    coding: git@e.coding.net:justlovesmile/justlovesmile.<span class="attribute">top.git</span></span><br><span class="line"><span class="attribute">    github</span>: git<span class="variable">@github</span>.<span class="attribute">com</span>:Justlovesmile/Justlovesmile.github.io.git</span><br><span class="line">  <span class="attribute">branch</span>: master</span><br></pre></td></tr></table></figure>

<p>4.在Gitee中保存你的密钥，方法同Github</p>
<figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line">cat ~<span class="regexp">/.ssh/i</span>d_rsa.pub</span><br></pre></td></tr></table></figure>

<p>5.开启GiteePages服务，Gitee只能免费使用gitee.io域名,其他的域名要收费，并且免费版每次部署后，需要手动点击更新来更新网站内容<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715181243.png"><br>5.推荐开启强制使用https</p>
<h2 id="4-5-绑定域名"><a href="#4-5-绑定域名" class="headerlink" title="4.5 绑定域名"></a>4.5 绑定域名</h2><p>1.在阿里云<a href="https://wanwang.aliyun.com/">https://wanwang.aliyun.com/</a>购买自己喜欢的域名</p>
<p>2.在阿里云控制台找到<code>云解析DNS</code></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715185711.png"></p>
<p>找到自己购买的域名,点击<code>解析设置</code></p>
<p>添加记录</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715185838.png"></p>
<p>3.如果多部署了，可以设置多条</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715190408.png"></p>
<p>一条给github.io，一条给coding-pages.com等等</p>
<p>4.再返回到对应的部署页面，修改解析域名</p>
<ul>
<li>Github的在仓库的<code>Settings--Github_Pages--Custon_domain</code></li>
<li>Coding的<code>静态网站-设置-自定义域名</code></li>
</ul>
<h2 id="4-6-安装插件"><a href="#4-6-安装插件" class="headerlink" title="4.6 安装插件"></a>4.6 安装插件</h2><p>1.安装hexo插件</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">npm <span class="keyword">install </span>hexo-generator-sitemap --save</span><br><span class="line">npm <span class="keyword">install </span>hexo-generator-<span class="keyword">baidu-sitemap </span>--save</span><br><span class="line">npm <span class="keyword">install </span>hexo-generator-feed --save</span><br></pre></td></tr></table></figure>

<p>2.在hexo根目录下的文件<code>_config.yml</code>中添加</p>
<figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="symbol">Plugins:</span> <span class="meta"># 在该区域添加两个插件名称</span></span><br><span class="line">  - hexo-generator-sitemap</span><br><span class="line">  - hexo-generator-baidu-sitemap</span><br><span class="line">  - hexo-generator-feed</span><br><span class="line"><span class="meta"># 自动生成sitemap</span></span><br><span class="line"><span class="symbol">sitemap:</span></span><br><span class="line"><span class="symbol">  path:</span> sitemap.xml</span><br><span class="line"><span class="symbol">baidusitemap:</span></span><br><span class="line"><span class="symbol">  path:</span> baidusitemap.xml</span><br></pre></td></tr></table></figure>

<p>3.更多插件见<a href="/posts/86111745.html">Hexo插件推荐</a></p>
<h2 id="4-7-添加robots-txt"><a href="#4-7-添加robots-txt" class="headerlink" title="4.7 添加robots.txt"></a>4.7 添加robots.txt</h2><p>1.在hexo根目录下的source文件夹中，创建一个名为robots.txt的文件<br>2.内容为</p>
<figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">User-agent: * </span><br><span class="line"><span class="symbol">Allow:</span> /</span><br><span class="line"><span class="symbol">Allow:</span> <span class="meta-keyword">/categories/</span></span><br><span class="line"><span class="symbol">Allow:</span> <span class="meta-keyword">/tags/</span></span><br><span class="line"><span class="symbol">Allow:</span> <span class="meta-keyword">/archives/</span></span><br><span class="line"><span class="symbol"></span></span><br><span class="line"><span class="symbol">Disallow:</span> <span class="meta-keyword">/js/</span></span><br><span class="line"><span class="symbol">Disallow:</span> <span class="meta-keyword">/css/</span></span><br><span class="line"><span class="symbol">Disallow:</span> <span class="meta-keyword">/images/</span></span><br><span class="line"><span class="symbol">Disallow:</span> <span class="meta-keyword">/img/</span></span><br><span class="line"><span class="symbol">Disallow:</span> <span class="meta-keyword">/lib/</span></span><br><span class="line"><span class="symbol"></span></span><br><span class="line"><span class="symbol">Sitemap:</span> https:<span class="comment">//XXXXXXXXXXX.XXX/sitemap.xml</span></span><br><span class="line"><span class="symbol">Sitemap:</span> https:<span class="comment">//XXXXXXXXXXX.XXX/baidusitemap.xml</span></span><br></pre></td></tr></table></figure>

<h2 id="4-8-创建百度站长账号"><a href="#4-8-创建百度站长账号" class="headerlink" title="4.8 创建百度站长账号"></a>4.8 创建百度站长账号</h2><p>1.进入百度站长<a href="https://ziyuan.baidu.com/">https://ziyuan.baidu.com/</a>，注册账号，登录<br>2.点击用户中心-站点管理-添加网站</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/image.png"></p>
<p>3.验证<br>（1）若选择文件验证，则下载文件到根目录下的source文件夹中，并在文件内容最上面添加三行</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">layout:</span> <span class="literal">false</span></span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></table></figure>

<p>（2）若选择HTML标签验证，需要找到主题下的head文件位置，添加其给的html代码，（一般在<code>/themes/xxxxxx/layout/**/head.pug(ejs)</code>内)</p>
<p>（3）若选择CNAME验证，操作和绑定域名操作一样，看其给的说明即可</p>
<p>4.推送你的网址，使之更快收录<br>点击左侧<code>资源提交-普通收录</code>可以选择三种方式提交网址</p>
<h2 id="4-9-创建百度-谷歌统计账号"><a href="#4-9-创建百度-谷歌统计账号" class="headerlink" title="4.9 创建百度/谷歌统计账号"></a>4.9 创建百度/谷歌统计账号</h2><p>1.现在绝大部分国内主题集成了百度统计<a href="https://tongji.baidu.com/">https://tongji.baidu.com/</a>和<a href="https://search.google.com/">谷歌统计</a>功能，如果没有可以自行在head文件内添加，和上面的html标签验证相似</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715193338.png"></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> _hmt = _hmt || [];</span></span><br><span class="line"><span class="javascript">(<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">  <span class="keyword">var</span> hm = <span class="built_in">document</span>.createElement(<span class="string">&quot;script&quot;</span>);</span></span><br><span class="line"><span class="javascript">  hm.src = <span class="string">&quot;https://hm.baidu.com/hm.js?a2ee893562999ebad688b0d82daa100a&quot;</span>;</span></span><br><span class="line"><span class="javascript">  <span class="keyword">var</span> s = <span class="built_in">document</span>.getElementsByTagName(<span class="string">&quot;script&quot;</span>)[<span class="number">0</span>]; </span></span><br><span class="line"><span class="javascript">  s.parentNode.insertBefore(hm, s);</span></span><br><span class="line"><span class="javascript">&#125;)();</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>其中问号<code>?</code>之后的一串数字为你的统计id</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">hm.src</span> = <span class="string">&quot;https://hm.baidu.com/hm.js?a2ee893562999ebad688b0d82daa100a&quot;</span><span class="comment">;</span></span><br></pre></td></tr></table></figure>

<p>2.谷歌同理，不过需要翻墙才能进去</p>
<h2 id="4-10-CDN图床"><a href="#4-10-CDN图床" class="headerlink" title="4.10 CDN图床"></a>4.10 CDN图床</h2><p>1.博客中往往会使用到很多图片，如果全部都保存在博客中，那肯定是不行的，推荐使用<code>Github+Jsdelivr+PicGo</code>搭建免费图床<br>2.在Github中创建一个新仓库<code>CDN</code>，名字随意<br>3.生成Token<br>在右上角个人设置处（不是仓库设置）依次选择<code>Settings</code>-<code>Developer settings</code>-<code>Personal access tokens</code>-<code>Generate new token</code>，勾选<code>repo</code>，然后点击<code>Generate token</code>生成一个<code>Token</code></p>
<p><strong>注意这个Token只会显示一次，自己先保存下来，或者等后面配置好PicGo后再关闭此网页</strong></p>
<p>4.配置PicGo，使用jsDelivr的CDN<br>(1)下载<code>PicGo</code> <a href="https://github.com/Molunerfinn/picgo/releases">https://github.com/Molunerfinn/picgo/releases</a><br>(2)设置仓库名<br>(3)设置分支名<br>(4)设置Token<br>(5)指定存储路径<br>(6)设定自定义域名</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200715200322.png"></p>
<figure class="highlight vala"><table><tr><td class="code"><pre><span class="line"><span class="meta">#每次上传后,生成图片路径</span></span><br><span class="line">自定义域名+/+储存路径+上传的图片名</span><br></pre></td></tr></table></figure>

<h1 id="5-主题配置总结"><a href="#5-主题配置总结" class="headerlink" title="5. 主题配置总结"></a>5. 主题配置总结</h1><h2 id="5-1-Ayer主题修改–适用ejs类型的主题"><a href="#5-1-Ayer主题修改–适用ejs类型的主题" class="headerlink" title="5.1 Ayer主题修改–适用ejs类型的主题"></a>5.1 Ayer主题修改–适用ejs类型的主题</h2><h3 id="5-1-1-随机博客封面"><a href="#5-1-1-随机博客封面" class="headerlink" title="5.1.1 随机博客封面"></a>5.1.1 随机博客封面</h3><p><a href="/posts/27301.html">Hexo博客美化之随机封面</a></p>
<h3 id="5-1-2-添加二级菜单"><a href="#5-1-2-添加二级菜单" class="headerlink" title="5.1.2 添加二级菜单"></a>5.1.2 添加二级菜单</h3><p><a href="/posts/14357.html">Hexo博客添加二级菜单</a></p>
<h3 id="5-1-3-添加公告板"><a href="#5-1-3-添加公告板" class="headerlink" title="5.1.3 添加公告板"></a>5.1.3 添加公告板</h3><p><a href="/posts/57206.html">Hexo博客美化之添加公告板</a></p>
<h2 id="5-2-Butterfly主题–适用pug类型的主题"><a href="#5-2-Butterfly主题–适用pug类型的主题" class="headerlink" title="5.2 Butterfly主题–适用pug类型的主题"></a>5.2 Butterfly主题–适用pug类型的主题</h2><ul>
<li>看Butterfly作者的教程<a href="https://butterfly.js.org/">https://butterfly.js.org/</a></li>
<li>看小康博客<a href="https://www.antmoe.com/posts/a811d614/index.html">https://www.antmoe.com/posts/a811d614/index.html</a></li>
</ul>
<h1 id="6-主题魔改"><a href="#6-主题魔改" class="headerlink" title="6. 主题魔改"></a>6. 主题魔改</h1><h2 id="6-1-页脚养鱼🐟"><a href="#6-1-页脚养鱼🐟" class="headerlink" title="6.1 页脚养鱼🐟"></a>6.1 页脚养鱼🐟</h2><ul>
<li>摘取自<a href="https://xiabor.com/714f.html">木槿：Hexo大结局</a></li>
</ul>
<p>1.在<code>\themes\butterfly\layout\includes\footer.pug</code>最后添加这句话</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#jsi-flying-fish-container.container</span><br><span class="line"></span><br><span class="line">style.</span><br><span class="line">  @media only screen and (max-width: 767px)&#123;</span><br><span class="line">    #sidebar_search_box input[type=text]&#123;width:calc(100% - 24px)&#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>2.然后添加js文件，如果是butterfly在主题配置的inject处添加即可</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">data-pjax</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.jsdelivr.net/gh/Justlovesmile/CDN@latest/js/fish.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>3.修改样式，butterfly在<code>themes\butterfly\source\css\_layout\footer.styl</code>，这一部分对应修改</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#footer</span></span><br><span class="line">  <span class="attr">position:</span> <span class="string">relative</span></span><br><span class="line">  <span class="attr">background:</span> <span class="string">$light-blue</span></span><br><span class="line">  <span class="attr">background-attachment:</span> <span class="string">local</span></span><br><span class="line">  <span class="attr">background-position:</span> <span class="string">bottom</span></span><br><span class="line">  <span class="attr">background-size:</span> <span class="string">cover</span></span><br><span class="line"></span><br><span class="line">  <span class="string">if</span> <span class="string">hexo-config(&#x27;footer_bg&#x27;)</span> <span class="type">!=</span> <span class="literal">false</span></span><br><span class="line">    <span class="string">&amp;:before</span></span><br><span class="line">      <span class="attr">position:</span> <span class="string">absolute</span></span><br><span class="line">      <span class="attr">width:</span> <span class="number">100</span><span class="string">%</span></span><br><span class="line">      <span class="attr">height:</span> <span class="number">100</span><span class="string">%</span></span><br><span class="line">      <span class="attr">background-color:</span> <span class="string">alpha($dark-black,</span> <span class="number">.1</span><span class="string">)</span></span><br><span class="line">      <span class="attr">content:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#footer-wrap</span></span><br><span class="line">  <span class="attr">position:</span> <span class="string">absolute</span></span><br><span class="line">  <span class="attr">padding:</span> <span class="number">1.</span><span class="string">2rem</span> <span class="string">1rem</span> <span class="number">1.</span><span class="string">4rem</span></span><br><span class="line">  <span class="attr">color:</span> <span class="string">$light-grey</span></span><br><span class="line">  <span class="attr">text-align:</span> <span class="string">center</span></span><br><span class="line">  <span class="attr">left:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">right:</span> <span class="number">0</span></span><br><span class="line">  <span class="string">top:0</span></span><br><span class="line">  <span class="attr">bottom:</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<h2 id="6-2-valine评论"><a href="#6-2-valine评论" class="headerlink" title="6.2 valine评论"></a>6.2 valine评论</h2><p><a href="/posts/27831.html">博客美化之valine</a></p>
<h2 id="6-3-博客文章加密"><a href="#6-3-博客文章加密" class="headerlink" title="6.3 博客文章加密"></a>6.3 博客文章加密</h2><p><a href="/posts/43010.html">添加博客加密</a>: <code>文章添加密码</code>功能</p>
<h2 id="6-4-打字机效果"><a href="#6-4-打字机效果" class="headerlink" title="6.4 打字机效果"></a>6.4 打字机效果</h2><p><a href="/posts/7e7ef81c.html">花里胡哨的打字机js</a></p>
<p><a href="/posts/24067.html">Type.js打字机效果</a>: 添加<code>打字机效果</code></p>
<h2 id="6-5-图标，动态图标，网页运行时间，全站黑白，鼠标点击特效，网页动态标题，樱花，音效"><a href="#6-5-图标，动态图标，网页运行时间，全站黑白，鼠标点击特效，网页动态标题，樱花，音效" class="headerlink" title="6.5 图标，动态图标，网页运行时间，全站黑白，鼠标点击特效，网页动态标题，樱花，音效"></a>6.5 图标，动态图标，网页运行时间，全站黑白，鼠标点击特效，网页动态标题，樱花，音效</h2><p><a href="/posts/56163.html">博客中能用到的代码</a>: 关于<code>font awesome图标</code>字体库，使用<code>动态图标</code>，添加<code>网页运行时间</code>，<code>全站变黑白</code>，<code>鼠标点击特效</code>，<code>网页标题的动态效果</code>，<code>网页樱花特效</code>，<code>鼠标触动音乐特效</code></p>
<h2 id="6-6-旋转小人，每日诗句"><a href="#6-6-旋转小人，每日诗句" class="headerlink" title="6.6 旋转小人，每日诗句"></a>6.6 旋转小人，每日诗句</h2><p><a href="/posts/15391.html">博客中能用到的代码（二）</a>: 添加<code>旋转小人</code>和<code>每日诗句</code></p>
<h2 id="6-7-展示pdf"><a href="#6-7-展示pdf" class="headerlink" title="6.7 展示pdf"></a>6.7 展示pdf</h2><p><a href="/posts/7376.html">Hexo竟然可以展示PDF</a></p>
<h2 id="6-8-插件汇总"><a href="#6-8-插件汇总" class="headerlink" title="6.8 插件汇总"></a>6.8 插件汇总</h2><p><a href="/posts/86111745.html">Hexo插件总结推荐</a></p>
<h2 id="6-9-前端禁止右键，F12，F5"><a href="#6-9-前端禁止右键，F12，F5" class="headerlink" title="6.9 前端禁止右键，F12，F5"></a>6.9 前端禁止右键，F12，F5</h2><ul>
<li>在文件中添加以下代码</li>
</ul>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="function"><span class="keyword">function</span> <span class="title">unmouse</span>(<span class="params"></span>)</span>&#123;	</span></span><br><span class="line"><span class="javascript">	<span class="built_in">document</span>.oncontextmenu = <span class="keyword">new</span> <span class="built_in">Function</span>(<span class="string">&quot;return false;&quot;</span>);</span></span><br><span class="line"><span class="javascript">	<span class="built_in">document</span>.onkeydown = <span class="built_in">document</span>.onkeyup = <span class="built_in">document</span>.onkeypress = <span class="function"><span class="keyword">function</span>(<span class="params">event</span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">		<span class="keyword">var</span> e = event || <span class="built_in">window</span>.event || <span class="built_in">arguments</span>.callee.caller.arguments[<span class="number">0</span>];</span></span><br><span class="line"><span class="javascript">		<span class="keyword">if</span> (e &amp;&amp; (e.keyCode == <span class="number">123</span> || (e.keyCode == <span class="number">116</span> &amp;&amp; e.type!=<span class="string">&#x27;keypress&#x27;</span>))) </span></span><br><span class="line"><span class="javascript">		&#123;</span></span><br><span class="line"><span class="javascript">			e.returnValue = <span class="literal">false</span>;</span></span><br><span class="line"><span class="javascript">			<span class="keyword">return</span> (<span class="literal">false</span>);</span></span><br><span class="line"><span class="javascript">		&#125;</span></span><br><span class="line"><span class="javascript">	&#125;</span></span><br><span class="line"><span class="javascript">&#125;</span></span><br><span class="line"><span class="javascript">unmouse()</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="6-10-星空背景"><a href="#6-10-星空背景" class="headerlink" title="6.10 星空背景"></a>6.10 星空背景</h2><ul>
<li><a href="/posts/6a260bf6.html">星空和流星特效</a><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202108121834269.gif"></li>
</ul>
<h2 id="6-11-动态分类条、标签条"><a href="#6-11-动态分类条、标签条" class="headerlink" title="6.11 动态分类条、标签条"></a>6.11 动态分类条、标签条</h2><ul>
<li><a href="/posts/2bfb1caa.html">动态分类标签条，自动获取全站分类与标签进行展示</a></li>
</ul>
<h2 id="6-12-提取图片主题色并修改字体颜色"><a href="#6-12-提取图片主题色并修改字体颜色" class="headerlink" title="6.12 提取图片主题色并修改字体颜色"></a>6.12 提取图片主题色并修改字体颜色</h2><ul>
<li><a href="/posts/b16c0eda.html">如何提取图片主题色并自动选择标题字体颜色</a></li>
</ul>
<h1 id="7-高级魔改"><a href="#7-高级魔改" class="headerlink" title="7. 高级魔改"></a>7. 高级魔改</h1><h2 id="7-1-Github-Calendar"><a href="#7-1-Github-Calendar" class="headerlink" title="7.1 Github Calendar"></a>7.1 Github Calendar</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210208220529.png"></p>
<p><a href="https://akilar.top/posts/1f9c68c9/">Gitcalendar</a><br><a href="https://zfe.space/post/6948.html">教程：基于Butterfly主题（去jquery）的gitcalendar3.0</a></p>
<h2 id="7-2-首页磁贴"><a href="#7-2-首页磁贴" class="headerlink" title="7.2 首页磁贴"></a>7.2 首页磁贴</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210208220855.png"><br><a href="https://akilar.top/posts/a9131002/">Akilar：Categories Magnet</a></p>
<h2 id="7-3-首页置顶轮播图"><a href="#7-3-首页置顶轮播图" class="headerlink" title="7.3 首页置顶轮播图"></a>7.3 首页置顶轮播图</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210208220928.png"></p>
<p><a href="https://akilar.top/posts/8e1264d1/">Akilar：Slider Bar</a></p>
<h2 id="7-4-友链朋友圈"><a href="#7-4-友链朋友圈" class="headerlink" title="7.4 友链朋友圈"></a>7.4 友链朋友圈</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220328133508.png"></p>
<ul>
<li><p><a href="https://github.com/Rock-Candy-Tea/hexo-circle-of-friends">友链朋友圈新版本：Github</a></p>
</li>
<li><p><a href="https://fcircle-doc.js.cool/#/">友链朋友圈新版本：文档</a></p>
</li>
<li><p><a href="https://zfe.space/post/friend-link-circle.html">小冰大佬版：初代友链朋友圈</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客 | 动态分类标签条，自动获取全站分类与标签进行展示</title>
    <url>/posts/2bfb1caa.html</url>
    <content><![CDATA[<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h1><p>本文是对Heo博主写的<a href="https://blog.zhheo.com/p/bc61964d.html">Butterfly魔改：动态分类条，可以根据页面变化而改变的分类列表展示方式</a>文章的补充，增加了动态标签条，并且可以自动获取全站分类和标签名称。</p>
<h1 id="2-预览"><a href="#2-预览" class="headerlink" title="2. 预览"></a>2. 预览</h1><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202108142116064.png" alt="image-20210814211626863"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202108142121159.png" alt="image-20210814212127747"></p>
<h1 id="3-配置"><a href="#3-配置" class="headerlink" title="3. 配置"></a>3. 配置</h1><h2 id="3-1-新建PUG文件"><a href="#3-1-新建PUG文件" class="headerlink" title="3.1 新建PUG文件"></a>3.1 新建PUG文件</h2><p>首先是分类条，在<code>themes/butterfly/layout/includes/</code>处新建文件<code>categoryBar.pug</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#category-bar</span><br><span class="line">  .category-bar-items#category-bar-items</span><br><span class="line">    !=getarray_bar(&quot;category&quot;)</span><br><span class="line">  a.category-bar-more(href=&quot;/categories/&quot;) 更多</span><br></pre></td></tr></table></figure>

<p>其次是标签条，在<code>themes/butterfly/layout/includes/</code>处新建文件<code>tagBar.pug</code>，因为样式一样，所以没有更改id和class名称。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#category-bar</span><br><span class="line">  .category-bar-items#category-bar-items</span><br><span class="line">    !=getarray_bar(&quot;tag&quot;)</span><br><span class="line">  a.category-bar-more(href=&quot;/tags/&quot;) 更多</span><br></pre></td></tr></table></figure>

<h2 id="3-2-新建Hexo辅助函数"><a href="#3-2-新建Hexo辅助函数" class="headerlink" title="3.2 新建Hexo辅助函数"></a>3.2 新建Hexo辅助函数</h2><p>在<code>theme/butterfly/scripts/helpers/</code>中创建<code>get_arrays.js</code></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">hexo.extend.helper.register(<span class="string">&#x27;getarray_bar&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">types</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!types) &#123;</span><br><span class="line">    types = <span class="string">&quot;category&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">const</span> categoriesBar = <span class="function"><span class="keyword">function</span> (<span class="params">categories</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!categories || !categories.length) <span class="keyword">return</span> <span class="string">``</span></span><br><span class="line">    <span class="keyword">const</span> categoryArr = []</span><br><span class="line">    hexo.locals.get(<span class="string">&#x27;categories&#x27;</span>).map(<span class="function"><span class="keyword">function</span> (<span class="params">category</span>) </span>&#123;</span><br><span class="line">      categoryArr.push(&#123; <span class="attr">name</span>: category.name, <span class="attr">value</span>: category.length &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line">    categoryArr.sort(<span class="function">(<span class="params">a, b</span>) =&gt;</span> &#123; <span class="keyword">return</span> b.value - a.value &#125;)</span><br><span class="line">    <span class="keyword">let</span> strCategoriesBar = <span class="string">``</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; categories.length; i++) &#123;</span><br><span class="line">      strTemp=<span class="string">`</span></span><br><span class="line"><span class="string">      &lt;div class=&quot;category-bar-item&quot; id=&quot;<span class="subst">$&#123;categoryArr[i].name&#125;</span>&quot;&gt;</span></span><br><span class="line"><span class="string">      &lt;a href=&quot;/categories/<span class="subst">$&#123;categoryArr[i].name&#125;</span>/&quot;&gt;<span class="subst">$&#123;categoryArr[i].name&#125;</span>&lt;/a&gt;</span></span><br><span class="line"><span class="string">      &lt;/div&gt;`</span></span><br><span class="line">      strCategoriesBar+=strTemp</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> strCategoriesBar</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">const</span> tagsBar = <span class="function"><span class="keyword">function</span>(<span class="params">tags</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!tags || !tags.length) <span class="keyword">return</span> <span class="string">``</span></span><br><span class="line">    <span class="keyword">const</span> tagArr = []</span><br><span class="line">    hexo.locals.get(<span class="string">&#x27;tags&#x27;</span>).map(<span class="function"><span class="keyword">function</span> (<span class="params">tag</span>) </span>&#123;</span><br><span class="line">      tagArr.push(&#123; <span class="attr">name</span>: tag.name, <span class="attr">value</span>: tag.length &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line">    tagArr.sort(<span class="function">(<span class="params">a, b</span>) =&gt;</span> &#123; <span class="keyword">return</span> b.value - a.value &#125;)</span><br><span class="line">    <span class="keyword">let</span> strTagsBar = <span class="string">``</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; tags.length; i++) &#123;</span><br><span class="line">      strTemp=<span class="string">`</span></span><br><span class="line"><span class="string">      &lt;div class=&quot;category-bar-item&quot; id=&quot;<span class="subst">$&#123;tagArr[i].name&#125;</span>&quot;&gt;</span></span><br><span class="line"><span class="string">      &lt;a href=&quot;/tags/<span class="subst">$&#123;tagArr[i].name&#125;</span>/&quot;&gt;<span class="subst">$&#123;tagArr[i].name&#125;</span>&lt;/a&gt;</span></span><br><span class="line"><span class="string">      &lt;/div&gt;`</span></span><br><span class="line">      strTagsBar+=strTemp</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> strTagsBar</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (types == <span class="string">&quot;category&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">return</span> categoriesBar(<span class="built_in">this</span>.site.categories)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (types == <span class="string">&quot;tag&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">return</span> tagsBar(<span class="built_in">this</span>.site.tags)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<h2 id="3-3-引用模块"><a href="#3-3-引用模块" class="headerlink" title="3.3 引用模块"></a>3.3 引用模块</h2><p>在需要的位置引用该模块，例如：</p>
<p>在分类页面引用：找到<code>theme/butterfly/layout/category.pug</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">extends includes/layout.pug</span><br><span class="line"></span><br><span class="line">block content</span><br><span class="line">  if theme.category_ui == &#x27;index&#x27;</span><br><span class="line">    include ./includes/mixins/post-ui.pug</span><br><span class="line">    #recent-posts.recent-posts.category_ui   </span><br><span class="line">      +postUI</span><br><span class="line">      include includes/pagination.pug    </span><br><span class="line">  else</span><br><span class="line">    include ./includes/mixins/article-sort.pug</span><br><span class="line">    #category</span><br><span class="line">+      .category-in-bar</span><br><span class="line">+        .category-in-bar-tips</span><br><span class="line">+          i.fa-fw.fas.fa-folder-open</span><br><span class="line">+        include includes/categoryBar.pug</span><br><span class="line">      .article-sort-title= _p(&#x27;page.category&#x27;) + &#x27; - &#x27; + page.category</span><br><span class="line">      +articleSort(page.posts)</span><br><span class="line">      include includes/pagination.pug</span><br></pre></td></tr></table></figure>

<p>在标签页引用：找到<code>theme/butterfly/layout/tag.pug</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">extends includes/layout.pug</span><br><span class="line"></span><br><span class="line">block content</span><br><span class="line">  if theme.tag_ui == &#x27;index&#x27;</span><br><span class="line">    include ./includes/mixins/post-ui.pug</span><br><span class="line">    #recent-posts.recent-posts</span><br><span class="line">      +postUI</span><br><span class="line">      include includes/pagination.pug</span><br><span class="line">  else</span><br><span class="line">    include ./includes/mixins/article-sort.pug</span><br><span class="line">    #tag</span><br><span class="line">+      .category-in-bar</span><br><span class="line">+        .category-in-bar-tips</span><br><span class="line">+          i.fa-fw.fas.fa-tags</span><br><span class="line">+        include includes/tagBar.pug</span><br><span class="line">      .article-sort-title= _p(&#x27;page.tag&#x27;) + &#x27; - &#x27; + page.tag</span><br><span class="line">      +articleSort(page.posts)</span><br><span class="line">      include includes/pagination.pug</span><br></pre></td></tr></table></figure>

<h1 id="4-引入js和css文件"><a href="#4-引入js和css文件" class="headerlink" title="4. 引入js和css文件"></a>4. 引入js和css文件</h1><p>这一部分和Heo博主的教程<a href="https://blog.zhheo.com/p/bc61964d.html">Butterfly魔改：动态分类条，可以根据页面变化而改变的分类列表展示方式 | 张洪Heo (zhheo.com)</a>一致。</p>
<p>不过如果添加了标签条，js文件需要增加一个函数</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">//标签条</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">tagsBarActive</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">  <span class="keyword">var</span> urlinfo = <span class="built_in">window</span>.location.pathname;</span><br><span class="line">  urlinfo = <span class="built_in">decodeURIComponent</span>(urlinfo)</span><br><span class="line">  <span class="comment">//console.log(urlinfo);</span></span><br><span class="line">  <span class="comment">//判断是否是首页</span></span><br><span class="line">  <span class="keyword">if</span> (urlinfo == <span class="string">&#x27;/&#x27;</span>)&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">document</span>.querySelector(<span class="string">&#x27;#tags-bar&#x27;</span>))&#123;</span><br><span class="line">      <span class="built_in">document</span>.getElementById(<span class="string">&#x27;首页&#x27;</span>).classList.add(<span class="string">&quot;select&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 验证是否是分类链接</span></span><br><span class="line">    <span class="keyword">var</span> pattern = <span class="regexp">/\/tags\/.*?\//</span>;</span><br><span class="line">    <span class="keyword">var</span> patbool = pattern.test(urlinfo);</span><br><span class="line">    <span class="comment">//console.log(patbool);</span></span><br><span class="line">    <span class="comment">// 获取当前的标签</span></span><br><span class="line">    <span class="keyword">if</span> (patbool) &#123;</span><br><span class="line">      <span class="keyword">var</span> valuegroup = urlinfo.split(<span class="string">&quot;/&quot;</span>);</span><br><span class="line">      <span class="comment">//console.log(valuegroup[2]);</span></span><br><span class="line">      <span class="comment">// 获取当前分类</span></span><br><span class="line">      <span class="keyword">var</span> nowTag = valuegroup[<span class="number">2</span>];</span><br><span class="line">      <span class="keyword">if</span> (<span class="built_in">document</span>.querySelector(<span class="string">&#x27;#category-bar&#x27;</span>))&#123;</span><br><span class="line">        <span class="built_in">document</span>.getElementById(nowTag).classList.add(<span class="string">&quot;select&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br><span class="line">tagsBarActive()</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客 | 如何让你的valine更好看</title>
    <url>/posts/27831.html</url>
    <content><![CDATA[<p>之前写了一个<a href="/posts/15391.html">博客中能用到的代码（二）</a>,这是第三篇<br>这篇文章介绍<code>valine的样式优化</code></p>
<h2 id="Valine介绍"><a href="#Valine介绍" class="headerlink" title="Valine介绍"></a>Valine介绍</h2><p><a href="https://valine.js.org/">Valine</a> 诞生于2017年8月7日，是一款基于<a href="https://www.leancloud.cn/">LeanCloud</a>的快速、简洁且高效的无后端评论系统。<br>理论上支持但不限于静态博客，目前已有Hexo、Jekyll、Typecho、Hugo、Ghost 等博客程序在使用Valine。</p>
<h2 id="Valine版本"><a href="#Valine版本" class="headerlink" title="Valine版本"></a>Valine版本</h2><p>这篇文章基于 <code>Valine 1.4.14</code>介绍</p>
<h2 id="Valine添加一言"><a href="#Valine添加一言" class="headerlink" title="Valine添加一言"></a>Valine添加一言</h2><p>效果如图：<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200628103932.png"></p>
<p>修改方法：</p>
<ol>
<li>找到博客对应添加valine的位置，例如Ayer主题的位于<code>hexo\themes\ayer\layout\_partial\post\valine.ejs</code></li>
<li>在内部添加一段代码：</li>
</ol>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript">   fetch(<span class="string">&#x27;https://v1.hitokoto.cn&#x27;</span>)</span></span><br><span class="line"><span class="javascript">    .then(<span class="function"><span class="params">response</span> =&gt;</span> response.json())</span></span><br><span class="line"><span class="javascript">    .then(<span class="function"><span class="params">data</span> =&gt;</span> &#123;</span></span><br><span class="line"><span class="javascript">      <span class="built_in">document</span>.getElementById(<span class="string">&quot;veditor&quot;</span>).setAttribute(<span class="string">&quot;placeholder&quot;</span>,data.hitokoto+<span class="string">&quot;__&quot;</span>+data.from);</span></span><br><span class="line"><span class="javascript">    &#125;)</span></span><br><span class="line"><span class="javascript">    .catch(<span class="built_in">console</span>.error)</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li><code>Api</code>接口说明：<br>（1）<code>https://v1.hitokoto.cn/</code> （从7种分类中随机抽取）<br>（2）<code>https://v1.hitokoto.cn/?c=b</code> （请求获得一个分类是漫画的句子）</li>
</ol>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>a</td>
<td>动画</td>
</tr>
<tr>
<td>b</td>
<td>漫画</td>
</tr>
<tr>
<td>c</td>
<td>游戏</td>
</tr>
<tr>
<td>d</td>
<td>文学</td>
</tr>
<tr>
<td>e</td>
<td>原创</td>
</tr>
<tr>
<td>f</td>
<td>来自网络</td>
</tr>
<tr>
<td>g</td>
<td>其他</td>
</tr>
<tr>
<td>h</td>
<td>影视</td>
</tr>
<tr>
<td>i</td>
<td>诗词</td>
</tr>
<tr>
<td>j</td>
<td>网易云</td>
</tr>
<tr>
<td>k</td>
<td>哲学</td>
</tr>
<tr>
<td>l</td>
<td>抖机灵</td>
</tr>
<tr>
<td>其他</td>
<td>作为动画类型处理</td>
</tr>
</tbody></table>
<blockquote>
<p>可选择多个分类，例如： <code>?c=a&amp;c=c</code></p>
</blockquote>
<p>（3）<code>https://v1.hitokoto.cn/?c=f&amp;encode=text</code> （请求获得一个来自网络的句子，并以纯文本格式输出）</p>
<ol start="4">
<li>返回的格式说明</li>
</ol>
<table>
<thead>
<tr>
<th>返回参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>一言标识</td>
</tr>
<tr>
<td>hitokoto</td>
<td>一言正文。编码方式 unicode。使用 utf-8。</td>
</tr>
<tr>
<td>type</td>
<td>类型</td>
</tr>
<tr>
<td>from</td>
<td>一言的出处</td>
</tr>
<tr>
<td>from_who</td>
<td>一言的作者</td>
</tr>
<tr>
<td>creator</td>
<td>添加者</td>
</tr>
<tr>
<td>creator_uid</td>
<td>添加者用户标识</td>
</tr>
<tr>
<td>reviewer</td>
<td>审核员标识</td>
</tr>
<tr>
<td>uuid</td>
<td>一言唯一标识；可以链接到 <code>https://hitokoto.cn?uuid=[uuid]</code> 查看这个一言的完整信息</td>
</tr>
<tr>
<td>commit_from</td>
<td>提交方式</td>
</tr>
<tr>
<td>created_at</td>
<td>添加时间</td>
</tr>
<tr>
<td>length</td>
<td>句子长度</td>
</tr>
</tbody></table>
<blockquote>
<p>例如：返回的data,通过data.hitokoto获取句子正文</p>
</blockquote>
<h2 id="valine添加每日诗句"><a href="#valine添加每日诗句" class="headerlink" title="valine添加每日诗句"></a>valine添加每日诗句</h2><blockquote>
<p>参考<a href="https://cungudafa.top/post/8202.html">https://cungudafa.top/post/8202.html</a></p>
</blockquote>
<p>添加方法和效果上面差不多，加进去就行了</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://sdk.jinrishici.com/v2/browser/jinrishici.js&quot;</span> <span class="attr">charset</span>=<span class="string">&quot;utf-8&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript"> jinrishici.load(<span class="function"><span class="keyword">function</span>(<span class="params">result</span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">     <span class="keyword">var</span> jrsc_plac =  result.data.content + <span class="string">&quot;\n「&quot;</span> + result.data.origin.title + <span class="string">&quot;」&quot;</span> + result.data.origin.dynasty + <span class="string">&quot; · &quot;</span> + result.data.origin.author;</span></span><br><span class="line"><span class="javascript">     <span class="built_in">document</span>.getElementById(<span class="string">&quot;veditor&quot;</span>).setAttribute(<span class="string">&quot;placeholder&quot;</span>,jrsc_plac);</span></span><br><span class="line"><span class="javascript"> &#125;)</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="valine自定义表情"><a href="#valine自定义表情" class="headerlink" title="valine自定义表情"></a>valine自定义表情</h2><ol>
<li><p>首先，你需要很多表情包<br>可以在GitHub上fork一些表情包仓库，然后使用Jsdelivr CDN调用<br>例如：我Fork的<a href="https://github.com/blogimg/emotion">https://github.com/blogimg/emotion</a></p>
</li>
<li><p>在Valine配置里面,添加emojiCDN和emojiMaps参数</p>
</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> Valine(&#123;</span><br><span class="line">    <span class="attr">el</span>:<span class="string">&#x27;#vcomment&#x27;</span>,</span><br><span class="line">    <span class="attr">appId</span>:<span class="string">&#x27;&lt;Your_APP_ID&gt;&#x27;</span>,</span><br><span class="line">    <span class="attr">appKey</span>:<span class="string">&#x27;&lt;Your_APP_KEY&gt;&#x27;</span>,</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这里设置CDN, 默认微博表情CDN</span></span><br><span class="line">    <span class="attr">emojiCDN</span>: <span class="string">&#x27;https://cdn.jsdelivr.net/gh/XXXXXX/emotion/&#x27;</span>, </span><br><span class="line">    <span class="comment">// 表情title和图片映射</span></span><br><span class="line">    <span class="attr">emojiMaps</span>: &#123;</span><br><span class="line">        <span class="string">&quot;黑人问号&quot;</span>:<span class="string">&quot;bilibili/tv_黑人问号.png&quot;</span>,<span class="string">&quot;鼓掌&quot;</span>:<span class="string">&quot;bilibili/tv_鼓掌.png&quot;</span></span><br><span class="line">        <span class="comment">// ... 更多表情</span></span><br><span class="line">    &#125; </span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>效果如图：<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200628110303.png"></li>
</ol>
<h2 id="valine背景"><a href="#valine背景" class="headerlink" title="valine背景"></a>valine背景</h2><ol>
<li><p>效果如图<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200628111715.png"></p>
</li>
<li><p>添加方法,一样的添加代码即可</p>
</li>
</ol>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="css"></span></span><br><span class="line"><span class="css"><span class="selector-class">.v</span><span class="selector-attr">[data-class=v]</span> <span class="selector-class">.veditor</span> &#123;</span></span><br><span class="line"><span class="css">    <span class="attribute">background-image</span>: <span class="built_in">url</span>(<span class="string">https://cdn.jsdelivr.net/gh/xxxxxx/xxxx/xxxx.xxx</span>);</span></span><br><span class="line"><span class="css">    <span class="attribute">background-size</span>: contain;</span></span><br><span class="line"><span class="css">    <span class="attribute">background-repeat</span>: no-repeat;</span></span><br><span class="line"><span class="css">    <span class="attribute">background-position</span>: right;</span></span><br><span class="line"><span class="css">&#125;</span></span><br><span class="line"><span class="css"></span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客 | 给博客导航栏添加二级菜单</title>
    <url>/posts/14357.html</url>
    <content><![CDATA[<p>Hexo主题导航栏添加二级菜单的简单方法</p>
<p>第一步，找到所使用主题的导航栏文件，例如：Ayer主题的位于<code>hexo\themes\ayer\layout\_partial\sidebar.ejs</code></p>
<p>第二步，打开文件，找到文件对应生成菜单的位置,一般在<code>&lt;li&gt;&lt;/li&gt;</code>内，在里面添加代码</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">&quot;nav nav-main&quot;</span>&gt;</span></span><br><span class="line">  &lt;% for (var i in theme.menu)&#123; %&gt;</span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;nav-item&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 找到这里，添加代码 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;nav-item-link&quot;</span> <span class="attr">href</span>=<span class="string">&quot;&lt;%- url_for(theme.menu[i].path) %&gt;&quot;</span>&gt;</span>&lt;%= i %&gt;<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    	&lt;% if (theme.menu[i].submenus) &#123; %&gt;</span><br><span class="line">        <span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">&quot;sub-menu&quot;</span>&gt;</span></span><br><span class="line">          &lt;% for (var submenu in theme.menu[i].submenus)&#123; %&gt;</span><br><span class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">small</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;nav-item-link&quot;</span> <span class="attr">href</span>=<span class="string">&quot;&lt;%- url_for(theme.menu[i].submenus[submenu].path) %&gt;&quot;</span>&gt;</span>&lt;%= submenu %&gt;</span><br><span class="line">              <span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">small</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">          &lt;% &#125; %&gt;</span><br><span class="line">        <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">      &lt;% &#125; %&gt;</span><br><span class="line">      <span class="comment">&lt;!-- 到这里结束 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  &lt;% &#125; %&gt;</span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>第三步，添加css,这是我的样式，当然可以自行修改</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="css"></span></span><br><span class="line"><span class="css"><span class="selector-class">.nav-main</span> <span class="selector-tag">li</span> <span class="selector-tag">ul</span>&#123;</span></span><br><span class="line"><span class="css">	<span class="attribute">display</span>: none;</span></span><br><span class="line"><span class="css">&#125;</span></span><br><span class="line"><span class="css"><span class="selector-class">.nav-main</span> <span class="selector-tag">li</span><span class="selector-pseudo">:hover</span> <span class="selector-tag">ul</span>&#123;</span></span><br><span class="line"><span class="css">	<span class="attribute">display</span>:block;</span></span><br><span class="line"><span class="css">&#125;</span></span><br><span class="line"><span class="css"><span class="selector-class">.sub-menu</span>&#123;</span></span><br><span class="line"><span class="css">    <span class="attribute">position</span>: absolute;</span></span><br><span class="line"><span class="css">    <span class="attribute">background</span>: <span class="number">#fff</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">padding</span>: <span class="number">5px</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">width</span>: <span class="number">8rem</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">z-index</span>:<span class="number">1000</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">text-align</span>: center;</span></span><br><span class="line"><span class="css">    <span class="attribute">border-radius</span>: <span class="number">5px</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">box-shadow</span>: <span class="number">0</span> <span class="number">1px</span> <span class="number">40px</span> -<span class="number">8px</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,.<span class="number">5</span>);</span></span><br><span class="line"><span class="css">    -webkit-<span class="attribute">animation</span>: fadeInUp .<span class="number">3s</span> .<span class="number">1s</span> ease both;</span></span><br><span class="line"><span class="css">    <span class="attribute">list-style</span>:none;</span></span><br><span class="line"><span class="css">&#125;</span></span><br><span class="line"><span class="css"><span class="selector-class">.nav-main</span> <span class="selector-tag">li</span> <span class="selector-tag">ul</span><span class="selector-pseudo">::before</span> &#123;</span></span><br><span class="line"><span class="css">    <span class="attribute">content</span>: <span class="string">&quot;&quot;</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">position</span>: absolute;</span></span><br><span class="line"><span class="css">    <span class="attribute">top</span>: -<span class="number">20px</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">left</span>: <span class="number">50%</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">margin-left</span>: -<span class="number">10px</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">border-width</span>: <span class="number">10px</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">border-style</span>: solid;</span></span><br><span class="line"><span class="css">    <span class="attribute">border-color</span>: transparent transparent <span class="number">#fff</span> transparent;</span></span><br><span class="line"><span class="css">&#125;</span></span><br><span class="line"><span class="css"></span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>第四步，找到主题下的配置文件，如ayer的位于<code>hexo\themes\ayer\_config.yml</code>，在需要的位置添加submenus，修改菜单menu信息，例如我的：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 侧边栏菜单</span></span><br><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="string">主页:</span> &#123; <span class="attr">path:</span> <span class="string">/</span> &#125;</span><br><span class="line">  <span class="string">说说:</span> &#123; <span class="attr">path:</span> <span class="string">/talks</span> &#125;  </span><br><span class="line">  <span class="string">友链:</span> &#123; <span class="attr">path:</span> <span class="string">/friends</span> &#125;</span><br><span class="line">  <span class="string">随机:</span> &#123; <span class="attr">path:</span> <span class="string">/random.html</span> &#125;</span><br><span class="line">  <span class="string">留言:</span> &#123; <span class="attr">path:</span> <span class="string">/guestbook</span> &#125;</span><br><span class="line">  <span class="string">归档:</span> &#123; <span class="attr">path:</span> <span class="string">/archives</span> ,<span class="attr">submenus:</span> &#123;</span><br><span class="line">    <span class="string">分类:</span> &#123; <span class="attr">path:</span> <span class="string">/categories</span> &#125;,</span><br><span class="line">    <span class="string">标签:</span> &#123; <span class="attr">path:</span> <span class="string">/tags</span> &#125;,</span><br><span class="line">    <span class="string">相册:</span> &#123; <span class="attr">path:</span> <span class="string">/photos</span> &#125;</span><br><span class="line">        &#125; &#125;</span><br><span class="line">  <span class="string">关于:</span> &#123; <span class="attr">path:</span> <span class="string">/about</span> ,<span class="attr">submenus:</span> &#123;</span><br><span class="line">      <span class="string">统计:</span> &#123; <span class="attr">path:</span> <span class="string">/analytics</span> &#125;,</span><br><span class="line">      <span class="string">监控:</span> &#123; <span class="attr">path:</span> <span class="string">https://monitor.justlovesmile.top</span> &#125;</span><br><span class="line">        &#125; &#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客 | 如何让你的博客拥有星空背景和流星特效</title>
    <url>/posts/6a260bf6.html</url>
    <content><![CDATA[<p>最近很多小伙伴留言想要<code>星空和流星特效</code>，于是写了这篇文章准备介绍如何部署。</p>
<blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202108121834269.gif"></p>
</blockquote>
<h2 id="1-插入Canvas标签"><a href="#1-插入Canvas标签" class="headerlink" title="1. 插入Canvas标签"></a>1. 插入Canvas标签</h2><p>首先打开Butterfly主题的<code>_config.yml</code>文件或者使用HTML直接插入，找到配置文件对应的<code>inject</code>部分，插入<code>&lt;canvas id=&quot;universe&quot;&gt;&lt;/canvas&gt;</code></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202108121759902.png" alt="image-20210812175952760"></p>
<h2 id="2-创建JS文件"><a href="#2-创建JS文件" class="headerlink" title="2. 创建JS文件"></a>2. 创建JS文件</h2><p>在<code>butterfly/source/js/</code>创建一个<code>universe.js</code>文件，或者添加到自己的<code>js</code>文件中</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">dark</span>(<span class="params"></span>) </span>&#123;<span class="built_in">window</span>.requestAnimationFrame=<span class="built_in">window</span>.requestAnimationFrame||<span class="built_in">window</span>.mozRequestAnimationFrame||<span class="built_in">window</span>.webkitRequestAnimationFrame||<span class="built_in">window</span>.msRequestAnimationFrame;<span class="keyword">var</span> n,e,i,h,t=<span class="number">.05</span>,s=<span class="built_in">document</span>.getElementById(<span class="string">&quot;universe&quot;</span>),o=!<span class="number">0</span>,a=<span class="string">&quot;180,184,240&quot;</span>,r=<span class="string">&quot;226,225,142&quot;</span>,d=<span class="string">&quot;226,225,224&quot;</span>,c=[];<span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>)</span>&#123;n=<span class="built_in">window</span>.innerWidth,e=<span class="built_in">window</span>.innerHeight,i=<span class="number">.216</span>*n,s.setAttribute(<span class="string">&quot;width&quot;</span>,n),s.setAttribute(<span class="string">&quot;height&quot;</span>,e)&#125;<span class="function"><span class="keyword">function</span> <span class="title">u</span>(<span class="params"></span>)</span>&#123;h.clearRect(<span class="number">0</span>,<span class="number">0</span>,n,e);<span class="keyword">for</span>(<span class="keyword">var</span> t=c.length,i=<span class="number">0</span>;i&lt;t;i++)&#123;<span class="keyword">var</span> s=c[i];s.move(),s.fadeIn(),s.fadeOut(),s.draw()&#125;&#125;<span class="function"><span class="keyword">function</span> <span class="title">y</span>(<span class="params"></span>)</span>&#123;<span class="built_in">this</span>.reset=<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;<span class="built_in">this</span>.giant=m(<span class="number">3</span>),<span class="built_in">this</span>.comet=!<span class="built_in">this</span>.giant&amp;&amp;!o&amp;&amp;m(<span class="number">10</span>),<span class="built_in">this</span>.x=l(<span class="number">0</span>,n-<span class="number">10</span>),<span class="built_in">this</span>.y=l(<span class="number">0</span>,e),<span class="built_in">this</span>.r=l(<span class="number">1.1</span>,<span class="number">2.6</span>),<span class="built_in">this</span>.dx=l(t,<span class="number">6</span>*t)+(<span class="built_in">this</span>.comet+<span class="number">1</span>-<span class="number">1</span>)*t*l(<span class="number">50</span>,<span class="number">120</span>)+<span class="number">2</span>*t,<span class="built_in">this</span>.dy=-l(t,<span class="number">6</span>*t)-(<span class="built_in">this</span>.comet+<span class="number">1</span>-<span class="number">1</span>)*t*l(<span class="number">50</span>,<span class="number">120</span>),<span class="built_in">this</span>.fadingOut=<span class="literal">null</span>,<span class="built_in">this</span>.fadingIn=!<span class="number">0</span>,<span class="built_in">this</span>.opacity=<span class="number">0</span>,<span class="built_in">this</span>.opacityTresh=l(<span class="number">.2</span>,<span class="number">1</span>-<span class="number">.4</span>*(<span class="built_in">this</span>.comet+<span class="number">1</span>-<span class="number">1</span>)),<span class="built_in">this</span>.do=l(<span class="number">5e-4</span>,<span class="number">.002</span>)+<span class="number">.001</span>*(<span class="built_in">this</span>.comet+<span class="number">1</span>-<span class="number">1</span>)&#125;,<span class="built_in">this</span>.fadeIn=<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;<span class="built_in">this</span>.fadingIn&amp;&amp;(<span class="built_in">this</span>.fadingIn=!(<span class="built_in">this</span>.opacity&gt;<span class="built_in">this</span>.opacityTresh),<span class="built_in">this</span>.opacity+=<span class="built_in">this</span>.do)&#125;,<span class="built_in">this</span>.fadeOut=<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;<span class="built_in">this</span>.fadingOut&amp;&amp;(<span class="built_in">this</span>.fadingOut=!(<span class="built_in">this</span>.opacity&lt;<span class="number">0</span>),<span class="built_in">this</span>.opacity-=<span class="built_in">this</span>.do/<span class="number">2</span>,(<span class="built_in">this</span>.x&gt;n||<span class="built_in">this</span>.y&lt;<span class="number">0</span>)&amp;&amp;(<span class="built_in">this</span>.fadingOut=!<span class="number">1</span>,<span class="built_in">this</span>.reset()))&#125;,<span class="built_in">this</span>.draw=<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;<span class="keyword">if</span>(h.beginPath(),<span class="built_in">this</span>.giant)h.fillStyle=<span class="string">&quot;rgba(&quot;</span>+a+<span class="string">&quot;,&quot;</span>+<span class="built_in">this</span>.opacity+<span class="string">&quot;)&quot;</span>,h.arc(<span class="built_in">this</span>.x,<span class="built_in">this</span>.y,<span class="number">2</span>,<span class="number">0</span>,<span class="number">2</span>*<span class="built_in">Math</span>.PI,!<span class="number">1</span>);<span class="keyword">else</span> <span class="keyword">if</span>(<span class="built_in">this</span>.comet)&#123;h.fillStyle=<span class="string">&quot;rgba(&quot;</span>+d+<span class="string">&quot;,&quot;</span>+<span class="built_in">this</span>.opacity+<span class="string">&quot;)&quot;</span>,h.arc(<span class="built_in">this</span>.x,<span class="built_in">this</span>.y,<span class="number">1.5</span>,<span class="number">0</span>,<span class="number">2</span>*<span class="built_in">Math</span>.PI,!<span class="number">1</span>);<span class="keyword">for</span>(<span class="keyword">var</span> t=<span class="number">0</span>;t&lt;<span class="number">30</span>;t++)h.fillStyle=<span class="string">&quot;rgba(&quot;</span>+d+<span class="string">&quot;,&quot;</span>+(<span class="built_in">this</span>.opacity-<span class="built_in">this</span>.opacity/<span class="number">20</span>*t)+<span class="string">&quot;)&quot;</span>,h.rect(<span class="built_in">this</span>.x-<span class="built_in">this</span>.dx/<span class="number">4</span>*t,<span class="built_in">this</span>.y-<span class="built_in">this</span>.dy/<span class="number">4</span>*t-<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>),h.fill()&#125;<span class="keyword">else</span> h.fillStyle=<span class="string">&quot;rgba(&quot;</span>+r+<span class="string">&quot;,&quot;</span>+<span class="built_in">this</span>.opacity+<span class="string">&quot;)&quot;</span>,h.rect(<span class="built_in">this</span>.x,<span class="built_in">this</span>.y,<span class="built_in">this</span>.r,<span class="built_in">this</span>.r);h.closePath(),h.fill()&#125;,<span class="built_in">this</span>.move=<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;<span class="built_in">this</span>.x+=<span class="built_in">this</span>.dx,<span class="built_in">this</span>.y+=<span class="built_in">this</span>.dy,!<span class="number">1</span>===<span class="built_in">this</span>.fadingOut&amp;&amp;<span class="built_in">this</span>.reset(),(<span class="built_in">this</span>.x&gt;n-n/<span class="number">4</span>||<span class="built_in">this</span>.y&lt;<span class="number">0</span>)&amp;&amp;(<span class="built_in">this</span>.fadingOut=!<span class="number">0</span>)&#125;,<span class="built_in">setTimeout</span>(<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;o=!<span class="number">1</span>&#125;,<span class="number">50</span>)&#125;<span class="function"><span class="keyword">function</span> <span class="title">m</span>(<span class="params">t</span>)</span>&#123;<span class="keyword">return</span> <span class="built_in">Math</span>.floor(<span class="number">1e3</span>*<span class="built_in">Math</span>.random())+<span class="number">1</span>&lt;<span class="number">10</span>*t&#125;<span class="function"><span class="keyword">function</span> <span class="title">l</span>(<span class="params">t,i</span>)</span>&#123;<span class="keyword">return</span> <span class="built_in">Math</span>.random()*(i-t)+t&#125;f(),<span class="built_in">window</span>.addEventListener(<span class="string">&quot;resize&quot;</span>,f,!<span class="number">1</span>),<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;h=s.getContext(<span class="string">&quot;2d&quot;</span>);<span class="keyword">for</span>(<span class="keyword">var</span> t=<span class="number">0</span>;t&lt;i;t++)c[t]=<span class="keyword">new</span> y,c[t].reset();u()&#125;(),<span class="function"><span class="keyword">function</span> <span class="title">t</span>(<span class="params"></span>)</span>&#123;<span class="built_in">document</span>.getElementsByTagName(<span class="string">&#x27;html&#x27;</span>)[<span class="number">0</span>].getAttribute(<span class="string">&#x27;data-theme&#x27;</span>)==<span class="string">&#x27;dark&#x27;</span>&amp;&amp;u(),<span class="built_in">window</span>.requestAnimationFrame(t)&#125;()&#125;;</span><br><span class="line">dark()</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202108121822274.png" alt="image-20210812182203080"></p>
<p>代码的这一部分要求<code>data-theme</code>也就是主题为<code>dark</code>暗色主题，因此仅在暗色主题生效，随后将<code>js</code>文件添加到配置文件的<code>inject</code>处或者其他需要的位置。</p>
<h2 id="3-CSS样式"><a href="#3-CSS样式" class="headerlink" title="3. CSS样式"></a>3. CSS样式</h2><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* 背景宇宙星光  */</span></span><br><span class="line"><span class="selector-id">#universe</span>&#123;</span><br><span class="line">  <span class="attribute">display</span>: block;</span><br><span class="line">  <span class="attribute">position</span>: fixed;</span><br><span class="line">  <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">padding</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">border</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">outline</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">left</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">top</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">100%</span>;</span><br><span class="line">  <span class="attribute">pointer-events</span>: none;</span><br><span class="line">  <span class="attribute">z-index</span>: -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客 | 采用随机图片作为博客封面背景，真香！</title>
    <url>/posts/27301.html</url>
    <content><![CDATA[<p>最近美化了一下我的博客<a href="/">首页</a>，每次打开会随机选择一张图片作为封面<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/display.gif"></p>
<p><strong>发现写了很多博客美化的文章了,罗列了一下</strong></p>
<ul>
<li><a href="/posts/24067.html">Type.js打字机效果</a>: 添加<code>打字机效果</code></li>
<li><a href="/posts/56163.html">博客中能用到的代码</a>: 关于<code>font awesome图标</code>字体库，使用<code>动态图标</code>，添加<code>网页运行时间</code>，<code>全站变黑白</code>，<code>鼠标点击特效</code>，<code>网页标题的动态效果</code>，<code>网页樱花特效</code>，<code>鼠标触动音乐特效</code></li>
<li><a href="/posts/15391.html">博客中能用到的代码（二）</a>: 添加<code>旋转小人</code>和<code>每日诗句</code></li>
<li><a href="/posts/27831.html">博客美化之Valine</a>: 关于valine添加<code>一言</code>，<code>每日诗句</code>，<code>自定义表情</code>，<code>自定义背景</code></li>
<li><a href="/posts/14357.html">添加二级菜单</a>: 添加<code>二级菜单</code>的简单方法</li>
<li><a href="/posts/43010.html">添加博客加密</a>: <code>文章添加密码</code>功能</li>
<li><a href="/posts/27301.html">Hexo博客美化之随机封面</a>: <code>封面图片随机更换</code>功能</li>
<li><a href="/posts/57206.html">Hexo博客添加公告板</a></li>
<li><a href="/posts/7e7ef81c.html">花里胡哨的打字机效果</a></li>
<li><a href="/posts/7376.html">Hexo竟然可以展示PDF</a></li>
<li><a href="/posts/86111745.html">Hexo插件总结推荐</a></li>
</ul>
<h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>本文是以我现在使用的Ayer主题为例</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="第一步-找到对应封面的代码位置"><a href="#第一步-找到对应封面的代码位置" class="headerlink" title="第一步 找到对应封面的代码位置"></a>第一步 找到对应封面的代码位置</h3><p>例如，ayer主题的位于<code>hexo\themes\ayer\layout\_partial\ayer.ejs</code></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;cover-frame&quot;</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 从这里开始，修改代码 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;bg-box&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;&quot;</span> <span class="attr">id</span>=<span class="string">&quot;cover-pic&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript">    $(<span class="built_in">document</span>).ready(<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span></span><br><span class="line"><span class="javascript">    	<span class="keyword">var</span> i=<span class="built_in">Math</span>.floor((<span class="built_in">Math</span>.random()*&lt;%= theme.cover.num %&gt;));</span></span><br><span class="line"><span class="javascript">    	imgs=[&lt;% <span class="keyword">for</span> (<span class="keyword">var</span> i <span class="keyword">in</span> theme.cover.path)&#123; %&gt; <span class="string">&quot;&lt;%- url_for(theme.cover.path[i]) -%&gt;&quot;</span>,&lt;% &#125; %&gt;]</span></span><br><span class="line"><span class="javascript">    	pic=<span class="built_in">document</span>.getElementById(<span class="string">&quot;cover-pic&quot;</span>);</span></span><br><span class="line"><span class="javascript">    	pic.src=imgs[i];</span></span><br><span class="line"><span class="javascript">    &#125;)</span></span><br><span class="line"><span class="javascript">    </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 到这里结束 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;cover-inner text-center text-white&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">h1</span> <span class="attr">class</span>=<span class="string">&quot;center-text glitch&quot;</span> <span class="attr">data-text</span>=<span class="string">&quot;&lt;%= config.title %&gt;&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;&lt;%- url_for() %&gt;&quot;</span>&gt;</span>&lt;%= config.title %&gt;<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;subtitle-box&quot;</span>&gt;</span></span><br><span class="line">        &lt;% if (theme.subtitle.enable) &#123; %&gt;</span><br><span class="line">        <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;subtitle&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">        &lt;% &#125;else&#123; %&gt;</span><br><span class="line">          <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;subtitle&quot;</span>&gt;</span>&lt;%= theme.subtitle.text %&gt;<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">        &lt;% &#125; %&gt;</span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="第二步，修改配置文件"><a href="#第二步，修改配置文件" class="headerlink" title="第二步，修改配置文件"></a>第二步，修改配置文件</h3><p>找到<code>主题</code>下的配置文件<code>_config.yml</code>，修改cover项，例如我的是</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 封面配置</span></span><br><span class="line">cover:</span><br><span class="line">  enable: true</span><br><span class="line">  num: <span class="number">8</span>  <span class="comment">#随机封面数量，前num张</span></span><br><span class="line">  path: <span class="comment">#path可以任意修改</span></span><br><span class="line">    img1: https:<span class="regexp">//</span>cdn.jsdelivr.net<span class="regexp">/gh/</span>Justlovesmile<span class="regexp">/CDN2/</span>post/cover1.JPG</span><br><span class="line">    img2: https:<span class="regexp">//</span>cdn.jsdelivr.net<span class="regexp">/gh/</span>Justlovesmile<span class="regexp">/CDN2/</span>post/cover2.jpg</span><br><span class="line">    img3: https:<span class="regexp">//</span>cdn.jsdelivr.net<span class="regexp">/gh/</span>Justlovesmile<span class="regexp">/CDN2/</span>post/cover3.jpg</span><br><span class="line">    img4: https:<span class="regexp">//</span>cdn.jsdelivr.net<span class="regexp">/gh/</span>Justlovesmile<span class="regexp">/CDN2/</span>post/cover4.jpg</span><br><span class="line">    img5: https:<span class="regexp">//</span>cdn.jsdelivr.net<span class="regexp">/gh/</span>Justlovesmile<span class="regexp">/CDN2/</span>post/cover5.JPG</span><br><span class="line">    img6: https:<span class="regexp">//</span>cdn.jsdelivr.net<span class="regexp">/gh/</span>Justlovesmile<span class="regexp">/CDN2/</span>post/cover6.JPG</span><br><span class="line">    img7: https:<span class="regexp">//</span>cdn.jsdelivr.net<span class="regexp">/gh/</span>Justlovesmile<span class="regexp">/CDN2/</span>post/cover7.JPG</span><br><span class="line">    img8: https:<span class="regexp">//</span>cdn.jsdelivr.net<span class="regexp">/gh/</span>Justlovesmile<span class="regexp">/CDN2/</span>post/cover8.JPG</span><br><span class="line">  logo: false <span class="comment">#如果不要直接设置成false</span></span><br></pre></td></tr></table></figure>

<h3 id="第三步，自定义"><a href="#第三步，自定义" class="headerlink" title="第三步，自定义"></a>第三步，自定义</h3><p>第二步中的num和path均可以任意修改，例如，如果想要减少对应的图片数量为4张：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">cover:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">num:</span> <span class="number">4</span>  <span class="comment">#随机封面数量，前num张</span></span><br><span class="line">  <span class="attr">path:</span> <span class="comment">#path可以任意修改</span></span><br><span class="line">    <span class="attr">img1:</span> <span class="string">换上自己的图片url1</span></span><br><span class="line">    <span class="attr">img2:</span> <span class="string">换上自己的图片url2</span></span><br><span class="line">    <span class="attr">img3:</span> <span class="string">换上自己的图片url3</span></span><br><span class="line">    <span class="attr">img4:</span> <span class="string">换上自己的图片url4</span></span><br><span class="line">  <span class="attr">logo:</span> <span class="literal">false</span> <span class="comment">#如果不要直接设置成false</span></span><br></pre></td></tr></table></figure>

<p>如果你想要自定义其他的，步骤和我这篇文章的一样，只需要找到对应的代码位置，一般在layout和source里面，再修改就行了，注意ejs的用法</p>
<blockquote>
<p><strong>下一篇文章想要介绍博客添加告示板😀</strong><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200629110750.png"></p>
</blockquote>
]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客 | 如何在博客首页添加公告板模块</title>
    <url>/posts/57206.html</url>
    <content><![CDATA[<p>在我的博客首页添加了<code>告示板模块</code>，有两种模式，一种是<code>自定义语句</code>，一种是<code>一言API</code><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200630163919.png"></p>
<blockquote>
<p><strong>发现写了很多博客美化的文章了,罗列了一下</strong></p>
</blockquote>
<ul>
<li><a href="/posts/24067.html">Type.js打字机效果</a>: 添加<code>打字机效果</code></li>
<li><a href="/posts/56163.html">博客中能用到的代码</a>: 关于<code>font awesome图标</code>字体库，使用<code>动态图标</code>，添加<code>网页运行时间</code>，<code>全站变黑白</code>，<code>鼠标点击特效</code>，<code>网页标题的动态效果</code>，<code>网页樱花特效</code>，<code>鼠标触动音乐特效</code></li>
<li><a href="/posts/15391.html">博客中能用到的代码（二）</a>: 添加<code>旋转小人</code>和<code>每日诗句</code></li>
<li><a href="/posts/27831.html">博客美化之Valine</a>: 关于valine添加<code>一言</code>，<code>每日诗句</code>，<code>自定义表情</code>，<code>自定义背景</code></li>
<li><a href="/posts/14357.html">添加二级菜单</a>: 添加<code>二级菜单</code>的简单方法</li>
<li><a href="/posts/43010.html">添加博客加密</a>: <code>文章添加密码</code>功能</li>
<li><a href="/posts/27301.html">Hexo博客美化之随机封面</a>: <code>封面图片随机更换</code>功能</li>
<li><a href="/posts/57206.html">Hexo博客添加公告板</a></li>
<li><a href="/posts/7e7ef81c.html">花里胡哨的打字机效果</a></li>
<li><a href="/posts/7376.html">Hexo竟然可以展示PDF</a></li>
<li><a href="/posts/86111745.html">Hexo插件总结推荐</a></li>
</ul>
<h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>本文是以我现在使用的Ayer主题为例</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="第一步-找到对应的首页文章页的代码文章"><a href="#第一步-找到对应的首页文章页的代码文章" class="headerlink" title="第一步 找到对应的首页文章页的代码文章"></a>第一步 找到对应的首页文章页的代码文章</h3><p>例如，ayer主题的位于<code>hexo\themes\ayer\layout\_partial\archive.ejs</code></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">class</span>=<span class="string">&quot;outer&quot;</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 找到这里，添加代码 --&gt;</span></span><br><span class="line">  &lt;% if (theme.broadcast.enable &amp;&amp; pagination == 2)&#123; %&gt;</span><br><span class="line">  &lt;%- partial(&#x27;_partial/broadcast&#x27;) %&gt;</span><br><span class="line">  &lt;% &#125; %&gt;</span><br><span class="line"><span class="comment">&lt;!-- 到这里结束 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">article</span> <span class="attr">class</span>=<span class="string">&quot;articles&quot;</span>&gt;</span></span><br><span class="line">    &lt;%</span><br><span class="line">    var title = &#x27;&#x27;;</span><br><span class="line">    if (page.category) title = page.category;</span><br><span class="line">    if (page.tag) title = &quot;#&quot; + &quot;&amp;nbsp&quot; + page.tag;</span><br><span class="line">    if (page.archive) &#123;</span><br><span class="line">      if (page.year) title = page.year + (page.month ? &#x27;/&#x27; + page.month : &#x27;&#x27;);</span><br><span class="line">      else title = __(&#x27;archive_a&#x27;);</span><br><span class="line">    &#125;</span><br><span class="line">    %&gt;</span><br></pre></td></tr></table></figure>

<h3 id="第二步-创建broadcast-ejs文件"><a href="#第二步-创建broadcast-ejs文件" class="headerlink" title="第二步 创建broadcast.ejs文件"></a>第二步 创建<code>broadcast.ejs</code>文件</h3><p>在第一步里，<code>&lt;%- partial(&#39;_partial/broadcast&#39;) %&gt;</code>调用了<code>_partial</code>文件夹里面的<code>broadcast.ejs</code>文件，因此需要自己创建一个，内容为：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&lt;% if (theme.broadcast.type===1 &amp;&amp; theme.broadcast.text)&#123; %&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;notice&quot;</span> <span class="attr">style</span>=<span class="string">&quot;margin-top:50px&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;fa &lt;%- theme.broadcast.icon -%&gt;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;notice-content&quot;</span>&gt;</span>&lt;%= theme.broadcast.text %&gt;<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">&lt;% &#125; %&gt;</span><br><span class="line">&lt;% if (theme.broadcast.type===2)&#123; %&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;notice&quot;</span> <span class="attr">style</span>=<span class="string">&quot;margin-top:50px&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;fa &lt;%- theme.broadcast.icon -%&gt;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;notice-content&quot;</span> <span class="attr">id</span>=<span class="string">&quot;broad&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript">   fetch(<span class="string">&#x27;https://v1.hitokoto.cn&#x27;</span>)</span></span><br><span class="line"><span class="javascript">    .then(<span class="function"><span class="params">response</span> =&gt;</span> response.json())</span></span><br><span class="line"><span class="javascript">    .then(<span class="function"><span class="params">data</span> =&gt;</span> &#123;</span></span><br><span class="line"><span class="javascript">      <span class="built_in">document</span>.getElementById(<span class="string">&quot;broad&quot;</span>).innerHTML=data.hitokoto;</span></span><br><span class="line"><span class="javascript">    &#125;)</span></span><br><span class="line"><span class="javascript">    .catch(<span class="built_in">console</span>.error)</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">&lt;% &#125; %&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="css"></span></span><br><span class="line"><span class="css"><span class="selector-class">.notice</span> &#123;</span></span><br><span class="line"><span class="css">    <span class="attribute">padding</span>: <span class="number">20px</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">border</span>: <span class="number">1px</span> dashed <span class="number">#e6e6e6</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">color</span>: <span class="number">#969696</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">position</span>: relative;</span></span><br><span class="line"><span class="css">    <span class="attribute">display</span>: inline-block;</span></span><br><span class="line"><span class="css">    <span class="attribute">width</span>: <span class="number">100%</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">background</span>: <span class="number">#fbfbfb</span>50;</span></span><br><span class="line"><span class="css">    <span class="attribute">border-radius</span>: <span class="number">10px</span>;</span></span><br><span class="line"><span class="css">&#125;</span></span><br><span class="line"><span class="css"><span class="selector-class">.notice</span> <span class="selector-tag">i</span>&#123;</span></span><br><span class="line"><span class="css">    <span class="attribute">float</span>: left;</span></span><br><span class="line"><span class="css">    <span class="attribute">color</span>: <span class="number">#999</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">font-size</span>: <span class="number">18px</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">padding-right</span>: <span class="number">10px</span>;</span></span><br><span class="line"><span class="css">    <span class="attribute">vertical-align</span>: middle;</span></span><br><span class="line"><span class="css">    <span class="attribute">margin-top</span>:<span class="number">3px</span>;</span></span><br><span class="line"><span class="css">&#125;</span></span><br><span class="line"><span class="css"><span class="selector-class">.notice-content</span>&#123;</span></span><br><span class="line"><span class="css">    <span class="attribute">display</span>: initial;</span></span><br><span class="line"><span class="css">    <span class="attribute">vertical-align</span>: middle;</span></span><br><span class="line"><span class="css">&#125;</span></span><br><span class="line"><span class="css"></span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>当然，为了优化，也可以自己把css整合到css文件中，或者把cdn文件放到after-footer里，这里不再详述</p>
<h3 id="第三步-打开主题的配置文件"><a href="#第三步-打开主题的配置文件" class="headerlink" title="第三步 打开主题的配置文件"></a>第三步 打开主题的配置文件</h3><p>注意是主题的配置文件！打开后添加配置项：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 告示板模块</span></span><br><span class="line"><span class="attr">broadcast:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span>   <span class="comment">#true开启，false关闭</span></span><br><span class="line">  <span class="attr">icon:</span> <span class="string">fa-bookmark</span>  <span class="comment">#fontawesome图标库，格式如示例</span></span><br><span class="line">  <span class="attr">type:</span> <span class="number">2</span> <span class="comment">#1：自定义输入，2：一言api</span></span><br><span class="line">  <span class="attr">text:</span> <span class="string">justlovesmile.top持续更新中...</span>  <span class="comment">#type为1时有效</span></span><br></pre></td></tr></table></figure>

<h3 id="第四步-效果"><a href="#第四步-效果" class="headerlink" title="第四步 效果"></a>第四步 效果</h3><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200630163919.png"></p>
]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客 | 插件推荐</title>
    <url>/posts/86111745.html</url>
    <content><![CDATA[<h2 id="Hexo插件汇总"><a href="#Hexo插件汇总" class="headerlink" title="Hexo插件汇总"></a>Hexo插件汇总</h2><table>
<thead>
<tr>
<th>插件</th>
<th>功能</th>
<th>文档链接</th>
</tr>
</thead>
<tbody><tr>
<td>hexo-generator-index-pin-top</td>
<td>文章置顶</td>
<td><a href="https://github.com/netcan/hexo-generator-index-pin-top">https://github.com/netcan/hexo-generator-index-pin-top</a></td>
</tr>
<tr>
<td>hexo-wordcount</td>
<td>文章字数统计和阅读时长统计</td>
<td><a href="https://github.com/willin/hexo-wordcount">https://github.com/willin/hexo-wordcount</a></td>
</tr>
<tr>
<td>hexo-abbrlink</td>
<td>生成URL短链接</td>
<td><a href="https://github.com/rozbo/hexo-abbrlink">https://github.com/rozbo/hexo-abbrlink</a></td>
</tr>
<tr>
<td>hexo-lazyload-image</td>
<td>图片懒加载</td>
<td><a href="https://github.com/Troy-Yang/hexo-lazyload-image">https://github.com/Troy-Yang/hexo-lazyload-image</a></td>
</tr>
<tr>
<td>hexo-generator-baidu-sitemap</td>
<td>生成baidusitemap.xml</td>
<td><a href="https://github.com/coneycode/hexo-generator-baidu-sitemap">https://github.com/coneycode/hexo-generator-baidu-sitemap</a></td>
</tr>
<tr>
<td>hexo-generator-sitemap</td>
<td>生成sitemap.xml</td>
<td><a href="https://github.com/hexojs/hexo-generator-sitemap">https://github.com/hexojs/hexo-generator-sitemap</a></td>
</tr>
<tr>
<td>hexo-generator-feed</td>
<td>生成RSS文件</td>
<td><a href="https://github.com/hexojs/hexo-generator-feed">https://github.com/hexojs/hexo-generator-feed</a></td>
</tr>
<tr>
<td>hexo-external-link</td>
<td>外链跳转</td>
<td><a href="https://github.com/hvnobug/hexo-external-link">https://github.com/hvnobug/hexo-external-link</a></td>
</tr>
<tr>
<td>hexo-autonofollow</td>
<td>自动对外部链接增加nofollow属性</td>
<td><a href="https://github.com/liuzc/hexo-autonofollow">https://github.com/liuzc/hexo-autonofollow</a></td>
</tr>
<tr>
<td>hexo-filter-nofollow</td>
<td>为外链添加<code>rel=&quot;noopener external nofollow noreferrer&quot;</code></td>
<td><a href="https://github.com/hexojs/hexo-filter-nofollow">https://github.com/hexojs/hexo-filter-nofollow</a></td>
</tr>
<tr>
<td>hexo-prism-plugin</td>
<td>代码高亮</td>
<td><a href="https://github.com/ele828/hexo-prism-plugin">https://github.com/ele828/hexo-prism-plugin</a></td>
</tr>
<tr>
<td>hexo-neat</td>
<td>博客压缩</td>
<td><a href="https://github.com/rozbo/hexo-neat">https://github.com/rozbo/hexo-neat</a></td>
</tr>
<tr>
<td>hexo-allminifier</td>
<td>博客压缩</td>
<td><a href="https://developer.aliyun.com/mirror/npm/package/hexo-all-minifier">https://developer.aliyun.com/mirror/npm/package/hexo-all-minifier</a></td>
</tr>
<tr>
<td>hexo-tag-aplayer</td>
<td>aplayer音乐播放器</td>
<td><a href="https://github.com/MoePlayer/hexo-tag-aplayer">https://github.com/MoePlayer/hexo-tag-aplayer</a></td>
</tr>
<tr>
<td>hexo-tag-dplayer</td>
<td>dplayer视频播放器</td>
<td><a href="https://github.com/MoePlayer/hexo-tag-dplayer">https://github.com/MoePlayer/hexo-tag-dplayer</a></td>
</tr>
<tr>
<td>hexo-douban</td>
<td>添加豆瓣读书，电影，游戏页面</td>
<td><a href="https://github.com/mythsman/hexo-douban">https://github.com/mythsman/hexo-douban</a></td>
</tr>
<tr>
<td>hexo-generator-searchdb</td>
<td>本地搜索,生成search.xml</td>
<td><a href="https://github.com/theme-next/hexo-generator-searchdb">https://github.com/theme-next/hexo-generator-searchdb</a></td>
</tr>
<tr>
<td>hexo-algoliasearch</td>
<td>搜索系统</td>
<td><a href="https://github.com/LouisBarranqueiro/hexo-algoliasearch">https://github.com/LouisBarranqueiro/hexo-algoliasearch</a></td>
</tr>
<tr>
<td>hexo-algolia</td>
<td>搜索系统</td>
<td><a href="https://github.com/oncletom/hexo-algolia">https://github.com/oncletom/hexo-algolia</a></td>
</tr>
<tr>
<td>hexo-generator-search</td>
<td>本地搜索系统</td>
<td><a href="https://github.com/wzpan/hexo-generator-search">https://github.com/wzpan/hexo-generator-search</a></td>
</tr>
<tr>
<td>hexo-baidu-url-submit</td>
<td>百度站长主动推送</td>
<td><a href="https://github.com/huiwang/hexo-baidu-url-submit">https://github.com/huiwang/hexo-baidu-url-submit</a></td>
</tr>
<tr>
<td>hexo-offline</td>
<td>开启PWA</td>
<td><a href="https://github.com/JLHwung/hexo-offline">https://github.com/JLHwung/hexo-offline</a></td>
</tr>
<tr>
<td>hexo-pwa</td>
<td>开启PWA</td>
<td><a href="https://github.com/lavas-project/hexo-pwa">https://github.com/lavas-project/hexo-pwa</a></td>
</tr>
<tr>
<td>hexo-helper-live2d</td>
<td>看板娘</td>
<td><a href="https://github.com/EYHN/hexo-helper-live2d">https://github.com/EYHN/hexo-helper-live2d</a></td>
</tr>
<tr>
<td>hexo-addlink</td>
<td>文末添加当前文章链接和版权声明</td>
<td><a href="https://github.com/acwong00/hexo-addlink">https://github.com/acwong00/hexo-addlink</a></td>
</tr>
<tr>
<td>hexo-blog-encrypt</td>
<td>博客文章加密</td>
<td><a href="https://github.com/MikeCoder/hexo-blog-encrypt">https://github.com/MikeCoder/hexo-blog-encrypt</a></td>
</tr>
<tr>
<td>hexo-simple-mindmap</td>
<td>博客添加脑图</td>
<td><a href="https://github.com/HunterXuan/hexo-simple-mindmap">https://github.com/HunterXuan/hexo-simple-mindmap</a></td>
</tr>
<tr>
<td>hexo-pdf</td>
<td>博客展示pdf</td>
<td><a href="https://github.com/superalsrk/hexo-pdf">https://github.com/superalsrk/hexo-pdf</a></td>
</tr>
<tr>
<td>hexo-tag-echarts</td>
<td>博客添加图表</td>
<td><a href="https://github.com/zhoulvjun/hexo-tag-echarts">https://github.com/zhoulvjun/hexo-tag-echarts</a></td>
</tr>
<tr>
<td>hexo-steam-games</td>
<td>添加Steam游戏界面</td>
<td><a href="https://github.com/HCLonely/hexo-steam-games">https://github.com/HCLonely/hexo-steam-games</a></td>
</tr>
<tr>
<td>hexo-bilibili-bangumi</td>
<td>添加bilibili番剧页面</td>
<td><a href="https://github.com/HCLonely/hexo-bilibili-bangumi">https://github.com/HCLonely/hexo-bilibili-bangumi</a></td>
</tr>
<tr>
<td>hexo-generator-random</td>
<td>生成随机文章页面</td>
<td><a href="https://github.com/Drew233/hexo-generator-random">https://github.com/Drew233/hexo-generator-random</a></td>
</tr>
<tr>
<td>hexo-web-push-notification</td>
<td>web推送插件</td>
<td><a href="https://github.com/glazec/hexo-web-push-notification">https://github.com/glazec/hexo-web-push-notification</a></td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客 | 加密！给你的文章添加密码</title>
    <url>/posts/43010.html</url>
    <content><![CDATA[<p>今天看到了一个很有趣的Hexo插件，可以轻松实现文章加密功能😋。<br>下面是添加加密功能的操作：</p>
<h1 id="安装hexo-blog-encrypt插件"><a href="#安装hexo-blog-encrypt插件" class="headerlink" title="安装hexo-blog-encrypt插件"></a>安装hexo-blog-encrypt插件</h1><ul>
<li>在hexo目录下<code>npm install hexo-blog-encrypt</code></li>
<li>在<code>/Hexo/_config.yml</code>文件中添加内容:</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">encrypt:</span><br><span class="line">	<span class="built_in">enable</span>:<span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h1 id="使用插件"><a href="#使用插件" class="headerlink" title="使用插件"></a>使用插件</h1><ul>
<li>在想要使用加密功能的Blog头部加上对应文字：</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">Hexo加密功能</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2019-09-04 23:20:00</span>   </span><br><span class="line"><span class="attr">tags:</span> [<span class="string">学习笔记</span>,<span class="string">Hexo</span>]</span><br><span class="line"><span class="attr">categories:</span> <span class="string">Hexo</span>      </span><br><span class="line"><span class="attr">password:</span> <span class="string">smile</span>   </span><br><span class="line"><span class="attr">abstract:</span> <span class="string">Welcome</span> <span class="string">to</span> <span class="string">my</span> <span class="string">blog,</span> <span class="string">enter</span> <span class="string">password</span> <span class="string">to</span> <span class="string">read.</span> </span><br><span class="line"><span class="attr">message:</span> <span class="string">密码输入框上描述性内容</span></span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></table></figure>
<ul>
<li>其中：<ul>
<li>password: 该Blog使用的密码</li>
<li>abstract: Blog摘要文字（少量）</li>
<li>message: 密码框上的描述性文字</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客 | Hexo竟然可以展示PDF</title>
    <url>/posts/7376.html</url>
    <content><![CDATA[<p>hexo-pdf插件一键搞定，页面展示PDF</p>
<span id="more"></span>

<h2 id="安装hexo-pdf"><a href="#安装hexo-pdf" class="headerlink" title="安装hexo-pdf"></a>安装hexo-pdf</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install --save hexo-pdf</span><br></pre></td></tr></table></figure>

<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>使用本地资源，可以在markdown文件路径下创建一个同名文件夹，其内放pdf文件<br>例如：<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200703172935.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200703173018.png"></p>
<p>在需要的文章添加如下语句：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#123;% pdf mydocument.pdf %&#125;</span><br></pre></td></tr></table></figure>

<p>使用外部资源同理，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% pdf https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/pdf/小作文讲义.pdf %&#125;</span><br></pre></td></tr></table></figure>

<h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200703173123.png"></p>
]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title>打字机效果 | 使用type.js模拟打字输入回退效果</title>
    <url>/posts/24067.html</url>
    <content><![CDATA[<p>今天在Github上发现了一个有趣的开源项目</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/typejs3.gif"></p>
<span id="more"></span>

<ul>
<li>github地址：<a href="https://github.com/mattboldt/typed.js/">https://github.com/mattboldt/typed.js/</a></li>
<li>文档：<a href="https://mattboldt.github.io/typed.js/docs/">https://mattboldt.github.io/typed.js/docs/</a></li>
</ul>
<h4 id="导入js"><a href="#导入js" class="headerlink" title="导入js"></a>导入js</h4><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.jsdelivr.net/npm/typed.js@2.0.11&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="实现效果"><a href="#实现效果" class="headerlink" title="实现效果"></a>实现效果</h4><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/typejs4.gif"></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="keyword">var</span> typed = <span class="keyword">new</span> Typed(<span class="string">&quot;#typed&quot;</span>, &#123;</span><br><span class="line">  <span class="attr">strings</span>: [<span class="string">&#x27;醒亦念卿，梦亦念卿&#x27;</span>,<span class="string">&#x27;频繁记录，只因生活和你太值得❤&#x27;</span>],<span class="comment">//字符串</span></span><br><span class="line">  <span class="attr">startDelay</span>: <span class="number">0</span>,<span class="comment">//开始的延迟</span></span><br><span class="line">  <span class="attr">typeSpeed</span>: <span class="number">200</span>,<span class="comment">//打字速度</span></span><br><span class="line">  <span class="attr">backSpeed</span>: <span class="number">100</span>,<span class="comment">//回退速度</span></span><br><span class="line">  <span class="attr">loop</span>: <span class="literal">true</span>,<span class="comment">//是否循环</span></span><br><span class="line">  <span class="attr">showCursor</span>: <span class="literal">true</span>,<span class="comment">//显示游标</span></span><br><span class="line">  <span class="attr">shuffle</span>: <span class="literal">false</span><span class="comment">//是否随机</span></span><br><span class="line">  &#125;);</span><br><span class="line">&#125; <span class="keyword">catch</span> (err) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="游标样式"><a href="#游标样式" class="headerlink" title="游标样式"></a>游标样式</h4><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/typejs5.gif"></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="keyword">var</span> typed1 = <span class="keyword">new</span> Typed(<span class="string">&quot;#typed1&quot;</span>, &#123;</span><br><span class="line">  <span class="comment">//一大堆同上</span></span><br><span class="line">  <span class="attr">cursorChar</span>: <span class="string">&#x27;_&#x27;</span>,<span class="comment">//游标样式</span></span><br><span class="line">  &#125;);</span><br><span class="line">&#125; <span class="keyword">catch</span> (err) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="批量输入"><a href="#批量输入" class="headerlink" title="批量输入"></a>批量输入</h4><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/typejs6.gif"></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="keyword">var</span> typed2 = <span class="keyword">new</span> Typed(<span class="string">&quot;#typed2&quot;</span>, &#123;</span><br><span class="line">  <span class="attr">strings</span>: [<span class="string">&#x27;醒亦念卿，梦亦念卿\n `频繁记录，只因生活和你太值得❤`&#x27;</span>],<span class="comment">//字符串</span></span><br><span class="line">  <span class="comment">//一大堆同上</span></span><br><span class="line">  &#125;);</span><br><span class="line">&#125; <span class="keyword">catch</span> (err) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="智能退格"><a href="#智能退格" class="headerlink" title="智能退格"></a>智能退格</h4><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/typejs7.gif"></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">&quot;text-align:center;font-size:2rem;&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">strong</span> <span class="attr">id</span>=<span class="string">&quot;typed3&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">strong</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">data-pjax</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript">  <span class="keyword">try</span> &#123;</span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> typed3 = <span class="keyword">new</span> Typed(<span class="string">&quot;#typed3&quot;</span>, &#123;</span></span><br><span class="line"><span class="javascript">    <span class="attr">strings</span>: [<span class="string">&#x27;我想说：我&#x27;</span>,<span class="string">&#x27;我想说：爱&#x27;</span>,<span class="string">&#x27;我想说：你&#x27;</span>],<span class="comment">//字符串</span></span></span><br><span class="line"><span class="javascript">    <span class="attr">startDelay</span>: <span class="number">0</span>,<span class="comment">//开始的延迟</span></span></span><br><span class="line"><span class="javascript">    <span class="attr">typeSpeed</span>: <span class="number">200</span>,<span class="comment">//打字速度</span></span></span><br><span class="line"><span class="javascript">    <span class="attr">backSpeed</span>: <span class="number">100</span>,<span class="comment">//回退速度</span></span></span><br><span class="line"><span class="javascript">    <span class="attr">loop</span>: <span class="literal">true</span>,<span class="comment">//是否循环</span></span></span><br><span class="line"><span class="javascript">    <span class="attr">showCursor</span>: <span class="literal">true</span>,<span class="comment">//显示游标</span></span></span><br><span class="line"><span class="javascript">    <span class="attr">smartBackspace</span>: <span class="literal">true</span>, <span class="comment">//默认true</span></span></span><br><span class="line"><span class="javascript">    &#125;);</span></span><br><span class="line"><span class="javascript">  &#125; <span class="keyword">catch</span> (err) &#123;</span></span><br><span class="line"><span class="javascript">  &#125;</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客 | 博客中能用到的代码（二）</title>
    <url>/posts/15391.html</url>
    <content><![CDATA[<p>之前写了一个<a href="/posts/56163.html">博客中能用到的代码</a>,这是第二篇<br>这篇文章介绍了如何添加<code>旋转小人</code>和<code>每日诗句</code></p>
<span id="more"></span>

<h1 id="gt-旋转小人"><a href="#gt-旋转小人" class="headerlink" title="&gt;旋转小人"></a>&gt;旋转小人</h1><blockquote>
<p>参考自<a href="https://codepen.io/">Codepen</a>和<a href="/posts/11952.html">CodePen — 前端利器分享</a></p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gif/twopeople.gif"></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;twopeople&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;container&quot;</span> <span class="attr">style</span>=<span class="string">&quot;height:200px;&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">canvas</span> <span class="attr">class</span>=<span class="string">&quot;illo&quot;</span> <span class="attr">width</span>=<span class="string">&quot;800&quot;</span> <span class="attr">height</span>=<span class="string">&quot;800&quot;</span> <span class="attr">style</span>=<span class="string">&quot;max-width: 200px; max-height: 200px; touch-action: none; width: 640px; height: 640px;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">canvas</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople1.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/zdog.dist.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">id</span>=<span class="string">&quot;rendered-js&quot;</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="css"></span></span><br><span class="line"><span class="css">        <span class="selector-class">.twopeople</span>&#123;</span></span><br><span class="line"><span class="css">            <span class="attribute">margin</span>: <span class="number">0</span>;</span></span><br><span class="line"><span class="css">            <span class="attribute">align-items</span>: center;</span></span><br><span class="line"><span class="css">            <span class="attribute">justify-content</span>: center;</span></span><br><span class="line"><span class="css">            <span class="attribute">text-align</span>: center;</span></span><br><span class="line"><span class="css">        &#125;</span></span><br><span class="line"><span class="css">        <span class="selector-tag">canvas</span> &#123;</span></span><br><span class="line"><span class="css">            <span class="attribute">display</span>: block;</span></span><br><span class="line"><span class="css">            <span class="attribute">margin</span>: <span class="number">0</span> auto;</span></span><br><span class="line"><span class="css">            <span class="attribute">cursor</span>: move;</span></span><br><span class="line"><span class="css">        &#125;</span></span><br><span class="line"><span class="css">    </span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h1 id="gt-念两句诗"><a href="#gt-念两句诗" class="headerlink" title="&gt;念两句诗"></a>&gt;念两句诗</h1><blockquote>
<p>参考自<a href="https://m1314.cn/210.html">Sakura主题在留言页动态诗句 Sakura主题美化第三弹</a></p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200727182841.png"></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;poem-wrap&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;poem-border poem-left&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;poem-border poem-right&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>念两句诗<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">&quot;poem&quot;</span>&gt;</span>挑选中...<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">&quot;info&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*诗*/</span></span><br><span class="line"><span class="selector-class">.poem-wrap</span> &#123;</span><br><span class="line">    <span class="attribute">position</span>: relative;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">730px</span>;</span><br><span class="line">    <span class="attribute">max-width</span>: <span class="number">80%</span>;</span><br><span class="line">    <span class="attribute">border</span>: <span class="number">2px</span> solid <span class="number">#797979</span>;</span><br><span class="line">    <span class="attribute">border-top</span>: none;</span><br><span class="line">    <span class="attribute">text-align</span>: center;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">80px</span> auto;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.poem-wrap</span> <span class="selector-tag">h1</span> &#123;</span><br><span class="line">    <span class="attribute">position</span>: relative;</span><br><span class="line">    <span class="attribute">margin-top</span>: -<span class="number">20px</span>;</span><br><span class="line">    <span class="attribute">display</span>: inline-block;</span><br><span class="line">    <span class="attribute">letter-spacing</span>: <span class="number">4px</span>;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#797979</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.poem-wrap</span> <span class="selector-tag">p</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">70%</span>;</span><br><span class="line">    <span class="attribute">margin</span>: auto;</span><br><span class="line">    <span class="attribute">line-height</span>: <span class="number">30px</span>;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#797979</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.poem-wrap</span> <span class="selector-tag">p</span><span class="selector-id">#poem</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">25px</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.poem-wrap</span> <span class="selector-tag">p</span><span class="selector-id">#info</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">15px</span>;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">15px</span> auto;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.poem-border</span> &#123;</span><br><span class="line">    <span class="attribute">position</span>: absolute;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">2px</span>;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">27%</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#797979</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.poem-right</span> &#123;</span><br><span class="line">    <span class="attribute">right</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.poem-left</span> &#123;</span><br><span class="line">    <span class="attribute">left</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">@media</span> (<span class="attribute">max-width</span>: <span class="number">685px</span>) &#123;</span><br><span class="line">    <span class="selector-class">.poem-border</span> &#123;</span><br><span class="line">        <span class="attribute">width</span>: <span class="number">18%</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">@media</span> (<span class="attribute">max-width</span>: <span class="number">500px</span>) &#123;</span><br><span class="line">    <span class="selector-class">.poem-wrap</span> &#123;</span><br><span class="line">        <span class="attribute">margin-top</span>: <span class="number">60px</span>;</span><br><span class="line">        <span class="attribute">margin-bottom</span>: <span class="number">20px</span>;</span><br><span class="line">        <span class="attribute">border-top</span>: <span class="number">2px</span> solid <span class="number">#797979</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="selector-class">.poem-wrap</span> <span class="selector-tag">h1</span> &#123;</span><br><span class="line">        <span class="attribute">margin</span>: <span class="number">20px</span> <span class="number">6px</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="selector-class">.poem-border</span> &#123;</span><br><span class="line">        <span class="attribute">display</span>: none;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*诗*/</span></span><br><span class="line"><span class="keyword">if</span> ($(<span class="string">&quot;div&quot;</span>).hasClass(<span class="string">&quot;poem-wrap&quot;</span>)) &#123;</span><br><span class="line">            get_poem(<span class="string">&#x27;#poem&#x27;</span>, <span class="string">&#x27;#info&#x27;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">get_poem</span>(<span class="params">poem_ele, info_ele</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> poem = <span class="built_in">document</span>.querySelector(poem_ele);</span><br><span class="line">    <span class="keyword">var</span> info = <span class="built_in">document</span>.querySelector(info_ele);</span><br><span class="line">    <span class="keyword">var</span> xhr = <span class="keyword">new</span> XMLHttpRequest();</span><br><span class="line">    xhr.open(<span class="string">&#x27;get&#x27;</span>, <span class="string">&#x27;https://v2.jinrishici.com/one.json&#x27;</span>);</span><br><span class="line">    xhr.withCredentials = <span class="literal">true</span>;</span><br><span class="line">    xhr.onreadystatechange = <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (xhr.readyState === <span class="number">4</span>) &#123;</span><br><span class="line">            <span class="keyword">var</span> data = <span class="built_in">JSON</span>.parse(xhr.responseText);</span><br><span class="line">            poem.innerHTML = data.data.content;</span><br><span class="line">            info.innerHTML = <span class="string">&#x27;【&#x27;</span> + data.data.origin.dynasty + <span class="string">&#x27;】&#x27;</span> + data.data.origin.author + <span class="string">&#x27;《&#x27;</span> + data.data.origin.title + <span class="string">&#x27;》&#x27;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    xhr.send();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客 | 博客中能用到的代码（一）</title>
    <url>/posts/56163.html</url>
    <content><![CDATA[<p>这篇文章介绍了如何使用<code>font awesome图标</code>字体库，使用<code>动态图标</code>，添加<code>网页运行时间</code>，<code>全站变黑白</code>，<code>鼠标点击特效</code>，<code>网页标题的动态效果</code>，<code>网页樱花特效</code>，<code>鼠标触动音乐特效</code>，之前还介绍过<code>打字机效果</code>，可以看看<a href="/posts/24067.html">这篇文章</a></p>
<span id="more"></span>

<h2 id="gt-使用font-awesome图标字体库"><a href="#gt-使用font-awesome图标字体库" class="headerlink" title="&gt;使用font awesome图标字体库"></a>&gt;使用font awesome图标字体库</h2><p><a href="http://www.fontawesome.com.cn/">Font Awesome中文网</a></p>
<p>第一步，只需要导入css文件，就可以在全文使用其图标</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>第二步，使用方法：<br>1.在网站中找到自己看上的图标,保存它的名字<code>XXXX</code><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GBwWy8.png" alt="GBwWy8.png"><br>2.在需要的位置,插入<code>&lt;i class=&quot;fa fa-XXXX&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;</code></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;fa fa-home&quot;</span> <span class="attr">aria-hidden</span>=<span class="string">&quot;true&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span>首页</span><br></pre></td></tr></table></figure>

<p>效果如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20201022105849.png"></p>
<h2 id="gt-使用动态图标"><a href="#gt-使用动态图标" class="headerlink" title="&gt;使用动态图标"></a>&gt;使用动态图标</h2><p><a href="https://l-lin.github.io/font-awesome-animation/">Font Awesome Animation</a></p>
<p>第一步，只需要导入css文件，就可以在全文使用其动态特效图标</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;https://cdn.jsdelivr.net/npm/font-awesome-animation@0.2.1/dist/font-awesome-animation.min.css&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>第二步，使用方法：<br>1.在网站中找到自己看上的动态效果,保存它的名字<code>faa-YYYY</code>，结合font awesome图标<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GBjP61.gif" alt="GBjP61.gif"><br>2.在需要的位置,插入<code>&lt;span class=&quot;faa-parent animated-hover&quot;&gt;&lt;i class=&quot;fa fa-XXXX faa-YYYY&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/span&gt;</code></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;faa-parent animated-hover&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;fa fa-home faa-wrench animated&quot;</span> <span class="attr">aria-hidden</span>=<span class="string">&quot;true&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span>首页<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>效果如下：<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/faa.gif"></p>
<h2 id="gt-网页运行时间"><a href="#gt-网页运行时间" class="headerlink" title="&gt;网页运行时间"></a>&gt;网页运行时间</h2><blockquote>
<p>参考自<a href="https://m1314.cn/140.html">网站底部添加网站运行时间代码</a></p>
</blockquote>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;webtime&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- js --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><span class="javascript"><span class="function"><span class="keyword">function</span> <span class="title">show_runtime</span>(<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">        <span class="built_in">window</span>.setTimeout(<span class="string">&quot;show_runtime()&quot;</span>, <span class="number">1000</span>);</span></span><br><span class="line"><span class="javascript">        X = <span class="keyword">new</span> <span class="built_in">Date</span>(<span class="string">&quot;12/31/2019 23:59:59&quot;</span>);</span></span><br><span class="line"><span class="javascript">        Y = <span class="keyword">new</span> <span class="built_in">Date</span>();</span></span><br><span class="line"><span class="javascript">        T = (Y.getTime() - X.getTime());</span></span><br><span class="line"><span class="javascript">        M = <span class="number">24</span> * <span class="number">60</span> * <span class="number">60</span> * <span class="number">1000</span>;</span></span><br><span class="line"><span class="javascript">        a = T / M;</span></span><br><span class="line"><span class="javascript">        A = <span class="built_in">Math</span>.floor(a);</span></span><br><span class="line"><span class="javascript">        b = (a - A) * <span class="number">24</span>;</span></span><br><span class="line"><span class="javascript">        B = <span class="built_in">Math</span>.floor(b);</span></span><br><span class="line"><span class="javascript">        c = (b - B) * <span class="number">60</span>;</span></span><br><span class="line"><span class="javascript">        C = <span class="built_in">Math</span>.floor((b - B) * <span class="number">60</span>);</span></span><br><span class="line"><span class="javascript">        D = <span class="built_in">Math</span>.floor((c - C) * <span class="number">60</span>);</span></span><br><span class="line"><span class="javascript">        <span class="built_in">document</span>.getElementById(<span class="string">&quot;webtime&quot;</span>).innerHTML = <span class="string">&quot;网站已运行了: &quot;</span> + A + <span class="string">&quot;天&quot;</span> + B + <span class="string">&quot;小时&quot;</span> + C + <span class="string">&quot;分&quot;</span> + D + <span class="string">&quot;秒&quot;</span></span></span><br><span class="line"><span class="javascript">    &#125;</span></span><br><span class="line"><span class="javascript">    show_runtime();</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>效果如下<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/runtime.gif"></p>
<h2 id="gt-全站变黑白"><a href="#gt-全站变黑白" class="headerlink" title="&gt;全站变黑白"></a>&gt;全站变黑白</h2><blockquote>
<p>参考自<a href="https://m1314.cn/375.html">全站变黑白CSS代码</a></p>
</blockquote>
<p>适合在公祭日哀悼使用，兼容所有主流浏览器，直接添加到header或者博客自定义CSS里就可以生效了，开了缓存的记得清除下~</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">html</span> &#123;</span><br><span class="line">    -webkit-<span class="attribute">filter</span>: <span class="built_in">grayscale</span>(<span class="number">100%</span>);</span><br><span class="line">    -moz-<span class="attribute">filter</span>: <span class="built_in">grayscale</span>(<span class="number">100%</span>);</span><br><span class="line">    -ms-<span class="attribute">filter</span>: <span class="built_in">grayscale</span>(<span class="number">100%</span>);</span><br><span class="line">    -o-<span class="attribute">filter</span>: <span class="built_in">grayscale</span>(<span class="number">100%</span>);</span><br><span class="line">    <span class="attribute">filter</span>: <span class="built_in">grayscale</span>(<span class="number">100%</span>);</span><br><span class="line">    <span class="attribute">filter</span>: progid:DXImageTransform.Microsoft.<span class="built_in">BasicImage</span>(grayscale=<span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="gt-鼠标点击特效"><a href="#gt-鼠标点击特效" class="headerlink" title="&gt;鼠标点击特效"></a>&gt;鼠标点击特效</h2><p><a href="https://github.com/djzhao627/JSClickBubble">github</a></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript">onload = <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> click_cnt = <span class="number">0</span>;</span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> $html = <span class="built_in">document</span>.getElementsByTagName(<span class="string">&quot;html&quot;</span>)[<span class="number">0</span>];</span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> $body = <span class="built_in">document</span>.getElementsByTagName(<span class="string">&quot;body&quot;</span>)[<span class="number">0</span>];</span></span><br><span class="line"><span class="javascript">    $html.onclick = <span class="function"><span class="keyword">function</span>(<span class="params">e</span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> $elem = <span class="built_in">document</span>.createElement(<span class="string">&quot;b&quot;</span>);</span></span><br><span class="line"><span class="javascript">        $elem.style.color = <span class="string">&quot;#E94F06&quot;</span>;</span></span><br><span class="line"><span class="javascript">        $elem.style.zIndex = <span class="number">9999</span>;</span></span><br><span class="line"><span class="javascript">        $elem.style.position = <span class="string">&quot;absolute&quot;</span>;</span></span><br><span class="line"><span class="javascript">        $elem.style.select = <span class="string">&quot;none&quot;</span>;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> x = e.pageX;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> y = e.pageY;</span></span><br><span class="line"><span class="javascript">        $elem.style.left = (x - <span class="number">10</span>) + <span class="string">&quot;px&quot;</span>;</span></span><br><span class="line"><span class="javascript">        $elem.style.top = (y - <span class="number">20</span>) + <span class="string">&quot;px&quot;</span>;</span></span><br><span class="line"><span class="javascript">        <span class="built_in">clearInterval</span>(anim);</span></span><br><span class="line"><span class="javascript">        <span class="keyword">switch</span> (++click_cnt) &#123;</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">10</span>:</span></span><br><span class="line"><span class="javascript">                $elem.innerText = <span class="string">&quot;OωO&quot;</span>;</span></span><br><span class="line"><span class="javascript">                <span class="keyword">break</span>;</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">20</span>:</span></span><br><span class="line"><span class="javascript">                $elem.innerText = <span class="string">&quot;(๑•́ ∀ •̀๑)&quot;</span>;</span></span><br><span class="line"><span class="javascript">                <span class="keyword">break</span>;</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">30</span>:</span></span><br><span class="line"><span class="javascript">                $elem.innerText = <span class="string">&quot;(๑•́ ₃ •̀๑)&quot;</span>;</span></span><br><span class="line"><span class="javascript">                <span class="keyword">break</span>;</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">40</span>:</span></span><br><span class="line"><span class="javascript">                $elem.innerText = <span class="string">&quot;(๑•̀_•́๑)&quot;</span>;</span></span><br><span class="line"><span class="javascript">                <span class="keyword">break</span>;</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">50</span>:</span></span><br><span class="line"><span class="javascript">                $elem.innerText = <span class="string">&quot;（￣へ￣）&quot;</span>;</span></span><br><span class="line"><span class="javascript">                <span class="keyword">break</span>;</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">60</span>:</span></span><br><span class="line"><span class="javascript">                $elem.innerText = <span class="string">&quot;(╯°口°)╯(┴—┴&quot;</span>;</span></span><br><span class="line"><span class="javascript">                <span class="keyword">break</span>;</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">70</span>:</span></span><br><span class="line"><span class="javascript">                $elem.innerText = <span class="string">&quot;૮( ᵒ̌皿ᵒ̌ )ა&quot;</span>;</span></span><br><span class="line"><span class="javascript">                <span class="keyword">break</span>;</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">80</span>:</span></span><br><span class="line"><span class="javascript">                $elem.innerText = <span class="string">&quot;╮(｡&gt;口&lt;｡)╭&quot;</span>;</span></span><br><span class="line"><span class="javascript">                <span class="keyword">break</span>;</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">90</span>:</span></span><br><span class="line"><span class="javascript">                $elem.innerText = <span class="string">&quot;( ง ᵒ̌皿ᵒ̌)ง⁼³₌₃&quot;</span>;</span></span><br><span class="line"><span class="javascript">                <span class="keyword">break</span>;</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">100</span>:</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">101</span>:</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">102</span>:</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">103</span>:</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">104</span>:</span></span><br><span class="line"><span class="javascript">            <span class="keyword">case</span> <span class="number">105</span>:</span></span><br><span class="line"><span class="javascript">                $elem.innerText = <span class="string">&quot;(ꐦ°᷄д°᷅)&quot;</span>;</span></span><br><span class="line"><span class="javascript">                <span class="keyword">break</span>;</span></span><br><span class="line"><span class="javascript">            <span class="keyword">default</span>:</span></span><br><span class="line"><span class="javascript">                $elem.innerText = <span class="string">&quot;❤&quot;</span>;</span></span><br><span class="line"><span class="javascript">                <span class="keyword">break</span>;</span></span><br><span class="line"><span class="javascript">        &#125;</span></span><br><span class="line"><span class="javascript">        $elem.style.fontSize = <span class="built_in">Math</span>.random() * <span class="number">10</span> + <span class="number">8</span> + <span class="string">&quot;px&quot;</span>;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> increase = <span class="number">0</span>;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> anim;</span></span><br><span class="line"><span class="javascript">        <span class="built_in">setTimeout</span>(<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">            anim = <span class="built_in">setInterval</span>(<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">                <span class="keyword">if</span> (++increase == <span class="number">150</span>) &#123;</span></span><br><span class="line"><span class="javascript">                    <span class="built_in">clearInterval</span>(anim);</span></span><br><span class="line"><span class="javascript">                    $body.removeChild($elem);</span></span><br><span class="line"><span class="javascript">                &#125;</span></span><br><span class="line"><span class="javascript">                $elem.style.top = y - <span class="number">20</span> - increase + <span class="string">&quot;px&quot;</span>;</span></span><br><span class="line"><span class="javascript">                $elem.style.opacity = (<span class="number">150</span> - increase) / <span class="number">120</span>;</span></span><br><span class="line"><span class="javascript">            &#125;, <span class="number">8</span>);</span></span><br><span class="line"><span class="javascript">        &#125;, <span class="number">70</span>);</span></span><br><span class="line"><span class="javascript">        $body.appendChild($elem);</span></span><br><span class="line"><span class="javascript">    &#125;;</span></span><br><span class="line"><span class="javascript">&#125;;</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="gt-网页标题的动态效果"><a href="#gt-网页标题的动态效果" class="headerlink" title="&gt;网页标题的动态效果"></a>&gt;网页标题的动态效果</h2><blockquote>
<p>参考自<a href="https://zhangge.net/5032.html">JS代码实现浏览器网页标题的动态切换</a></p>
</blockquote>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript">jQuery(<span class="built_in">document</span>).ready(<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">    <span class="function"><span class="keyword">function</span> <span class="title">c</span>(<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">        <span class="comment">/* 排除首页（记得自行修改下首页地址） */</span></span></span><br><span class="line"><span class="javascript">	<span class="keyword">if</span> (location.href != <span class="string">&quot;https://justlovesmile.top/&quot;</span>) &#123; <span class="built_in">document</span>.title = <span class="built_in">document</span>[a] ? <span class="string">&quot;(つェ⊂)誒呀→《&quot;</span> + d + <span class="string">&quot;》&quot;</span> : <span class="string">&quot;(*´∇｀*) 咦好了→《&quot;</span> + d + <span class="string">&quot;》&quot;</span> &#125;</span></span><br><span class="line"><span class="javascript">    &#125;</span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> a, b, d = <span class="built_in">document</span>.title;</span></span><br><span class="line"><span class="javascript">    <span class="string">&quot;undefined&quot;</span> != <span class="keyword">typeof</span> <span class="built_in">document</span>.hidden ? (a = <span class="string">&quot;hidden&quot;</span>, b = <span class="string">&quot;visibilitychange&quot;</span>) : <span class="string">&quot;undefined&quot;</span> != <span class="keyword">typeof</span> <span class="built_in">document</span>.mozHidden ? (a = <span class="string">&quot;mozHidden&quot;</span>, b = <span class="string">&quot;mozvisibilitychange&quot;</span>) : <span class="string">&quot;undefined&quot;</span> != <span class="keyword">typeof</span> <span class="built_in">document</span>.webkitHidden &amp;&amp; (a = <span class="string">&quot;webkitHidden&quot;</span>, b = <span class="string">&quot;webkitvisibilitychange&quot;</span>);</span></span><br><span class="line"><span class="javascript">    <span class="string">&quot;undefined&quot;</span> == <span class="keyword">typeof</span> <span class="built_in">document</span>.addEventListener &amp;&amp; <span class="string">&quot;undefined&quot;</span> == <span class="keyword">typeof</span> <span class="built_in">document</span>[a] || <span class="built_in">document</span>.addEventListener(b, c, !<span class="number">1</span>)</span></span><br><span class="line"><span class="javascript">&#125;);</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>效果如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GDF12T.png" alt="GDF12T.png"></p>
<h2 id="gt-网页樱花特效"><a href="#gt-网页樱花特效" class="headerlink" title="&gt;网页樱花特效"></a>&gt;网页樱花特效</h2><blockquote>
<p>参考自<a href="https://hylpq.com/archives/sakuracss3/">博客樱花飘落动效</a></p>
</blockquote>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/sakura.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>只需要导入js就可以了</p>
<h2 id="gt-鼠标触动音乐特效"><a href="#gt-鼠标触动音乐特效" class="headerlink" title="&gt;鼠标触动音乐特效"></a>&gt;鼠标触动音乐特效</h2><blockquote>
<p>参考自<a href="https://www.zhangxinxu.com/wordpress/2017/06/html5-web-audio-api-js-ux-voice/">利用HTML5 Web Audio API给网页JS交互增加声音</a></p>
</blockquote>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">button</span> <span class="attr">id</span>=<span class="string">&quot;button&quot;</span>&gt;</span>经过我<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="built_in">window</span>.AudioContext = <span class="built_in">window</span>.AudioContext || <span class="built_in">window</span>.webkitAudioContext;</span></span><br><span class="line"><span class="javascript">(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">    <span class="keyword">if</span> (!<span class="built_in">window</span>.AudioContext) &#123;</span></span><br><span class="line"><span class="javascript">        alert(<span class="string">&#x27;当前浏览器不支持Web Audio API&#x27;</span>);</span></span><br><span class="line"><span class="javascript">        <span class="keyword">return</span>;</span></span><br><span class="line"><span class="javascript">    &#125;</span></span><br><span class="line"><span class="javascript">    <span class="comment">// 按钮元素</span></span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> eleButton = <span class="built_in">document</span>.getElementById(<span class="string">&#x27;button&#x27;</span>);</span></span><br><span class="line"><span class="javascript">    <span class="comment">// 创建新的音频上下文接口</span></span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> audioCtx = <span class="keyword">new</span> AudioContext();</span></span><br><span class="line"><span class="javascript">    <span class="comment">// 发出的声音频率数据，表现为音调的高低</span></span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> arrFrequency = <span class="string">&quot;880 987 1046 987 1046 1318 987 659 659 880 784 880 1046 784 659 659 698 659 698 1046 659 1046 1046 1046 987 698 698 987 987 880 987 1046 987 1046 1318 987 659 659 880 784 880 1046 784 659 698 1046 987 1046 1174 1174 1174 1046 1046 880 987 784 880 1046 1174 1318 1174 1318 1567 1046 987 1046 1318 1318 1174 784 784 880 1046 987 1174 1046 784 784 1396 1318 1174 659 1318 1046 1318 1760 1567 1567 1318 1174 1046 1046 1174 1046 1174 1567 1318 1318 1760 1567 1318 1174 1046 1046 1174 1046 1174 987 880 880 987 880&quot;</span>.split(<span class="string">&quot; &quot;</span>);</span></span><br><span class="line"><span class="javascript">    <span class="comment">// 音调依次递增或者递减处理需要的参数</span></span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> start = <span class="number">0</span>, direction = <span class="number">1</span>;</span></span><br><span class="line"><span class="javascript">    <span class="comment">// 鼠标hover我们的按钮的时候</span></span></span><br><span class="line"><span class="javascript">    eleButton.addEventListener(<span class="string">&#x27;mouseenter&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">        <span class="comment">// 当前频率</span></span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> frequency = arrFrequency[start];</span></span><br><span class="line"><span class="javascript">        <span class="comment">// 如果到头，改变音调的变化规则（增减切换）</span></span></span><br><span class="line"><span class="javascript">        <span class="keyword">if</span> (!frequency) &#123;</span></span><br><span class="line"><span class="javascript">            direction = -<span class="number">1</span> * direction;</span></span><br><span class="line"><span class="javascript">            start = start + <span class="number">2</span> * direction;</span></span><br><span class="line"><span class="javascript">            frequency = arrFrequency[start];</span></span><br><span class="line"><span class="javascript">        &#125;</span></span><br><span class="line"><span class="javascript">        <span class="comment">// 改变索引，下一次hover时候使用</span></span></span><br><span class="line"><span class="javascript">        start = start + direction;</span></span><br><span class="line"><span class="javascript">        <span class="comment">// 创建一个OscillatorNode, 它表示一个周期性波形（振荡），基本上来说创造了一个音调</span></span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> oscillator = audioCtx.createOscillator();</span></span><br><span class="line"><span class="javascript">        <span class="comment">// 创建一个GainNode,它可以控制音频的总音量</span></span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> gainNode = audioCtx.createGain();</span></span><br><span class="line"><span class="javascript">        <span class="comment">// 把音量，音调和终节点进行关联</span></span></span><br><span class="line"><span class="javascript">        oscillator.connect(gainNode);</span></span><br><span class="line"><span class="javascript">        <span class="comment">// audioCtx.destination返回AudioDestinationNode对象，表示当前audio context中所有节点的最终节点，一般表示音频渲染设备</span></span></span><br><span class="line"><span class="javascript">        gainNode.connect(audioCtx.destination);</span></span><br><span class="line"><span class="javascript">        <span class="comment">// 指定音调的类型，其他还有square|triangle|sawtooth</span></span></span><br><span class="line"><span class="javascript">        oscillator.type = <span class="string">&#x27;sine&#x27;</span>;</span></span><br><span class="line"><span class="javascript">        <span class="comment">// 设置当前播放声音的频率，也就是最终播放声音的调调</span></span></span><br><span class="line"><span class="javascript">        oscillator.frequency.value = frequency;</span></span><br><span class="line"><span class="javascript">        <span class="comment">// 当前时间设置音量为0</span></span></span><br><span class="line"><span class="javascript">        gainNode.gain.setValueAtTime(<span class="number">0</span>, audioCtx.currentTime);</span></span><br><span class="line"><span class="javascript">        <span class="comment">// 0.01秒后音量为1</span></span></span><br><span class="line"><span class="javascript">        gainNode.gain.linearRampToValueAtTime(<span class="number">1</span>, audioCtx.currentTime + <span class="number">0.01</span>);</span></span><br><span class="line"><span class="javascript">        <span class="comment">// 音调从当前时间开始播放</span></span></span><br><span class="line"><span class="javascript">        oscillator.start(audioCtx.currentTime);</span></span><br><span class="line"><span class="javascript">        <span class="comment">// 1秒内声音慢慢降低，是个不错的停止声音的方法</span></span></span><br><span class="line"><span class="javascript">        gainNode.gain.exponentialRampToValueAtTime(<span class="number">0.001</span>, audioCtx.currentTime + <span class="number">1</span>);</span></span><br><span class="line"><span class="javascript">        <span class="comment">// 1秒后完全停止声音</span></span></span><br><span class="line"><span class="javascript">        oscillator.stop(audioCtx.currentTime + <span class="number">1</span>);</span></span><br><span class="line"><span class="javascript">    &#125;);</span></span><br><span class="line"><span class="javascript">&#125;)();</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>博客相关 | 如何提取图片主题色并自动选择标题字体颜色</title>
    <url>/posts/b16c0eda.html</url>
    <content><![CDATA[<p>今天在写博客的时候，做了一个封面图，然后<code>hexo cl &amp;&amp; hexo g &amp;&amp; gulp &amp;&amp; hexo s</code>一键生成，点开后却发现这个标题的字体颜色亮瞎我的眼睛：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220328124305.png"></p>
<p>于是试了很多帖子，终于把它改好了：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20220328124527.png"></p>
<p>提取主题色的js:<a href="https://github.com/briangonzalez/rgbaster.js">https://github.com/briangonzalez/rgbaster.js</a></p>
<p>处理配色js如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="built_in">document</span>.getElementById(<span class="string">&#x27;post-cover&#x27;</span>)) &#123;</span><br><span class="line">  <span class="keyword">const</span> img = <span class="built_in">document</span>.getElementById(<span class="string">&#x27;post-cover&#x27;</span>).getAttribute(<span class="string">&#x27;data-lazy-src&#x27;</span>)</span><br><span class="line">  RGBaster.colors(img, &#123;</span><br><span class="line">      <span class="attr">paletteSize</span>: <span class="number">30</span>,</span><br><span class="line">      <span class="attr">exclude</span>: [<span class="string">&quot;rgb(255,255,255)&quot;</span>, <span class="string">&quot;rgb(0,0,0)&quot;</span>, <span class="string">&quot;rgb(254,254,254)&quot;</span>],</span><br><span class="line">      <span class="attr">success</span>: <span class="function"><span class="keyword">function</span>(<span class="params">t</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (t.dominant != <span class="string">&#x27;rgb()&#x27;</span>)&#123;</span><br><span class="line">          <span class="keyword">const</span> c = t.dominant.match(<span class="regexp">/\d+/g</span>);</span><br><span class="line">          <span class="keyword">const</span> Color = <span class="string">`rgba(<span class="subst">$&#123;c[<span class="number">0</span>]&#125;</span>,<span class="subst">$&#123;c[<span class="number">1</span>]&#125;</span>,<span class="subst">$&#123;c[<span class="number">2</span>]&#125;</span>,0.8)`</span>;</span><br><span class="line">          <span class="keyword">let</span> fontColor;</span><br><span class="line">          <span class="comment">//const grayLevel = c[0] * 0.299 + c[1] * 0.587 + c[2] * 0.114;</span></span><br><span class="line">          <span class="keyword">const</span> grayLevel = c[<span class="number">0</span>] * <span class="number">0.213</span> + c[<span class="number">1</span>] * <span class="number">0.715</span> + c[<span class="number">2</span>] * <span class="number">0.072</span>;</span><br><span class="line">          <span class="comment">//if (grayLevel &gt;= 190) &#123;</span></span><br><span class="line">          <span class="keyword">if</span> (grayLevel &gt;= <span class="number">255</span>/<span class="number">2</span>) &#123;</span><br><span class="line">            <span class="comment">// 若为浅色，把文字设置为黑色</span></span><br><span class="line">            fontColor = <span class="string">&#x27;#000&#x27;</span>;</span><br><span class="line">            metaColor = <span class="string">&#x27;#1C1C1C&#x27;</span>;</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            fontColor = <span class="string">&#x27;#fff&#x27;</span>;</span><br><span class="line">            metaColor = <span class="string">&#x27;#eee&#x27;</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="built_in">document</span>.styleSheets[<span class="number">0</span>].addRule(<span class="string">&quot;:root&quot;</span>, <span class="string">&quot;--mj-main:&quot;</span> + Color + <span class="string">&quot;!important&quot;</span>)</span><br><span class="line">          <span class="built_in">document</span>.styleSheets[<span class="number">0</span>].addRule(<span class="string">&quot;:root&quot;</span>, <span class="string">&quot;--mj-titlecolor:&quot;</span> + fontColor + <span class="string">&quot;!important&quot;</span>)</span><br><span class="line">          <span class="built_in">document</span>.styleSheets[<span class="number">0</span>].addRule(<span class="string">&quot;:root&quot;</span>, <span class="string">&quot;--mj-metacolor:&quot;</span> + metaColor + <span class="string">&quot;!important&quot;</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="built_in">document</span>.styleSheets[<span class="number">0</span>].addRule(<span class="string">&quot;:root&quot;</span>, <span class="string">&quot;--mj-main: rgba(255,250,240,0.5) !important&quot;</span>)</span><br><span class="line">          <span class="built_in">document</span>.styleSheets[<span class="number">0</span>].addRule(<span class="string">&quot;:root&quot;</span>, <span class="string">&quot;--mj-titlecolor: #000 !important&quot;</span>)</span><br><span class="line">          <span class="built_in">document</span>.styleSheets[<span class="number">0</span>].addRule(<span class="string">&quot;:root&quot;</span>, <span class="string">&quot;--mj-metacolor: #1C1C1C !important&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">error</span>: <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">          <span class="built_in">document</span>.styleSheets[<span class="number">0</span>].addRule(<span class="string">&quot;:root&quot;</span>, <span class="string">&quot;--mj-main: rgba(255,250,240,0.5) !important&quot;</span>)</span><br><span class="line">          <span class="built_in">document</span>.styleSheets[<span class="number">0</span>].addRule(<span class="string">&quot;:root&quot;</span>, <span class="string">&quot;--mj-titlecolor: #000 !important&quot;</span>)</span><br><span class="line">          <span class="built_in">document</span>.styleSheets[<span class="number">0</span>].addRule(<span class="string">&quot;:root&quot;</span>, <span class="string">&quot;--mj-metacolor: #1C1C1C !important&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="built_in">document</span>.styleSheets[<span class="number">0</span>].addRule(<span class="string">&quot;:root&quot;</span>, <span class="string">&quot;--mj-main: transparent !important&quot;</span>)</span><br><span class="line">  <span class="built_in">document</span>.styleSheets[<span class="number">0</span>].addRule(<span class="string">&quot;:root&quot;</span>, <span class="string">&quot;--mj-titlecolor: var(--light-grey) !important&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://juejin.cn/post/6844903511956815885">https://juejin.cn/post/6844903511956815885</a></li>
<li><a href="https://blog.realwds.com/posts/84339efc.html">https://blog.realwds.com/posts/84339efc.html</a></li>
</ul>
]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>学习笔记 | CSP201912认证考试部分题解</title>
    <url>/posts/7c5e3f37.html</url>
    <content><![CDATA[<h1 id="CSP练习"><a href="#CSP练习" class="headerlink" title="CSP练习"></a>CSP练习</h1><h2 id="201912-1-报数"><a href="#201912-1-报数" class="headerlink" title="201912-1 报数"></a>201912-1 报数</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/csp201912101.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/csp201912102.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n=<span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">a=[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)]</span><br><span class="line">i,j=<span class="number">1</span>,<span class="number">1</span></span><br><span class="line"><span class="keyword">while</span>(j&lt;=n):</span><br><span class="line">    <span class="keyword">if</span>(i%<span class="number">7</span>==<span class="number">0</span> <span class="keyword">or</span> (<span class="string">&#x27;7&#x27;</span> <span class="keyword">in</span> <span class="built_in">str</span>(i))):<span class="comment">#7的倍数或者含有7则跳过</span></span><br><span class="line">        a[(i-<span class="number">1</span>)%<span class="number">4</span>]+=<span class="number">1</span><span class="comment">#跳过次数加1</span></span><br><span class="line">        j-=<span class="number">1</span><span class="comment">#不计被跳过的数</span></span><br><span class="line">    i+=<span class="number">1</span><span class="comment">#下一个人</span></span><br><span class="line">    j+=<span class="number">1</span><span class="comment">#下一个数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>

<pre><code>66
7
5
11
5
</code></pre>
<h2 id="201912-2-回收站选址"><a href="#201912-2-回收站选址" class="headerlink" title="201912-2 回收站选址"></a>201912-2 回收站选址</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/csp201912201.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/csp201912202.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/csp201912203.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,x,y,w=<span class="number">0</span>,a=<span class="number">0</span>,s=<span class="number">0</span>,d=<span class="number">0</span>,score=<span class="number">0</span></span>):</span></span><br><span class="line">        self.x,self.y,self.w,self.a,self.s,self.d,self.score=x,y,w,a,s,d,score</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">newscore</span>(<span class="params">self,p</span>):</span><span class="comment">#四对角得分</span></span><br><span class="line">        <span class="keyword">if</span>(self.x+<span class="number">1</span>==p.x <span class="keyword">and</span> self.y+<span class="number">1</span>==p.y):</span><br><span class="line">            self.score+=<span class="number">1</span></span><br><span class="line">            p.score+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span>(self.x+<span class="number">1</span>==p.x <span class="keyword">and</span> self.y-<span class="number">1</span>==p.y):</span><br><span class="line">            self.score+=<span class="number">1</span></span><br><span class="line">            p.score+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span>(self.x-<span class="number">1</span>==p.x <span class="keyword">and</span> self.y+<span class="number">1</span>==p.y):</span><br><span class="line">            self.score+=<span class="number">1</span></span><br><span class="line">            p.score+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span>(self.x-<span class="number">1</span>==p.x <span class="keyword">and</span> self.y-<span class="number">1</span>==p.y):</span><br><span class="line">            self.score+=<span class="number">1</span></span><br><span class="line">            p.score+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">begood</span>(<span class="params">self,p</span>):</span><span class="comment">#上下左右</span></span><br><span class="line">        <span class="keyword">if</span>(self.x+<span class="number">1</span>==p.x <span class="keyword">and</span> self.y==p.y):</span><br><span class="line">            self.d+=<span class="number">1</span></span><br><span class="line">            p.a+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span>(self.x-<span class="number">1</span>==p.x <span class="keyword">and</span> self.y==p.y):</span><br><span class="line">            self.a+=<span class="number">1</span></span><br><span class="line">            p.d+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span>(self.x==p.x <span class="keyword">and</span> self.y+<span class="number">1</span>==p.y):</span><br><span class="line">            self.w+=<span class="number">1</span></span><br><span class="line">            p.s+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span>(self.x==p.x <span class="keyword">and</span> self.y-<span class="number">1</span>==p.y):</span><br><span class="line">            self.s+=<span class="number">1</span></span><br><span class="line">            p.w+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">good</span>(<span class="params">self</span>):</span><span class="comment">#是否上下左右满足</span></span><br><span class="line">        <span class="keyword">if</span>(self.w==<span class="number">1</span> <span class="keyword">and</span> self.a==<span class="number">1</span> <span class="keyword">and</span> self.s==<span class="number">1</span> <span class="keyword">and</span> self.d==<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">s=<span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">p=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(s):</span><br><span class="line">    s=<span class="built_in">input</span>().split()</span><br><span class="line">    tempP=Point(<span class="built_in">int</span>(s[<span class="number">0</span>]),<span class="built_in">int</span>(s[<span class="number">1</span>]))</span><br><span class="line">    <span class="keyword">for</span> eachp <span class="keyword">in</span> p:</span><br><span class="line">        dx=eachp.x-tempP.x</span><br><span class="line">        dy=eachp.y-tempP.y</span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">not</span> eachp.good() <span class="keyword">and</span> dx*dx+dy*dy==<span class="number">1</span>):</span><br><span class="line">            eachp.begood(tempP)</span><br><span class="line">        <span class="keyword">if</span>(eachp.score!=<span class="number">4</span> <span class="keyword">and</span> dx*dx+dy*dy==<span class="number">2</span>):</span><br><span class="line">            eachp.newscore(tempP)</span><br><span class="line"></span><br><span class="line">    p.append(tempP)</span><br><span class="line"></span><br><span class="line">ans=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> p:</span><br><span class="line">    <span class="keyword">if</span>(i.good()):</span><br><span class="line">        ans[i.score]+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> ans:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>

<pre><code>7
1 2
2 1
0 0
1 1
1 0
2 0
0 1
0
0
1
0
0
</code></pre>
<h2 id="201912-3-化学方程式"><a href="#201912-3-化学方程式" class="headerlink" title="201912-3 化学方程式"></a>201912-3 化学方程式</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/csp201912301.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/csp201912302.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/csp201912303.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//样例：</span><br><span class="line">11</span><br><span class="line">H2+O2=H2O</span><br><span class="line">2H2+O2=2H2O</span><br><span class="line">H2+Cl2=2NaCl</span><br><span class="line">H2+Cl2=2HCl</span><br><span class="line">CH4+2O2=CO2+2H2O</span><br><span class="line">CaCl2+2AgNO3=Ca(NO3)2+2AgCl</span><br><span class="line">3Ba(OH)2+2H3PO4=6H2O+Ba3(PO4)2</span><br><span class="line">3Ba(OH)2+2H3PO4=Ba3(PO4)2+6H2O</span><br><span class="line">4Zn+10HNO3=4Zn(NO3)2+NH4NO3+3H2O</span><br><span class="line">4Au+8NaCN+2H2O+O2=4Na(Au(CN)2)+4NaOH</span><br><span class="line">Cu+As=Cs+Au</span><br><span class="line">//结果：</span><br><span class="line">N</span><br><span class="line">Y</span><br><span class="line">N</span><br><span class="line">Y</span><br><span class="line">Y</span><br><span class="line">Y</span><br><span class="line">Y</span><br><span class="line">Y</span><br><span class="line">Y</span><br><span class="line">Y</span><br><span class="line">N</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chemistry</span>(<span class="params">x</span>):</span></span><br><span class="line">    each=x.split(<span class="string">&#x27;+&#x27;</span>) <span class="comment">#拆成每个化学式</span></span><br><span class="line">    res=&#123;&#125;<span class="comment">#化学元素字典</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> each:</span><br><span class="line">        i=<span class="number">0</span></span><br><span class="line">        num=<span class="string">&quot;&quot;</span><span class="comment">#存储每个化学式前面的数字</span></span><br><span class="line">        <span class="keyword">if</span>(<span class="number">48</span>&lt;=<span class="built_in">ord</span>(item[i])&lt;=<span class="number">57</span>):<span class="comment">#如果开始是数字</span></span><br><span class="line">            num+=item[i]</span><br><span class="line">            i+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span>(i&lt;<span class="built_in">len</span>(item)-<span class="number">1</span> <span class="keyword">and</span> <span class="number">48</span>&lt;=<span class="built_in">ord</span>(item[i])&lt;=<span class="number">57</span>):</span><br><span class="line">                num+=item[i]</span><br><span class="line">                i+=<span class="number">1</span></span><br><span class="line">        n=<span class="number">1</span> <span class="keyword">if</span> num==<span class="string">&quot;&quot;</span> <span class="keyword">else</span> <span class="built_in">int</span>(num)</span><br><span class="line">        <span class="comment">#化学式前面没有数字，代表为1</span></span><br><span class="line">        re=single(item[i:],n)</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> re:</span><br><span class="line">            res[key]=res.get(key,<span class="number">0</span>)+re[key]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">single</span>(<span class="params">item,m</span>):</span></span><br><span class="line">    res=&#123;&#125;<span class="comment">#化学元素字典</span></span><br><span class="line">    i=<span class="number">0</span></span><br><span class="line">    s=<span class="string">&quot;&quot;</span></span><br><span class="line">    num=<span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">while</span>(i&lt;<span class="built_in">len</span>(item)):</span><br><span class="line">        <span class="keyword">if</span>(item[i]==<span class="string">&quot;(&quot;</span>):</span><br><span class="line">            p=<span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>,<span class="built_in">len</span>(item)):</span><br><span class="line">                <span class="keyword">if</span>(item[j]==<span class="string">&quot;(&quot;</span>):</span><br><span class="line">                    p+=<span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> (item[j]==<span class="string">&quot;)&quot;</span>):</span><br><span class="line">                    p-=<span class="number">1</span></span><br><span class="line">                    index=j</span><br><span class="line">                <span class="keyword">if</span>(p==<span class="number">0</span>):</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            k=i+<span class="number">1</span><span class="comment">#第一个左括号之后的位置</span></span><br><span class="line">            i=index<span class="comment">#括号结束的位置</span></span><br><span class="line">            <span class="keyword">if</span>(i&lt;<span class="built_in">len</span>(item)-<span class="number">1</span> <span class="keyword">and</span> <span class="number">48</span>&lt;=<span class="built_in">ord</span>(item[i+<span class="number">1</span>])&lt;=<span class="number">57</span>):<span class="comment">#如果是数字</span></span><br><span class="line">                num+=item[i+<span class="number">1</span>]</span><br><span class="line">                i+=<span class="number">1</span></span><br><span class="line">                <span class="keyword">while</span>(i&lt;<span class="built_in">len</span>(item)-<span class="number">1</span> <span class="keyword">and</span> <span class="number">48</span>&lt;=<span class="built_in">ord</span>(item[i+<span class="number">1</span>])&lt;=<span class="number">57</span>):</span><br><span class="line">                    num+=item[i+<span class="number">1</span>]</span><br><span class="line">                    i+=<span class="number">1</span></span><br><span class="line">            n=<span class="number">1</span> <span class="keyword">if</span> num==<span class="string">&quot;&quot;</span> <span class="keyword">else</span> <span class="built_in">int</span>(num)</span><br><span class="line">            re=single(item[k:index],n*m)</span><br><span class="line">            <span class="keyword">for</span> key <span class="keyword">in</span> re:</span><br><span class="line">                res[key]=res.get(key,<span class="number">0</span>)+re[key]</span><br><span class="line">        <span class="keyword">elif</span>(<span class="number">65</span>&lt;=<span class="built_in">ord</span>(item[i])&lt;=<span class="number">90</span>):<span class="comment">#如果是大写字母</span></span><br><span class="line">            s+=item[i]</span><br><span class="line">            <span class="keyword">if</span>(i&lt;<span class="built_in">len</span>(item)-<span class="number">1</span> <span class="keyword">and</span> <span class="number">97</span>&lt;=<span class="built_in">ord</span>(item[i+<span class="number">1</span>])&lt;=<span class="number">122</span>):<span class="comment">#如果是小写字母</span></span><br><span class="line">                s+=item[i+<span class="number">1</span>]</span><br><span class="line">                i+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span>(i&lt;<span class="built_in">len</span>(item)-<span class="number">1</span> <span class="keyword">and</span> <span class="number">48</span>&lt;=<span class="built_in">ord</span>(item[i+<span class="number">1</span>])&lt;=<span class="number">57</span>):<span class="comment">#如果是数字</span></span><br><span class="line">                num+=item[i+<span class="number">1</span>]</span><br><span class="line">                i+=<span class="number">1</span></span><br><span class="line">                <span class="keyword">while</span>(i&lt;<span class="built_in">len</span>(item)-<span class="number">1</span> <span class="keyword">and</span> <span class="number">48</span>&lt;=<span class="built_in">ord</span>(item[i+<span class="number">1</span>])&lt;=<span class="number">57</span>):</span><br><span class="line">                    num+=item[i+<span class="number">1</span>]</span><br><span class="line">                    i+=<span class="number">1</span></span><br><span class="line">            n=<span class="number">1</span> <span class="keyword">if</span> num==<span class="string">&quot;&quot;</span> <span class="keyword">else</span> <span class="built_in">int</span>(num)</span><br><span class="line">            res[s]=res.get(s,<span class="number">0</span>)+m*n<span class="comment">#这个化学元素个数，初始为0</span></span><br><span class="line">        num=<span class="string">&quot;&quot;</span></span><br><span class="line">        s=<span class="string">&quot;&quot;</span></span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    n=<span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">    expressions=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        expressions.append(<span class="built_in">input</span>())</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> expressions:</span><br><span class="line">        express=item.split(<span class="string">&quot;=&quot;</span>)<span class="comment">#每个表达式从等号分开</span></span><br><span class="line">        left,right=express[<span class="number">0</span>],express[<span class="number">1</span>]</span><br><span class="line">        ans1=chemistry(left)</span><br><span class="line">        ans2=chemistry(right)</span><br><span class="line">        <span class="keyword">if</span>(ans1==ans2):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;N&#x27;</span>)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

<pre><code>11
H2+O2=H2O
2H2+O2=2H2O
H2+Cl2=2NaCl
H2+Cl2=2HCl
CH4+2O2=CO2+2H2O
CaCl2+2AgNO3=Ca(NO3)2+2AgCl
3Ba(OH)2+2H3PO4=6H2O+Ba3(PO4)2
3Ba(OH)2+2H3PO4=Ba3(PO4)2+6H2O
4Zn+10HNO3=4Zn(NO3)2+NH4NO3+3H2O
4Au+8NaCN+2H2O+O2=4Na(Au(CN)2)+4NaOH
Cu+As=Cs+Au
N
Y
N
Y
Y
Y
Y
Y
Y
Y
N
</code></pre>
<h2 id="201912-4-区块链"><a href="#201912-4-区块链" class="headerlink" title="201912-4 区块链"></a>201912-4 区块链</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/csp201912401.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/csp201912402.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/csp201912403.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/csp201912404.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/csp201912405.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="201912-5-魔数"><a href="#201912-5-魔数" class="headerlink" title="201912-5 魔数"></a>201912-5 魔数</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/201912501.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/201912502.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/201912503.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/201912504.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/201912505.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/201912506.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/201912507.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/201912508.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>打字机效果 | 又一款花里胡哨的打字机js</title>
    <url>/posts/7e7ef81c.html</url>
    <content><![CDATA[<p>又一款花里胡哨的打字机效果，之前在github上看到过一个不那么花的<a href="/posts/24067.html">打字机</a>，它的效果大概是下面这样：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/typejs1.gif"></p>
<p>源码如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/typed.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">strong</span> <span class="attr">id</span>=<span class="string">&quot;typedjs1&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">strong</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> typed = <span class="keyword">new</span> Typed(<span class="string">&quot;#typedjs1&quot;</span>, &#123;</span></span><br><span class="line"><span class="javascript">  <span class="attr">strings</span>: [<span class="string">&#x27;醒亦念卿，梦亦念卿&#x27;</span>,<span class="string">&#x27;频繁记录，只因生活和你太值得❤&#x27;</span>],</span></span><br><span class="line"><span class="javascript">  <span class="attr">startDelay</span>: <span class="number">0</span>,</span></span><br><span class="line"><span class="javascript">  <span class="attr">typeSpeed</span>: <span class="number">200</span>,</span></span><br><span class="line"><span class="javascript">  <span class="attr">backSpeed</span>: <span class="number">100</span>,</span></span><br><span class="line"><span class="javascript">  <span class="attr">loop</span>: <span class="literal">true</span>,</span></span><br><span class="line"><span class="javascript">  <span class="attr">showCursor</span>: <span class="literal">true</span>,</span></span><br><span class="line"><span class="javascript">  <span class="attr">shuffle</span>: <span class="literal">false</span></span></span><br><span class="line"><span class="javascript">&#125;);</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>最近又看到一款五彩斑斓的打字机，效果是👇下面这样的</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/typejs2.gif"></p>
<p>源码是这个样子的👇：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span><span class="tag">&lt;<span class="name">strong</span> <span class="attr">id</span>=<span class="string">&quot;colortap1&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">strong</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> colortap = <span class="function"><span class="keyword">function</span> (<span class="params">r</span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">	<span class="function"><span class="keyword">function</span> <span class="title">t</span>(<span class="params"></span>) </span>&#123;<span class="keyword">return</span> b[<span class="built_in">Math</span>.floor(<span class="built_in">Math</span>.random() * b.length)]&#125;  </span></span><br><span class="line"><span class="javascript">	<span class="function"><span class="keyword">function</span> <span class="title">e</span>(<span class="params"></span>) </span>&#123;<span class="keyword">return</span> <span class="built_in">String</span>.fromCharCode(<span class="number">94</span> * <span class="built_in">Math</span>.random() + <span class="number">33</span>)&#125;</span></span><br><span class="line"><span class="javascript">	<span class="function"><span class="keyword">function</span> <span class="title">n</span>(<span class="params">r</span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">		<span class="keyword">for</span>(<span class="keyword">var</span> n=<span class="built_in">document</span>.createDocumentFragment(),i=<span class="number">0</span>;r&gt;i;i++)&#123;</span></span><br><span class="line"><span class="javascript">			<span class="keyword">var</span> l=<span class="built_in">document</span>.createElement(<span class="string">&quot;span&quot;</span>);</span></span><br><span class="line"><span class="javascript">			l.textContent=e(),l.style.color=t(),n.appendChild(l)</span></span><br><span class="line"><span class="javascript">		&#125;</span></span><br><span class="line"><span class="javascript">		<span class="keyword">return</span> n;</span></span><br><span class="line"><span class="javascript">	&#125;</span></span><br><span class="line"><span class="javascript">	<span class="function"><span class="keyword">function</span> <span class="title">i</span>(<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">		<span class="keyword">var</span> t = o[c.skillI];</span></span><br><span class="line"><span class="javascript">		c.step ? c.step-- : (c.step = g, c.prefixP &lt; l.length ? (c.prefixP &gt;= <span class="number">0</span> &amp;&amp; (c.text += l[c.prefixP]), c.prefixP++) : <span class="string">&quot;forward&quot;</span> === c.direction ? c.skillP &lt; t.length ? (c.text += t[c.skillP], c.skillP++) : c.delay ? c.delay-- : (c.direction = <span class="string">&quot;backward&quot;</span>, c.delay = a) : c.skillP &gt; <span class="number">0</span> ? (c.text = c.text.slice(<span class="number">0</span>, -<span class="number">1</span>), c.skillP--) : (c.skillI = (c.skillI + <span class="number">1</span>) % o.length, c.direction = <span class="string">&quot;forward&quot;</span>)), </span></span><br><span class="line"><span class="javascript">		r.textContent = c.text,</span></span><br><span class="line"><span class="javascript">		r.appendChild(n(c.prefixP &lt; l.length ? <span class="built_in">Math</span>.min(s, s + c.prefixP) : <span class="built_in">Math</span>.min(s, t.length - c.skillP))),</span></span><br><span class="line"><span class="javascript">		<span class="built_in">setTimeout</span>(i, d)</span></span><br><span class="line"><span class="javascript">	&#125;</span></span><br><span class="line"><span class="javascript">	<span class="keyword">var</span> l = <span class="string">&quot;&quot;</span>,</span></span><br><span class="line"><span class="javascript">	o = [<span class="string">&quot;醒亦念卿，梦亦念卿&quot;</span>,<span class="string">&quot;频繁记录，只因生活和你太值得&quot;</span>,<span class="string">&quot;孜孜不倦，认真且怂&quot;</span>].map(<span class="function"><span class="keyword">function</span> (<span class="params">r</span>) </span>&#123;<span class="keyword">return</span> r + <span class="string">&quot;&quot;</span>&#125;),</span></span><br><span class="line"><span class="javascript">	a = <span class="number">2</span>,g = <span class="number">1</span>,s = <span class="number">5</span>,d = <span class="number">75</span>,</span></span><br><span class="line"><span class="javascript">	b = [<span class="string">&quot;rgb(110,64,170)&quot;</span>, <span class="string">&quot;rgb(150,61,179)&quot;</span>, <span class="string">&quot;rgb(191,60,175)&quot;</span>, <span class="string">&quot;rgb(228,65,157)&quot;</span>, <span class="string">&quot;rgb(254,75,131)&quot;</span>, <span class="string">&quot;rgb(255,94,99)&quot;</span>, <span class="string">&quot;rgb(255,120,71)&quot;</span>, <span class="string">&quot;rgb(251,150,51)&quot;</span>, <span class="string">&quot;rgb(226,183,47)&quot;</span>, <span class="string">&quot;rgb(198,214,60)&quot;</span>, <span class="string">&quot;rgb(175,240,91)&quot;</span>, <span class="string">&quot;rgb(127,246,88)&quot;</span>, <span class="string">&quot;rgb(82,246,103)&quot;</span>, <span class="string">&quot;rgb(48,239,130)&quot;</span>, <span class="string">&quot;rgb(29,223,163)&quot;</span>, <span class="string">&quot;rgb(26,199,194)&quot;</span>, <span class="string">&quot;rgb(35,171,216)&quot;</span>, <span class="string">&quot;rgb(54,140,225)&quot;</span>, <span class="string">&quot;rgb(76,110,219)&quot;</span>, <span class="string">&quot;rgb(96,84,200)&quot;</span>],</span></span><br><span class="line"><span class="javascript">	c = &#123;<span class="attr">text</span>: <span class="string">&quot;&quot;</span>,<span class="attr">prefixP</span>: -s,<span class="attr">skillI</span>: <span class="number">0</span>,<span class="attr">skillP</span>: <span class="number">0</span>,<span class="attr">direction</span>: <span class="string">&quot;forward&quot;</span>,<span class="attr">delay</span>: a,<span class="attr">step</span>: g&#125;;i()</span></span><br><span class="line"><span class="javascript">&#125;;</span></span><br><span class="line"><span class="javascript">colortap(<span class="built_in">document</span>.getElementById(<span class="string">&#x27;colortap1&#x27;</span>));</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>博客相关</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>学习笔记 | Flask学习从入门到放弃（2）</title>
    <url>/posts/3494.html</url>
    <content><![CDATA[<p>Flask Web学习笔记之Flask与HTTP</p>
<h1 id="2-1-请求响应循环"><a href="#2-1-请求响应循环" class="headerlink" title="2.1 请求响应循环"></a>2.1 请求响应循环</h1><ul>
<li>每一个Web应用都包含这种处理模式：客户端发出请求，服务器端处理请求并返回响应</li>
<li>HTTP是客户端和服务器端沟通的桥梁，当用户点击URL时，浏览器会生成http请求，经互联网发送到对应的web服务器，Web服务器端接收请求，通过WSGI将HTTP格式数据转换成能用的数据，并生成响应又依次返回给客户端</li>
</ul>
<h1 id="2-2-HTTP请求"><a href="#2-2-HTTP请求" class="headerlink" title="2.2 HTTP请求"></a>2.2 HTTP请求</h1><h2 id="2-2-1-报文"><a href="#2-2-1-报文" class="headerlink" title="2.2.1 报文"></a>2.2.1 报文</h2><ul>
<li>常见HTTP方法：GET，POST，PUT，DELETE，HEAD，OPTIONS</li>
</ul>
<h2 id="2-2-2-Request对象"><a href="#2-2-2-Request对象" class="headerlink" title="2.2.2 Request对象"></a>2.2.2 Request对象</h2><ul>
<li>当Flask接收到请求后，请求对象会提供多个属性来获取URL的各个部分，除了URL，请求报文中的其他信息都可以通过request对象提供的属性和方法获取</li>
<li>常用属性和方法如：<code>args</code>,<code>cookies</code>,<code>data</code>,<code>form</code>,<code>files</code>,<code>json</code>,<code>method</code>,<code>user_agent</code>,<code>get_json()</code>等等</li>
</ul>
<h2 id="2-2-3-在Flask中处理请求"><a href="#2-2-3-在Flask中处理请求" class="headerlink" title="2.2.3 在Flask中处理请求"></a>2.2.3 在Flask中处理请求</h2><h3 id="1-路由匹配"><a href="#1-路由匹配" class="headerlink" title="1. 路由匹配"></a>1. 路由匹配</h3><ul>
<li>程序实例中存储了一个路由表(app.url_map)，当请求发来后，Flask会根据请求报文中的URL来尝试与该表中所有的URL规则匹配，调用匹配成功的视图函数。</li>
<li>可使用<code>flask routes</code>查看路由</li>
</ul>
<h3 id="2-设置监听的HTTP方法"><a href="#2-设置监听的HTTP方法" class="headerlink" title="2. 设置监听的HTTP方法"></a>2. 设置监听的HTTP方法</h3><ul>
<li>当查看了路由表后可以发现，每一个路由还包含了一个监听的HTTP方法。</li>
<li>我们可以在app.route()装饰器中使用methods参数传入一个包含监听的HTTP方法的可迭代对象。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/hello&#x27;</span>,methods=[<span class="string">&#x27;GET&#x27;</span>,<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span>():</span></span><br><span class="line">	<span class="keyword">return</span> <span class="string">&quot;&lt;h1&gt;Hello,Flask!&lt;/h1&gt;&quot;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>当请求的方法不符合要求时，请求将无法被正常处理（出现405错误响应），因此我们可以为同一个URL根据请求方式定义多个视图函数</li>
</ul>
<h3 id="3-URL处理"><a href="#3-URL处理" class="headerlink" title="3. URL处理"></a>3. URL处理</h3><ul>
<li>URL中的变量部分默认类型是字符串，但Flask提供了一些转换器可以在URL规则中使用</li>
</ul>
<table>
<thead>
<tr>
<th>转换器</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>string</td>
<td>不包含斜线的字符串（默认值）</td>
</tr>
<tr>
<td>int</td>
<td>整型</td>
</tr>
<tr>
<td>float</td>
<td>浮点数</td>
</tr>
<tr>
<td>path</td>
<td>包含斜线的字符串，static路由的URL规则中的filename变量就是使用了这个转换器</td>
</tr>
<tr>
<td>any</td>
<td>匹配一系列给定值中的一个元素</td>
</tr>
<tr>
<td>uuid</td>
<td>UUID字符串</td>
</tr>
</tbody></table>
<ul>
<li>规则：<code>&lt;转换器：变量名&gt;</code>,例如：<code>&lt;int:year&gt;</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/hello/&lt;int:year&gt;&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span>():</span></span><br><span class="line">	<span class="keyword">return</span> <span class="string">&#x27;&lt;p&gt;hello,I am %d years old!&lt;/p&gt;&#x27;</span>%(year-<span class="number">2019</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>在这个例子中，如果不使用int转换器，默认的string转换器会将其转换成string类型，为了计算数值，需要使用int转换器将变量转换成整型</li>
<li>在用法上比较独特的是any转换器，<code>&lt;any(value1,value2...):变量名&gt;</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/colors/&lt;any(blue,white,red):color&gt;&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">three_colors</span>(<span class="params">color</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&lt;p&gt;You choose %s&lt;/p&gt;&#x27;</span>%color  </span><br></pre></td></tr></table></figure>

<h2 id="2-2-4-请求钩子"><a href="#2-2-4-请求钩子" class="headerlink" title="2.2.4 请求钩子"></a>2.2.4 请求钩子</h2><ul>
<li>Flask提供一些请求钩子(HOOK)，来对请求进行预处理和后处理，它们可以用来注册在请求处理的不同阶段执行的回调函数</li>
</ul>
<table>
<thead>
<tr>
<th>钩子</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>before_first_request</td>
<td>注册一个函数，在处理第一个请求前运行</td>
</tr>
<tr>
<td>before_request</td>
<td>注册一个函数，在处理每个请求前运行</td>
</tr>
<tr>
<td>after_request</td>
<td>注册一个函数，如果没有未处理的异常抛出，会在每个请求结束后运行</td>
</tr>
<tr>
<td>teardown_request</td>
<td>注册一个函数，即使有未处理的异常抛出，会在每个请求结束后运行。如果发送异常，会传入异常对象作为参数到注册的函数中</td>
</tr>
<tr>
<td>after_this_request</td>
<td>在注册函数内注册一个函数，会在这个请求结束后运行</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.before_request</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_something</span>():</span></span><br><span class="line">    <span class="keyword">pass</span> <span class="comment">#这里的代码会在每个请求处理前执行</span></span><br></pre></td></tr></table></figure>

<h1 id="2-3-HTTP响应"><a href="#2-3-HTTP响应" class="headerlink" title="2.3 HTTP响应"></a>2.3 HTTP响应</h1><h2 id="2-3-1-响应报文"><a href="#2-3-1-响应报文" class="headerlink" title="2.3.1 响应报文"></a>2.3.1 响应报文</h2><ul>
<li>响应报文主要由<strong>协议版本</strong>,<strong>状态码</strong>(status code),<strong>原因短语</strong>(reason phrase),<strong>响应首部</strong>和<strong>响应主体</strong>组成。</li>
<li>响应报文的首部包含一些关于响应和服务器的信息，这些内容由Flask生成，而我们在视图函数中返回的内容即为响应报文中的主题内容</li>
<li>HTTP状态码用来表示请求处理的结果</li>
</ul>
<table>
<!-- rowspan是要跨的行数，colspan是要跨的列数 -->
    <tr>
        <th>类型</th>
        <th>状态码</th>
        <th>原因短语</th>
        <th>说明</th>
    </tr>
    <tr>
        <td rowspan="3">成功</td>
        <td>200</td>
        <td>OK</td>
        <td>请求被正常处理</td>
    </tr>
    <tr>
        <td>201</td>
        <td>Created</td>
        <td>请求被处理,并创建了一个新资源</td>
    </tr>
    <tr>
        <td>204</td>
        <td>No Content</td>
        <td>请求处理成功，但无内容返回</td>
    </tr>
    <tr>
        <td rowspan="3">重定向</td>
        <td>301</td>
        <td>Moved Permanently</td>
        <td>永久重定向</td>
    </tr>
    <tr>
        <td>302</td>
        <td>Found</td>
        <td>临时性重定向</td>
    </tr>
    <tr>
        <td>304</td>
        <td>Not Modified</td>
        <td>请求的资源未被修改，重定向到缓存的资源</td>
    </tr>
    <tr>
        <td rowspan="4">客户端错误</td>
        <td>400</td>
        <td>Bad Request</td>
        <td>请求无效，即请求报文中存在错误</td>
    </tr>
    <tr>
        <td>401</td>
        <td>Unauthorized</td>
        <td>表示请求的资源需要获取授权信息，在浏览器中会弹出认证弹窗</td>
    </tr>
    <tr>
        <td>403</td>
        <td>Forbidden</td>
        <td>请求的资源被服务器拒绝访问</td>
    </tr>
    <tr>
        <td>404</td>
        <td>Not Found</td>
        <td>服务器上无法找到请求的资源或者URL无效</td>
    </tr>
    <tr>
        <td rowspan="1">服务器端错误</td>
        <td>500</td>
        <td>Internet Server Error</td>
        <td>服务器内部发送错误</td>
    </tr>

</table>

<h2 id="2-3-1-在Flask中生成响应"><a href="#2-3-1-在Flask中生成响应" class="headerlink" title="2.3.1 在Flask中生成响应"></a>2.3.1 在Flask中生成响应</h2><ul>
<li>视图函数可以返回：响应主体，状态码，首部字段</li>
</ul>
<h3 id="1-重定向"><a href="#1-重定向" class="headerlink" title="1. 重定向"></a>1. 重定向</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask,redirect</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/hello&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span>():</span></span><br><span class="line">    <span class="keyword">return</span> redirect(<span class="string">&#x27;http://justlovesmile.top&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>redirect函数默认的状态码是302即临时重定向，可以通过code关键字传入或作为第二参数传入修改</p>
</li>
<li><p>如果要在程序内重定向到其他视图，只需在redirect函数中使用url_for()函数生成目标URL</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask,redirect,url_for</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/hi&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hi</span>():</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> redirect(url_for(<span class="string">&#x27;hello&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/hello&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span>():</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>

<h3 id="2-错误响应"><a href="#2-错误响应" class="headerlink" title="2. 错误响应"></a>2. 错误响应</h3><ul>
<li> 使用Flask提供的abort()函数，手动返回错误响应</li>
<li>abort()函数前不需要执行使用return语句，一旦abort函数被调用，其之后的代码不被执行</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask,abort</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/404&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">not_found</span>():</span></span><br><span class="line">    abort(<span class="number">404</span>)</span><br></pre></td></tr></table></figure>

<h2 id="2-3-2-响应格式"><a href="#2-3-2-响应格式" class="headerlink" title="2.3.2 响应格式"></a>2.3.2 响应格式</h2><ul>
<li>默认情况下Flask使用html格式响应，在特定情况下，也会使用其他格式，不同的响应数据格式需要设置不同的MIME类型，MIME类型在首部的Content-Type定义，以默认的html类型为例<br><code>Content-Type: text/html;charset=utf-8</code></li>
<li>如果想使用其他的MIME类型，可以通过Flask提供的make_response()方法,生成对应响应对象，传入响应的主体作为参数，然后使用响应对象的mimetype属性设置MIME类型</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> make_response</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/foo&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span>():</span></span><br><span class="line">    response=make_response(<span class="string">&#x27;Hello World&#x27;</span>)</span><br><span class="line">    response.mimetype=<span class="string">&#x27;text/plain&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> response</span><br></pre></td></tr></table></figure>

<ul>
<li><p>常用MIME类型：</p>
<ul>
<li>纯文本：<code>text/plain</code></li>
<li>HTML：<code>text/html</code> </li>
<li>XML：<code>application/xml</code></li>
<li>json: <code>application/json</code></li>
</ul>
</li>
<li><p>对于json数据，python的json模块具有<code>dumps()</code>和<code>load()</code>等方法,并且Flask提供了包装好的更方便的<code>jsonify()</code>函数</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> falsk <span class="keyword">import</span> Flask,make_response,json</span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/foo&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span>():</span></span><br><span class="line">    data=&#123;</span><br><span class="line">      <span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;justlovesmile&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;gender&#x27;</span>:<span class="string">&#x27;male&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    response=make_response(json.dumps(data))</span><br><span class="line">    response.mimetype=<span class="string">&#x27;application/json&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> response</span><br></pre></td></tr></table></figure>

<p>等价于</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask,jsonify</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/foo&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span>():</span></span><br><span class="line">    <span class="keyword">return</span> jsonify(&#123;name=<span class="string">&#x27;justlovesmile&#x27;</span>,gender=<span class="string">&#x27;male&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure>

<ul>
<li>jsonify()函数默认返回码为200，可以附加状态码自定义响应类型</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/foo&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span>():</span></span><br><span class="line">    <span class="keyword">return</span> jsonify(&#123;name=<span class="string">&#x27;&#x27;</span>,gender=<span class="string">&#x27;&#x27;</span>&#125;),<span class="number">500</span></span><br></pre></td></tr></table></figure>

<h2 id="2-3-3-来一块Cookie"><a href="#2-3-3-来一块Cookie" class="headerlink" title="2.3.3 来一块Cookie"></a>2.3.3 来一块Cookie</h2>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title>学习笔记 | Flask学习从入门到放弃（1）</title>
    <url>/posts/3302.html</url>
    <content><![CDATA[<p>Flask web开发学习笔记之初识Flask</p>
<ul>
<li>Flask是使用python编写的Web微框架</li>
<li>Flask有两个主要依赖：<ul>
<li>WSGI（Web Server Gateway Interface，Web服务器网关接口）</li>
<li>Jinja2模块引擎</li>
</ul>
</li>
</ul>
<h1 id="1-1搭建开发环境"><a href="#1-1搭建开发环境" class="headerlink" title="1.1搭建开发环境"></a>1.1搭建开发环境</h1><h2 id="1-1-1-Pipenv工作流"><a href="#1-1-1-Pipenv工作流" class="headerlink" title="1.1.1 Pipenv工作流"></a>1.1.1 Pipenv工作流</h2><ul>
<li>可看作是pip加强版，是pip和pipfile和virtualenv的结合体，使得包安装，包依赖管理和虚拟环境管理更加方便</li>
<li>python3.4及以上版本自带pip工具，使用    <code>$ pip --version</code>     查看已安装版本</li>
<li>安装pipenv： <code>$ pip install pipenv</code></li>
<li>选择并进入工作目录，创建虚拟环境： <code>$ pipenv install</code></li>
<li>虚拟环境文件夹的目录名称的形式是’当前项目目录名+一串随机字符’</li>
<li>显式激活虚拟环境： <code>$ pipenv shell</code> ,使用<code>exit</code>退出</li>
<li>非显式激活虚拟环境： <code>$ pipenv run python xxxx.py</code></li>
<li>管理依赖（会使用到的python包）,查看Pipfile和Pipfile.lock文件,或者输入<code>$ pipenv graph</code>或者在虚拟环境中输入 <code>$ pip list</code></li>
</ul>
<h2 id="1-1-2-安装Flask"><a href="#1-1-2-安装Flask" class="headerlink" title="1.1.2 安装Flask"></a>1.1.2 安装Flask</h2><ul>
<li>在虚拟环境中安装Flask： <code>$ pipenv install Flask</code></li>
</ul>
<h2 id="1-1-3-集成开发环境IDE"><a href="#1-1-3-集成开发环境IDE" class="headerlink" title="1.1.3 集成开发环境IDE"></a>1.1.3 集成开发环境IDE</h2><ul>
<li>pycharm</li>
<li>点击File → Setting → Project：XXX → Project Interpreter → Add local Python Interpreter → Virtualenv Environment → Existing environment → （输入 <code>$ pipenv --venv</code> 查看对应虚拟环境路径，找到其下的python.exe文件，linux/MacOS在bin，windows在Scripts）</li>
<li>推荐使用浏览器 Firefox 和 Chorme</li>
</ul>
<h1 id="1-2-第一的程序"><a href="#1-2-第一的程序" class="headerlink" title="1.2 第一的程序"></a>1.2 第一的程序</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask //导入Flask类</span><br><span class="line">app=Flask(__name__)     //实例化这个类</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/&#x27;</span></span>)			//注册路由</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span>():</span>			//视图函数</span><br><span class="line">	<span class="keyword">return</span> <span class="string">&#x27;&lt;h1&gt;Hello World!&lt;/h1&gt;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">	app.run(debug=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h2 id="1-2-1-创建程序实例"><a href="#1-2-1-创建程序实例" class="headerlink" title="1.2.1 创建程序实例"></a>1.2.1 创建程序实例</h2><ul>
<li>导入Flask类，实例化这个类</li>
</ul>
<h2 id="1-2-2-注册路由"><a href="#1-2-2-注册路由" class="headerlink" title="1.2.2 注册路由"></a>1.2.2 注册路由</h2><ul>
<li>为函数附加app.route()装饰器，并传入URL规则作参数</li>
<li>可以为一个视图函数绑定多个URL</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/hi&#x27;</span></span>)</span></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/hello&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">say</span>():</span></span><br><span class="line">	<span class="keyword">return</span> <span class="string">&#x27;&lt;h1&gt;hello&lt;/h1&gt;&#x27;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>动态URL：使用‘&lt;变量名&gt;’表示变量</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/greet/&lt;name&gt;&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greet</span>(<span class="params">name</span>):</span></span><br><span class="line">	<span class="keyword">return</span> <span class="string">&#x27;&lt;h1&gt;hello, %s!&lt;/h1&gt;&#x27;</span> % name</span><br></pre></td></tr></table></figure>

<ul>
<li>URL中包含变量时，如果用户访问的URL中没有包含变量，则会返回错误，所以可以设置装饰器使用defaults参数设置变量的默认值</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/greet&#x27;</span>,defaults=&#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;programmer&#x27;</span>&#125;</span>)</span></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/greet/&lt;name&gt;&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greet</span>(<span class="params">name</span>):</span></span><br><span class="line"><span class="keyword">return</span> <span class="string">&#x27;&lt;h1&gt;Hello, %s!&lt;/h1&gt;&#x27;</span> % name</span><br><span class="line"></span><br><span class="line">//等价于</span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/greet&#x27;</span></span>)</span></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/greet/&lt;name&gt;&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greet</span>(<span class="params">name=<span class="string">&#x27;programmer&#x27;</span></span>):</span></span><br><span class="line"><span class="keyword">return</span> <span class="string">&#x27;&lt;h1&gt;Hello, %s!&lt;/h1&gt;&#x27;</span> % name</span><br></pre></td></tr></table></figure>

<h1 id="1-3-启动开发服务器"><a href="#1-3-启动开发服务器" class="headerlink" title="1.3 启动开发服务器"></a>1.3 启动开发服务器</h1><h2 id="1-3-1-运行"><a href="#1-3-1-运行" class="headerlink" title="1.3.1 运行"></a>1.3.1 运行</h2><ul>
<li><code>$ flask run</code></li>
<li>自动发现程序实例：（Linux/macOS）<code>$ export FlASK_APP=XXX </code>或（Windows）<code>set FlASK_APP=XXX </code>,但是当我在Windows使用powershell时我输入<code>set FLASK_APP=appname.py</code>时，出错了，解决办法是输入<code>$env:FLASK_APP=&quot;appname.py&quot;</code> </li>
<li>管理环境变量： 安装python-dotenv,<code>pip install python-dotenv</code>,在项目根目录下创建两个文件：.env（存储敏感信息的环境变量）和.flaskenv（存储与flask相关公开环境变量）,每行一个，以#为注释的键值对</li>
<li>使用pycharm运行,需要配置一系列变量…..</li>
</ul>
<h2 id="1-3-2-更多启动选项"><a href="#1-3-2-更多启动选项" class="headerlink" title="1.3.2 更多启动选项"></a>1.3.2 更多启动选项</h2><ul>
<li>设置主机地址：<code>flask run --host=0.0.0.0</code></li>
<li>设置端口： <code>flask run --port=8000</code></li>
<li>设置开发环境：可在.flaskenv文件中写入<code>FALSK_ENV=development</code>，在开发环境下，调试模式自动开启，通过FALSK_DEBUG控制是(=1)否(=0)开启.</li>
<li>调试模式下，会激活调试器和重载器，调试器允许在错误页面输入PIN码调试，重载器可以检测文件变动，重启服务器。</li>
<li>内置stat重载器性能一般，可以使用watchdog，<code>pipenv install watchdog --dev</code>,添加–dev的目的是声明为开发依赖。</li>
</ul>
<h1 id="1-4-shell"><a href="#1-4-shell" class="headerlink" title="1.4 shell"></a>1.4 shell</h1><ul>
<li>python shell与flask shell</li>
</ul>
<h1 id="1-5-Flask扩展"><a href="#1-5-Flask扩展" class="headerlink" title="1.5 Flask扩展"></a>1.5 Flask扩展</h1><ul>
<li>即使用Flask提供的API接口编写的Python库</li>
</ul>
<h1 id="1-6-项目配置"><a href="#1-6-项目配置" class="headerlink" title="1.6 项目配置"></a>1.6 项目配置</h1><ul>
<li>配置变量都是通过Flask对象的app.config属性作为统一的接口来设置和获取</li>
<li>单个设置：<code>app.cofig[&#39;ADMIN_NAME&#39;]=&#39;xiaoming&#39;</code>,也可以保存在文件中</li>
<li>多个设置：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">app.config.update&#123;</span><br><span class="line">	TESTING=<span class="literal">True</span>,</span><br><span class="line">	SECRET_KEY=<span class="string">&#x27;XXXXXXXXXXX&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>获取：<code>value=app.config[&#39;ADMIN_NAME&#39;]</code></li>
</ul>
<h1 id="1-7-URL与端点"><a href="#1-7-URL与端点" class="headerlink" title="1.7 URL与端点"></a>1.7 URL与端点</h1><ul>
<li>使用Flask提供的url_for()函数获取URL，第一个参数是端点名（默认是视图函数名）,其后还可以加动态参数，形如：name=’Jack’,得到的URL是相对的URL（内部的URL）</li>
</ul>
<h1 id="1-8-Flask命令"><a href="#1-8-Flask命令" class="headerlink" title="1.8 Flask命令"></a>1.8 Flask命令</h1><ul>
<li>flask run/flask shell/flask –help等等</li>
<li>注册flask命令：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.cli.command()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span>():</span></span><br><span class="line">	click.env(<span class="string">&#x27;Hello , Human!&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>然后在控制台输入：<code>flask hello</code> </p>
<h1 id="1-9-模板和静态文件"><a href="#1-9-模板和静态文件" class="headerlink" title="1.9 模板和静态文件"></a>1.9 模板和静态文件</h1><ul>
<li>项目结构示例：templates中存放html文件，static中存放css和js文件</li>
</ul>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">hello/</span><br><span class="line"><span class="bullet">   -</span> templates/</span><br><span class="line"><span class="bullet">   -</span> static/</span><br><span class="line"><span class="bullet">   -</span> app.py</span><br></pre></td></tr></table></figure>

<h1 id="1-10-Flask与MVC框架"><a href="#1-10-Flask与MVC框架" class="headerlink" title="1.10 Flask与MVC框架"></a>1.10 Flask与MVC框架</h1><ul>
<li>MVC框架最初是设计桌面程序的，在MVC框架中，程序被分成了三个组件：数据处理（Model），用户界面（View），交互逻辑（Controller）</li>
<li>严格来说Flask不是MVC架构的框架</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title>学习笔记 | 什么是Node.js</title>
    <url>/posts/49210.html</url>
    <content><![CDATA[<p>开始去了解node.js</p>
<span id="more"></span>
<h1 id="Node-js简介"><a href="#Node-js简介" class="headerlink" title="Node.js简介"></a>Node.js简介</h1><ul>
<li>Node.js是运行在服务端的JavaScript，是一个事件驱动I/O服务端Javascript环境。</li>
<li>查看版本：<figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line"><span class="keyword">node</span> <span class="title">-v</span></span><br></pre></td></tr></table></figure></li>
<li>node版本管理工具nvm</li>
</ul>
<h1 id="Node-js应用"><a href="#Node-js应用" class="headerlink" title="Node.js应用"></a>Node.js应用</h1><ul>
<li>Node.js应用的构成：<ul>
<li>引入required模块</li>
<li>创建服务器</li>
<li>接收请求与响应请求</li>
</ul>
</li>
</ul>
<h2 id="创建Node-js应用"><a href="#创建Node-js应用" class="headerlink" title="创建Node.js应用"></a>创建Node.js应用</h2><ul>
<li>步骤一：引入required模块<ul>
<li>使用require指令来载入http模块，并将实例化的HTTP复制给变量http，实例如下：</li>
</ul>
</li>
</ul>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> http = <span class="built_in">require</span>(<span class="string">&quot;http&quot;</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li>步骤二：创建服务器</li>
</ul>
<ol>
<li>创建一个server.js的文件:</li>
</ol>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> http = <span class="built_in">require</span>(<span class="string">&quot;http&quot;</span>);</span><br><span class="line"></span><br><span class="line">http.createServer(<span class="function"><span class="keyword">function</span>(<span class="params">request,response</span>)</span>&#123;</span><br><span class="line">    <span class="comment">//发送http头部</span></span><br><span class="line">    <span class="comment">//HTTP状态值：200 ：OK</span></span><br><span class="line">    <span class="comment">//内容类型：text/plain</span></span><br><span class="line">    response.writeHead(<span class="number">200</span>,&#123;<span class="string">&#x27;Content-Type&#x27;</span>:<span class="string">&#x27;text/plain&#x27;</span>&#125;);</span><br><span class="line">    <span class="comment">//发送响应数据 “Hello World”</span></span><br><span class="line">    response.end(<span class="string">&#x27;Hello World\n&#x27;</span>);</span><br><span class="line">&#125;).listen(<span class="number">8888</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//终端打印如下信息</span></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&#x27;Server running at http://127.0.0.1:8888/&#x27;</span>);</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>使用node命令执行以上代码</li>
</ol>
<figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line"><span class="keyword">node</span> <span class="title">server</span>.js</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>访问<a href="http://127.0.0.1:8888/">http://127.0.0.1:8888/</a></li>
</ol>
<h2 id="npm使用介绍"><a href="#npm使用介绍" class="headerlink" title="npm使用介绍"></a>npm使用介绍</h2><ul>
<li>查看npm版本</li>
</ul>
<figure class="highlight coffeescript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">npm</span> -v</span><br></pre></td></tr></table></figure>
<ul>
<li>升级版本</li>
</ul>
<figure class="highlight coffeescript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">npm</span> install <span class="built_in">npm</span> -g</span><br></pre></td></tr></table></figure>
<ul>
<li>安装包</li>
</ul>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">npm <span class="keyword">install</span> &lt;Module Name&gt;          <span class="comment"># 本地安装</span></span><br><span class="line">npm <span class="keyword">install</span> &lt;Module Name&gt; -g       <span class="comment"># 全局安装</span></span><br></pre></td></tr></table></figure>
<ul>
<li>查看安装信息</li>
</ul>
<figure class="highlight coffeescript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">npm</span> list -g                        <span class="comment"># 查看全局安装的模块</span></span><br><span class="line"><span class="built_in">npm</span> list &lt;Module Name&gt;             <span class="comment"># 查看某个模块的版本号</span></span><br><span class="line"><span class="built_in">npm</span> ls                             <span class="comment"># 查看当前目录下的包信息</span></span><br></pre></td></tr></table></figure>
<ul>
<li>卸载模块</li>
</ul>
<figure class="highlight fortran"><table><tr><td class="code"><pre><span class="line">npm uninstall &lt;<span class="keyword">Module</span> <span class="keyword">Name</span>&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>更新模块</li>
</ul>
<figure class="highlight fortran"><table><tr><td class="code"><pre><span class="line">npm update &lt;<span class="keyword">Module</span> <span class="keyword">Name</span>&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>搜索模块</li>
</ul>
<figure class="highlight fortran"><table><tr><td class="code"><pre><span class="line">npm search &lt;<span class="keyword">Module</span> <span class="keyword">Name</span>&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>创建模块</li>
</ul>
<figure class="highlight autoit"><table><tr><td class="code"><pre><span class="line">$npm init                            <span class="meta"># 会自动生成package.json</span></span><br><span class="line"></span><br><span class="line">$npm adduser                         <span class="meta"># 在npm资源库中注册用户</span></span><br><span class="line">Username:XXXX</span><br><span class="line">Password:XXXXXXX</span><br><span class="line">Email: XXXXXXXXX<span class="symbol">@XXX</span>.XXX</span><br><span class="line"></span><br><span class="line">$npm publish                         <span class="meta"># 发布模块</span></span><br></pre></td></tr></table></figure>

<h2 id="Node-js-REPL-交互式解释器"><a href="#Node-js-REPL-交互式解释器" class="headerlink" title="Node.js REPL(交互式解释器)"></a>Node.js REPL(交互式解释器)</h2><ul>
<li>REPL(Read Eval Print Loop:交互式解释器)，Node自带交互式解释器，可以执行<code>读取</code>,<code>执行</code>,<code>打印</code>,<code>循环</code>等任务</li>
<li>在Node的REPL中可以执行：</li>
</ul>
<ol>
<li>简单的表达式运算</li>
</ol>
<figure class="highlight node-repl"><table><tr><td class="code"><pre><span class="line">$ node</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript"><span class="number">1</span>+<span class="number">4</span></span></span><br><span class="line">5</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript"><span class="number">5</span>/<span class="number">2</span></span></span><br><span class="line">2.5</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript"> </span></span><br></pre></td></tr></table></figure>
<ol start="2">
<li>使用变量</li>
</ol>
<figure class="highlight node-repl"><table><tr><td class="code"><pre><span class="line">$ node</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript"><span class="number">1</span>+<span class="number">4</span></span></span><br><span class="line">5</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript"><span class="number">5</span>/<span class="number">2</span></span></span><br><span class="line">2.5</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript">x=<span class="number">10</span></span></span><br><span class="line">10</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript"><span class="keyword">var</span> y=<span class="number">10</span></span></span><br><span class="line">undefined</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript">x+y</span></span><br><span class="line">20</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript"><span class="built_in">console</span>.log(<span class="string">&quot;Hello World!&quot;</span>)</span></span><br><span class="line">Hello World!</span><br><span class="line">undefined</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript"> </span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>多行表达式</li>
</ol>
<figure class="highlight node-repl"><table><tr><td class="code"><pre><span class="line">$ node</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript"><span class="keyword">do</span> &#123;</span></span><br><span class="line"><span class="meta">...</span> <span class="javascript">x++;</span></span><br><span class="line"><span class="meta">...</span> <span class="javascript"><span class="built_in">console</span>.log(<span class="string">&quot;x:&quot;</span>+x);</span></span><br><span class="line"><span class="meta">...</span> <span class="javascript">&#125;<span class="keyword">while</span>(x&lt;<span class="number">5</span>);</span></span><br><span class="line">x:1</span><br><span class="line">x:2</span><br><span class="line">x:3</span><br><span class="line">x:4</span><br><span class="line">x:5</span><br><span class="line">undefined</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript">      </span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>下划线变量<code>[使用下划线(_)获取上一个表达式的运算结果]</code></li>
</ol>
<figure class="highlight node-repl"><table><tr><td class="code"><pre><span class="line">$ node</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript"><span class="keyword">var</span> x=<span class="number">10</span>;</span></span><br><span class="line">undefined</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript">y=<span class="number">10</span>;</span></span><br><span class="line">10</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript">x+y</span></span><br><span class="line">20</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript"><span class="keyword">var</span> sum=_</span></span><br><span class="line">undefined</span><br><span class="line"><span class="meta">&gt;</span> <span class="javascript"><span class="built_in">console</span>.log(sum)</span></span><br><span class="line">20</span><br><span class="line">undefined</span><br><span class="line"><span class="meta">&gt;</span></span><br></pre></td></tr></table></figure>
<ol start="5">
<li>两次ctrl+c停止REPL</li>
</ol>
<h2 id="Node-js的回调函数"><a href="#Node-js的回调函数" class="headerlink" title="Node.js的回调函数"></a>Node.js的回调函数</h2><ul>
<li>Node.js异步编程的直接体现就是回调</li>
<li>阻塞代码实例</li>
<li>创建一个文件 input.txt ，内容如下：</li>
</ul>
<figure class="highlight erlang-repl"><table><tr><td class="code"><pre><span class="line">Hello world!</span><br></pre></td></tr></table></figure>
<ul>
<li>创建 main.js 文件, 代码如下：</li>
</ul>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">&quot;fs&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> data = fs.readFileSync(<span class="string">&#x27;input.txt&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(data.toString());</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&quot;程序执行结束!&quot;</span>);</span><br></pre></td></tr></table></figure>
<ul>
<li>以上代码执行结果如下：</li>
</ul>
<figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">node</span> <span class="title">main</span>.js</span><br><span class="line">Hello World！</span><br><span class="line"></span><br><span class="line">程序执行结束!</span><br></pre></td></tr></table></figure>
<ul>
<li>非阻塞代码实例</li>
<li>创建一个文件 input.txt ，内容如下：</li>
</ul>
<figure class="highlight erlang-repl"><table><tr><td class="code"><pre><span class="line">Hello World!</span><br></pre></td></tr></table></figure>
<ul>
<li>创建 main.js 文件, 代码如下：</li>
</ul>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">&quot;fs&quot;</span>);</span><br><span class="line"></span><br><span class="line">fs.readFile(<span class="string">&#x27;input.txt&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">err, data</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (err) <span class="keyword">return</span> <span class="built_in">console</span>.error(err);</span><br><span class="line">    <span class="built_in">console</span>.log(data.toString());</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&quot;程序执行结束!&quot;</span>);</span><br></pre></td></tr></table></figure>
<ul>
<li>以上代码执行结果如下：</li>
</ul>
<figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">node</span> <span class="title">main</span>.js</span><br><span class="line">程序执行结束!</span><br><span class="line">Hello World!</span><br></pre></td></tr></table></figure>

<ul>
<li>第一个实例在文件读取完后才执行完程序。 第二个实例我们不需要等待文件读取完，这样就可以在读取文件时同时执行接下来的代码，大大提高了程序的性能。</li>
<li>因此，阻塞是按顺序执行的，而非阻塞是不需要按顺序的，所以如果需要处理回调函数的参数，我们就需要写在回调函数内。</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Node.js</tag>
      </tags>
  </entry>
  <entry>
    <title>学习笔记 | 四六级复习卡片</title>
    <url>/posts/10024.html</url>
    <content><![CDATA[<div style="text-align: center;background-color: #fbdff0;">
<div class="card">
    <div class="headpic">
        <img src="https://s2.ax1x.com/2019/12/09/Q0YD61.jpg" alt="Q0YD61.jpg" border="0" />
    </div>
    <hr class="cardhr">
    <div class="content">
        <strong>高频词汇</strong>
        <p>candidate n.候选人</p>
        <p>absence n.缺席，缺乏（absent a.不在场的；缺乏的）</p>
        <p>abundant a.丰富的；大量的</p>
        <p>accidental a.偶然的（accident n.事故）</p>
        <p>agriculture n.农业，农学</p>
        <p>appropriate a.适当的，恰当的</p>
        <p>barrier n.障碍，栅栏</p>
        <p>sibling n.兄，弟，姐，妹</p>
        <p>demonstrate v.证明</p>
        <p>facilitate v.促进</p>
        <p>plunge v.暴跌,骤降n.骤降</p>
        <p>recruit v.吸收，招募</p>
        <p>commit v.自杀，犯罪，承诺</p>
        <p>advocate v.拥护</p>
        <p>asset n.资产</p>
        <p>diversity n.多样性</p>
        <p>institute n.学院；学会</p>
        <p>empire n.帝国；大企业</p>
        <p>economic 与财政相关<-->economical 与节约相关</p>
        <p>insure 保险<-->ensure  确保</p>
        <p>considerable 相当多（大）的<-->considerate 体谅的</p>
        <p>invalueable 非常贵重的<-->valueless 毫无价值的</p>
        <p>sensitive 敏感的<-->sensibl 明智的</p>
        <p>complement 补全<-->compliment 赞辞</p>
        <P>resist 抵制<-->persist 坚持</P>
        <p>principal 最重要的<-->principle 原则，定律</p>
        <p>intense 强烈的<-->intensive 精深的</p>
    </div>
</div>
<div class="card">
    <div class="headpic"><img src="https://s2.ax1x.com/2019/12/22/QzAz8O.jpg" alt="QzAz8O.jpg" border="0" /></div>
    <div class="hr"></div>
    <div class="content">
        <strong>英语六级翻译预测</strong>
<p>
一，垃圾分类<br>
【题干:】<br>
       随着人民生活水平和消费水平的提高，中国的垃圾问题日益严峻。很多城市被垃圾包围。<br>
       面对日益增长的垃圾产量和环境状况的恶化，中国政府正在努力推行垃极分类(garbage classification)的政策。<br>
　　垃圾分类是指将垃圾分为可回收利用和不可回收利用两类，要求人们将垃圾投放至不同的垃圾桶(trash can)，通过不同的清理、运输和回收方式，使之变成新的资源。<br>
　　它可以减少垃圾处理量，降低处理成本，减少土地资源的消耗，对社会、经济、生态三方面都有益。<br>
</p>
<p>
【参考译文:】<br>
　　With the improvement of people's living standards and the increase in consumption level, the garbage problem in China becomes increasingly urgent. Many cities are surrounded by garbage.<br>
　　Confronted with the growing garbage output and deteriorating environment, the Chinese government is implementing the policy of garbage classification with great effort.<br>
　　Garbage classification means dividing garbage into recyclable and unrecyclable, and requires people to put garbage into different trash cans so that it can become new resources through different ways of cleaning, transporting and recycling.<br>
　　It can reduce not only the amount of garbage that needs to be disposed of, but also the deposing cost and the usage of the land, benefiting our society, economy, and environment.<br>
　　【难点点拨：】<br>
　　1. 第二句中的“面对日益增长的垃圾产量和环境状况的恶化”，其逻辑主语是后面的“中国政府”，故此处可采用过去分词短语作状语，置于句首，译成confronted with the growing garbage output and deteriorating environment。<br>
　　2.“垃圾分类是指将垃圾分为…使之变成新的资源”句子较长，由三个短句组成，第一、第二个短句主语均是“垃圾分类”，因此可用and连接两个谓语“是指”和“要求”。<br>
　　“要求人们…”用require sb.to do结构。“通过……方式使之变成新的资源”可看作是“人们将垃圾投放至不同的垃圾桶”的结果，可用so that连接，加强句子逻辑。<br>
　　3.最后一句的主干可理解为“它可以减少…，降低…，减少…”，三个谓语动词都可用reduce来翻译，因此可共一个动词，后接不同的宾语，用not only...but also...连接。“对社会、经济、生态三方面都有益”则可处理成现在分词短语benefiting...,表结果。<br>
二，一带一路<br>
【题干：】<br>
“一带一路”(The Belt and Road)是“丝绸之路经济带”和“21世纪海上丝绸之路”的简称。它将充分依靠中国与有关国家既有的双多边机制，借助既有的、行之有效的区域合作平台。一带一路旨在借用古代丝绸之路的历史符号，高举和平发展的旗帜，积极发展与沿线国家的经济合作伙伴关系，共同打造政治互信、经济融合、文化包容的利益共同体、命运共同体和责任共同体。<br>
【参考译文：】<br>
　　“The Belt and Road” is short for the Silk Road Economic Belt and the 21st-Century Maritime Silk Road. It will fully depend on the bi-lateral and multi-lateral mechanism between China and its related nations with the help of existing and effective regional cooperation platforms. It aims to use the historic symbol of the ancient Silk Road, raise the flag of peace and development, and develop the economic partnership with nations along the line positively, in order to build a community of interests with trustful politics, integrated economy and inclusive culture, a community with a shared future, a community with common responsibilities.<br>
三，郑和下西洋<br>
【题干：】<br>
    明朝(the Ming Dynasty)初期,中国是世界上最发达的国家之一。为了弘扬国力、加强与其他各国的联系,明成祖多次派遣郑和出使西洋。1405年,郑和开始了第一次航行。他的舰队由200多艘船构成,所载人数超过2万人,包括水手、军人、技术人员、译员等,还有大量黄金和丝绸,用于交易和作为礼品。往返用了两年时间。郑和出使的一些国家随船派遣使者(envoy),并带来向明朝进贡的贡品(tribute)。郑和下西洋是世界航海史上的一大壮举(feat)。今天,东南亚仍有很多纪念郑和的建筑。<br>
【参考译文：】    <br>
    In the early Ming Dynasty, China was one of the most developed countries in the world.In order to transmit its national power and strengthen contacts with other countries,Emperor Chengzu sent Zheng He to the Western Ocean many times.In 1405,Zheng He embarked on his first voyage.His fleet was composed of more than 200 ships and carried over 20,000 men,including sailors,soldiers,technical personnel,interpreters etc.,and large amounts of gold and silk to be used for trade and as gifts.The round trip took two years.Some of the countries Zheng He visited dispatched envoys bearing tributes to the Ming court on his ships.Zheng He's voyages were a great feat in the world's navigation history.Today,there are still many buildings in Southeast Asia dedicated to his memory.<br>
四，故宫<br>
【题干：】<br>
　　故宫，又名紫禁城，为明清共二十四位皇帝统治中国近500年的皇宫。它位于北京市中心，在天安门广场的北侧，形状为长方形。南北长960米，东西宽 750米，占地72公顷，总建筑面积达15万平方米。故宫是世界上现存规模最大、最完整的古代木构宫殿。它分为外朝和内廷两部分，外朝是皇帝上朝处理国家大事的地方，内廷是皇帝和皇室的居住地。1987年，故宫被联合国教科文组织列入世界文化遗产。<br>
【翻译词汇：】<br>
　　故宫 the Imperial Palace<br>
　　紫禁城 the Forbidden City<br>
　　天安门广场 Tian’anmen Square<br>
　　长方形 rectangular<br>
　　建筑面积 floor space<br>
　　现存 in existence<br>
　　上朝 give audience<br>
　　处理 handle<br>
　　世界文化遗产 World Cultural Heritage<br>
【参考译文：】<br>
　　The Imperial Palace, also called the Forbidden City was the palace where the 24 emperors of the Ming and Qing Dynasties ruled China for roughly 500 years. The Imperial Palace is located in the center of Beijing, on the northern side of Tian’anmen Square, rectangular in shape, 960 meters from north to south and 750 meters wide from east to west, with an area of 72 hectares and a total floor space of 150 000 square meters. It’s the world’s largest and most integral palace made of wood in existence. The Forbidden City is divided into two parts: the outer court and the inner court. The outer court was the place where the emperors gave audience and handled state affairs, while the inner court was the living quarters for the emperors and their families. In 1987 the Imperial Palace was listed by the UNESCO as one of the World Cultural Heritage sites.<br>
五，孔子<br>
【题干：】<br>
孔子(Confucius)是我国古代著名的思想家、教育家，儒家学派(Confucian School)的创始人。相传孔子有弟子三千，贤弟子72人，孔子曾带领部分弟子周游列国14年。在中国五千年的历史上，对华夏民族的性格、气质 (temperament)产生最大影响的人就算是孔子了。他正直（upright）、乐观向上、积极进取。他一生都在追求真、善、美，一生都在追求理想的社会。他品格中的优点，几千年来影响着中国人，特别是影响着中国的知识分子。<br>
【参考译文：】<br>
Confucius is a famous ideologist, educator, and the founder of Confucian School in ancient China. It's said he has 3,000 disciples, 72 out of whom are excellent ones, and he has led some disciples to visit various states for 14 years. During 5,000 years' history of China, it's Confucius who has exerted the greatest impact on Chinese nation's characteristic and temperament. He is upright,optimistic, active and enterprising, striving for truthfulness, kindness and beauty, and seeking for an ideal society all his life. The shining points in his characteristics have been influencing the Chinese people, especially the Chinese intellectuals for thousands of years.<br>
六，皇帝<br>
【题干：】<br>
皇帝是中国封建社会(feudal society)最高统治者。秦王赢政统一中国之后，称自己为皇帝。自此，中国开始了长达2132年的皇帝统治时期。到1912年中国最后一个皇帝溥仪退位，中国历史上共有495位皇帝。皇帝一人掌握国家政策制定、军事决策等全部大权，决定着国家和人民的命运。中国历史上有许多英明的皇帝，他们勤政爱民，制定了许多合理的政策，促进了经济和社会的发展。还有一些残暴无能的皇帝，他们带给了人民无尽的灾难，受到人民的激烈反抗。<br>
【参考译文:】<br>
　　Emperor was the supreme ruler of the feudalsociety in China. After Yingzheng, the king of Qin,unified China, he called himself Emperor. Sincethen, China had entered a period of emperors'reign,which lasted for 2,132 years. There were totally 495emperors in the history of China until 1912, when Puyi, the last emperor of China gave up thethrone. Emperors dominated all the rights of policy making and military decision and so on.They were the only ones who could decide the fate of the country and its people. In Chinesehistory many wise emperors were diligent in politics and loved their people. They made manyreasonable policies to promote the development of economy and society. There were alsomany cruel and incompetent emperors who brought endless disasters to the people and wereresisted fiercely.<br>
【解析：】<br>
    1.第一句中，“中国封建社会”可用of带出，放在所修饰的名词后面作定语，符合英文表达习惯。<br>
　　2.第三句中“长达2132年的”译为英语时可用which引导的非限制性定语从句来表达，放在中心词后面，使译文前后平衡，避免头重脚轻。<br>
　　3.“到1912年中国最后一个皇帝…”一句的主句采用there be句型，说明中国历史上皇帝的数量;再用until对时间范围进行限制;在“1912”后面使用when引导的定语从句，说明该年份的特殊性：最后一个皇帝退位。<br>
　　4.“皇帝一人掌握…国家和人民的命运”一句偏长，可拆译成两个句子。后半句“决定着国家和人民的命运”翻译时增译主语“皇帝一人”，虽然原文说的是“一个人”，但由于历朝历代都有很多皇帝，因此要处理成复数：theywere the only ones，后面再加who引导的定语从句。<br>
　　5.最后一句中的“他们带给…”译为who引导的定语从句，指代前面的emperors，使译文避免了代词的重复，也使译文的句式更加多样化。<br>
七，5G<br>
China is expected to launch a commercial operation of 5G (5th generation) mobile networks in 2020, and to realize a large-scale application in 2022 or 2023, an expert with the Ministry of Industry and Information Technology (MIIT) of China said here in a recent interview with Xinhua.<br>
　　中国将在2020年推出5G(第5代)移动网络的商业运营，并在2022年或2023 年实现大规模应用，中国工业和信息化部(MIIT)的专家最近接受新华社记者采访时说。<br>
　　Wang Zhiqin, an expert with the China Academy of Telecommunication Research of MIIT, said China started 5G research and development as early as other countries. In 2013, the Chinese government established IMT-2020 (5G) Promotion Group, to boost systematic promotion of 5G.<br>
　　中国工信部电信研究院专家王志勤说，中国早在其他国家之前就开始了5G的研发。2013年，中国政府成立了IMT-2020(5G)推进组，促进5G系统推广。<br>
　　As one of the leaders of the group, Wang said MIIT coordinated to conduct the worldwide biggest experiment of 5G technology research and development in January this year, and completed the phase 1 test in September.<br>
　　作为推进组领导之一的王先生表示，工信部今年1月协调开展了全球最大的5G技术研发实验，并于9月完成了第一阶段的测试。<br>
　　"China is willing to formulate a unified global 5G standard with other countries," She said, adding that the global research on 5G standard started in March, and it is estimated that the first version will be completed in June, 2018.<br>
　　“中国愿意与其他国家制定统一的全球5G标准”她说，并补充说，5G标准的全球研究于3月开始，预计第一版将于2018年6月完成。<br>
　　"We started early and have accumulated a lot of experience," Wang said. "I hope China can be one of the ’dominant players’ in standard formulation."<br>
　　“我们开始得很早，积累了很多经验，”王说。“我希望中国可以成为标准制定的‘主导者’之一。<br>
　　She explained that telecommunication is a globalized and huge industry, and customers are looking forward to a unified standard, "we need to be more responsible and cooperate with the international mainstream enterprises."<br>
　　她解释说，电信是一个全球化的巨大产业，客户期待着统一的标准，“我们需要更加负责任地与国际主流企业合作。”<br>
　　She said 5G is designed for Internet of Everything (IoE), and 4G offers mobile Internet to people. As the increasing need for low delay and high reliability, 4G faces big challenges.<br>
　　她说，5G是为一切互联网(IoE)设计的，4G为人们提供移动互联网。随着对低延迟和高可靠性的日益增长的需求，4G面临着巨大的挑战。<br>
　　"Time delay of 4G is from 10ms to 20ms, but some application scenarios with low delay and high reliability requires less than 0.5ms," Wang said, "and 5G can do that."<br>
　　“4G的延时是10到20毫秒，但是一些具有低延迟和高可靠性的应用场景要求不到0.5毫秒，”王说，“5G可以做到。”<br>
　　She took automatic drive as example - "to realize automatic drive, vehicles should be connected with each other and have the ability to avoid crashes in high speed, which needs a very low time delay."<br>
　　她以自动驾驶为例——“为了实现自动驾驶，车辆应该彼此连接，并具有避免高速撞击的能力，这需要非常低的时间延迟。”<br>
　　China has attached great importance to 5G in the 13th national Five-Year Plan (2016-2020) and has set the goal of 5G commercialization by 2020.<br>
　　中国在十三五规划(2016-2020)中十分重视5G，设立到2020年实现5G的商业化目标。</p>
    </div>
</div>
<div class="card">
<div class="headpic"><img src="https://s2.ax1x.com/2019/12/22/QzVLh6.jpg" alt="QzVLh6.jpg" border="0" /></div>
</div>
<style>
    .card{
        background:var(--mj-card-bg);
        width:70%;
        margin-left: 15%;
        margin-top:15px;
        padding:15px;
        border-radius:15px;
        box-shadow: 0 1px 3px rgb(234, 234, 234);
        text-align:center;
    }
    .cardhr{
        width: 90%;
        margin-left: 5%;        
    }
    .content{
        text-align:left; 
        color: var(--mj-fontcolor);
    }
</style>
</div>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>英语</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐 | 计算机专业，大学课程「笔记归档」</title>
    <url>/posts/a806bebe.html</url>
    <content><![CDATA[<blockquote>
<p>题外话：时光荏苒，青春在时间的河岸慢慢行走，不知不觉中，博主的大学生活渐行渐远，带走的是那四年青春的美好回忆，而留下的是那厚厚的、考试前兢兢业业记录下来的学习笔记，看着一篇篇动辄上W字数的笔记，脑海中还能会想起当时的场景。</p>
</blockquote>
<p>本文是博主本科期间的专业课程学习笔记的整理和归档，适合计算机专业的同学阅读。</p>
<h2 id="一、数据库原理"><a href="#一、数据库原理" class="headerlink" title="一、数据库原理"></a>一、数据库原理</h2><ol>
<li><a href="/posts/41347.html">《数据库原理》笔记</a>，字数总计:18.3k，阅读时长:59分钟</li>
<li><a href="https://github.com/Justlovesmile/database_program">基于MYSQL的BBS论坛管理系统</a>，第一次接触Flask和前端，在自己电脑上做的数据库课设</li>
</ol>
<h2 id="二、软件工程基础"><a href="#二、软件工程基础" class="headerlink" title="二、软件工程基础"></a>二、软件工程基础</h2><ol>
<li><a href="/posts/38368.html">《软件工程基础》知识点</a>，字数总计:5.9k，阅读时长:17分钟</li>
</ol>
<h2 id="三、计算机网络"><a href="#三、计算机网络" class="headerlink" title="三、计算机网络"></a>三、计算机网络</h2><ol>
<li><a href="/posts/28758.html">《计算机网络》学习笔记</a>，字数总计:35.3k，阅读时长:108分钟</li>
</ol>
<h2 id="四、操作系统"><a href="#四、操作系统" class="headerlink" title="四、操作系统"></a>四、操作系统</h2><ol>
<li><a href="/posts/8398.html">计算机《操作系统》笔记</a>，字数总计:20.1k，阅读时长:61分钟</li>
</ol>
<h2 id="五、编译原理"><a href="#五、编译原理" class="headerlink" title="五、编译原理"></a>五、编译原理</h2><ol>
<li><a href="/posts/50753.html">《编译原理》知识点</a>，字数总计:4.5k，阅读时长:13分钟</li>
</ol>
<h2 id="六、算法分析与设计"><a href="#六、算法分析与设计" class="headerlink" title="六、算法分析与设计"></a>六、算法分析与设计</h2><ol>
<li><a href="/posts/16050.html">《算法分析与设计》笔记</a>，字数总计:14k，阅读时长:62分钟，主要是动手敲敲代码，看看算法如何实现</li>
</ol>
<h2 id="七、计算机组成原理"><a href="#七、计算机组成原理" class="headerlink" title="七、计算机组成原理"></a>七、计算机组成原理</h2><ol>
<li><a href="/posts/51917.html">《计算机组成原理》笔记</a>，字数总计:1.9k，阅读时长:5分钟，说实话这门课我没学好</li>
</ol>
<h2 id="八、计算机系统结构"><a href="#八、计算机系统结构" class="headerlink" title="八、计算机系统结构"></a>八、计算机系统结构</h2><ol>
<li><a href="/posts/50754.html">《计算机系统结构》笔记</a>，字数总计:12k，阅读时长:35分钟</li>
<li><a href="/posts/651e6a0b.html">《计算机系统结构》精简知识点</a>，字数总计:8k，阅读时长:24分钟</li>
<li><a href="/posts/47699.html">基于WINDLX的系统结构实验</a>，字数总计:2.9k，阅读时长:10分钟，随机输入n个数，求数i的概率</li>
</ol>
<h2 id="九、计算机图形学"><a href="#九、计算机图形学" class="headerlink" title="九、计算机图形学"></a>九、计算机图形学</h2><ol>
<li><a href="/posts/16593.html">基于MFC和二维变换的画图软件</a>，字数总计:4.2k，阅读时长:14分钟，基于MFC完成的一个画图软件，并且为了完成老师的要求，强行加了二维变换动画</li>
</ol>
<h2 id="十、嵌入式技术课程设计"><a href="#十、嵌入式技术课程设计" class="headerlink" title="十、嵌入式技术课程设计"></a>十、嵌入式技术课程设计</h2><ol>
<li><a href="/posts/14495.html">嵌入式智能大棚监测管理系统</a>，字数总计:5.5k，阅读时长:17分钟，基于Proteus，Arduino，Flask搭建的智能大棚管理系统</li>
</ol>
<h2 id="十一、微机原理与接口技术"><a href="#十一、微机原理与接口技术" class="headerlink" title="十一、微机原理与接口技术"></a>十一、微机原理与接口技术</h2><ol>
<li><a href="/posts/43666.html">《微机原理与接口技术》笔记</a>，字数总计:12.9k，阅读时长:41分钟，有一说一，这篇文章在CSDN阅读1w+是我没想到的</li>
</ol>
<blockquote>
<p>人生的长短不是时间衡量的，而是以思想和行为去衡量，且行且珍惜！</p>
</blockquote>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>大学课程</tag>
      </tags>
  </entry>
  <entry>
    <title>大学课程 | 计算机图形学，基于MFC和二维变换的画图软件</title>
    <url>/posts/16593.html</url>
    <content><![CDATA[<p>我终于肝完了计算机图形学的作业，记录一下我的报告</p>
<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200619203709.png" style="max-width:75%;">

<p>报告里面没有代码，不过上传到github了</p>
<ul>
<li><a href="https://github.com/Justlovesmile/MFC-WORK">Github链接🔗</a></li>
<li><a href="https://gitee.com/justlovesmile/MFC-WORK">Gitee链接🔗</a></li>
</ul>
<h1 id="基于MFC和二维变换的画图软件"><a href="#基于MFC和二维变换的画图软件" class="headerlink" title="基于MFC和二维变换的画图软件"></a>基于MFC和二维变换的画图软件</h1><h2 id="摘-要"><a href="#摘-要" class="headerlink" title="摘  要"></a>摘  要</h2><p>本文描述了二维复合变换的基本方法和思想，根据鼠标位置坐标获取起始点pStart和终止点pEnd的坐标，设计实现每个基本图形的画图方法，根据pStart和pEnd即可确定基本图形的控制点，进而绘制对应图形。规范化齐次坐标以后，图形几何变换可以表示为图形控制点点集合的规范化齐次坐标矩阵与二维变换矩阵相乘的形式，分别设置二维变换矩阵的参数信息，设计实现对应的方法，即可实现图形的二维变换功能。</p>
<h2 id="设-计"><a href="#设-计" class="headerlink" title="设 计"></a>设 计</h2><p>“基于二维复合变换的动画制作软件”的设计中包括以下几个部分：(1) 程序结构设计，(2)鼠标消息映射，(3) 图形绘制实现，(4) 图形变换,（5）动画扩展实现,（6）信息保存,(7)程序交互设计。</p>
<h3 id="1-程序总体结构"><a href="#1-程序总体结构" class="headerlink" title="1 程序总体结构"></a>1 程序总体结构</h3><h4 id="1-1-总体结构设计"><a href="#1-1-总体结构设计" class="headerlink" title="1.1 总体结构设计"></a>1.1 总体结构设计</h4><h5 id="1-1-1-绘图设计"><a href="#1-1-1-绘图设计" class="headerlink" title="1.1.1 绘图设计"></a>1.1.1 绘图设计</h5><p>基本图形包括点，直线，曲线，自由画笔，矩形，圆形，椭圆，三角形，左箭头，上箭头，五角星，四角形，五边形共12钟类型，每个基本图形都有自己的编号，用户在选择基本图形后，被选择图形的编号信息保存到dstyle变量中，绘图模块即可根据dstyle中的编号绘制相应的图形。图形大小，位置信息由全局变量pStart和pEnd控制，pStart和pEnd分别为用户在窗口内拖动鼠标时的起点坐标和终点坐标。根据两个坐标确定一个矩形，按照比例，设置相应的控制点，再根据控制点即可绘制相应图形。绘图流程图见图1.1。</p>
<h5 id="1-1-2-变换设计"><a href="#1-1-2-变换设计" class="headerlink" title="1.1.2 变换设计"></a>1.1.2 变换设计</h5><p>图形变换包括图形移动，图形旋转，图形放缩。绘图模块绘制图形结束后，会将pStart，pEnd，style等基本信息存入图表中。例如，选择旋转类型后，执行对应函数，将图表中所有图形的位置信息修改，再执行重绘函数，按照点表内容依次重绘变换之后的图形，即可实现图形的旋转变换。变换流程图见图1.2。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200619203701.png"></p>
<p>图1.1 绘图流程图</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200619203702.png"></p>
<p>图1.2 变换流程图</p>
<h3 id="2-程序实现"><a href="#2-程序实现" class="headerlink" title="2 程序实现"></a>2 程序实现</h3><h4 id="2-1-鼠标绘图的消息映射"><a href="#2-1-鼠标绘图的消息映射" class="headerlink" title="2.1 鼠标绘图的消息映射"></a>2.1 鼠标绘图的消息映射</h4><p>为了实现基本图形的绘制和组合，需要在项目的视图View类中定义鼠标左键按下OnLButtonDown，鼠标移动OnMouseMove，以及鼠标左键抬起OnLButtonUp的消息映射，以实现拖动鼠标绘图功能。当鼠标左键按下时，设置一个变量为true保存绘图状态并且记录按下时的点，记为pStart，只有当该变量为true时，鼠标移动时才会将绘图，当鼠标左键抬起时，该变量赋值为false,并保存此时的点，记为pEnd。<br>其中，在鼠标左键按下并移动时，使用橡皮筋技术，即移动过程中选用画笔颜色取反模式（SetROP2(R2_NOT)），即可消除移动过程中不断绘制的图形，在鼠标左键抬起时，设置画笔为颜色覆盖模式（SETROP2(R2_COPYPEN)），绘制最终的图形，并保存pStart点和pEnd点，以及笔的粗细，形状，颜色等其他信息。</p>
<h4 id="2-2-图形绘制实现"><a href="#2-2-图形绘制实现" class="headerlink" title="2.2 图形绘制实现"></a>2.2 图形绘制实现</h4><h5 id="2-2-1-点"><a href="#2-2-1-点" class="headerlink" title="2.2.1 点"></a>2.2.1 点</h5><p>由于单个点的像素太小，不利于在图形绘制中使用与观察。这里使用了画一个微型填充圆的方法代替原始像素点。</p>
<h5 id="2-2-2-直线"><a href="#2-2-2-直线" class="headerlink" title="2.2.2 直线"></a>2.2.2 直线</h5><p>从直线起的以下图形的绘制均为根据外接矩形绘制内部图形。绘制图形时，当点击鼠标左键时获取矩形起点，按住不放拖动鼠标直至放开左键，放开鼠标左键的位置记录为矩形的终点。直线的绘制则根据矩形起始点使用MoveTo()和LineTo()函数绘制。</p>
<h5 id="2-2-3-等腰和直角三角形"><a href="#2-2-3-等腰和直角三角形" class="headerlink" title="2.2.3 等腰和直角三角形"></a>2.2.3 等腰和直角三角形</h5><p>在使用鼠标拉取的矩形中选取点位置并用画线函数连接点实现。三角形包括3个顶点。拉取矩形的起点坐标为(pStart.x,pStart.y),终点坐标为(pEnd.x,pEnd.y)。根据两种三角形在矩形中绘制时的对应比例，等腰三角形3个顶点坐标分别为：<br>P1  (pStart.x+pEnd.x)/2,pStart.y);<br>P2  (pStart.x,pEnd.y);<br>P3  (pEnd.x,pEnd.y);<br>直角三角形的三个顶点坐标为：<br>P1  (pStart.x,pStart.y);<br>P2  (pEnd.x,pEnd.y);<br>P3  (pStart.x,pEnd.y);</p>
<h5 id="2-2-4-矩形和填充矩形"><a href="#2-2-4-矩形和填充矩形" class="headerlink" title="2.2.4 矩形和填充矩形"></a>2.2.4 矩形和填充矩形</h5><p>在使用鼠标拉取的矩形中获取了起始点和终止点后用矩形函数实现。拉取矩形的起点坐标为(pStart.x,pStart.y),终点坐标为(pEnd.x,pEnd.y)。要绘制矩形由绘制矩形的函数实现pdc-&gt;Rectangle(pStart.x , pStart.y , pEnd.x,  pEnd.y)。绘制填充矩形则在绘制前使用画刷以填充内部。</p>
<h5 id="2-2-5-圆形和填充圆"><a href="#2-2-5-圆形和填充圆" class="headerlink" title="2.2.5 圆形和填充圆"></a>2.2.5 圆形和填充圆</h5><p>在使用鼠标拉取的矩形中获取了起始点后。将两点间的距离作为要画圆的半径r。使用绘制圆函数进行绘制pdc-&gt;Ellipse(pStart.x-r,pStart.y-r , pStart.x+r , pStart.y+r)。绘制填充矩形则在绘制前使用画刷以填充内部。</p>
<h5 id="2-2-6-自由画笔"><a href="#2-2-6-自由画笔" class="headerlink" title="2.2.6 自由画笔"></a>2.2.6 自由画笔</h5><p>在鼠标左键按下，并且移动的过程中，通过不断触发OnMouseMove消息映射，在移动中的点的位置和上一个位置间连线，即可实现自由画笔功能。</p>
<h5 id="2-2-7-左箭头"><a href="#2-2-7-左箭头" class="headerlink" title="2.2.7 左箭头"></a>2.2.7 左箭头</h5><p>在使用鼠标拉取的矩形中选取点位置并用画线函数连接点实现。左箭头包括7个顶点。拉取矩形的起点坐标为(pStart.x,pStart.y),终点坐标为(pEnd.x,pEnd.y)。根据左箭头在矩形中绘制时的对应比例，7个顶点坐标为：<br>P1  (pStart.x, pStart.y-dy/2);<br>P2  (pStart.x+dx/2),pStart.y);<br>P3  (pStart.x+dx/2), pStart.y-dy/4);<br>P4  (pEnd.x, pStart.y-dy/4);<br>P5  (pEnd.x, pStart.y-3*dy/4);<br>P6  (pStart.x+dx/2), pStart.y-3*dy/4);<br>P7  (pStart.x+dx/2),pEnd.y);<br>其中dy=pStart.y-pEnd.y;dx= pEnd.x-pStart.x</p>
<h5 id="2-2-8-上箭头"><a href="#2-2-8-上箭头" class="headerlink" title="2.2.8 上箭头"></a>2.2.8 上箭头</h5><p>在使用鼠标拉取的矩形中选取点位置并用画线函数连接点实现。上箭头包括7个顶点。拉取矩形的起点坐标为(pStart.x,pStart.y),终点坐标为(pEnd.x,pEnd.y)。根据上箭头在矩形中绘制时的对应比例，7个顶点坐标为：<br>P1  (pStart.x, pStart.y-dy0/2);<br>P2  ( (pStart.x+dx0/2,pStart.y);<br>P3  (pEnd.x, pStart.y-dy0/2);<br>P4  (pStart.x+3*dx0/4, pStart.y-dy0/2);<br>P5  (pStart.x+3*dx0/4,pEnd.y);<br>P6  (pStart.x+dx0/4,pEnd.y);<br>P7  (pStart.x+dx0/4, pStart.y-dy0/2);<br>其中dy0=pStart.y-pEnd.y;dx0=pEnd.x-pStart.x</p>
<h5 id="2-2-9-五角星"><a href="#2-2-9-五角星" class="headerlink" title="2.2.9 五角星"></a>2.2.9 五角星</h5><p>在使用鼠标拉取的矩形中选取点位置并用画线函数连接点实现。五角星绘制包括5个顶点。拉取矩形的起点坐标为(pStart.x,pStart.y),终点坐标为(pEnd.x,pEnd.y)。根据五角星在矩形中绘制时的对应比例，5个顶点坐标为：<br>P1(pStart.x+pEnd.x)/2),pStart.y);<br>P2(pStart.x+RX*(sin(72*pi/180)cos(54*pi/180))/2/sin(72*pi/180)),pEnd.y);<br>P3(pEnd.x, pStart.y+RY*(1-cos(72*pi/180))/(1+sin(54*pi/180)));<br>P4(pStart.x, pStart.y+RY*(1-cos(72*pi/180))/(1+sin(54*pi/180)));<br>P5(pStart.x+RX*(sin(72*pi/180)+cos(54*pi/180))/2/sin(72*pi/180),pEnd.y);<br>其中pi = 3.1415926;RX = -(pStart.x-pEnd.x);RY = -(pStart.y-pEnd.y);</p>
<h5 id="2-2-10-五边形"><a href="#2-2-10-五边形" class="headerlink" title="2.2.10 五边形"></a>2.2.10 五边形</h5><p>在使用鼠标拉取的矩形中选取点位置并用画线函数连接点实现。五边形包括5个顶点。拉取矩形的起点坐标为(pStart.x,pStart.y),终点坐标为(pEnd.x,pEnd.y)。根据五边形在矩形中绘制时的对应比例，5个顶点坐标为：<br>P1  (pStart.x+pEnd.x)/2,pStart.y);<br>P2  (pStart.x,(pEnd.y-pStart.y)*0.41+pStart.y);<br>P3  (pStart.x+(pEnd.x - pStart.x)*0.19,pEnd.y);<br>P4  (pStart.x+(pEnd.x - pStart.x)*0.81,pEnd.y);<br>P5  (pEnd.x, (pEnd.y-pStart.y)*0.41+pStart.y);</p>
<h5 id="2-2-11-四角星"><a href="#2-2-11-四角星" class="headerlink" title="2.2.11 四角星"></a>2.2.11 四角星</h5><p>在使用鼠标拉取的矩形中选取点位置并用画线函数连接点实现。四角星包括8个顶点。拉取矩形的起点坐标为(pStart.x,pStart.y),终点坐标为(pEnd.x,pEnd.y)。根据四角星在矩形中绘制时的对应比例，8个顶点坐标为：<br>P1  ((pStart.x+pEnd.x)/2,pStart.y)<br>P2  (pStart.x+(pEnd.x-pStart.x)*3/8,(pEnd.y-pStart.y)* 3/8+pStart.y);<br>P3  (pStart.x,(pStart.y+pEnd.y)/2);<br>P4  (pStart.x+(pEnd.x-pStart.x)* 3/8,(pEnd.y-pStart.y)*6/8+pStart.y);<br>P5  ((pStart.x + pEnd.x)/2),pEnd.y);<br>P6  (pStart.x+(pEnd.x-pStart.x)* 6/8,(pEnd.y-pStart.y)*6/8+pStart.y);<br>P7  (pEnd.x,(pStart.y+pEnd.y)/2);<br>P8  (pStart.x+(pEnd.x-pStart.x)*6/8,(pEnd.y-pStart.y)*3/8+pStart.y);</p>
<h5 id="2-2-12-弧线"><a href="#2-2-12-弧线" class="headerlink" title="2.2.12 弧线"></a>2.2.12 弧线</h5><p>在使用鼠标拉取的矩形中获取了起始点后,使用绘制椭圆弧线函数进行绘制pdc-&gt;Arc(pStart.x,pStart.y,pEnd.x,pEnd.y,int((pStart.x+pEnd.x)/2),pStart.y,pEnd.x,int((pStart.y+pEnd.y)/2));</p>
<h4 id="2-3-图形变换实现"><a href="#2-3-图形变换实现" class="headerlink" title="2.3 图形变换实现"></a>2.3 图形变换实现</h4><h5 id="2-3-1-图形移动"><a href="#2-3-1-图形移动" class="headerlink" title="2.3.1 图形移动"></a>2.3.1 图形移动</h5><p>图形移动包括包括左移，右移和上移，下移，点表中存有每个图形的pStart点，pEnd点和其他样式信息，绘图函数可根据这些信息重新绘制对应图形，所以只要调用transform.tranlate()函数将pStart，pEnd的x，y坐标同时增加减少相同数值即可完成图形的上下左右移动。</p>
<h5 id="2-3-2-图形旋转"><a href="#2-3-2-图形旋转" class="headerlink" title="2.3.2 图形旋转"></a>2.3.2 图形旋转</h5><p>图形旋转包括顺时针旋转和逆时针旋转。与其他的变换不同的是，旋转需要定义一个旋转中心，默认为坐标系原点。如果没有设置旋转中心，旋转变换可能会导致图形变换到窗口之外，所以设置坐标点(pStart+pEnd)/2为旋转中心，调用Transform.Rotate()函数，即可实现在原位置旋转变换。</p>
<h5 id="2-3-3-图形放缩"><a href="#2-3-3-图形放缩" class="headerlink" title="2.3.3 图形放缩"></a>2.3.3 图形放缩</h5><p>图形放大和缩小是由pStart和pEnd坐标的等比变换实现的。每次放大，将pStart和pEnd的x，y坐标放大两倍，每次缩小将pStart和pEnd的x，y坐标设置为原来的1/2。经过多次放缩后，可能导致图形太大或者太小而不能正常显示的问题，所以每次放缩判断pStart和pEnd之间的距离，如果距离大于窗口距离，或距离小于5个像素则终止放缩并给出相应提示。</p>
<h5 id="2-4-图形变换扩展"><a href="#2-4-图形变换扩展" class="headerlink" title="2.4 图形变换扩展"></a>2.4 图形变换扩展</h5><h5 id="2-4-1-动画设计"><a href="#2-4-1-动画设计" class="headerlink" title="2.4.1 动画设计"></a>2.4.1 动画设计</h5><p>通过自定义文本对话框类（Cchoosedig），实现通过输入框输入获取复合图形变换运动时间的功能，基于原有的图形变化函数，增加根据输入时间循环移动以及延时（Sleep()）的功能，即实现了自定义动画时间的动画制作。</p>
<h5 id="2-4-2-自定义点表结构"><a href="#2-4-2-自定义点表结构" class="headerlink" title="2.4.2 自定义点表结构"></a>2.4.2 自定义点表结构</h5><p>由于动画制作需要修改组合复杂图形的所有点的信息，因此需要遍历点集，再重绘所有图形，因此，自定义了一个结构体，用来存储每一个图形的信息，其中信息包括：起始点，终止点，图形类型，画笔类型，画笔粗细，画笔颜色，结构体如图2.1，然后为这个结构体创建链表，再修改文档类的串行化Serialize函数即可。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200619203703.png"></p>
<p>图2.1 自定义结构体</p>
<h5 id="2-4-3-运动时间设置"><a href="#2-4-3-运动时间设置" class="headerlink" title="2.4.3 运动时间设置"></a>2.4.3 运动时间设置</h5><p>为了自定义运动时间，采用了文本对话框，通过输入运动时间，从对话框获取信息，保存到变量，再传递到View类，实现动画制作功能。时间设置效果如图2.2所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200619203704.png"></p>
<p>图2.2 运动时间设置</p>
<h5 id="2-4-4-图形重绘"><a href="#2-4-4-图形重绘" class="headerlink" title="2.4.4 图形重绘"></a>2.4.4 图形重绘</h5><p>对于图形重绘，先暂存当前所选择的图形类型，画笔，颜色等信息，再获取点表的长度，然后循环遍历点表，取出点表中的数据，赋值给CDC类的指针对象pdc，根据图形类型和其他信息画出所有对应的图形。最后恢复之前暂存的信息，即可实现图形重绘功能，且不影响当前选择的样式。</p>
<h5 id="2-5-程序交互实现"><a href="#2-5-程序交互实现" class="headerlink" title="2.5 程序交互实现"></a>2.5 程序交互实现</h5><h5 id="2-5-1-绘图类型选择"><a href="#2-5-1-绘图类型选择" class="headerlink" title="2.5.1 绘图类型选择"></a>2.5.1 绘图类型选择</h5><p>通过点击菜单栏的图标按钮，如图2.3所示，可以设置绘制图形的类型。具体实现是，当按钮被点击，调用相应的响应函数设置dstyle，并设置cclick为false即可。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200619203705.png"></p>
<p>图2.3 菜单栏中选择绘图类型的按钮</p>
<h5 id="2-5-2-画笔颜色选择"><a href="#2-5-2-画笔颜色选择" class="headerlink" title="2.5.2 画笔颜色选择"></a>2.5.2 画笔颜色选择</h5><p>颜色设置是调用系统自带的颜色对话框（CColorDialog）完成对画笔、画刷颜色的选择，同时选用该对话框能够实现自定义颜色。颜色选择对话框如图2.4所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200619203706.png"></p>
<p>图2.4 颜色选择对话框</p>
<h5 id="2-5-3-画笔类型选择"><a href="#2-5-3-画笔类型选择" class="headerlink" title="2.5.3 画笔类型选择"></a>2.5.3 画笔类型选择</h5><p>在菜单栏中，有画笔形状和画笔粗细可以选择。其中，画笔形状包含包含直线（PS_SOLID），点线（PS_DOT），虚线（PS_DASH），画笔粗细包括粗线，标准线和细线。根据选择的画笔类型，设置type和thickness的值即可。其中，画笔形状中的虚线和点线只有在画笔粗细为细线的时候才能正常显示，当画笔粗细为标准或者粗线时，画出来的都是实线。</p>
<h5 id="2-5-4-清屏"><a href="#2-5-4-清屏" class="headerlink" title="2.5.4 清屏"></a>2.5.4 清屏</h5><p>在清屏时，首先会有弹窗提示是否确定清屏，点击“否”则取消操作，点击“是”则进行清屏。清屏功能的具体操作是先调用RedrawWindow()函数清屏，然后清空点表MyList并设置dstyle和cclick分别为初始值0和false即可。</p>
<h5 id="2-5-5-回退"><a href="#2-5-5-回退" class="headerlink" title="2.5.5 回退"></a>2.5.5 回退</h5><p>由于本项目把每个图形外接矩形的一对顶点保存在了点表MyList中的一个自定义的节点结构体中，所以在回退时，我们只需要删除点表中的最后一个节点，然后根据点表重新绘图即可。</p>
<h3 id="3-程序运行效果"><a href="#3-程序运行效果" class="headerlink" title="3 程序运行效果"></a>3 程序运行效果</h3><h4 id="3-1-基本图形实现"><a href="#3-1-基本图形实现" class="headerlink" title="3.1 基本图形实现"></a>3.1 基本图形实现</h4><p>设计实现了包含点，直线段，椭圆弧线，矩形，填充矩形，等腰三角形，直角三角形，椭圆，圆，填充圆，五边形，五角星，四角星，箭头等多种基础图形，并且实现画图以及选择画笔类型功能，初始窗口如图3.1所示，基础图形效果如图3.2所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200619203707.png"></p>
<p>图3.1 初始窗口</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200619203708.png"></p>
<p>图3.2 基础图形效果</p>
<h4 id="3-2-组合复杂图形以及整体变换"><a href="#3-2-组合复杂图形以及整体变换" class="headerlink" title="3.2 组合复杂图形以及整体变换"></a>3.2 组合复杂图形以及整体变换</h4><p>实现了基本图形组合成复杂图形的功能，并且具有回退，清空画布，颜色等功能，具有包含平移，旋转，放大缩小，输入动画时长的功能。组合复杂图形以及变换效果如图3.3所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200619203709.png"></p>
<p>图3.3 组合复杂图形及变换</p>
<h3 id="4-结论"><a href="#4-结论" class="headerlink" title="4 结论"></a>4 结论</h3><p>通过这次的计算机图形学实践，我们熟悉了计算机是如何利用算法来生成，处理和显示图形的，学习了如何通过使用Visual C++ 6.0编程环境的MFC框架进行计算机图形学的编程。在程序编写的过程中，我们掌握了很多MFC库所提供的类及其功能函数的使用方法，也根据项目的需要编写了很多自定义的结构体和功能函数。在实验的过程中，我们逐渐了解了MFC框架中，不同类的功能和定义方法，明白了双缓冲机制的原理，熟悉了基本的消息映射功能和对话框的设计，以及如何在不同类间传递数据的方法。并且，在动画制作的过程中，我们又进一步加强了对于二维变化的理解，知道了图形变化的本质还是数学计算。在老师的帮助和我们小组的努力下，我们的收获是如此巨大，我们相信在今后的学习生活中，图形学的原理知识将会给我们很大的帮助。</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>大学课程</tag>
        <tag>计算机图形学</tag>
        <tag>MFC</tag>
      </tags>
  </entry>
  <entry>
    <title>大学课程 | 基于WINDLX的系统结构实验</title>
    <url>/posts/47699.html</url>
    <content><![CDATA[<p>基于WindLX的计算机系统结构实验，随机输入n个数，求数i的概率</p>
<p>源码：<br><a href="https://github.com/Justlovesmile/WindLX-Experiment">https://github.com/Justlovesmile/WindLX-Experiment</a><br><a href="https://gitee.com/justlovesmile/WindLX-Experiment">https://gitee.com/justlovesmile/WindLX-Experiment</a></p>
<h1 id="《计算机系统结构》课程实验"><a href="#《计算机系统结构》课程实验" class="headerlink" title="《计算机系统结构》课程实验"></a>《计算机系统结构》课程实验</h1><h3 id="一、实验名称："><a href="#一、实验名称：" class="headerlink" title="一、实验名称："></a>一、实验名称：</h3><p>随机输入n个数，求数i的概率</p>
<h3 id="二、实验原理："><a href="#二、实验原理：" class="headerlink" title="二、实验原理："></a>二、实验原理：</h3><ol>
<li>WinDLX平台与流水线<br>WinDLX是一个基于Windows的、图形化、交互式的模拟器，能够演示DLX流水线是如何工作的，它采取伪汇编形式编码，模拟流水线的工作方式。流水线的指令执行分为5个阶段：取指、译码、执行、访存、写回。<br>WinDLX模拟器还提供了对流水线操作的统计功能，便于对流水线进行性能分析。</li>
<li>流水线中的相关及解决办法<br>（1）结构相关：当某一条机器指令需要访问物理器件时，该器件可能正在被占用，例如连续的两条加法指令都需要用到浮点加法器，就产生结构相关，可以通过增加加法器的方式解决结构相关；<br>（2）数据相关：当某一条指令需要访问某个寄存器时，此时这个寄存器正被另一条指令所使用，从而产生数据相关，可以通过重定向技术解决数据相关；<br>（3）控制相关：当程序执行到某个循环语句时，顺序执行的下一条语句将被跳继续执行循环体的内容，从而产生控制相关，可以通过循环展开解决控制相关。</li>
</ol>
<h3 id="三、实验目的："><a href="#三、实验目的：" class="headerlink" title="三、实验目的："></a>三、实验目的：</h3><p>1、加深对流水线理论知识的理解；<br>2、掌握对流水线性能分析的方法，了解影响流水线效率的因素；<br>3、熟悉在WinDLX体系结构下的汇编代码编写和优化；<br>4、了解相关的类型及各类相关的解决办法；<br>5、培养运用所学知识解决实际问题的能力。</p>
<h3 id="四、实验内容："><a href="#四、实验内容：" class="headerlink" title="四、实验内容："></a>四、实验内容：</h3><p>1、根据WinDLX模拟器伪汇编指令规则编写：随机输入n个数后，求数i的概率的程序gailv.s以及input.s<br>2、分别按照不同顺序将gailv.s和input.s装入主存，分析输入顺序不同对运行结果产生的影响；<br>3、观察程序中出现的数据、控制、结构相关，指出程序中出现上述现象的指令组合，并提出解决相关的办法；<br>4、分别考察各类解决的相关办法，分析解决相关后性能的变化。<br>注意：<br>除解决结构相关，其他情况下加、乘、除运算器都只有一个。<br>本问题中所有浮点延迟部件设置为：加法：2个延迟周期；乘法：5个延迟周期；除法：19个延迟周期。</p>
<h3 id="五、实验器材（设备、元器件）："><a href="#五、实验器材（设备、元器件）：" class="headerlink" title="五、实验器材（设备、元器件）："></a>五、实验器材（设备、元器件）：</h3><p>设备：笔记本电脑一台<br>软件：VMware Workstation<br>虚拟机：Windows7 32位操作系统<br>WinDLX模拟器</p>
<h3 id="六、实验步骤及操作："><a href="#六、实验步骤及操作：" class="headerlink" title="六、实验步骤及操作："></a>六、实验步骤及操作：</h3><p>1、初始化WinDLX模拟器<br>（1）为WinDLX创建目录，C:\WinDLX。将WinDLX和gailv.s、gailv2.s、input.s放在这个目录中。<br>（2）初始化WinDLX模拟器：点击File 菜单中的 Reset all 菜单项，弹出一个“Reset DLX”对话框，点击窗口中的“确认”按钮即可。如图1所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200614105647.png"></p>
<p>图1 初始化模拟器界面</p>
<p>2、将程序装入WinDLX平台<br>点击File 菜单中的 Load Code or Data 菜单项，依次双击gailv.s和input.s。点击load，将两个程序装入。如图2所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200614110049.png"></p>
<p>图2 程序装入界面</p>
<p>3、运行程序并观察</p>
<p>进行单步调试，在WinDLX模拟器的6个子窗口观察程序的执行情况。观察程序运行的总时钟周期，产生的相关种类以及每种相关的数量。</p>
<p>4、解决数据相关</p>
<p>勾选Enable Forwading，采用重定向技术添加专用数据通路减少数据相关，观察数据相关的数量变化。</p>
<p>5、解决结构相关</p>
<p>将Addition Units的数目由1到2，观察结构相关的数量变化。</p>
<p>6、解决控制相关</p>
<p>将gaillv.s的循环体展开形成新文件gailv2.s，采用循环展开的方法减少控制相关，观察控制相关的数量变化。</p>
<h3 id="七、实验数据及结果分析："><a href="#七、实验数据及结果分析：" class="headerlink" title="七、实验数据及结果分析："></a>七、实验数据及结果分析：</h3><p>1、程序装入顺序对运行结果的影响<br>先装入gailv.s再装入input.s时，程序能够正确执行；当先装入input.s再装入gailv.s时，因为input.s的地址高，而程序顺序执行到input.s时无法正确地输出，因此不会出现结果。</p>
<p>2、主要代码及说明<br>(1)gailv.s主要代码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.data</span><br><span class="line">Prompt:         .asciiz     &quot;input An integer which is array&#x27;s size value &gt;=0 : &quot;</span><br><span class="line">PromptLast:    .asciiz     &quot;input an integer :&quot;</span><br><span class="line">PromptNum:     .asciiz     &quot;input an integer&gt;=0 which you need:&quot;</span><br><span class="line">PrintfFormat:   .asciiz     &quot;Probability: %g &quot;</span><br><span class="line">PromptError:   .asciiz     &quot;Error!Need int&gt;=0!Input:(Go:1,other to End)&quot;</span><br><span class="line">.align   2</span><br><span class="line">PrintfPar:      .word        PrintfFormat</span><br><span class="line">Printf:        .space       8</span><br><span class="line">PrintfValue:    .space       1024</span><br><span class="line">.text</span><br><span class="line">.global main</span><br><span class="line">main:</span><br><span class="line">                ;*** 输入数组大小和相关初始化</span><br><span class="line">                addi            r1,r0,Prompt     ;将Prompt字符串首地址放入r1寄存器中</span><br><span class="line">                jal         InputUnsigned    ;跳转子函数，输入数组大小n</span><br><span class="line">                bnez           r10,Error        ;输入异常处理</span><br><span class="line">                beqz           r1,InputNum      ;如果r1为0，跳转InputNum</span><br><span class="line">                add            r2,r0,r1         ;将数组大小n存于r2</span><br><span class="line">                add            r6,r0,r1         ;将数组大小n存于r6</span><br><span class="line">                addi           r3,r0,0          ;初始化r3</span><br><span class="line">                addi           r7,r0,1          ;r7等于1</span><br><span class="line">                movi2fp        f1,r7            ;f1等于1</span><br><span class="line">                addf           f2,f2,f0         ;初始化f2,f3,f4</span><br><span class="line">                addf           f3,f3,f0</span><br><span class="line">                addf           f4,f4,f0</span><br><span class="line">                movi2fp        f5,r1            ;将数组大小n存于f5</span><br><span class="line"></span><br><span class="line">InputArray:</span><br><span class="line">                ;*** 输入数组</span><br><span class="line">                beqz           r2, ProcessPart      ;如果r2等于0则跳转ProcessPart </span><br><span class="line">                addi           r1,r0,PromptLast     ;输入数字</span><br><span class="line">                jal            InputUnsigned</span><br><span class="line">                bnez           r10,Error</span><br><span class="line">                sw             PrintfValue(r3),r1   ;将r1寄存器中的数放入r3寄存区中所存数地址的存储器中</span><br><span class="line">                addi           r3,r3,4              ;r3后移</span><br><span class="line">                subi           r2,r2,1              ;r2减1</span><br><span class="line">                j              InputArray           ;循环输入</span><br><span class="line"></span><br><span class="line">ProcessPart:</span><br><span class="line">                addi           r3,r0,0              ;初始化r3</span><br><span class="line"></span><br><span class="line">InputNum:</span><br><span class="line">                ;*** 输入求概率的数字 </span><br><span class="line">                addi           r1,r0,PromptNum</span><br><span class="line">                jal            InputUnsigned</span><br><span class="line">                 bnez           r10,Error</span><br><span class="line">                add            r2,r0,r1             ;保存i到r2</span><br><span class="line">                movi2fp        f2,r2                ;保存i到f2</span><br><span class="line"></span><br><span class="line">Loop:</span><br><span class="line">                ;*** 循环与计数       </span><br><span class="line">                beqz           r6,Output          ;如果r6等于0则结束Loop跳转Output</span><br><span class="line">                subi           r6,r6,1            ;r6减1</span><br><span class="line">                lf             f3,PrintfValue(r3) ;取出r3地址中的数到f3</span><br><span class="line">                addi           r3,r3,4            ;r3后移</span><br><span class="line">                movfp2i        r7,f2                </span><br><span class="line">                movfp2i        r8,f3</span><br><span class="line">                seq            r12,r7,r8          ;如果r7等于r8,r12为1，否则为0 </span><br><span class="line">                bnez           r12,Sum            ;r12为不等于0,则跳转到Sum计数，否则继续循环</span><br><span class="line">                j              Loop               ;循环</span><br><span class="line"></span><br><span class="line">Sum:</span><br><span class="line">                addf           f4,f4,f1           ;计数</span><br><span class="line">                j              Loop</span><br><span class="line"></span><br><span class="line">Output:</span><br><span class="line">                cvti2d         f0,f4              ;单精度转换为双精度</span><br><span class="line">                cvti2d         f6,f5</span><br><span class="line">                movfp2i        r5,f5</span><br><span class="line">                beqz           r5,OutputInner     ;分母为0</span><br><span class="line">                divd           f6,f0,f6           ;f6=f0/f6</span><br><span class="line"></span><br><span class="line">OutputInner:</span><br><span class="line">                sd              Printf,f6</span><br><span class="line">                addi            r14,r0,PrintfPar     </span><br><span class="line">                trap            5                    ;标准输出</span><br><span class="line">                trap            0                    ;程序结束</span><br><span class="line"></span><br><span class="line">Error:</span><br><span class="line">                addi            r1,r0,PromptError</span><br><span class="line">                jal             InputUnsigned</span><br><span class="line">                bnez            r1,main</span><br><span class="line">                    trap                0</span><br></pre></td></tr></table></figure>

<p>（2）input.s主要代码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Loop:       ;*** reads digits to end of line</span><br><span class="line">        lbu         r3,0(r2)</span><br><span class="line">        seqi        r5,r3,10    ;LF -&gt; Exit</span><br><span class="line">        bnez        r5,Finish</span><br><span class="line">        slti        r11,r3,58;***判断是否为非法字符</span><br><span class="line">        beqz        r11,Error</span><br><span class="line">        slti        r10,r3,48   </span><br><span class="line">        bnez        r10,Error</span><br><span class="line">        subi        r3,r3,48    ;转换ASCAII码</span><br><span class="line">        multu       r1,r1,r4    ;转换十进制</span><br><span class="line">        add         r1,r1,r3</span><br><span class="line">        addi        r2,r2,1     ;指针后移</span><br><span class="line">        j           Loop</span><br></pre></td></tr></table></figure>

<p>3、程序分析及运行结果</p>
<p>（1）根据提示输入一个正整数n代表接下来输入的数的总个数。<br>测试用例：n=5。</p>
<p>（2）再根据提示输入n个数字。<br>测试用例：1，2，3，3，4</p>
<p>（3）输入想要求概率的数i。<br>测试用例：3</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200614110236.png"></p>
<p>图3 运行结果截图</p>
<p>由图3可知运行结果为0.4，计算结果正确。</p>
<p>（4）异常处理：输入任何不是自然数的字符，如：负数，小数，以及其他非法字符均会提示错误。异常处理结果如图4所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200614110251.png"></p>
<p>图4 异常处理结果截图</p>
<p>（5）点击Statistics窗口，查看程序执行的时钟周期以及数据相关、结构相关、控制相关的发生次数。<br>程序执行共用621个时钟周期，数据相关发生172次，结构相关发生2次，控制相关发生42次，如图5所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200614110327.png"></p>
<p>图5 时钟周期和相关数据截图</p>
<p>4、数据相关及解决</p>
<p>（1）数据相关产生的原因</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movfp2i              r8,f3</span><br><span class="line">seq                  r12,r7,r8       ;如果r7等于r8,r12为1，否则为0 </span><br><span class="line">bnez                 r12,Sum         ;r12为不等于0,则跳转到Sum计数，否则继续循环</span><br></pre></td></tr></table></figure>

<p>seq指令要使用r8寄存器的数据，但是上一条指令movfp2i刚刚执行完数据还没有更新，产生数据相关，并且之后的bnez指令也需要上一条seq指令的中还没更新的寄存器r12，产生数据相关，如图6所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200614110345.png"> </p>
<p>图6 数据相关截图</p>
<p>（2）数据相关的解决</p>
<p>采用重定向技术，勾选Configuration的Enable Forwading选项。在第一条指令结束后直接将寄存器r8的内容更新，在第二条指令结束后直接将寄存器r12数据更新，以此来消除数据相关，如图7所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200614110407.png"></p>
<p>图7 解决数据相关截图</p>
<p>查看运行结果，数据相关数量降低了64，处理后的数据相关个数为108，如图8所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200614110622.png"></p>
<p>图8 解决数据相关的数据截图</p>
<p>5、控制相关及解决</p>
<p>（1）控制相关的产生原因</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Loop:       ;*** 循环与计数       </span><br><span class="line">            beqz          r6,Output          ;如果r6等于0则结束Loop跳转Output</span><br><span class="line">            subi          r6,r6,1            ;r6减1</span><br><span class="line">            lf            f3,PrintfValue(r3) ;取出r3地址中的数到f3</span><br><span class="line">            addi          r3,r3,4          ;r3后移</span><br><span class="line">                movfp2i       r7,f2                </span><br><span class="line">            movfp2i       r8,f3</span><br><span class="line">            seq           r12,r7,r8        ;如果r7等于r8,r12为1，否则为0 </span><br><span class="line">            bnez          r12,Sum   ;r12为不等于0,则跳转到Sum计数，否则继续循环</span><br><span class="line">            j             Loop      ;循环</span><br></pre></td></tr></table></figure>

<p>在这段程序中，循环体的出现造成了控制相关。</p>
<p>（2）控制相关的解决</p>
<p>采用循环展开的方式将循环体的内容复制一次。可以降低控制相关的个数。如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Loop:       ;*** 循环与计数      </span><br><span class="line">            beqz          r6,Output          ;如果r6等于0则结束Loop跳转Output</span><br><span class="line">            subi          r6,r6,1            ;r6减1</span><br><span class="line">            lf            f3,PrintfValue(r3) ;取出r3地址中的数到f3</span><br><span class="line">            addi          r3,r3,4            ;r3后移</span><br><span class="line">                movfp2i       r7,f2                </span><br><span class="line">            movfp2i       r8,f3</span><br><span class="line">            seq           r12,r7,r8    ;如果r7等于r8,r12为1，否则为0 </span><br><span class="line">            bnez          r12,Sum      ;r12为不等于0,则跳转到Sum计数，否则继续循环</span><br><span class="line">            beqz          r6,Output          ;如果r6等于0则结束Loop跳转Output</span><br><span class="line">            subi          r6,r6,1            ;r6减1</span><br><span class="line">            lf            f3,PrintfValue(r3) ;取出r3地址中的数到f3</span><br><span class="line">            addi          r3,r3,4            ;r3后移</span><br><span class="line">                movfp2i       r7,f2                </span><br><span class="line">            movfp2i       r8,f3</span><br><span class="line">            seq           r12,r7,r8    ;如果r7等于r8,r12为1，否则为0 </span><br><span class="line">            bnez          r12,Sum      ;r12为不等于0,则跳转到Sum计数，否则继续循环</span><br><span class="line">            j             Loop         ;循环</span><br></pre></td></tr></table></figure>

<p>重新运行后控制相关数量减少为40，如图9所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200614120000.png"></p>
<p>图9 解决控制相关的数据截图</p>
<p>6、结构相关及解决</p>
<p>（1）结构相关产生的原因</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">addf          f2,f2,f0         ;初始化f2,f3,f4</span><br><span class="line">addf          f3,f3,f0</span><br><span class="line">addf          f4,f4,f0</span><br></pre></td></tr></table></figure>

<p>在这段语句运行时需要连续进行加操作，由于加法器只有一个，产生结构相关。</p>
<p>（2）结构相关的解决</p>
<p>添加加法器Addition Units的个数，如图10所示。</p>
<p> <img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200614110830.png"></p>
<p>图10 增加加法器Addition Units界面的截图</p>
<p>再次运行程序可以发现结构相关数量降低，降低到0个，如图11所示。</p>
<p> <img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200614120002.png"></p>
<p>图11 解决结构相关的数据截图</p>
<p>7、程序流程图</p>
<p>如图12所示。</p>
<p> <img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200614120003.png"></p>
<p>图12 程序流程图</p>
<h3 id="八、实验结论："><a href="#八、实验结论：" class="headerlink" title="八、实验结论："></a>八、实验结论：</h3><ol>
<li>通过采用重定向技术减少了数据相关；</li>
<li>通过循环展开的方式将循环体的内容展开来减少控制相关；</li>
<li>通过增加硬件的数目来减少结构相关；</li>
<li>执行程序的顺序会影响程序执行是否正确，必须先执行源程序gailv.s，再执行input.s；修改后的程序必须清空之前所有的操作（reset all）之后再重新运行。</li>
</ol>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>大学课程</tag>
        <tag>计算机系统结构</tag>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title>大学课程 | 嵌入式智能大棚监测管理系统</title>
    <url>/posts/14495.html</url>
    <content><![CDATA[<p>我又肝完了一门课，<strong>嵌入式课程设计</strong>==&gt;基于Proteus，Arduino，Flask搭建的<strong>智能大棚管理系统</strong><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624120328.png"></p>
<blockquote>
<p>源程序👇<br><a href="https://github.com/Justlovesmile/Greenhouse-management-system">Github🔗</a><br><a href="https://gitee.com/justlovesmile/Greenhouse-management-system">Gitee🔗</a></p>
</blockquote>
<h1 id="智能大棚监测管理系统简介"><a href="#智能大棚监测管理系统简介" class="headerlink" title="智能大棚监测管理系统简介"></a>智能大棚监测管理系统简介</h1><h2 id="1-主要内容"><a href="#1-主要内容" class="headerlink" title="1.主要内容"></a>1.主要内容</h2><ul>
<li>硬件嵌入式系统：采用FreeRTOS实时系统和Arduino UNO平台，以及ATMEGA328P微控制器，进行控制，结合DHT11,BMP180等多种传感器进行数据监测，具有自动控制和监测警报功能，能通过前端切换工作模式</li>
<li>数据库：基于Python的pymsql库使用MYSQL数据库，能自动创建数据库，表以及存储和查找数据。</li>
<li>服务器：基于Python的Flask框架搭建，能控制串口读写</li>
<li>前端：具有登录检测，数据查询，远程控制功能</li>
</ul>
<h2 id="2-采用的工具方法"><a href="#2-采用的工具方法" class="headerlink" title="2.采用的工具方法"></a>2.采用的工具方法</h2><ul>
<li>Proteus 8.6</li>
<li>Visual Studio Code</li>
<li>Arduino</li>
<li>Python3.8</li>
<li>MySQL 8.0.15</li>
</ul>
<h1 id="我的报告-爆肝"><a href="#我的报告-爆肝" class="headerlink" title="我的报告(爆肝)"></a>我的报告(爆肝)</h1><div style="text-align: center;"><h1>智能大棚设计与实现</h1></div>

<p><strong>摘要：</strong>随着社会的不断发展，传统的农业生产活动方式，诸如农民亲自灌溉，施肥，搭棚保温的方式，这些落后的生产方式已经不能满足现代的经济发展需求，智能化，信息化的农业设计成为了农业发展的趋势。本文设计了一款简单易操作的智能大棚环境监测管理系统，能适用于温室大棚的数据监控和远程硬件操作功能，该系统基于嵌入式系统设计方法，使用了RTOS和Arduino UNO微处理器作为系统的主控芯片，使用了DHT11温湿度传感器，LDR光敏电阻，BMP180气压传感器作为外界环境监测模块，使用了COMPIM进行串口通信，结合Flask服务器框架和MySQL数据库，搭建了Web端和数据库，并优化了前端界面。实现了传感器对环境数据和设备数据进行收集分析处理后，通过串口存储于数据库中，用户通过前端网页实时监测环境数据，并可以控制硬件的状态。该智能大棚监测管理系统，简单易操作，智能化程度高，功能完备，十分适用于农业大棚的监测与管理。</p>
<p><strong>关键词：</strong>嵌入式；智能大棚；传感器；服务器；Arduino</p>
<h2 id="一，系统简介"><a href="#一，系统简介" class="headerlink" title="一，系统简介"></a><strong>一，系统简介</strong></h2><p>  为了实现农业温室大棚的自动化，智能化管理，设计了智能大棚监测管理系统，该系统是基于嵌入式设计技术，利用了Arduino Uno平台，虚拟仿真实验环境Proteus软件，实时操作系统FreeRTOS，实现硬件及Arduino虚拟开发和仿真，根据传感器的检测值，进行判断处理，具有自动控制硬件调节功能和警报功能，再结合Python的Flask库搭建服务器端，serial库进行硬件和服务器端信息传输，以及MySQL进行数据存储，实现了对大棚内温度，湿度，光照，气压的监测和记录，以及对硬件设备，如风机，除湿器，照明，气泵的运行状态的监测和管理，能在Web端实时显示环境和设备运行数据和选择自动以及手动控制硬件的模式，能在前端控制硬件运行，能从数据库选择获取不同时间段的数据并以图表形式展示，并且具有登录登出功能。该系统操作简单，不需耗费大量人力物力学习掌握，能满足正常的数据监控和远程管理以及自动管理需要。</p>
<h2 id="二，需求分析和概要设计"><a href="#二，需求分析和概要设计" class="headerlink" title="二，需求分析和概要设计"></a><strong>二，需求分析和概要设计</strong></h2><h3 id="1-需求分析"><a href="#1-需求分析" class="headerlink" title="1.需求分析"></a>1.需求分析</h3><p>  在当今智能化的背景下，传统的管理方式已经无法满足对温室大棚的实时监测和控制，尤其是因为当今的温室大棚种植面积普遍较大的，因此，从用户的角度出发，对于大棚的管理，最重要的就是实时监测处理大棚内的温度，湿度，光照和棚内气压等数据，这就需要智能大棚管理系统具有对环境的敏感性和监测的实时性，对于用户而言，他可能还需要了解最近一段时间棚内环境的变换以对未来可能发生的情况进行提前预测，以及了解设备的运行情况做出相应更换等措施，因此需要保存环境和设备运行状况的历史数据。并且系统还应该具有智能处理的功能，当环境变量发生改变，处于不适宜大棚内作物生长的环境时，系统还应该自动控制设备进行相应操作。除此以外，系统需要具有简单易操作，低成本的特点，这样才能减少人工看护和操作的费用，降低成本。对于远程在外的用户，还可以通过云平台进行实时监测和设备控制，从而实现对大棚的智能化，自动化监测管理。</p>
<h3 id="2-概要设计"><a href="#2-概要设计" class="headerlink" title="2.概要设计"></a>2.概要设计</h3><p>  通过上文对需求的分析，可以得出，智能大棚监测管理系统应该具有数据监控模块，数据传输模块，控制模块，警报模块，数据库模块，服务器模块以及前端模块，系统功能结构框图如图2.1所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624114845.png"></p>
<p>图2.1 系统功能结构框图</p>
<h4 id="2-1-数据监控模块"><a href="#2-1-数据监控模块" class="headerlink" title="2.1 数据监控模块"></a>2.1 数据监控模块</h4><p>  数据监控是本系统最为重要的一环，数据的获取主要通过三种器件，包括DHT11温湿度传感器，LDR光敏电阻以及BMP180气压传感器，它们在Proteus软件示意图如图2.2所示。数据监控模块的逻辑控制流程图如图2.3所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624114924.png"></p>
<p>图2.2  DHT11(左上),LDR(左下),BMP180(右上)在Proteus中的示意图</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624114940.png"></p>
<p>图2.3 数据监控控制流程图</p>
<p>  由流程图可以看出，数据监控模块主要依靠不断读取三个传感器对温度，湿度，光照，气压的数据信息实现。</p>
<h4 id="2-2-数据传输模块"><a href="#2-2-数据传输模块" class="headerlink" title="2.2 数据传输模块"></a>2.2 数据传输模块</h4><p>  数据传输模块包括了，硬件端传输数据到数据库以及服务器端传输数据到硬件两个部分。</p>
<h5 id="2-2-1-硬件到数据库"><a href="#2-2-1-硬件到数据库" class="headerlink" title="2.2.1 硬件到数据库"></a>2.2.1 硬件到数据库</h5><p>  硬件端到数据库之间的数据传输主要是为了进行数据存储，因此需要规定硬件写入到串口的格式，并传到服务器端接受，按照规定的格式解析并存储到数据库，硬件到数据库的数据传输流程图如图2.4所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624115022.png"></p>
<p>图2.4 硬件到数据库的数据传输流程图</p>
<h5 id="2-2-2-服务器到硬件"><a href="#2-2-2-服务器到硬件" class="headerlink" title="2.2.2 服务器到硬件"></a>2.2.2 服务器到硬件</h5><p>  服务器端到硬件的数据传输主要是为了传输前端的控制信息，包括控制选择自动与手动模式，是否开启或关闭相应硬件等控制信息，服务器到硬件的数据传输流程图如图2.5所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624115155.png"></p>
<p>图2.5 服务器到硬件的数据传输流程图</p>
<h4 id="2-3-控制模块"><a href="#2-3-控制模块" class="headerlink" title="2.3 控制模块"></a>2.3 控制模块</h4><p>  控制模块包括了自动控制模块和手动控制模块。</p>
<h5 id="2-3-1-自动控制模块"><a href="#2-3-1-自动控制模块" class="headerlink" title="2.3.1 自动控制模块"></a>2.3.1 自动控制模块</h5><p>  当硬件第一次运行时，默认为自动模式，此时，数据监控时会根据设定的危险范围进行相应的操作，例如当温度超过某个值时，打开风机，否则关闭风机，当湿度超过某个值时，打开除湿器，否则关闭除湿器，自动控制流程图如图2.6所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624115306.png"></p>
<p>图2.6 自动控制流程图</p>
<h5 id="2-3-2-手动控制模块"><a href="#2-3-2-手动控制模块" class="headerlink" title="2.3.2 手动控制模块"></a>2.3.2 手动控制模块</h5><p>  当服务器端传进来的数据为9时，关闭自动模式，此时硬件运行状态通过之后服务器端传来的数据控制，不同的数据对应不同的操作，手动控制流程图如图2.7所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624115328.png"></p>
<p>图2.7 手动控制流程图</p>
<h4 id="2-4-警示灯模块"><a href="#2-4-警示灯模块" class="headerlink" title="2.4 警示灯模块"></a>2.4 警示灯模块</h4><p>  为了更好的提醒用户温室大棚内的环境是否正常，设置了警示灯模块，通过不断获取环境数据并和危险区间的上下界进行比较，执行相应的警示灯亮起或熄灭操作，警示灯流程图如图2.8所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624115347.png"></p>
<p>图2.8 警示灯流程图</p>
<h4 id="2-5-数据库模块"><a href="#2-5-数据库模块" class="headerlink" title="2.5 数据库模块"></a>2.5 数据库模块</h4><p>  数据库模块主要是编写成数据库相关的API，在前端点击，或者自动更新后将会向服务器端请求数据，然后服务器端调用数据库API执行相应的操作，包括：数据库和表的创建，初始用户数据导入，插入数据，按次数搜索最新数据，按时间搜索范围内的数据等等，数据库API结构图如图2.9所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624115503.png"></p>
<p>图2.9 数据库模块API结构图</p>
<h4 id="2-6-服务器模块"><a href="#2-6-服务器模块" class="headerlink" title="2.6 服务器模块"></a>2.6 服务器模块</h4><p>  对于智能大棚管理系统，服务器的作用主要用于响应前端的请求，以及对串口和数据库的连接和处理，当前端发来不同的请求后，服务器进行相应的操作，包括，返回HTML页面，调用数据库API以及对串口的读取和写入，打开和关闭操作，其具体的功能结构图如图2.10所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624115452.png"></p>
<p>图2.10 服务器功能结构图</p>
<h4 id="2-7-前端模块"><a href="#2-7-前端模块" class="headerlink" title="2.7 前端模块"></a>2.7 前端模块</h4><p>  智能大棚系统的前端部分主要功能是展示环境数据和设备数据，通过向服务器端请求不同数据，实现对两种数据的最新一条数据和最近一小时数据，最近三小时数据，最近一天数据，最近两天数据的获取，并用折线图，柱状图和表格的形式展示，并且前端会像服务器请求登录状态，如果没有登陆则会自动跳转到登陆页面，保障了用户的信息安全，登录后用户可以通过前端监测数据，并且选择登出，打开或关闭自动模式，打开或关闭风机等硬件设备的功能，除此之外，前端还能每个一段时间自动更新，具体的功能结构图如图2.11所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624115534.png"></p>
<p>图2.11 前端功能结构图</p>
<h2 id="三，系统设计与实现"><a href="#三，系统设计与实现" class="headerlink" title="三，系统设计与实现"></a><strong>三，系统设计与实现</strong></h2><h3 id="1-硬件设计与实现"><a href="#1-硬件设计与实现" class="headerlink" title="1.硬件设计与实现"></a>1.硬件设计与实现</h3><h4 id="1-1-硬件总体电路原理图"><a href="#1-1-硬件总体电路原理图" class="headerlink" title="1.1 硬件总体电路原理图"></a>1.1 硬件总体电路原理图</h4><p>  硬件电路主要依靠Proteus软件，仿真实现，如图3.1所示。其中包括了DHTT11温湿度传感器用于获取大棚内的温度和湿度；LDR，其阻值随光照强度的增大而减小，将其与一个10K电阻组成分压电路，使得读取模拟IO的电压值可以用于监测大棚内的光照强度；BMP180，是一种高精度的气压传感器，用于监测大棚内气压。D2,D3,D4,D5为警示灯，D6,D7,D8,D9依次模拟风机，除湿器，照明，气泵设备。COMPIM用于串口通信。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624115623.png"></p>
<p>图3.1 硬件总体设计</p>
<h4 id="1-2-硬件系统设计"><a href="#1-2-硬件系统设计" class="headerlink" title="1.2 硬件系统设计"></a>1.2 硬件系统设计</h4><p>  硬件系统采用免费的实时系统FreeRTOS，其通过创建任务并调度实现系统的主要程序，在智能大棚系统中，硬件系统首先配置一系列IO口，定义了一些全局变量，如传感器的引脚，电压变量，所选择的智能模式，led端口等等，通过start_task()任务创建总任务zong_task()，在总任务内，不断读取串口传来的数据和传感器的数值，并写入串口，传递给服务器。</p>
<h5 id="1-2-1-数据监控与传输"><a href="#1-2-1-数据监控与传输" class="headerlink" title="1.2.1 数据监控与传输"></a>1.2.1 数据监控与传输</h5><p>  在zong_task()中，程序在延迟3秒后依次读取每个传感器的值，并通过串口传递固定格式的数据，最终传递的数据格式，如图3.2所示，依次分别代表温度，湿度，光强，气压，自动模式，风机状态，除湿器状态，照明状态，气泵状态。读取传感器的函数如下所示。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">delay</span>(<span class="number">3000</span>); <span class="comment">//每隔3s更新一次数据</span></span><br><span class="line"><span class="keyword">float</span> h = dht.<span class="built_in">readHumidity</span>();   <span class="comment">//读取湿度</span></span><br><span class="line"><span class="keyword">float</span> t = dht.<span class="built_in">readTemperature</span>(); <span class="comment">//读取温度</span></span><br><span class="line">var = <span class="built_in">analogRead</span>(LDR_PIN);   <span class="comment">//读取光照强度</span></span><br><span class="line">Serial.<span class="built_in">print</span>(bmp.<span class="built_in">readSealevelPressure</span>());  <span class="comment">//读取气压值</span></span><br><span class="line">Serial.<span class="built_in">print</span>(<span class="built_in">digitalRead</span>(led_pin[<span class="number">4</span>])); <span class="comment">//读取并传输硬件（其一）运行状态</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624115737.png"></p>
<p>图3.2 数据传输格式</p>
<h5 id="1-2-2-自动控制和手动控制"><a href="#1-2-2-自动控制和手动控制" class="headerlink" title="1.2.2 自动控制和手动控制"></a>1.2.2 自动控制和手动控制</h5><p>  程序定义了一个bool类型的全局变量MYBOOL，用于表示当前模式是自动还是手动，当模式是自动时，串口读入的数据将不能控制硬件状态改变，只能控制模式的改变，此时，硬件系统将根据传感器的值进行自动打开或关闭硬件设备，而当模式是手动时，则只能通过串口读入的值来控制硬件设备的开启与关闭。定义的读入手动控制操作的伪代码如下：</p>
<figure class="highlight haskell"><table><tr><td class="code"><pre><span class="line"><span class="type">While</span>(<span class="type">Serial</span>.available())&#123;</span><br><span class="line">    读取<span class="class"><span class="keyword">data</span></span></span><br><span class="line">    如果为自动模式&#123;</span><br><span class="line">        当<span class="class"><span class="keyword">data</span>=9时，关闭自动模式</span></span><br><span class="line">&#125;</span><br><span class="line">如果为手动模式&#123;</span><br><span class="line">    当<span class="class"><span class="keyword">data</span>=1时，打开风机</span></span><br><span class="line">当<span class="class"><span class="keyword">data</span>=2时，关闭风机</span></span><br><span class="line">当<span class="class"><span class="keyword">data</span>=3时，打开除湿</span></span><br><span class="line">当<span class="class"><span class="keyword">data</span>=4时，关闭除湿</span></span><br><span class="line">当<span class="class"><span class="keyword">data</span>=5时，打开灯光</span></span><br><span class="line">当<span class="class"><span class="keyword">data</span>=6时，关闭灯光</span></span><br><span class="line">当<span class="class"><span class="keyword">data</span>=7时，打开气泵</span></span><br><span class="line">当<span class="class"><span class="keyword">data</span>=8时，关闭气泵</span></span><br><span class="line">当<span class="class"><span class="keyword">data</span>=0时，切换自动模式</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>定义的自动控制和警报操作伪代码如下：</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">If</span><span class="params">(自动模式)</span></span>&#123;</span><br><span class="line">    如果温度异常，警报灯亮，操作风机，否则关闭警报灯和风机</span><br><span class="line">    如果湿度异常，警报灯亮，操作除湿器，否则关闭警报灯和除湿</span><br><span class="line">    如果光强异常，警报灯亮，操作照明，否则关闭警报灯和照明</span><br><span class="line">    如果气压异常，警报灯亮，操作气泵，否则关闭警报灯和气泵</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-数据库设计与实现"><a href="#2-数据库设计与实现" class="headerlink" title="2.数据库设计与实现"></a>2.数据库设计与实现</h3><p>  数据库的连接与操作，主要使用了Python的pymysql库，以及MYSQL数据库，主要实现当服务器连接时，自动查找大棚数据库，如果不存在则自动创建数据库BigPeng和三张数据表users,logs,e_logs,分别记录用户，环境数据，设备数据，并且提供了基于SQL语句的数据插入，数据查询功能，并有良好的异常处理机制。其中环境数据表的创建如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cur.execute(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        create table `logs`(</span></span><br><span class="line"><span class="string">            `log_id` int(11) unsigned unique NOT NULL AUTO_INCREMENT,</span></span><br><span class="line"><span class="string">            `time` char(20) not null,</span></span><br><span class="line"><span class="string">            `temperature` float(2),</span></span><br><span class="line"><span class="string">            `humidity` float(2),</span></span><br><span class="line"><span class="string">            `light` float(2),</span></span><br><span class="line"><span class="string">            `pressure` float(2),</span></span><br><span class="line"><span class="string">            PRIMARY KEY(`log_id`),</span></span><br><span class="line"><span class="string">            index id(log_id)</span></span><br><span class="line"><span class="string">        )DEFAULT CHARSET=utf8mb4 AUTO_INCREMENT=1;&quot;&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>  数据查找主要有两种模式，一种是select_logs(timestamp),其会根据传入的时间戳，查找大于这一个时间的数据，即可以实现查找最近一小时，最近一天等的数据，具体的实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">select_logs</span>(<span class="params">timestamp</span>):</span></span><br><span class="line">    conn=connect_BigPeng()</span><br><span class="line">    cur=conn.cursor()</span><br><span class="line">    sql=<span class="string">f&quot;select * from logs where time&gt;=<span class="subst">&#123;timestamp&#125;</span>;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ans=cur.fetchmany(cur.execute(sql))</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        conn.close()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;数据查找失败！&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        conn.close()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;数据查找成功&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>

<p>  第二种是select_newlogs(index),其会根据传入的数量，按照时间倒序，查找最新的index条数据，具体的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">select_newlogs</span>(<span class="params">index</span>):</span></span><br><span class="line">    conn=connect_BigPeng()</span><br><span class="line">    cur=conn.cursor()</span><br><span class="line">    sql=<span class="string">f&quot;select * from logs order by time desc limit 0,<span class="subst">&#123;index&#125;</span>;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ans=cur.fetchmany(cur.execute(sql))</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        conn.close()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;数据查找失败！&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        conn.close()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;数据查找成功&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>

<h3 id="3-服务器设计与实现"><a href="#3-服务器设计与实现" class="headerlink" title="3.服务器设计与实现"></a>3.服务器设计与实现</h3><h4 id="3-1-串口连接和数据插入"><a href="#3-1-串口连接和数据插入" class="headerlink" title="3.1 串口连接和数据插入"></a>3.1 串口连接和数据插入</h4><p>  服务器端的串口操作，主要运用了python的serial库和threading库，serial用于串口通信交互。而threading用于使用多线程循环接受串口数据，并存储到数据库中。<br>  串口的操作部分，主要功能有，打开串口DopenPort(portx,bps,timeout)，读取数据ReadData(ser)，关闭串口DclosePort(ser)，写入数据DWritePort(ser,text)四个部分。<br>  当串口打开后，将会自动执行读取数据操作。具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 端口，Windows上的 COM2</span></span><br><span class="line"><span class="comment"># 波特率，9600</span></span><br><span class="line"><span class="comment"># 超时设置,None：永远等待操作，0为立即返回请求结果，其他值为等待超时时间(单位为秒）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">DOpenPort</span>(<span class="params">portx,bps,timeout</span>):</span></span><br><span class="line">    ret=<span class="literal">False</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 打开串口，并得到串口对象</span></span><br><span class="line">        ser = serial.Serial(portx, bps, timeout=timeout)</span><br><span class="line">        <span class="comment">#print(ser)</span></span><br><span class="line">        <span class="comment">#判断是否打开成功</span></span><br><span class="line">        <span class="keyword">if</span>(ser.is_open):</span><br><span class="line">           ret=<span class="literal">True</span></span><br><span class="line">           threading.Thread(target=ReadData, args=(ser,)).start()</span><br><span class="line">           <span class="comment">#ReadData(ser)</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;---异常---：&quot;</span>, e)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> ser,ret</span><br></pre></td></tr></table></figure>

<h4 id="3-2-服务器框架设计与实现"><a href="#3-2-服务器框架设计与实现" class="headerlink" title="3.2 服务器框架设计与实现"></a>3.2 服务器框架设计与实现</h4><p>  该智能大棚系统的服务器端主要使用Python的Flask服务器框架，能够快速接受前端的响应，支持session保存如登录状态等数据，结合之前编写的数据库API以及串口操作函数，能够实现对前端请求数据的获取和传递。其中获取某一时间段的函数如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/getjson/&#x27;</span>,methods=[<span class="string">&#x27;GET&#x27;</span>,<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getjson</span>():</span></span><br><span class="line">    H=<span class="built_in">int</span>(request.form.get(<span class="string">&#x27;Hour&#x27;</span>))</span><br><span class="line">    beforetime=time.strptime((datetime.now()-timedelta(hours=H)).strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>),<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>)</span><br><span class="line">    timestamp=<span class="built_in">int</span>(time.mktime(beforetime))</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ans=dealdata(sqlapi.select_logs(timestamp))</span><br><span class="line">        <span class="comment">#数据处理</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Get Json 失败！&quot;</span>)</span><br><span class="line">        <span class="comment">#print(e)</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> json.dumps(ans)</span><br></pre></td></tr></table></figure>

<p>  由于json不支持时间类型的数据解析，因此每次需要服务器端将获取时间并转换为字符串类型的数据进行传递.</p>
<h3 id="4-前端设计与实现"><a href="#4-前端设计与实现" class="headerlink" title="4.前端设计与实现"></a>4.前端设计与实现</h3><p>  前端包含四个页面，即登录页，首页，详细数据页，设备数据页。前端需要导入两个js文件，一个是jQuery,一个是echarts.js，后者主要用于数据图表的显示。<br>  前端页面具有登录检测功能，如果没有登录，则会自动跳转到登录页面，部分代码如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">check_session=<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">            $.get(<span class="string">&#x27;/check_session/&#x27;</span>).done(<span class="function"><span class="keyword">function</span>(<span class="params">ans</span>)</span>&#123;</span><br><span class="line">                data=$.parseJSON(ans);</span><br><span class="line">                <span class="built_in">console</span>.log(data)</span><br><span class="line">                <span class="keyword">if</span>(data[<span class="string">&quot;session&quot;</span>]==<span class="string">&quot;false&quot;</span>)&#123;</span><br><span class="line">                    <span class="built_in">window</span>.location.replace(<span class="string">&quot;/login/&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>前端具有数据图表以及按钮实时显示功能，每隔一定时间，将会请求服务器再次更新数据，设置定时更新的代码如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="built_in">window</span>.onload=<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    check_session()</span><br><span class="line">    showdata()</span><br><span class="line">    drawcharts()</span><br><span class="line">    <span class="built_in">setInterval</span>(<span class="string">&quot;showdata()&quot;</span>,<span class="number">5000</span>);</span><br><span class="line">    <span class="built_in">setInterval</span>(<span class="string">&quot;drawcharts()&quot;</span>,<span class="number">5000</span>);</span><br><span class="line">    <span class="built_in">setInterval</span>(<span class="string">&quot;check_session()&quot;</span>,<span class="number">5000</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="四，系统测试"><a href="#四，系统测试" class="headerlink" title="四，系统测试"></a><strong>四，系统测试</strong></h2><h3 id="1-硬件运行"><a href="#1-硬件运行" class="headerlink" title="1.硬件运行"></a>1.硬件运行</h3><p>  当硬件开启后，默认为自动模式，此时如果检测值超过设定的危险值后，警示灯将会点亮，并且运行响应的硬件设备，温度超过范围后自动控制的硬件运行图，如图4.1所示。一切正常时的运行图，如图4.2所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624120018.png"></p>
<p>图4.1 温度超过范围后自动控制的硬件运行图</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624120203.png"></p>
<p>图4.2 正常运行硬件图</p>
<h3 id="2-服务器运行"><a href="#2-服务器运行" class="headerlink" title="2.服务器运行"></a>2.服务器运行</h3><p>  当服务器运行后，将会查找BigPeng数据库是否存在，如果不存在，将会自动创建数据库和表，如果存在，则自动连接数据库，如图4.3所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624120236.png"></p>
<p>图4.3 服务器正常运行示意图</p>
<h3 id="3-前端运行"><a href="#3-前端运行" class="headerlink" title="3.前端运行"></a>3.前端运行</h3><p>  当服务器和硬件系统开启后，进入首页将会自动跳转登录页面，如图4.4所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624120259.png"></p>
<p>图4.4 登陆页面</p>
<p>  输入默认的用户名root和密码123456，即可自动跳转首页，首页上半部分如图4.5所示，下部分如图4.6所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624120328.png"></p>
<p>图4.5 首页上部分示意图</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624120459.png"></p>
<p>图4.6 首页下部分示意图</p>
<p>  此时当服务器第一运行时，串口并没有打开，因此需要点击开始监测按钮才能进行数据记录，按下按钮后，可以看到数据表在实时更新，并且按钮状态已改变，这一将存储到服务器端，不会随刷新而改变，如图4.7所示。并且首页还能控制硬件端的模式和硬件设备的开启与停止，如果点击了关闭自动，并打开风机和气泵，等待几秒后将如图4.8所示，对应的硬件状态如图4.9所示</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624120512.png"></p>
<p>图4.7 开启实时监测</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624120524.png"></p>
<p>图4.8 关闭了自动模式打开风机气泵示意图</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624120538.png"></p>
<p>图4.9 对应打开风机和气泵的硬件状态图</p>
<p>  通过点击导航栏，可以跳转到详细数据页面，里面可以显示最近三小时，最近一天和最近两天的数据，如图4.10所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624120700.png"></p>
<p>图4.10 详细数据页面</p>
<p>  再点击导航栏上的设备详情，即可跳转设备数据页面，同样可以查看最近三小时，最近一天和最近两天的数据，如图4.11所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200624120715.png"></p>
<p>图4.11 设备数据页</p>
<h2 id="五，总结"><a href="#五，总结" class="headerlink" title="五，总结"></a><strong>五，总结</strong></h2><p>  通过对智能大棚监测管理系统的设计，我们团队实现了对系统的全部预期目标，不仅能实时监控环境数据，还能监控硬件运行状态数据，并存储到数据库，并且通过不懈努力，前端页面具有高效的实时性和动态效果，能定时获取数据实时更新数据，前端也会根据数据的不同发生相对应的改变，在实验过程中也遇到了很多问题，但是在查阅了很多文档后，问题都得到了解决，目前需要改进的地方是，硬件端的传感器数量较少，能够实现的功能可以继续增加，其次是前端的数据更新仍需要5到10秒中时间，当点击了打开硬件设备后需要等待较长时间才会更新。这次智能大棚监测管理系统的设计，让我受益匪浅，希望以后的我，能将它继续完善。</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>大学课程</tag>
        <tag>Arduino</tag>
        <tag>嵌入式</tag>
      </tags>
  </entry>
  <entry>
    <title>Github | 学习Git&amp;Github</title>
    <url>/posts/42803.html</url>
    <content><![CDATA[<p>关于Git与Github的基础知识的笔记</p>
<span id="more"></span>
<h1 id="GitHub与Git区别"><a href="#GitHub与Git区别" class="headerlink" title="GitHub与Git区别"></a>GitHub与Git区别</h1><ul>
<li>Git属于分散型版本管理系统，开发者使用Git将源代码存入名叫“Git仓库”的资料库中并加以使用。</li>
<li>GitHub事在网络上提供Git仓库的一项服务，使用GitHub可以实现多人协作</li>
</ul>
<h1 id="Git初始设置"><a href="#Git初始设置" class="headerlink" title="Git初始设置"></a>Git初始设置</h1><h2 id="git-config命令的–global参数"><a href="#git-config命令的–global参数" class="headerlink" title="git config命令的–global参数"></a>git config命令的–global参数</h2><ul>
<li>设置Git提交时的姓名与邮箱<br>$ git config –global user.name “justlovesmile”<br>$ git config –global user.email “<a href="mailto:&#x38;&#x36;&#x35;&#x37;&#49;&#55;&#49;&#x35;&#48;&#x40;&#113;&#x71;&#x2e;&#x63;&#x6f;&#x6d;">&#x38;&#x36;&#x35;&#x37;&#49;&#55;&#49;&#x35;&#48;&#x40;&#113;&#x71;&#x2e;&#x63;&#x6f;&#x6d;</a>“</li>
<li>让命令的输出具有更高的可读性<br>$ git config –global color.ui auto</li>
</ul>
<h2 id="创建版本库"><a href="#创建版本库" class="headerlink" title="创建版本库"></a>创建版本库</h2><ul>
<li>把这个目录编程Git可以管理的仓库<br>$ git init</li>
<li>将文件添加到仓库缓冲区<br>$ git add hello_world.php</li>
<li>添加说明并正式提交<br>$ git commit -m “wrote a file”<br>[master (root-commit) a4207ca] wrote a file<br> 1 file changed, 3 insertions(+)<br> create mode 100644 hello_world.php</li>
<li>查看提交日志</li>
</ul>
<p>（1）$ git log（+文件名）</p>
<p>commit a4207cab55e08e29847031903c3d885f522483d3 (HEAD -&gt; master)<br>Author: justlovesmile <a href="mailto:&#56;&#54;&#x35;&#55;&#x31;&#55;&#x31;&#53;&#x30;&#x40;&#x71;&#113;&#46;&#99;&#x6f;&#109;">&#56;&#54;&#x35;&#55;&#x31;&#55;&#x31;&#53;&#x30;&#x40;&#x71;&#113;&#46;&#99;&#x6f;&#109;</a><br>Date:   Thu Jun 13 11:04:29 2019 +0800<br>    wrote a file</p>
<p>（2）$ git log –pretty=oneline</p>
<p>db0644b6e8c15385d34c80b44fab5a2124289526 (HEAD -&gt; master) add one line<br>5022ed9f401a7a95b2c325d1f57ef7c9c291e860 wrote a read.txt<br>a4207cab55e08e29847031903c3d885f522483d3 wrote a file</p>
<p>（3）$ git log -p查看文件改动</p>
<ul>
<li><p>查看仓库状态<br>$ git status</p>
</li>
<li><p>查看修改的不同之处<br>$ git diff read.txt </p>
</li>
<li><p>回退版本到上一个版本<br>$ git reset –hard HEAD^<br>（回退后就看不见之前那个了，但是如果还没关命令窗口可以向上查找commit id然后再👇）<br>$ git reset –hard 1094a（id不一定要写全）</p>
</li>
<li><p>使用cat查看文件内容<br>$ cat read.txt</p>
</li>
<li><p>Git提供了查看你的每一次命令的方法<br>$ git reflog</p>
</li>
<li><p>丢弃工作区修改（当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时）<br>$ git checkout – read.txt</p>
</li>
<li><p>撤销暂存区的修改（当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD <file>，就回到了工作区的修改，再执行👆）<br>$ git reset HEAD read.txt</p>
</li>
<li><p>删除文件<br>$ rm read.txt</p>
</li>
<li><p>删除版本库<br>$ git rm read.txt</p>
</li>
<li><p>误删恢复<br>（用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”，但是会失去最近一次提交后的修改内容）<br>$ git checkout – test.txt</p>
</li>
</ul>
<h1 id="远程仓库"><a href="#远程仓库" class="headerlink" title="远程仓库"></a>远程仓库</h1><ul>
<li><p>创建SSH Key<br>$ ssh-keygen -t rsa -C “<a href="mailto:&#121;&#111;&#117;&#x72;&#x65;&#109;&#97;&#x69;&#108;&#64;&#101;&#120;&#x61;&#x6d;&#x70;&#x6c;&#x65;&#46;&#x63;&#x6f;&#x6d;">&#121;&#111;&#117;&#x72;&#x65;&#109;&#97;&#x69;&#108;&#64;&#101;&#120;&#x61;&#x6d;&#x70;&#x6c;&#x65;&#46;&#x63;&#x6f;&#x6d;</a>“</p>
</li>
<li><p>查看id_rsa.pub文件，并复制<br>$ cat ~/.ssh/id_rsa.pub</p>
</li>
<li><p>然后再在github中添加ssh key</p>
</li>
<li><p>输入命令测试<br>$ ssh -T <a href="mailto:&#x67;&#x69;&#116;&#64;&#x67;&#105;&#x74;&#104;&#117;&#x62;&#46;&#x63;&#111;&#x6d;">&#x67;&#x69;&#116;&#64;&#x67;&#105;&#x74;&#104;&#117;&#x62;&#46;&#x63;&#111;&#x6d;</a></p>
</li>
<li><p>在github中创建一个git仓库</p>
</li>
<li><p>关联远程库<br>$ git remote add origin <a href="mailto:&#103;&#x69;&#x74;&#64;&#103;&#105;&#116;&#x68;&#117;&#98;&#x2e;&#99;&#111;&#109;">&#103;&#x69;&#x74;&#64;&#103;&#105;&#116;&#x68;&#117;&#98;&#x2e;&#99;&#111;&#109;</a>:Justlovesmile/Hello-World.git</p>
</li>
<li><p>将本地库的所有内容推送到远程库上<br>$ git push -u origin master</p>
</li>
<li><p>从现在起，只要本地作了提交，就可以通过命令：<br>$ git push origin master</p>
</li>
<li><p>克隆远程库到本地库<br>$ git clone <a href="mailto:&#x67;&#x69;&#116;&#64;&#x67;&#105;&#116;&#x68;&#117;&#x62;&#x2e;&#x63;&#x6f;&#109;">&#x67;&#x69;&#116;&#64;&#x67;&#105;&#116;&#x68;&#117;&#x62;&#x2e;&#x63;&#x6f;&#109;</a>:Justlovesmile/practice.git</p>
</li>
</ul>
<h1 id="分支管理"><a href="#分支管理" class="headerlink" title="分支管理"></a>分支管理</h1><h2 id="创建于合并"><a href="#创建于合并" class="headerlink" title="创建于合并"></a>创建于合并</h2><ul>
<li><p>创建dev分支，并切换<br>$ git checkout -b dev<br>（即<br>$ git branch dev<br>$ git checkout dev<br>）</p>
</li>
<li><p>查看分支<br>$ git branch</p>
</li>
<li><p>在切换到分支后，可以在分支上继续修改文件，再提交</p>
</li>
<li><p>然后切回master<br>$ git checkout master<br>此时，master上看不见分支</p>
</li>
<li><p>将分支的工作结果与master合并<br>$ git merge dev</p>
</li>
<li><p>合并完成后删掉分支<br>$ git branch -d dev</p>
</li>
</ul>
<h2 id="出现冲突的情况"><a href="#出现冲突的情况" class="headerlink" title="出现冲突的情况"></a>出现冲突的情况</h2><ul>
<li><p>如果创建了分支，并进行了修改与提交</p>
</li>
<li><p>而master也进行了提交，那么两者就不能直接进行合并，需要检查冲突手动修改<br>$ git status（会告述你哪里冲突了）</p>
</li>
<li><p>查看合并情况图<br>$ git log –graph –pretty=oneline –abbrev-commit</p>
</li>
</ul>
<h2 id="分支管理-1"><a href="#分支管理-1" class="headerlink" title="分支管理"></a>分支管理</h2><ul>
<li><p>一般master仅用来发布新版本，其他工作，修改在分支上进行</p>
</li>
<li><p>合并分支时，加上–no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而fast forward合并就看不出来曾经做过合并。</p>
</li>
</ul>
<p>$ git merge –no-ff -m “merge with no-ff” dev</p>
<h2 id="bug分支"><a href="#bug分支" class="headerlink" title="bug分支"></a>bug分支</h2><ul>
<li><p>当工作只进行了一半，但是又要修改另外的bug时，可以将工作现场先储藏起来<br>$ git stash</p>
</li>
<li><p>然后再创建一个分支，例如叫issue，在这上面修改bug</p>
</li>
<li><p>再提交，然后切换回master合并，最后删除这个分支</p>
</li>
<li><p>切回之前工作的分支，恢复工作现场</p>
</li>
</ul>
<h2 id="强制删除分支"><a href="#强制删除分支" class="headerlink" title="强制删除分支"></a>强制删除分支</h2><ul>
<li>如果分支中的修改已经提交，但是发现不能加到master中，并且，该修改属于机密，所以你需要强制删除该分支（因为系统会提示你该修改未合并，使用D）</li>
</ul>
<p>$ git branch -D feature</p>
<h2 id="多人协作"><a href="#多人协作" class="headerlink" title="多人协作"></a>多人协作</h2><ul>
<li><p>查看远程库的信息<br>$ git remote<br>origin</p>
</li>
<li><p>查看远程库的详细信息<br>$ git remote -v<br>origin  <a href="mailto:&#103;&#105;&#116;&#x40;&#x67;&#105;&#116;&#x68;&#x75;&#x62;&#x2e;&#x63;&#x6f;&#x6d;">&#103;&#105;&#116;&#x40;&#x67;&#105;&#116;&#x68;&#x75;&#x62;&#x2e;&#x63;&#x6f;&#x6d;</a>:Justlovesmile/Hello-World.git (fetch)<br>origin  <a href="mailto:&#103;&#x69;&#116;&#x40;&#103;&#105;&#116;&#104;&#117;&#98;&#x2e;&#99;&#x6f;&#x6d;">&#103;&#x69;&#116;&#x40;&#103;&#105;&#116;&#104;&#117;&#98;&#x2e;&#99;&#x6f;&#x6d;</a>:Justlovesmile/Hello-World.git (push)</p>
</li>
<li><p>推送master主分支<br>$ git push origin master</p>
</li>
<li><p>推送其他分支<br>$ git push origin dev</p>
</li>
<li><p>抓取分支<br>$ git clone <a href="mailto:&#103;&#x69;&#116;&#64;&#103;&#x69;&#x74;&#x68;&#117;&#x62;&#46;&#99;&#x6f;&#109;">&#103;&#x69;&#116;&#64;&#103;&#x69;&#x74;&#x68;&#117;&#x62;&#46;&#99;&#x6f;&#109;</a>:Justlovesmile/Hello-World.git</p>
</li>
</ul>
<ul>
<li>多人协作的工作模式通常是这样：<ul>
<li>首先，可以试图用git push origin <branch-name>推送自己的修改；</li>
<li>如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并；</li>
<li>如果合并有冲突，则解决冲突，并在本地提交；</li>
<li>没有冲突或者解决掉冲突后，再用git push origin <branch-name>推送就能成功！</li>
</ul>
</li>
<li>如果git pull提示no tracking information，则说明本地分支和远程分支的链接关系没有创建，用命令git branch –set-upstream-to <branch-name> origin/<branch-name>。</li>
</ul>
<h1 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h1><h2 id="创建标签"><a href="#创建标签" class="headerlink" title="创建标签"></a>创建标签</h2><ul>
<li>切换到需要打标签的分支上<br>$ git branch</li>
</ul>
<ul>
<li>dev<br>master<br>$ git checkout master<br>Switched to branch ‘master’</li>
</ul>
<ul>
<li><p>创建标签<br>$ git tag v1.0</p>
</li>
<li><p>给对应的版本打上标签<br>$ git tag v0.9 f52c633</p>
</li>
<li><p>标签它是按字母排序的，查看标签<br>$ git show v0.9commit f52c63349bc3c1593499807e5c8e972b82c8f286 (tag: v0.9)<br>Author: Michael Liao <a href="mailto:&#x61;&#x73;&#x6b;&#x78;&#117;&#101;&#x66;&#x65;&#110;&#x67;&#64;&#103;&#x6d;&#97;&#x69;&#x6c;&#46;&#x63;&#111;&#x6d;">&#x61;&#x73;&#x6b;&#x78;&#117;&#101;&#x66;&#x65;&#110;&#x67;&#64;&#103;&#x6d;&#97;&#x69;&#x6c;&#46;&#x63;&#111;&#x6d;</a><br>Date:   Fri May 18 21:56:54 2018 +0800<br>  add merge<br>diff –git a/readme.txt b/readme.txt</p>
</li>
<li><p>创建带有说明的标签，用-a指定标签名，-m指定说明文字：<br>$ git tag -a v0.1 -m “version 0.1 released” 1094adb</p>
</li>
</ul>
<h2 id="操作标签"><a href="#操作标签" class="headerlink" title="操作标签"></a>操作标签</h2><ul>
<li><p>删除标签<br>$ git tag -d v0.1</p>
</li>
<li><p>推送某个标签到远程<br>$ git push origin v1.0</p>
</li>
<li><p>一次性推送全部尚未推送到远程的本地标签：$ git push origin –tags</p>
</li>
<li><p>如果标签已经推送到远程，又想要删除标签，先从本地删除<br>$ git tag -d v0.9<br>然后再从远程删除<br>$ git push origin :refs/tags/v0.9</p>
</li>
</ul>
<h1 id="github"><a href="#github" class="headerlink" title="github"></a>github</h1><ul>
<li>对于感兴趣的项目，先点Fork克隆仓库，然后再从自己的账号下clone<br>git clone <a href="mailto:&#103;&#105;&#x74;&#64;&#x67;&#105;&#x74;&#104;&#117;&#x62;&#x2e;&#x63;&#x6f;&#109;">&#103;&#105;&#x74;&#64;&#x67;&#105;&#x74;&#104;&#117;&#x62;&#x2e;&#x63;&#x6f;&#109;</a>:michaelliao/clone.git</li>
</ul>
<h1 id="码云gitee-com"><a href="#码云gitee-com" class="headerlink" title="码云gitee.com"></a>码云gitee.com</h1><ul>
<li>国内的Git托管服务</li>
</ul>
<h1 id="自定义git命令"><a href="#自定义git命令" class="headerlink" title="自定义git命令"></a>自定义git命令</h1><ul>
<li>自定义st表示status<br>$ git config –global alias.st status</li>
<li>修改在配置文件.gitconfig中</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title>学习笔记 | 什么是比特币？</title>
    <url>/posts/4475.html</url>
    <content><![CDATA[<p>第一次去了解比特币，看了B站上的视频后做了一点笔记</p>
<h1 id="比特币"><a href="#比特币" class="headerlink" title="比特币"></a>比特币</h1><p>1.比特币是一种电子货币，数字货币<br>2.其来自于中本聪《白皮书》<br>3.去中心化的电子记账系统，每个人的账本都是公开的<br>4.每个人的消费账本都会广播给其他所有人（billboard），将账单打包成一个块，就是区块，一块大小大约1M，可以存储4000多条记录，区块连接在一起形成区块链<br>5.以谁为准？</p>
<ul>
<li>中本聪提出 工作量证明 的方法，即 挖矿。</li>
<li>可以理解为通过做一个很难的数学题，如果做出来了，你就可以打包，去获得奖励。但是这个数学题很难，只能用计算机算出来</li>
<li>SHA256：安全哈希函数，正向算容易，反向算非常困难，得到256位的二进制数</li>
<li>挖矿原理:区块链中每个区块要包含头部，以及其他信息，例如：<ul>
<li>字符串包含前块的头部+账单+时间戳+随机数</li>
<li>Hash=sha256(sha256（字符串）)</li>
<li>Hash（256位）要求前n位是0</li>
<li>满足上述条件则算对</li>
</ul>
</li>
<li>所以一般来说，谁的计算能力强，谁就更可能算出来</li>
<li>中本聪要求每10分钟，就打包一个块，所以，通过调节n的值，就可以满足要求，例如：<ul>
<li>如果有10000台矿机，每台矿机计算能力是14T/s=1.4×10^13,那么1.4×10^13×10000×600s=8×10^19</li>
<li>对于SHA256的结果，前n个二进制数的概率是（1/2）^n，次数就是2^n次</li>
<li>即此时n=66，则满足中本聪的要求</li>
</ul>
</li>
</ul>
<p>6.为什么记账？为什么别人发的账本我们要接受，花自己的电脑资源去记录？</p>
<ul>
<li>记账有奖励。有手续费收益较低。手续费由付费方出</li>
<li>打包的人有奖励，每过四年减半：<br>比特币打包一次要一个小时，连续不断的打包，第一个四年，每打包一次奖励50bitcoin：可以得下式：50×6×24×365×4×（1+1/2+（1/2）×（1/2）+……）=2100万<br>也就是说比特币最多2100万个</li>
</ul>
<p>7.怎么防伪？</p>
<ul>
<li>身份认证：电子签名<ul>
<li>用户注册时生成随机数，通过随机数产生私钥字符串（重要），又通过私钥产生公钥字符串（公开）和一个地址（公开）</li>
<li>私钥可以对一个数据加密，公钥用于解密（非对称加密）</li>
<li>如果A要付给B钱：则A先进行记录，再用hash函数计算摘要，再用私钥进行加密，产生密码，对全网广播  A给B钱+公钥+刚刚的密码，其他人拿到接受的信息，进行摘要计算，再用公钥解密，比较两个值是否相等，若果不对，则其他用户不承认</li>
</ul>
</li>
</ul>
<p>8.如何对付双重支付？</p>
<ul>
<li>余额检查（追溯）：区块链中包含很多信息，当A要给B钱时，其他用户就检查区块链中的信息，查看A的余额是否足够</li>
<li>双重支付：指一个人同时给两个人支付钱</li>
<li>如果A只有10bitcoin但是A同时给B和C支付10bitcoin，其他人先接受到的消息可能不一样，如果有个人接受消息后最先找到解，打包了一个块并加到主链上，并包含其中一个消息，则这个消息被承认，另一个不被承认。</li>
</ul>
<p>9.如何防止串改？</p>
<ul>
<li>比特币有最长链原则：即如果有两个人同时挖到矿，并且广播出去，其他人先接受到的消息不相同，但是只接受一个，即站队后他们各自算自己的区块，哪个支链长，那个支链就最有可能成为主链（被大多数人认可）</li>
<li>防止篡改：如果有一个人想要修改之前的一个记录，他就在包含那条记录的链的位置创造一条新支链，但是只有当你在其后添加的区块超过当时全世界在主链上的区块数后，你的链才会成为主链，这是不太现实的。</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>比特币</tag>
      </tags>
  </entry>
  <entry>
    <title>大学课程 | 《微机原理与接口技术》笔记</title>
    <url>/posts/43666.html</url>
    <content><![CDATA[<p>大学课程《微机原理与接口技术》学习笔记整理</p>
<span id="more"></span>

<h1 id="第一章-微型计算机基础概论"><a href="#第一章-微型计算机基础概论" class="headerlink" title="第一章 微型计算机基础概论"></a>第一章 微型计算机基础概论</h1><h2 id="第一讲-关于"><a href="#第一讲-关于" class="headerlink" title="第一讲 关于"></a>第一讲 关于</h2><ul>
<li>计算机的主要应用：数值计算，信息处理，过程控制</li>
<li>微机原理与接口技术包括：数值信息表示，微型机基本原理，汇编程序设计，半导体存储器及其接口设计，输入输出技术</li>
</ul>
<h2 id="第二讲-微型计算机系统组成"><a href="#第二讲-微型计算机系统组成" class="headerlink" title="第二讲 微型计算机系统组成"></a>第二讲 微型计算机系统组成</h2><ul>
<li>计算机系统：<ul>
<li>硬件系统<ul>
<li>主机系统：CPU，存储器，输入输出接口，总线</li>
<li>外部设备</li>
</ul>
</li>
<li>软件系统</li>
</ul>
</li>
<li>能够与CPU直接进行信息交换的部件属于主机系统，不能够与CPU直接进行信息交换的部件属于外部设备</li>
<li>CPU<ul>
<li>微处理器简称CPU，是计算机的核心</li>
<li>主要包括：运算器，控制器，寄存器组</li>
</ul>
</li>
<li>存储器：<ul>
<li>计算机中的记忆装置。用于存放计算机工作过程中需要操作的数据和程序</li>
<li>内存储器 ：<ul>
<li>存取速度较快，容量相对较小</li>
<li>内存按单元组织，每单元都对应一个惟一的地址 </li>
<li>每个内存单元中存放1Byte数据【每8位0或1称 为1字节（Byte）】</li>
<li>内存单元个数称为内存容量</li>
<li>按工作方式分类：随机存取存储器（RAM），只读存储器（ROM） </li>
</ul>
</li>
<li>外存储器 <ul>
<li>联机外存：硬磁盘 </li>
<li>脱机外存：各种移动存储设备</li>
</ul>
</li>
</ul>
</li>
<li>输入/输出接口 <ul>
<li>接口是CPU与外部设备间的桥梁</li>
<li>主要功能：<ul>
<li>数据缓冲寄存；</li>
<li>信号电平或类型的转换；</li>
<li>实现主机与外设间的运行匹配。 </li>
</ul>
</li>
</ul>
</li>
<li>总线 <ul>
<li>是一组导线和相关的控制、驱动电路的集合。</li>
<li>是计算机系统各部件之间传输地址、数据和控制信息的通道 </li>
<li>地址总线（AB） 数据总线（DB） 控制总线（CB） </li>
</ul>
</li>
</ul>
<h2 id="第三讲-微机工作过程"><a href="#第三讲-微机工作过程" class="headerlink" title="第三讲 微机工作过程"></a>第三讲 微机工作过程</h2><ul>
<li>计算机的工作就是按照一定的顺序，一条条地执行指令</li>
<li>指令： 由人向计算机发出的、能够为计算机所识别的命令 </li>
<li>过程：<strong>取指令</strong>-&gt;<strong>分析指令</strong>-&gt;读取操作数-&gt;<strong>执行指令</strong>-&gt;存放结果 </li>
<li>顺序执行： 一条指令执行完了再执行下一条指令。 <ul>
<li>执行时间=取指令+分析指令+执行指令 </li>
<li>设：三个部分的执行时间均为Δt，则：执行n条指令时间T0为：  </li>
<li>T0=3nΔt </li>
</ul>
</li>
<li>并行执行： 同时执行两条或多条指令。 <ul>
<li>仅第1条指令需要3 Δt时间，之后每经过1 Δt，就有一条指令执行结束</li>
<li>执行时间： T =3Δt +（ n-1）Δt </li>
</ul>
</li>
<li>并行： 更高的效率，更高的复杂度 </li>
<li>相对于顺序执行方式，指令并行执行的优势用加速比S表示： <ul>
<li>S=顺序执行花费的时间/并行执行花费的时间 </li>
<li>例： 3n Δt /（3Δt +（ n-1）Δt) =3n/（2+n） </li>
</ul>
</li>
<li>冯 • 诺依曼计算机的工作原理: 存储程序工作原理,结构特点:运算器为核心 </li>
<li>冯 • 诺依曼机的工作过程 <ul>
<li>取一条指令的工作过程： <ul>
<li>① 将指令所在地址赋给程序计数器PC； </li>
<li>② PC内容送到地址寄存器AR，PC自动加1； </li>
<li>③ 把AR的内容通过地址总线送至内存储器，经地址译码器译码，选中相应单元。 </li>
<li>④ CPU的控制器发出读命令。 </li>
<li>⑤ 在读命令控制下，把所选中单元的内容（即指令操作码）读到数据总线 DB。 </li>
<li>⑥ 把读出的内容经数据总线送到数据寄存器DR。 </li>
<li>⑦ 指令译码:数据寄存器DR将它送到指令寄存器IR，然后再送到指令译码器ID </li>
</ul>
</li>
<li>特点： <ul>
<li>程序存储，共享数据，顺序执行 </li>
<li>属于顺序处理机，适合于确定的算法和数值数据的处理。</li>
</ul>
</li>
<li>不足： <ul>
<li>与存储器间有大量数据交互，对总线要求很高；</li>
<li>执行顺序由程序决定，对大型复杂任务较困难；</li>
<li>以运算器为核心，处理效率较低；</li>
<li>由PC控制执行顺序，难以进行真正的并行处理。 </li>
</ul>
</li>
</ul>
</li>
<li>哈佛结构 <ul>
<li>指令和数据分别存放在两个独立的存储器模块中； </li>
<li>CPU与存储器间指令和数据的传送分别采用两组独立的总线；</li>
<li>可以在一个机器周期内同时获得指令操作码和操作数。 </li>
</ul>
</li>
</ul>
<h2 id="第四讲-常用数制"><a href="#第四讲-常用数制" class="headerlink" title="第四讲 常用数制"></a>第四讲 常用数制</h2><ul>
<li>计算机中的常用计数制：十进制 ，二进制数 ，十六进制数 ，八进制数 </li>
</ul>
<h2 id="第五讲-编码"><a href="#第五讲-编码" class="headerlink" title="第五讲 编码"></a>第五讲 编码</h2><ul>
<li>编码：<ul>
<li>信息从一种形式或格式转换为另一种形式的过程</li>
<li>用代码来表示各种信息，以便于计算机处理。 </li>
</ul>
</li>
<li>需要编码的信息种类：数值，字符，声音，图形，图像 </li>
<li>所有需要由计算机处理的信息，都需要编码，使所有信息都以二进制码形式表示</li>
<li>计算机中的编码 <ul>
<li>数值编码：<ul>
<li>二进制码</li>
<li>BCD码 </li>
</ul>
</li>
<li>西文字符编码<ul>
<li>ASCII码 </li>
</ul>
</li>
</ul>
</li>
<li>BCD（Binary Coded Decimal）码 <ul>
<li>用二进制表示的十进制数</li>
<li>特点： <ul>
<li>保留十进制的权，数字用0和1表示。</li>
</ul>
</li>
</ul>
</li>
<li>8421BCD编码： <ul>
<li>用4位二进制码表示1位十进制数，每4位之间有一个空格 </li>
<li>1010—1111是非法BCD码</li>
<li>（0001 0001 .0010 0101）BCD    =11 .25    =（1011 .01）B </li>
</ul>
</li>
<li>BCD码在计算机中的存储方式 <ul>
<li>以压缩BCD码形式存放：<ul>
<li>用4位二进制码表示1位BCD码</li>
<li>一个存储单元中存放2位BCD数</li>
</ul>
</li>
<li>以扩展BCD码形式存放 <ul>
<li>用8位二进制码表示1位BCD码.即高4位为0，低4位为有效位 </li>
<li>每个存储单元存放1位BCD </li>
</ul>
</li>
</ul>
</li>
<li>ASCII码 <ul>
<li>西文字符编码：将每个字母、数字、标点、控制符用1Byte二进制码表示 </li>
<li>标准ASCII的有效位：7bit，最高位默认为0 </li>
</ul>
</li>
<li>ASCII码的奇偶校验 <ul>
<li>奇校验：加上校验位后编码中“1”的个数为奇数。</li>
<li>偶校验：加上校验位后编码中“1”的个数为偶数。 </li>
</ul>
</li>
</ul>
<h2 id="第六讲-数及其运算"><a href="#第六讲-数及其运算" class="headerlink" title="第六讲 数及其运算"></a>第六讲 数及其运算</h2><ul>
<li>定点数</li>
<li>浮点数 <ul>
<li>小数点的位置可以左右移动的数</li>
<li>规格化浮点数：尾数部分用纯小数表示，即小数点右边第1位不为0 </li>
</ul>
</li>
<li>无符号数</li>
<li>有符号数：用最高位表示符号，其余是数值，0正，1负<ul>
<li>原码：最高位为符号位，其余为真值部分<ul>
<li>[X]原=符号位+|绝对值| </li>
<li>有[+0]和[-0]之分</li>
</ul>
</li>
<li>反码：<ul>
<li>若X&gt;0 ，则 [X]反 = [X]原 </li>
<li>若X&lt;0， 则 [X]反 = 对应原码的符号位不变，数值部分按位求反。</li>
<li>有[+0]和[-0]之分</li>
</ul>
</li>
<li>补码：<ul>
<li>若X&gt;0， 则 [X]补 = [X]反= [X]原</li>
<li>若X&lt;0， 则 [X]补 = [X]反+1 </li>
<li>没有[+0]和[-0]之分</li>
</ul>
</li>
</ul>
</li>
<li>无符号整数的表示范围(n表示字长)： 0 ≤ X ≤ 2^n - 1</li>
<li>有符号整数的表示范围： <ul>
<li>原码和反码： -（2^(n-1) -1） ≤ X ≤ 2^(n-1) -1 </li>
<li>补码： -2^(n-1) ≤ X ≤ 2^(n-1) -1 </li>
<li>对8位二进制数：<ul>
<li>原码： -127 ～+127</li>
<li>反码： -127 ～+127</li>
<li>补码： -128 ～+127 </li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="第七讲-基本逻辑运算和逻辑门"><a href="#第七讲-基本逻辑运算和逻辑门" class="headerlink" title="第七讲 基本逻辑运算和逻辑门"></a>第七讲 基本逻辑运算和逻辑门</h2><ul>
<li>逻辑，命题，推理</li>
<li>基本逻辑运算：与或非</li>
<li>逻辑运算是按位进行的运算，低位运算结果对高位运算不产生影响 </li>
<li>算术运算是两个数之间的运算，低位运算结果将对高位运算产生影响</li>
</ul>
<h2 id="第八讲-基本逻辑运算及其门电路"><a href="#第八讲-基本逻辑运算及其门电路" class="headerlink" title="第八讲 基本逻辑运算及其门电路"></a>第八讲 基本逻辑运算及其门电路</h2><ul>
<li>与非，或非，异或，同或</li>
</ul>
<h1 id="第二章-微处理器与总线"><a href="#第二章-微处理器与总线" class="headerlink" title="第二章 微处理器与总线"></a>第二章 微处理器与总线</h1><h2 id="第九讲-8088-8086微处理器"><a href="#第九讲-8088-8086微处理器" class="headerlink" title="第九讲 8088/8086微处理器"></a>第九讲 8088/8086微处理器</h2><ul>
<li>8088/8086 CPU的特点 <ul>
<li>采用并行流水线工作方式<ul>
<li>通过设置指令预取队列实现</li>
</ul>
</li>
<li>对内存空间实行分段管理<ul>
<li>将内存分为4个段并设置地址段寄存器，以实现对1MB空间的寻址</li>
</ul>
</li>
<li>支持协处理器</li>
</ul>
</li>
<li>8088/8086可工作于两种模式下 <ul>
<li>最小模式：单处理器模式，所有控制信号由微处理器产生<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200605180344.png"></li>
</ul>
</li>
<li>最大模式：最大模式为多处理器模式，部分控制信号由外部总线控制器产生 <ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200605180420.png"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="第十讲-8088的主要引线及其内部结构"><a href="#第十讲-8088的主要引线及其内部结构" class="headerlink" title="第十讲 8088的主要引线及其内部结构"></a>第十讲 8088的主要引线及其内部结构</h2><ul>
<li>8088最小模式下的主要引脚信号<ul>
<li>完成一次访问内存或接口所需要的主要信号</li>
<li>与外部同步控制信号</li>
<li>中断请求和响应信号</li>
<li>总线保持和响应信号<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200605180737.png"></li>
</ul>
</li>
<li>主要控制信号<ul>
<li>WR：  写信号；</li>
<li>RD：  读信号；</li>
<li>IO/M：为“0”表示访问内存，为“1”表示访问接口；</li>
<li>DEN： 低电平有效时，允许进行读/写操作；</li>
<li>DT/R：数据收发器的传送方向控制；</li>
<li>ALE：  地址锁存信号；</li>
<li>RESET：复位信号。 </li>
</ul>
</li>
<li>中断请求和响应信号<ul>
<li>INTR：可屏蔽中断请求输入端</li>
<li>NMI： 非屏蔽中断请求输入端 </li>
<li>INTA：中断响应输出端 </li>
</ul>
</li>
<li>总线保持信号<ul>
<li>HOLD：总线保持请求信号输入端。当CPU以外的其他设备要求占用总线时，通过该引脚向CPU发出请求。</li>
<li>HLDA：总线保持响应信号输出端。CPU对HOLD信号的响应信号。 </li>
</ul>
</li>
<li>微处理器读取一条指令的控制过程<ul>
<li>1.发出读取数据所在的目标地址<ul>
<li>内存储器单元地址</li>
<li>I/O接口地址 </li>
</ul>
</li>
<li>2.发出读控制信号</li>
<li>3.送出传输的数据 </li>
</ul>
</li>
<li>地址线和数据线：<ul>
<li>20位地址信号(20根地址线)–》可产生2^20=1M个编码 </li>
<li>8位数据信号(8位数据线)–》可同时传输8bit二进制码 </li>
</ul>
</li>
<li>8088内部结构：<ul>
<li>执行单元EU<ul>
<li>构成：运算器，8个通用寄存器，1个标志寄存器，EU部分控制电路</li>
<li>功能：指令译码，指令执行，暂存中间运算结果，保存运算结果特征 </li>
</ul>
</li>
<li>总线接口单元BIU<ul>
<li>功能：</li>
<li>从内存中取指令到指令预取队列，指令预取队列是并行流水线工作的基础</li>
<li>负责与内存或输入/输出接口之间的数据传送</li>
<li>在执行转移程序时，BIU使指令预取队列复位，从指定的新地址取指令，并立即传给执行单元执行。 </li>
</ul>
</li>
</ul>
</li>
<li>指令预取队列的存在使EU和BIU两个部分可同时进行工作 </li>
<li>8088和8086CPU引线功能比较 <ul>
<li>数据总线宽度不同：8088的外部总线宽度是8位，8086为16位。 </li>
<li>访问存储器和输入输出控制信号含义不同：8088——IO/M=0表示访问内存；8086——IO/M=1表示访问内存。 </li>
<li>其他部分引线功能的区别 </li>
</ul>
</li>
</ul>
<h2 id="第十一讲-8088CPU内部寄存器"><a href="#第十一讲-8088CPU内部寄存器" class="headerlink" title="第十一讲 8088CPU内部寄存器"></a>第十一讲 8088CPU内部寄存器</h2><ul>
<li>含14个16位寄存器，按功能可分为三类： <ul>
<li>8个通用寄存器<ul>
<li>数据寄存器（AX，BX，CX，DX）</li>
<li>地址指针寄存器（SP，BP）</li>
<li>变址寄存器（SI，DI） </li>
</ul>
</li>
<li>4个段寄存器</li>
<li>2个控制寄存器  </li>
</ul>
</li>
<li>通用寄存器：<ul>
<li>数据寄存器：8088/8086含4个16位数据寄存器，它们又可分为8个8位寄存器，即： <ul>
<li>AX——-AH，AL：累加器，所有I/O指令都通过AX与接口传送信息，中间运算结果也多放于AX中； </li>
<li>BX——-BH，BL：基址寄存器,在间接寻址中用于存放基地址</li>
<li>CX——-CH，CL：计数寄存器,用于在循环或串操作指令中存放计数值</li>
<li>DX——-DH，DL：数据寄存器,在间接寻址的I/O指令中存放I/O端口地址；在32位乘除法运算时，存放高16位数。 </li>
</ul>
</li>
<li>地址指针寄存器:<ul>
<li>SP：堆栈指针寄存器，其内容为栈顶的偏移地址 </li>
<li>BP：基址指针寄存器，常用于在访问内存时存放内存单元的偏移地址。 </li>
</ul>
</li>
<li>变址寄存器 <ul>
<li>SI：源变址寄存器</li>
<li>DI：目标变址寄存器</li>
<li>变址寄存器在指令中常用于存放数据在内存中的地址。 </li>
</ul>
</li>
</ul>
</li>
<li>BX与BP在应用上的区别 <ul>
<li>作为通用寄存器，二者均可用于存放数据；</li>
<li>作为基址寄存器，用BX表示所寻找的数据在数据段；用BP 则表示数据在堆栈段。 </li>
</ul>
</li>
<li>段寄存器:<ul>
<li>作用:用于存放相应逻辑段的段基地址</li>
<li>8086/8088内存中逻辑段的类型<ul>
<li>代码段: 存放指令代码</li>
<li>数据段: 存放操作的数据</li>
<li>附加段: 存放附加的操作的数据</li>
<li>堆栈段: 存放暂时不用但需保存的数据。 </li>
</ul>
</li>
<li>CS:代码段寄存器，存放代码段的段基地址。</li>
<li>DS:数据段寄存器，存放数据段的段基地址。</li>
<li>ES:附加段寄存器，存放附加段的段基地址。</li>
<li>SS:堆栈段寄存器，存放堆栈段的段基地址 </li>
<li>段寄存器的值表明相应逻辑段在内存中的位置 </li>
</ul>
</li>
<li>控制寄存器：<ul>
<li>指令指针控制寄存器IP</li>
<li>状态标志寄存器FLAGS<ul>
<li>状态标志位：<ul>
<li>CF:进位标志位。加(减)法运算时，若最高位有进(借)位则CF=1</li>
<li>OF:溢出标志位。当算术运算的结果超出了有符号数的可表达范围时，OF=l</li>
<li>ZF:零标志位。当运算结果为零时ZF=1</li>
<li>SF:符号标志位。当运算结果的最高位为1时，SF=l</li>
<li>PF:奇偶标志位。运算结果的低8位中“1”的个数为偶数时PF=l</li>
<li>AF:辅助进位标志位。加(减)操作中，若Bit3(D3)向Bit4(D4)有进位(借位)， AF=1</li>
</ul>
</li>
<li>控制标志位：<ul>
<li>TF:单步陷阱标志位，也叫跟踪标志位。TF=1时，使CPU处于单步执行指令的工作方式。</li>
<li>IF:中断允许标志位。IF=1时，CPU可以响应中断请求。</li>
<li>DF:方向标志位。在数据串操作时确定操作的方向。 </li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="第十二讲-实模式下的存储器寻址"><a href="#第十二讲-实模式下的存储器寻址" class="headerlink" title="第十二讲 实模式下的存储器寻址"></a>第十二讲 实模式下的存储器寻址</h2><ul>
<li>存储单位地址及其内容表示<ul>
<li>若X表示某个单元地址，则[X]表示X单元的内容</li>
<li>例如：[0004H]=34H代表34存放在4号单元，而[0004H]=1234H，代表34存放在4号单元，12存放在5号单元</li>
</ul>
</li>
<li>字的存储<ul>
<li>占连续两个字节（16位）</li>
<li>低对低，高对高</li>
<li>用低位地址来表示字的地址</li>
</ul>
</li>
<li>规则存放，非规则存放<ul>
<li>8088：数据总线8位，每次传送1个字节</li>
<li>8086：数据总线16位<ul>
<li>字：16位，规则字，以偶地址开始存放</li>
<li>字节： 高8位传送奇地址，低8位传送偶地址</li>
</ul>
</li>
</ul>
</li>
<li>内存储器管理<ul>
<li>8088CPU是16位体系结构的微处理器</li>
<li>可以同时处理16位二进制码</li>
<li>8088CPU需要管理1MB内存</li>
</ul>
</li>
<li>分段技术<ul>
<li>分为若干个逻辑段，取内地址，用16位表示，每段最大64KB</li>
<li>对段首地址（物理地址）规定，段首地址低4位为0，例如：00000H,00010H,FFFF0H</li>
<li>段地址：段的起始地址的高16位</li>
<li>偏移地址：段内相对于段的起始地址的偏移量（字节数）</li>
</ul>
</li>
<li>实地址模式下的存储器地址变换<ul>
<li>内存物理地址由段基地址和偏移地址组成</li>
<li>物理地址=段基地址×16+偏移地址</li>
</ul>
</li>
<li>内存地址变换<ul>
<li>内存单元编址<ul>
<li>段（基）地址</li>
<li>段内地址（相对地址/偏移地址）</li>
</ul>
</li>
<li>存储器的编址<ul>
<li>段（基）地址</li>
<li>相对地址（偏移地址）</li>
<li>逻辑段的起始地址称为段首，段首的偏移地址0000H</li>
</ul>
</li>
</ul>
</li>
<li>段寄存器：<ul>
<li>作用：用于存放相应逻辑段的段基地址</li>
<li>8086/8088内存中逻辑段的类型<ul>
<li>代码段==&gt;CS（代码段寄存器）<ul>
<li>CS×16+IP</li>
</ul>
</li>
<li>数据段==&gt;DS（数据段寄存器）<ul>
<li>DS×16+偏移地址</li>
</ul>
</li>
<li>附加段==&gt;ES（附加段寄存器）<ul>
<li>ES×16+偏移地址</li>
</ul>
</li>
<li>堆栈段==&gt;SS（堆栈段寄存器）<ul>
<li>SS×16+SP</li>
</ul>
</li>
</ul>
</li>
<li>8086/8088内存中每类逻辑段的数量最多64K个</li>
</ul>
</li>
<li>逻辑段与逻辑地址<ul>
<li>内存的分段式逻辑分段，不是物理段</li>
<li>两个逻辑段可以完全重合或部分重合</li>
</ul>
</li>
<li>堆栈及堆栈段的使用<ul>
<li>堆栈： <ul>
<li>内存中一个特殊区域，用于存放暂时不用或需要保护的数据。</li>
<li>常用于响应中断或子程序调用</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200626171551.png"></p>
<h2 id="第十三讲-8088-系统总线"><a href="#第十三讲-8088-系统总线" class="headerlink" title="第十三讲 8088 系统总线"></a>第十三讲 8088 系统总线</h2><ul>
<li>总线时序<ul>
<li>CPU工作时序<ul>
<li>CPU各引脚信号在时间上的关系</li>
</ul>
</li>
<li>总线周期<ul>
<li>CPU完成一次访问内存（或接口）操作所需要的时间</li>
<li>8086的基本总线周期为4个时钟周期，每个时钟周期间隔称为一个T状态（8086/8088：5MHz时钟信号，时钟周期T=200ns）<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200626181818.png"></li>
<li>T1 状态：BIU将RAM或I/O地址放在地址/数据复用             总线（AD）上。</li>
<li>T2 状态：   <ul>
<li>读总线周期： A/D总线为接收数据做准备。改变线路的方向。</li>
<li>写总线周期： A/D总线上形成待写的数据，且保持到总线周期的结束(T4)。</li>
</ul>
</li>
<li>T3, T4:对于读或写总线周期，AD总线上均为数据。</li>
<li>Tw: 当RAM或I/O接口速度不够时，T3与 T4 之间可插入等待状态 Tw 。</li>
<li>Ti : 当BIU无访问操作数和取指令的任务时，8086不执行总线操作，总线周期处于空闲状态 Ti 。</li>
</ul>
</li>
</ul>
</li>
<li>总线：<ul>
<li>按层次结构分类：<ul>
<li>CPU总线</li>
<li>系统总线</li>
<li>外部总线</li>
</ul>
</li>
<li>按传送信息的类别分类：<ul>
<li>地址总线</li>
<li>数据总线</li>
<li>控制总线</li>
</ul>
</li>
<li>按总线在微机系统的位置分类：<ul>
<li>片内总线</li>
<li>片间总线</li>
<li>系统总线</li>
<li>通信总线</li>
</ul>
</li>
<li>总线的基本功能<ul>
<li>数据传送</li>
<li>仲裁控制</li>
<li>出错处理</li>
<li>总线驱动</li>
</ul>
</li>
<li>总线的主要性能指标<ul>
<li>总线带宽（B/S）<ul>
<li>单位时间内总线上可传送的数据量</li>
<li>总线带宽=位宽×工作频率</li>
</ul>
</li>
<li>总线位宽（bit）<ul>
<li>能同时传送的数据位数</li>
</ul>
</li>
<li>总线的工作频率（MHz）<ul>
<li>总线带宽=（位宽/8）×（工作频率/每个存储周期的时钟数）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>引脚信号设计特点<ul>
<li>分时复用，如引脚AD0-AD15<ul>
<li>如何实现：增加地址锁存器</li>
<li>8282三位锁存器</li>
<li>8286八位数据收发器</li>
</ul>
</li>
<li>两种工作模式复用<ul>
<li>最大模式</li>
<li>最小模式</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="第三章-指令系统概述"><a href="#第三章-指令系统概述" class="headerlink" title="第三章 指令系统概述"></a>第三章 指令系统概述</h1><h2 id="第十四讲-8088-8086指令系统"><a href="#第十四讲-8088-8086指令系统" class="headerlink" title="第十四讲 8088/8086指令系统"></a>第十四讲 8088/8086指令系统</h2><ul>
<li>指令：控制计算机完成某种操作的命令</li>
<li>指令系统：处理器所能识别的所有指令的集合</li>
<li>指令的兼容性：同一系列机的指令都是兼容的</li>
<li>一条指令应包含的信息：<ul>
<li>运算数据的来源</li>
<li>运算结果的去向</li>
<li>执行的操作</li>
</ul>
</li>
<li>指令格式<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200626182906.png"></li>
<li>指令中的操作数<ul>
<li>立即数：参加操作的数据本身，可以是8位或16位，只能作为源操作数，无法作为目标操作数<ul>
<li><code>MOV AX, 1234H</code></li>
</ul>
</li>
<li>寄存器：数据存放地址<ul>
<li><code>MOV AX, BX</code></li>
</ul>
</li>
<li>存储器：数据存放地址<ul>
<li>参加运算的数存放在存储器的某一个或两个单元中</li>
<li>表现形式： [操作数在内存中的偏移地址]</li>
<li><code>MOV AL, [1200H]</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="第十五讲-指令的寻址方式"><a href="#第十五讲-指令的寻址方式" class="headerlink" title="第十五讲 指令的寻址方式"></a>第十五讲 指令的寻址方式</h2><ul>
<li><p>操作数可能的来源或运算结果可能的去处：</p>
<ul>
<li>由指令直接给出</li>
<li>寄存器</li>
<li>内存单元</li>
</ul>
</li>
<li><p>寻找操作数所在地址的方法可以有三种大类型：</p>
<ul>
<li>指令直接给出的方式</li>
<li>存放于寄存器中的寻址方式</li>
<li>存放于存储器中的寻址方式</li>
</ul>
</li>
<li><p>1.直接寻址：</p>
<ul>
<li>指令中直接给出操作数的偏移地址</li>
<li>直接寻址方式下，操作数默认为在数据段，但允许段重设，即由指令给出所在逻辑段。 </li>
<li><code>MOV AX，ES：[1200H]</code>  ES：段重设符</li>
</ul>
</li>
<li><p>2.寄存器间接寻址</p>
<ul>
<li>操作数存放在内存中，数据在内存中的偏移地址为方括号中通用寄存器的内容</li>
<li>仅有4个通用寄存器可用于存放数据的偏移地址，<code>BX</code>，<code>BP</code>，<code>SI</code>，<code>DI</code><ul>
<li>若使用<code>BX</code>,<code>SI</code>,<code>DI</code>，则操作数在数据段<code>DS</code>中<ul>
<li>物理地址=DS×16+{BX/SI/DI}</li>
</ul>
</li>
<li>若使用<code>BP</code>，则操作数在堆栈段<code>SS</code>中<ul>
<li>物理地址=SS×16+BP</li>
</ul>
</li>
</ul>
</li>
<li>间接寻址的一般格式：[ 间址寄存器 ] </li>
<li>例： <code>MOV AX，[BX]</code></li>
<li>可以段重设</li>
</ul>
</li>
<li><p>3.寄存器相对寻址</p>
<ul>
<li>操作数的偏移地址为寄存器的内容加上一个位移量</li>
<li>相对寻址主要用于一维数组的操作</li>
<li><code>MOV AX，[BX+DATA]</code></li>
</ul>
</li>
<li><p>4.基址、变址寻址</p>
<ul>
<li>操作数的偏移地址为<ul>
<li>一个基址寄存器的内容 + 一个变址寄存器的内容；</li>
</ul>
</li>
<li>操作数的<strong>段地址由选择的基址寄存器决定</strong><ul>
<li>基址寄存器为<code>BX</code>，默认在数据段<code>DS</code></li>
<li>基址寄存器为<code>BP</code>，默认在堆栈段<code>SS</code></li>
</ul>
</li>
<li>基址变址寻址方式与相对寻址方式一样，主要用于一维数组操作。 </li>
</ul>
</li>
<li><p>5.基址、变址、相对寻址</p>
<ul>
<li>操作数的偏移地址为：<ul>
<li>基址寄存器内容+变址寄存器内容+位移量</li>
</ul>
</li>
<li>操作数的段地址由选择的基址寄存器决定。</li>
<li>基址变址相对寻址方式主要用于二维表格操作。</li>
<li>例如：<code>MOV AL, [BP][DI]5</code>==&gt;也可以表示为<code>[BP+DI+5]</code></li>
</ul>
</li>
<li><p>6.隐含寻址</p>
<ul>
<li>指令中隐含了一个或两个操作数的地址，即操作数在默认的地址中。</li>
<li>例：<ul>
<li><code>MUL BL</code></li>
</ul>
</li>
<li>指令执行：<ul>
<li><code>AL×BL--&gt;AX</code></li>
</ul>
</li>
</ul>
</li>
<li><p>I/O端口寻址方式</p>
<ul>
<li>直接端口寻址<ul>
<li>由指令提供一个8位端数（0-255）</li>
</ul>
</li>
<li>间接端口寻址<ul>
<li>由DX寄存器给出，寻址64KB</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200626201755.png"></p>
<h2 id="第十六讲-数据传送指令"><a href="#第十六讲-数据传送指令" class="headerlink" title="第十六讲 数据传送指令"></a>第十六讲 数据传送指令</h2><ul>
<li>8086指令系统从功能上包括六大类：<ul>
<li>数据传送</li>
<li>算术运算</li>
<li>逻辑运算和移位</li>
<li>串操作</li>
<li>程序控制</li>
<li>处理器控制</li>
</ul>
</li>
<li>数据传送类指令<ul>
<li>1.通用数据传送指令<ul>
<li>一般数据传送指令<ul>
<li><code>MOV</code></li>
<li>格式：<code>MOV dest,src</code></li>
<li>操作：<code>src-&gt;dest</code></li>
<li>例子：<code>MOV AL, BL</code></li>
<li>注意点：两操作数字长必须相同；两操作数不允许同时为存储器操作数；两操作数不允许同时为段寄存器；在源操作数是立即数时，目标操作数不能是段寄存器；IP和CS不作为目标操作数，FLAGS一般也不作为操作数在指令中出现。 </li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200626203308.png"></li>
</ul>
</li>
<li>堆栈操作指令<ul>
<li>先进后出，以字为单位</li>
<li>压栈：<code>PUSH OPRD</code> 16位寄存器或存储器两单元</li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200626204137.png"></li>
<li>出栈：<code>POP OPRD</code></li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200626204453.png"></li>
<li>指令的操作数必须是16位；操作数可以是寄存器或存储器两单元，但不能是立即数；不能从栈顶弹出一个字给CS；PUSH和POP指令在程序中一般成对出现；PUSH指令的操作方向是从<code>高地址向低地址</code>，而POP指令的操作正好相反。 </li>
<li>堆栈指针寄存器SP指向栈顶位置</li>
</ul>
</li>
<li>交换指令<ul>
<li>格式：<code>XCHG REG，MEM/REG</code></li>
<li>注：两操作数必须有一个是寄存器操作数;不允许使用段寄存器。</li>
<li>例：<code>XCHG AX, BX</code>,<code>XCHG [2000], CL</code></li>
</ul>
</li>
<li>查表转换指令<ul>
<li>格式：<code>XLAT</code></li>
<li>说明：用BX的内容代表表格首地址，AL内容为表内位移量，BX+AL得到要查找元素的偏移地址</li>
<li>操作：将BX+AL所指单元的内容送AL（将BX为首地址的,偏移地址为AL的内容送给AL。）</li>
</ul>
</li>
<li>字位扩展指令 <ul>
<li>将符号数的符号位扩展到高位；</li>
<li>指令为零操作数指令，采用隐含寻址，隐含的操作数为AX及AX，DX</li>
<li>无符号数的扩展规则为在高位补0</li>
<li>字节到字：<code>CBW</code>，将AL内容扩展到AX ，若AL最高位=1，则执行后AH=FFH，若AL最高位=0，则执行后AH=00H 。AL不变（即将AL的符号位移至AH）<ul>
<li>CBW属符号扩展指令，它可以把8位扩展到16位，扩展前后两数的真值不变，主要用于数据类型不同时用符号扩展指令可以使得数据类型相同。</li>
</ul>
</li>
<li>字到双字：<code>CWD</code>，将AX内容扩展到DX AX ，若AX最高位=1，则执行后DX=FFFFH，若AX最高位=0，则执行后DX=0000H<ul>
<li>CWD的作用是将带符号的16位整数（AX）转为32位的带符号位的整数(DX:AX),例如：AX=0xFFFE, 转为32位带符号位的整数时，DX=0xFFFF,AX=0XFFFE.又例如：AX=0x0002,转为带符号位的整数时DX=0x0000,AX=0x0002.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>2.输入输出指令<ul>
<li>从端口地址读入数据到累加器/将累加器的值输出到端口中 </li>
<li>指令格式：<ul>
<li>输入指令： <code>IN acc，PORT</code></li>
<li>输出指令 ：<code>OUT PORT，acc</code></li>
</ul>
</li>
<li>根据端口地址码的长度，指令具有两种不同的端口地址表现形式：直接寻址，间接寻址</li>
</ul>
</li>
<li>3.地址传送指令<ul>
<li><code>LEA</code>取偏移地址指令<ul>
<li>将变量的16位偏移地址写入到目标寄存器</li>
<li><code>LEA REG,SRC</code></li>
</ul>
</li>
<li><code>LDS</code>指令<ul>
<li><code>LDS</code>（Load pointer using DS）的一般格式：</li>
<li><code>LDS 通用寄存器，存储器操作数(32位)</code></li>
</ul>
</li>
<li><code>LES</code>指令<ul>
<li><code>LDS</code>和<code>LES</code>均用于将一个32位的远地址指针写入到目标寄存器。</li>
<li><code>LES</code>（Load pointer using ES）的一般格式：</li>
<li><code>LES 通用寄存器，存储器操作数(32位)</code></li>
</ul>
</li>
</ul>
</li>
<li>4.标志传送指令<ul>
<li>隐含操作数AH,将FLAGS的低8位装入AH <ul>
<li><code>LAHF</code>（Load AH from Flags）</li>
<li><code>SAHF</code>（Store AH into Flags）</li>
</ul>
</li>
<li>隐含操作数FLAGS<ul>
<li><code>PUSHF</code>（Push flags onto stack）</li>
<li><code>POPF</code>（Pop flags off stack）</li>
</ul>
</li>
<li>除标志传送指令外，其它指令的执行对标志位不产生影响</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="第四章-算术运算，逻辑运算与移位操作指令"><a href="#第四章-算术运算，逻辑运算与移位操作指令" class="headerlink" title="第四章 算术运算，逻辑运算与移位操作指令"></a>第四章 算术运算，逻辑运算与移位操作指令</h1><h2 id="第十七讲-算术运算类指令"><a href="#第十七讲-算术运算类指令" class="headerlink" title="第十七讲 算术运算类指令"></a>第十七讲 算术运算类指令</h2><ul>
<li>加法运算指令<ul>
<li>1.<code>ADD</code>加法指令<ul>
<li>格式：<code>ADD OPRD1，OPRD2</code></li>
<li>操作：<code>OPRD1+OPRD2--&gt;OPRD1</code></li>
<li>ADD指令的执行对全部6个状态标志位都产生影响</li>
</ul>
</li>
<li>2.<code>ADC</code>带进位的加法指令<ul>
<li><code> OPRD1+OPRD2+CF--&gt;OPRD1</code></li>
</ul>
</li>
<li>3.<code>INC</code>加1指令<ul>
<li>格式：<code>INC OPRD</code></li>
<li>操作：<code>OPRD+1--&gt;OPRD</code></li>
<li>常用于在程序中修改地址指针,OPRD不能是段寄存器,不能是立即数，除CF外，影响其他标志位</li>
</ul>
</li>
</ul>
</li>
<li>减法运算指令<ul>
<li>1.普通减法指令<code>SUB</code><ul>
<li>格式：<code>SUB OPRD1，OPRD2</code></li>
<li>操作：<code>OPRD1- OPRD2--&gt;OPRD1</code></li>
<li>对标志位的影响与ADD指令同</li>
</ul>
</li>
<li>2.考虑借位的减法指令<code>SBB</code><ul>
<li>操作：<code>OPRD1- OPRD2- CF--&gt;OPRD1</code></li>
</ul>
</li>
<li>3.减1指令<code>DEC</code><ul>
<li>格式：<code>DEC OPRD</code></li>
<li>操作：<code>OPRD - 1--&gt;OPRD</code></li>
<li>除了不影响CF外，影响其他标志位</li>
</ul>
</li>
<li>4.比较指令<code>CMP</code><ul>
<li>格式：    <code>CMP OPRD1，OPRD2</code></li>
<li>操作：<code>OPRD1- OPRD2</code></li>
<li>指令执行的结果不影响目标操作数，仅影响标志位！</li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200626210751.png"></li>
</ul>
</li>
<li>5.求补指令<code>NEG</code><ul>
<li><code>NEG OPRD</code></li>
<li>操作：<code>0-OPRD--&gt;OPRD</code></li>
</ul>
</li>
</ul>
</li>
<li>乘法指令<ul>
<li>乘法指令采用隐含寻址，隐含的是存放被乘数的累加器AL或AX及存放结果的AX，DX； </li>
<li>1.无符号的乘法指令MUL<ul>
<li><code>MUL OPRD</code>不能是立即数和段寄存器</li>
<li>操作：<ul>
<li>OPRD为字节数<code>AL×OPRD--&gt;AX</code></li>
<li>OPRD为16位数<code>AX×OPRD--&gt;DX,AX</code></li>
</ul>
</li>
</ul>
</li>
<li>2.带符号的乘法指令IMUL <ul>
<li>格式：<code>IMUL OPRD</code></li>
<li>指令格式及对操作数的要求与MUL指令相同。</li>
<li>指令执行原理：<ul>
<li>① 将两个操作数取补码（对负数按位取反加1，正数不变）；</li>
<li>② 做乘法运算；</li>
<li>③ 将乘积按位取反加1。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>除法指令<ul>
<li>1.无符号除法指令<ul>
<li>格式： <code>DIV OPRD</code></li>
<li>操作：<ul>
<li>操作数是字节(8位)：<code>AX/OPRD</code>,商–&gt;AL,余数–&gt;AH</li>
<li>操作数是字(16位)：<code>DX,AX/OPRD</code>,商–&gt;AX,余数–&gt;DX</li>
</ul>
</li>
</ul>
</li>
<li>2.有符号除法指令<ul>
<li>格式： <code>IDIV OPRD</code></li>
<li>指令格式及对操作数的要求与DIV指令相同。</li>
</ul>
</li>
<li>注：<ul>
<li>余数符号与被除数相同</li>
<li>范围<ul>
<li>双字/字：商范围 -32768到+32767</li>
<li>字/字节：商范围 -128到+127</li>
<li>超过范围按除数为0处理，产生0号中断<br>算术运算指令的执行大多对状态标志位会产生影响</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="第十八讲-逻辑运算指令"><a href="#第十八讲-逻辑运算指令" class="headerlink" title="第十八讲 逻辑运算指令"></a>第十八讲 逻辑运算指令</h2><ul>
<li>逻辑运算指令<ul>
<li>对操作数的要求：<ul>
<li>大多与MOV指令相同。</li>
<li>“非”运算指令要求操作数不能是立即数；</li>
</ul>
</li>
<li>对标志位的影响<ul>
<li>除“非”运算指令，其余指令的执行都会影响除<code>AF</code>外的5个状态标志；</li>
<li>无论执行结果如何，都会使标志位<code>OF=CF=0</code>。</li>
<li>“非”运算指令的执行不影响标志位。 </li>
</ul>
</li>
</ul>
</li>
<li>1.”与”指令<ul>
<li>格式：<code>AND OPRD1，OPRD2</code></li>
<li>操作：两操作数相“与”，结果送目标地址。<code>(OPRD1)∧(OPRD2)--&gt;(OPRD1)</code></li>
<li>CF=0,OF=0,SF,ZF,PF有影响，对AF无影响</li>
</ul>
</li>
<li>2.”或”指令<ul>
<li>格式：<code>OR OPRD1，OPRD2</code></li>
<li>操作：两操作数相“或”，结果送目标地址 </li>
</ul>
</li>
<li>3.”非”指令<ul>
<li>格式：<code>NOT OPRD</code></li>
<li>操作：操作数按位取反再送回原地址</li>
</ul>
</li>
<li>4.”异或”指令<ul>
<li>格式：<code>XOR OPRD1，OPRD2</code></li>
<li>操作：两操作数相“异或”，结果送目标地址 </li>
</ul>
</li>
<li>5.”测试”指令<ul>
<li>格式：<code>TEST OPRD1，OPRD2</code></li>
<li>操作：执行“与”运算，但运算的结果不送回目标地址。</li>
<li>应用：常用于测试某些位的状态 </li>
</ul>
</li>
</ul>
<h2 id="第十九讲-移位操作指令"><a href="#第十九讲-移位操作指令" class="headerlink" title="第十九讲 移位操作指令"></a>第十九讲 移位操作指令</h2><ul>
<li>移位操作指令<ul>
<li>控制二进制位向左或向右移动的指令<ul>
<li>非循环移位指令</li>
<li>循环移位指令</li>
</ul>
</li>
<li>移动移动1位时由指令直接给出；移动两位及以上时，移位次数必须由CL指定</li>
</ul>
</li>
<li>1.非循环移位指令<ul>
<li>逻辑左移<code>SHL</code><ul>
<li>格式： <code>SHL OPR,CNT</code></li>
<li>注：<ul>
<li>OPR不能是立即数和段寄存器操作数</li>
<li>CNT移位次数，若为1，直接写在指令中，若为几，必须先写入CL中</li>
<li>对CF，OP，PF,ZF，SF有影响，对AF无意义</li>
</ul>
</li>
</ul>
</li>
<li>算术左移<code>SAL</code><ul>
<li>格式：<code>SAL OPR,CNT</code></li>
<li>操作同<code>SHL</code></li>
</ul>
</li>
<li>逻辑右移<code>SHR</code><ul>
<li>格式：<code>SHR OPR,CNT</code></li>
</ul>
</li>
<li>算术右移<code>SAR</code><ul>
<li>格式：<code>SAR OPR,CNT</code></li>
<li>操作：左边补上符号位，和之前的符号一样</li>
</ul>
</li>
</ul>
</li>
<li>2.循环移位指令<ul>
<li>不带进位位的循环移位<ul>
<li>左移 <code>ROL</code><ul>
<li>格式： <code>ROL OPR,CNT</code></li>
</ul>
</li>
<li>右移 <code>ROR</code><ul>
<li>格式： <code>ROR OPR,CNT</code></li>
</ul>
</li>
</ul>
</li>
<li>带进位位的循环移位<ul>
<li>左移 <code>RCL</code><ul>
<li>格式： <code>RCL OPR,CNT</code></li>
</ul>
</li>
<li>右移 <code>RCR</code><ul>
<li>格式： <code>RCR OPR,CNT</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="第五章-串操作指令"><a href="#第五章-串操作指令" class="headerlink" title="第五章 串操作指令"></a>第五章 串操作指令</h1><h2 id="第二十讲-串操作指令"><a href="#第二十讲-串操作指令" class="headerlink" title="第二十讲 串操作指令"></a>第二十讲 串操作指令</h2><ul>
<li>针对数据块或字符串的操作 </li>
<li>可实现存储器到存储器的数据传送； </li>
<li>待操作的数据串称为源串，目标地址称为目标串。 </li>
<li>串操作指令的操作对象是多个字节数（一串字符或数据），因此，指令的执行需要确定：<ul>
<li>串所在的区域<ul>
<li>源串一般存放在数据段，偏移地址由SI指定。允许段重设。</li>
<li>目标串必须在附加段，偏移地址由DI指定</li>
</ul>
</li>
<li>串的首地址（原串、目标串起始地址）</li>
<li>串长度（大小）<ul>
<li>串长度值由CX指定 </li>
</ul>
</li>
<li>串的操作方向<ul>
<li>由DF标志位决定。指令根据DF状态自动修改地址指针<ul>
<li>DF=0 增地址方向 </li>
<li>DF=1 减地址方向 </li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>通过增加重复前缀， 可以实现对CX值的自动修改 <ul>
<li> 无条件重复</li>
<li>REP<ul>
<li>当CX≠0时，REP后的指令将继续重复执行</li>
<li>常用于传送类指令前–》未传完则继续传送 </li>
</ul>
</li>
<li>条件重复<ul>
<li>相等（为零）重复：REPE（REPZ）</li>
<li>CX≠0  ∩  ZF=1，则前缀后的指令将继续重复执行</li>
<li>不相等（不为零）重复：REPNE（ REPNZ）</li>
<li>CX≠0  ∩  ZF=0，则前缀后的指令将继续重复执行 </li>
<li>条件前缀常用于运算类指令前，当：<ul>
<li>1）操作未结束  AND  结果=0</li>
<li>2）操作未结束  AND  结果≠0 使其后的指令继续重复执行。 </li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>串操作指令 <ul>
<li>串传送 <code>MOVS</code> </li>
<li>串比较 <code>CMPS</code> </li>
<li>串扫描 <code>SCAS</code> </li>
<li>串装入 <code>LODS</code> </li>
<li>串送存 <code>STOS</code> </li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627102608.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627102624.png"></p>
<h2 id="第二十一讲-串传送与串比较指令"><a href="#第二十一讲-串传送与串比较指令" class="headerlink" title="第二十一讲 串传送与串比较指令"></a>第二十一讲 串传送与串比较指令</h2><p>1.串传送指令</p>
<ul>
<li>功能：将原数据串传送到目标地址</li>
<li>格式：<ul>
<li><code>MOVS OPRD1，OPRD2</code></li>
<li><code>MOVSB</code>,按字节传送</li>
<li><code>MOVSW</code>，按字传送</li>
</ul>
</li>
<li>串传送指令常与无条件重复前缀连用</li>
</ul>
<p>2.串比较指令</p>
<ul>
<li>功能：用于实现两个数据串的比较</li>
<li>操作：<ul>
<li>目标串-源串，结果不写回目标地址</li>
<li>常与条件重复前缀连用</li>
</ul>
</li>
<li>格式：<ul>
<li><code>CMPS OPRD1，OPRD2</code></li>
<li><code>CMPSB</code></li>
<li><code>CMPSW</code></li>
</ul>
</li>
<li>前缀的操作对标志位不影响</li>
</ul>
<h2 id="第二十二讲-串扫描指令"><a href="#第二十二讲-串扫描指令" class="headerlink" title="第二十二讲 串扫描指令"></a>第二十二讲 串扫描指令</h2><ul>
<li><p>格式：</p>
<ul>
<li><code>SCAS OPRD</code></li>
<li><code>SCASB</code></li>
<li><code>SCASW</code></li>
</ul>
</li>
<li><p>执行与CMPS指令相似的操作，区别是：这里的源操作数是AX或AL</p>
</li>
<li><p>串扫描指令应用例：</p>
<ul>
<li>在ES段中从2000H单元开始存放了10个字符，寻找其中有无字符“A”。若有则记下搜索次数，将搜索次数写入到DATA1单元，并将存放“A”的地址写入DATA2单元。</li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627103549.png"></li>
</ul>
</li>
</ul>
<h2 id="第二十三讲-串装入与串存储指令"><a href="#第二十三讲-串装入与串存储指令" class="headerlink" title="第二十三讲 串装入与串存储指令"></a>第二十三讲 串装入与串存储指令</h2><p>1.串装入指令</p>
<ul>
<li>格式：<ul>
<li><code>LODS OPRD</code></li>
<li><code>LODSB</code></li>
<li><code>LODSW</code></li>
</ul>
</li>
<li>操作：<ul>
<li>对字节：AL  [DS:SI]</li>
<li>对  字：AX  [DS:SI]</li>
</ul>
</li>
</ul>
<p>2.串存储指令</p>
<ul>
<li><p>格式：</p>
<ul>
<li><code>STOS OPRD</code></li>
<li><code>STOSB</code></li>
<li><code>STOSW</code></li>
</ul>
</li>
<li><p>操作：</p>
<ul>
<li>对字节： AL  [ES:DI]</li>
<li>对  字： AX  [ES:DI]</li>
</ul>
</li>
<li><p>串操作指令应用注意事项:</p>
<ul>
<li>需要定义附加段<ul>
<li>目标操作数必须在附加段</li>
</ul>
</li>
<li>需要设置数据的操作方向<ul>
<li>确定DF的状态</li>
</ul>
</li>
<li>源串和目标串指针分别为SI和DI</li>
<li>串长度值必须由CX给出</li>
<li>注意重复前缀的使用方法<ul>
<li>传送类指令前加无条件重复前缀</li>
<li>串比较类指令前加条件重复前缀，但前缀不影响ZF状态 </li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="第六章-程序与处理器控制指令"><a href="#第六章-程序与处理器控制指令" class="headerlink" title="第六章 程序与处理器控制指令"></a>第六章 程序与处理器控制指令</h1><h2 id="第二十四讲-程序控制指令"><a href="#第二十四讲-程序控制指令" class="headerlink" title="第二十四讲 程序控制指令"></a>第二十四讲 程序控制指令</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627104125.png"></p>
<ul>
<li>程序控制类指令<ul>
<li>转移指令<ul>
<li>通过修改指令的偏移地址或段地址及偏移地址实现程序的转移</li>
<li>无条件转移指令–&gt;无条件转移到目标地址<ul>
<li><code>JMP OPRD</code></li>
<li>段内直接转移<ul>
<li>当偏移量为8位时，称为段内直接短跳转<ul>
<li>格式：<code>JMP (SHORT) 标号</code></li>
<li>操作：<code>(IP)&lt;--disp8+(IP)</code></li>
</ul>
</li>
<li>当偏移量为8位时，称为段内直接近跳转<ul>
<li>格式：<code>JMP (NEAR PTR) 标号</code></li>
<li>操作：<code>(IP)&lt;--disp16+(IP)</code></li>
</ul>
</li>
</ul>
</li>
<li>段内间接转移<ul>
<li><code>JMP BP</code><ul>
<li>转向(SS):(BP)</li>
</ul>
</li>
<li><code>JMP BX</code><ul>
<li>转向(CS):(BX)</li>
</ul>
</li>
<li><code>JMP (WORD PTR) [BX][DI]</code><ul>
<li>转向(CS):(BX)+(DI)</li>
</ul>
</li>
</ul>
</li>
<li>段间直接转移<ul>
<li><code>JMP (FAR PTR) 标号</code></li>
<li>执行该指令时，将把标号所在的段的值送CS，将标号在所属段内的偏移量送IP，从而形成新的转移地址CS:IP</li>
</ul>
</li>
<li>段间间接转移<ul>
<li><code>JMP DWORD PTR [BX]</code></li>
<li>中间的<code>DWORD PTR</code>不能省略，表示存储器双字操作数</li>
</ul>
</li>
</ul>
</li>
<li>条件转移指令–&gt;当具备一定条件时转移到目标地址<ul>
<li><code>JC/JNC</code><ul>
<li>判断CF的状态。常用于两个无符号数大小比较</li>
</ul>
</li>
<li><code>JZ/JNZ</code><ul>
<li>判断ZF的状态。常用于循环体的结束判断</li>
</ul>
</li>
<li><code>JO/JNO</code><ul>
<li>判断OF的状态。常用于有符号数溢出的判断</li>
</ul>
</li>
<li><code>JP/JNP</code><ul>
<li>判断PF的状态。用于判断运算结果低8位中1的个数是否为偶数</li>
</ul>
</li>
<li><code>JS /JNS</code><ul>
<li>判断SF的状态。常用于判断数的性质 </li>
</ul>
</li>
<li><code>JA/JAE/JB/JBE</code><ul>
<li>判断CF或CF+ZF的状态。常用于无符号数大小的比较</li>
</ul>
</li>
<li><code>JG/JGE/JL/JLE</code><ul>
<li>判断SF+OF或SF+OF+ZF的状态。常用于有符号数大小的比较</li>
</ul>
</li>
<li><code>JCXZ</code><ul>
<li>可根据指令执行后CX的结果实现转移<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200829201509.png"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>循环控制<ul>
<li><code>LOOP</code><ul>
<li>条件：CX≠0</li>
</ul>
</li>
<li><code>LOOPZ</code><ul>
<li>条件：CX≠0，且ZF=1</li>
</ul>
</li>
<li><code>LOOPNZ</code><ul>
<li>条件：CX≠0，且ZF=0</li>
</ul>
</li>
</ul>
</li>
<li>过程调用<ul>
<li>用于调用一个子过程，必须保护返回地址 </li>
<li>调用指令的执行过程<ul>
<li>① 保护断点：将调用指令的下一条指令的地址（断点）压入堆栈</li>
<li>② 获取子过程的入口地址：子过程第1条指令的偏移地址</li>
<li>③ 执行子过程：功能实现，参数的保存及恢复</li>
<li>④ 恢复断点，返回原程序：将断点偏移地址由堆栈弹出 </li>
</ul>
</li>
<li>段内调用：被调用程序与调用程序在同一代码段<ul>
<li><code>CALL NEAR PROCC</code></li>
</ul>
</li>
<li>段间调用:子过程与原调用程序不在同一代码段</li>
<li>返回指令:<ul>
<li>功能：从堆栈中弹出断点地址，返回原程序</li>
<li>格式：<code>RET</code></li>
<li>子程序的最后一条指令必须是RET</li>
</ul>
</li>
</ul>
</li>
<li>中断控制<ul>
<li>中断的概念:某种异常或随机事件使处理器暂时停止正在运行的程序，转去执行一段特殊处理程序，并在处理结束后返回原程序被中断处继续执行的过程。</li>
<li>中断指令：引起CPU产生一次中断的指令 <ul>
<li>格式：<code>INT n</code></li>
<li>说明： nх4</li>
</ul>
</li>
<li>中断指令的执行过程<ul>
<li>① 将FLAGS压入堆栈；</li>
<li>② 将INT指令的下一条指令的CS、IP压栈；</li>
<li>③ 由n×4得到存放中断向量的地址；</li>
<li>④ 将中断向量（中断服务程序入口地址）送CS和IP寄存器；</li>
<li>⑤ 转入中断服务程序</li>
</ul>
</li>
<li>中断返回指令:<ul>
<li>格式：<code>IRET</code></li>
<li>中断服务程序的最后一条指令，负责：恢复断点;恢复标志寄存器内容</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="第二十五讲-处理器控制指令"><a href="#第二十五讲-处理器控制指令" class="headerlink" title="第二十五讲 处理器控制指令"></a>第二十五讲 处理器控制指令</h2><ul>
<li>这类指令用来对CPU进行控制，如修改标志寄存器，使CPU暂停，使CPU与外部设备同步等。<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627113916.png"></li>
</ul>
<h1 id="第七章-汇编语言"><a href="#第七章-汇编语言" class="headerlink" title="第七章 汇编语言"></a>第七章 汇编语言</h1><h2 id="第二十六讲-汇编语言程序设计"><a href="#第二十六讲-汇编语言程序设计" class="headerlink" title="第二十六讲 汇编语言程序设计"></a>第二十六讲 汇编语言程序设计</h2><ol>
<li>汇编语言源程序与汇编程序<br>（1）汇编语言源程序：用助记符编写<br>（2）汇编程序：源程序的编译程序</li>
<li>汇编语言程序设计与执行过程<br>（1）输入汇编语言源程序：源文件.ASM<br>（2）汇编MASM：目标文件.OBJ<br>（3）链接LINK：可执行文件.EXE<br>（4）调试TD：最终程序</li>
<li>汇编语言语句类型和格式<br>（1）语句类型：指令性语句，指示性语句<br>（2）语句格式：<br>指令性语句：<code>[标号：] [前缀] 助记符 [操作数]，[操作数] [ ；注释] </code><br>指示性语句格式： <code>[名字] 伪指令助记符 操作数 [，操作数，…] [ ；注释] </code></li>
<li>汇编语言语句中的操作数<br>(1)寄存器<br>(2)存储器单元<br>(3)常量:（数字/字符串）<br>(4)变量或标号<br>(5)表达式 ：算术运算；逻辑运算；关系运算；取值运算（<code>OFFSET</code>,<code>SEG</code>）和属性运算(<code>PTR</code>)；其它运算 </li>
</ol>
<h2 id="第二十七讲-数据定义伪代码"><a href="#第二十七讲-数据定义伪代码" class="headerlink" title="第二十七讲 数据定义伪代码"></a>第二十七讲 数据定义伪代码</h2><ol>
<li>数据定义伪指令<br>（1）用于定义数据区中变量的类型及其所占内存空间大小<br>（2）DB（Define Byte）:定义的变量为字节型<br>（3）DW （Define Word） :定义的变量为字类型<br>（4）DD （Define Double Word） :定义的变量为双字型<br>（5）DQ （Define Quadword） :定义的变量为4字型<br>（6）DT （Define Tenbytes） :定义的变量为10字节型</li>
<li>重复操作符<br>（1）当同样的操作数重复多次时，可以使用重复操作符<br>（2）作用：为一个数据区的各单元设置相同的初值<br>（3）格式：[变量名] 伪指令助记符 n DUP（初值 [,初值,… ] ）<br>（4）例：<code>M1 DB 10 DUP（0）</code></li>
<li>“？”的作用<br>（1）表示随机值，用于预留存储空间<br>（2）例：<code>MEM1 DB 34H，’A’，？</code>，例：<code>DW 20 DUP（？）</code></li>
<li>调整偏移量伪指令<br>（1）规定程序或变量在逻辑段中的起始地址<br>（2）格式：<code>ORG 表达式</code><br>（3）例：<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">DATA <span class="meta">SEGMENT</span></span><br><span class="line">ORG <span class="number">1200H</span></span><br><span class="line">BUFF <span class="built_in">DB</span> <span class="number">1</span>,<span class="number">2</span></span><br><span class="line">DATA ENDS </span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="第二十八讲-符号与段定义相关伪指令"><a href="#第二十八讲-符号与段定义相关伪指令" class="headerlink" title="第二十八讲 符号与段定义相关伪指令"></a>第二十八讲 符号与段定义相关伪指令</h2><ol>
<li>符号定义伪指令<br>（1）将表达式的值赋给一个名字。当源程序中需多次引用某一表达式时，可以利用EQU伪指令，用一个符号代替表达式，以便于程序维护。<br>（2）格式：<code>符号名 EQU 表达式</code><br>（3）操作：用符号名取代后边的表达式，不可重新定义<br>（4）例：<code>CONSTANT EQU 100 </code></li>
<li>段定义伪指令<br>（1）在汇编语言源程序中定义逻辑段<br>说明逻辑段的起始和结束<br>说明不同程序模块中同类逻辑段之间的联系形态<br>（2）格式：<code>段名 SEGMENT [定位类型] [组合类型] [’类别’] </code></li>
<li>设定段寄存器伪指令<br>（1）说明所定义逻辑段的性质<br>（2）格式：<code>ASSUME 段寄存器名:段名[，段寄存器名:段名，…] </code></li>
<li>结束伪指令<br>（1）表示源程序结束<br>（2）格式：<code>END [标号] </code></li>
</ol>
<h2 id="第二十九讲-其他伪指令"><a href="#第二十九讲-其他伪指令" class="headerlink" title="第二十九讲 其他伪指令"></a>第二十九讲 其他伪指令</h2><ol>
<li>过程定义伪指令<br>（1）用于定义一个过程体<br>（2）格式：<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">过程名 PROC [ <span class="built_in">NEAR</span> / <span class="built_in">FAR</span> ]</span><br><span class="line">┇</span><br><span class="line"><span class="keyword">RET</span></span><br><span class="line">过程名 ENDP</span><br></pre></td></tr></table></figure>
（3）<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627120345.png"></li>
<li>宏命令伪指令<br>（1）宏：源程序中由汇编程序识别的具有独立功能的一段程序代码<br>（2）当源程序中需要多次使用同一个程序段时，可以将该程序段定义为一个宏<br>（3）格式：<code>宏命令名 MACRO &lt;形式参数&gt;</code><br>（4）<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627120517.png"></li>
</ol>
<h2 id="第三十讲-系统功能调用"><a href="#第三十讲-系统功能调用" class="headerlink" title="第三十讲 系统功能调用"></a>第三十讲 系统功能调用</h2><ol>
<li>BIOS、DOS功能调用<br>（1）BIOS：驻留在ROM中的基本输入/输出系统<br>加电自检，装入引导，主要I/O设备处理程序及接口控制<br>（2）DOS：磁盘操作系统<br>DOS功能/BIOS功能调用是调用系统内核子程序<br>（3）BIOS、DOS功能调用：DOS功能与BIOS功能均通过中断方式调用，DOS和BIOS中断均可能影响AX</li>
<li>DOS软中断<br>（1）DOS中断包括：设备管理，目录管理，文件管理，其它用中断类型码区分<br>（2）DOS软中断：类型码为21H </li>
<li>单字符输入<br>（1）调用方法：<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">MOV</span> <span class="number">AH</span>，<span class="number">01</span></span><br><span class="line"><span class="keyword">INT</span> <span class="number">21H</span></span><br></pre></td></tr></table></figure>
（2）输入的字符在AL中 </li>
<li>字符串输入<br>（1）接收由键盘输入一串字符<br>（2）输入的字符串存储在内存指导区域中<br>（3）用户自定义缓冲区格式：<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627121105.png"></li>
<li>单字符显示输出<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627121240.png"></li>
<li>字符串显示输出<br>AH 功能号09H<br>DS：DX 待输出字符串的偏移地址<br>INT 21H</li>
<li>返回操作系统（DOS）功能<br>（1）功能号：4CH<br>（2）调用格式：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MOV AH，4CH</span><br><span class="line">INT 21H</span><br></pre></td></tr></table></figure>
（3）功能：程序执行完该2条语句后能正常返回OS;常位于程序结尾处</li>
</ol>
<h1 id="第八章-半导体存储器"><a href="#第八章-半导体存储器" class="headerlink" title="第八章 半导体存储器"></a>第八章 半导体存储器</h1><h2 id="第三十一讲-半导体存储器概述"><a href="#第三十一讲-半导体存储器概述" class="headerlink" title="第三十一讲 半导体存储器概述"></a>第三十一讲 半导体存储器概述</h2><ol>
<li>半导体存储器<br>（1）由能够表示二进制数“0”和“1”的，具有记忆功能的半导体器件组成<br>（2）能存放一位二进制数的半导体器件称为一个存储元<br>（3）若干存储元构成一个存储单元</li>
<li>半导体存储器的分类</li>
</ol>
<ul>
<li>内存储器：<ul>
<li>随机存取存储器（RAM）<ul>
<li>静态存储器（SRAM）</li>
<li>动态存储器（DRAM）</li>
</ul>
</li>
<li>只读存储器（ROM）<ul>
<li>掩模ROM</li>
<li>一次性可写ROM</li>
<li>可读写ROM<ul>
<li>EPROM</li>
<li>EEPROM</li>
<li>PROM</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ol start="3">
<li>半导体存储器的主要技术指标<br>（1）存储容量：存储单元个数×每单元的二进制数位数<br>存储容量=2^m×N<br>（m：芯片地址线根数）<br>（N：芯片数据线根数）<br>（2）存取时间：实现一次读/写所需要的时间<br>（3）存取周期：连续启动两次独立的存储器操作所需间隔的最小时间<br>（4）可靠性，功耗</li>
</ol>
<h2 id="第三十二讲-微机中的存储器"><a href="#第三十二讲-微机中的存储器" class="headerlink" title="第三十二讲 微机中的存储器"></a>第三十二讲 微机中的存储器</h2><ol>
<li>微机中的存储器<br>（1）内存储器<br>主内存<br>高速缓冲存储器<br>（2）外存储器<br>联机外存<br>脱机外存<br>（3）虚拟存储器<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627143039.png"></li>
</ol>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">内存</th>
<th align="center">外存</th>
</tr>
</thead>
<tbody><tr>
<td align="center">速度</td>
<td align="center">快</td>
<td align="center">慢</td>
</tr>
<tr>
<td align="center">容量</td>
<td align="center">小</td>
<td align="center">大</td>
</tr>
<tr>
<td align="center">单位容量价格</td>
<td align="center">高</td>
<td align="center">低</td>
</tr>
<tr>
<td align="center">制造材料</td>
<td align="center">半导体</td>
<td align="center">磁性材料</td>
</tr>
</tbody></table>
<ol start="2">
<li><p>微机中的存储系统主要有：<br>（1）Cache存储器系统<br>（2）虚拟存储器系统</p>
</li>
<li><p>随机存取存储器<br>（1）特点：可以随机读或写操作；掉电后存储内容即丢失<br>（2）类型：静态随机存取存储器（SRAM）；动态随机存取存储器（DRAM）</p>
</li>
</ol>
<h2 id="第三十三讲-存储单元的编址"><a href="#第三十三讲-存储单元的编址" class="headerlink" title="第三十三讲 存储单元的编址"></a>第三十三讲 存储单元的编址</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627143427.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627143454.png"></p>
<ol>
<li>地址译码电路<br>（1）单译码结构<br>（2）双译码结构<br>（3）3-8译码器（741S138）</li>
</ol>
<h2 id="第三十四讲-存储器扩展技术"><a href="#第三十四讲-存储器扩展技术" class="headerlink" title="第三十四讲 存储器扩展技术"></a>第三十四讲 存储器扩展技术</h2><ol>
<li>存储器扩展：用已有的存储器芯片构造一个需要的存储空间<br>（1）用多片存储芯片构成一个需要的内存空间；<br>（2）各存储器芯片在整个内存中占据不同的地址范围；<br>（3）任一时刻仅有一片（或一组）被选中。<br>（4）存储器芯片的存储容量等于：单元数×每单元的位数 </li>
<li>存储器扩展方法<br>（1）位扩展–》扩展字长<br>（2）字扩展–》扩展单元数<br>（3）字位扩展–》既扩展字长也扩展单元数</li>
</ol>
<h1 id="第九章-输入输出与中断技术"><a href="#第九章-输入输出与中断技术" class="headerlink" title="第九章 输入输出与中断技术"></a>第九章 输入输出与中断技术</h1><h2 id="第三十五讲-输入输出技术概述"><a href="#第三十五讲-输入输出技术概述" class="headerlink" title="第三十五讲 输入输出技术概述"></a>第三十五讲 输入输出技术概述</h2><ol>
<li>I/O接口<br>（1）接口要解决的问题<br>速度匹配👉数据的缓冲与暂存<br>信号的驱动能力👉信号驱动<br>信号形式和电平的匹配👉信号类型转换<br>信息格式👉信号格式转换<br>时序匹配（定时关系）<br>总线隔离👉三态门 </li>
<li>I/O端口及其编址<br>（1）端口：接口电路中用于缓存数据及控制信息的部件<br>（2）分类：数据端口，控制端口，状态端口<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627144642.png"><br>（3）I/0端口编址：为确保CPU能够访问到每个不同的端口<br>（4）寻址端口的方法：</li>
</ol>
<ul>
<li>先找到端口所在的接口电路芯片</li>
<li>再在该芯片上找具体访问的端口<ul>
<li>若接口中仅有一个端口，则找到芯片即找到端口</li>
<li>若接口中有多个端口，则找到芯片后需再找端口<br>（5）每个端口地址=片选地址（高位地址）+片内地址 </li>
</ul>
</li>
</ul>
<ol start="3">
<li> I/O地址译码<br>（1）目的：确定端口的地址<br>（2）参加译码的信号：<br><code>#IOR，#IOW，高位地址信号</code><br>（3）对端口读/写信号的产生条件</li>
</ol>
<ul>
<li><code>IO/#M=1</code></li>
<li><code>#RD=0 #IOR=0</code></li>
<li><code>#WR=0 #IOW=0</code><br>（4）当接口只有一个端口时：无片内地址，全部地址信号均为高位地址（可全部参与译码），译码输出直接选择该端口；<br>（5）当接口具有多个端口时：则16位地址线的高位参与译码（决定接口的基地址），而低位则用于确定要访问哪一个端口</li>
</ul>
<h2 id="第三十六讲-简单接口芯片"><a href="#第三十六讲-简单接口芯片" class="headerlink" title="第三十六讲 简单接口芯片"></a>第三十六讲 简单接口芯片</h2><ol>
<li> 接口的分类及特点<br>（1）按传输信息的方向分类：<br>输入接口<br>输出接口<br>（2）按传输信息的类型分类：<br>数字接口<br>模拟接口<br>（3）按传输信息的方式分类：<br>并行接口<br>串行接口</li>
<li>接口特点<br>（1）输入接口：<br>要求对数据具有控制能力<br>常用三态门实现<br>（2）输出接口：<br>要求对数据具有锁存能力<br>常用锁存器实现</li>
</ol>
<h2 id="第三十七讲-基本输入输出方法"><a href="#第三十七讲-基本输入输出方法" class="headerlink" title="第三十七讲 基本输入输出方法"></a>第三十七讲 基本输入输出方法</h2><ol>
<li>基本输入/输出方法<br>（1）无条件传送：要求外设总是处于准备好状态<br>优点：软件及接口硬件简单<br>缺点：只适用于简单外设，适应范围较窄<br>（2）查询式传送：仅当条件满足时才能进行数据传送；每满足一次条件只能进行一次数据传送。<br>适用场合：外设并不总是准备好；对传送速率和效率要求不高<br>工作条件：外设应提供设备状态信息；接口应具备状态端口<br>（3）中断方式传送<br>特点：外设在需要时向CPU提出请求，CPU再去为它服务。服务结束后或在外设不需要时，CPU可执行自己的程序。<br>优点：CPU效率高，实时性好，速度快。<br>缺点：程序编制相对较为复杂。<br>（4）直接存储器存取(DMA) ：<br>特点：<br>①外设直接与存储器进行数据交换 ，CPU不再担当数据传输的中介者；<br>②总线由DMA控制器（DMAC）进行控制（CPU要放弃总线控制权），内存/外设的地址和读写控制信号均由DMAC提供。<br>③DMA传送方式有单元传送方式，快传送方式，请求传送方式<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627145513.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627145541.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627145557.png"></li>
</ol>
<h3 id="DMA控制器8237A"><a href="#DMA控制器8237A" class="headerlink" title="DMA控制器8237A"></a>DMA控制器8237A</h3><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200907143459.png"></p>
<h2 id="第三十八讲-中断技术"><a href="#第三十八讲-中断技术" class="headerlink" title="第三十八讲 中断技术"></a>第三十八讲 中断技术</h2><ol>
<li>中断的基本概念<br>（1）CPU执行程序时，由于发生了某种随机的事件(外部或内部)，<br>引起CPU暂时中断正在运行的程序，转去执行一段特殊的服务<br>程序，以处理该事件，该事件处理完后又返回被中断的程序<br>继续执行，这一过程称为中断。<br>（2）引入中断的原因<br>提高对外设请求的响应实时性。<br>提高了CPU的利用率<br>避免了CPU不断检测外设状态的过程<br>（3）中断类型<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200627145857.png"></li>
</ol>
<h1 id="第十章-可编程数字接口电路"><a href="#第十章-可编程数字接口电路" class="headerlink" title="第十章 可编程数字接口电路"></a>第十章 可编程数字接口电路</h1><h2 id="可编程定时计数器8253"><a href="#可编程定时计数器8253" class="headerlink" title="可编程定时计数器8253"></a>可编程定时计数器8253</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/8253-1.PNG"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/8253-2.PNG"></p>
<h2 id="可编程并行接口8255"><a href="#可编程并行接口8255" class="headerlink" title="可编程并行接口8255"></a>可编程并行接口8255</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/8255-1.PNG"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/8255-2.PNG"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/8255-3.PNG"></p>
<h2 id="可编程中断控制器8259"><a href="#可编程中断控制器8259" class="headerlink" title="可编程中断控制器8259"></a>可编程中断控制器8259</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/8259-1.PNG"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/8259-2.PNG"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/8259-3.PNG"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/8259-4.PNG"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/8259-5.PNG"></p>
<h1 id="第十一章-模拟接口电路"><a href="#第十一章-模拟接口电路" class="headerlink" title="第十一章 模拟接口电路"></a>第十一章 模拟接口电路</h1><h2 id="模拟量的输入输出"><a href="#模拟量的输入输出" class="headerlink" title="模拟量的输入输出"></a>模拟量的输入输出</h2><p>D： （Digital） 数字量<br>A： （Analog） 模拟量<br>采样和量化</p>
<h2 id="D-A转换器和A-D转换器"><a href="#D-A转换器和A-D转换器" class="headerlink" title="D/A转换器和A/D转换器"></a>D/A转换器和A/D转换器</h2><ol>
<li>主要参数<br>（1）分辨率<br>输入的二进制数每+1/-1个最低有效位LSB，使输出变化的程度 , 1LSB = 1/(2^n-1)<br>[n：D/A转换器的字长]<br>（2）转换时间<br>（3）精度<br>（4）线性度</li>
<li>D/A转换器与微处理器的接口方法<br>（1）接口任务:解决数据锁存，缓冲问题<br>（2）特点：控制信号，无专门数据传送间隔时间，调节数据宽度<br>（3）接口电路结构：通用并行接口或直连<br>（4）D/A：数字量转换为模拟量</li>
</ol>
<h2 id="D-A转换器（DAC0832）NS"><a href="#D-A转换器（DAC0832）NS" class="headerlink" title="D/A转换器（DAC0832）NS"></a>D/A转换器（DAC0832）NS</h2><ol>
<li>三种工作方式：直通方式，单缓冲方式，双缓冲方式</li>
<li>8位寄存器，T型电阻网络，电流型输出，不可编程</li>
<li>主要引脚功能：D7-D0，ILE，CS，WR1，WR2，XFER（低电平有效）</li>
<li>内部结构：<br>（1）8位输入寄存器<br>（2）8位DAC寄存器<br>（3）8位D/A转换器<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200907141224.png"></li>
</ol>
<h2 id="A-D转换器（ADC0809）"><a href="#A-D转换器（ADC0809）" class="headerlink" title="A/D转换器（ADC0809）"></a>A/D转换器（ADC0809）</h2><p>1.特点</p>
<ul>
<li>8通道（8路）输入</li>
<li>8位字长</li>
<li>逐位逼近型</li>
<li>转换时间100us</li>
<li>内置三态输出缓冲器</li>
</ul>
<p>2.主要引脚功能</p>
<ul>
<li>D7-D0：输出数据线，三态</li>
<li>IN0-IN7：8通道模拟输入</li>
<li>ADDC,ADDB,ADDA通道地址选择</li>
<li>Start：启动变换</li>
<li>ALE：通道地址锁存</li>
<li>EOC：转换结束状态输出</li>
<li>OE：输出允许</li>
<li>CLK：工作时钟</li>
</ul>
<h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><ol>
<li>控制信号<br>（1）M/IO=1,CPU对存储器操作，M/IO=0,CPU对I/O操作<br>（2）DT/R=1,CPU→【内存/（I/O）】，DT/R=0，外部→CPU<br>（3）8086，RD，WR低电平有效</li>
<li>ADC0809<br>（1）EOC发出中断请求<br>（2）CPU查询EOC状态</li>
<li>D/A和A/D<br>（1）主要参数：分辨率，转换时间，精度</li>
<li>数据传输方式（输入输出控制方式）<br>（1）程序控制方式<br> (1.1)无条件传送<br> (1.2)有条件传送（查询）<br>（2）中断控制方式<br>（3）DMA<br> （3.1）DMA传送方式：单元传送，块传送，请求传送<br> （3.2）DMAC，8237A<br> （3.3）DMA方式写，外设到存储器<br> （3.4）8237占用8个输入输出端口<br> （3.5）DMA控制方式中需要用到的一对联络信号是HLDA/HRQ</li>
<li>串行接口<br>（1）串行接口中，并行数据和串行数据的转换通过移位寄存器实现<br>（2）RS-232是串行通信标准</li>
<li>片选控制方式，全译码，部分译码，线译码</li>
<li>I/O接口有独立编址和统一编址方式</li>
<li>复位后段寄存器的初值为：CS=FFFFH，DS=0000H，SS=0000H，ES=0000H,其他寄存器的初值都是0，特别是CS=FFFFH，IP=0000H，因此复位后CPU从FFFF0H开始执行程序</li>
<li>奇地址存储体和系统数据总线高8位相连，用BHE=0作为选通信号；偶地址存储体和系统数据总线低8位相连，用A0=0作为连通信号</li>
<li>对准字，从偶地址开始存放字数据的存放方式（传一次，A0和BHE都有效），非对准字，从奇地址开始存放字数据的存放方式（传两次，先奇BHE后偶A0）</li>
<li>寻址隐含约定：<br>（1）直接寻址，DS<br>（2）寄存器寻址：DS←BX/SI/DI；SS←BP<br>（3）基址变址寻址：DS←BX+SI/DI ； SS：BP+SI/DI<br>（4）堆栈：SS←SP<br>（5）取指令：CS←IP</li>
</ol>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>大学课程</tag>
        <tag>微机原理与接口技术</tag>
      </tags>
  </entry>
  <entry>
    <title>学习笔记 | 《算法导论》之从入门到放弃（1）</title>
    <url>/posts/4646.html</url>
    <content><![CDATA[<p>《算法导论》打卡1，主要内容：插入排序，分治法，归并排序</p>
<span id="more"></span>
<h1 id="第一部分-基础知识"><a href="#第一部分-基础知识" class="headerlink" title="第一部分 基础知识"></a>第一部分 基础知识</h1><h2 id="第一章-算法在计算中的作用"><a href="#第一章-算法在计算中的作用" class="headerlink" title="第一章 算法在计算中的作用"></a>第一章 算法在计算中的作用</h2><h3 id="1-1-算法"><a href="#1-1-算法" class="headerlink" title="1.1 算法"></a>1.1 算法</h3><ul>
<li>算法就是任何良定义的计算过程，该过程取某个值或值的集合作为<strong>输入</strong>并产生某个值或者值的集合作为<strong>输出</strong>。</li>
<li>规范书写：</li>
</ul>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">问题：XXXX</span><br><span class="line">输入：XXXXXXXX</span><br><span class="line">输出：XXXXXXXX</span><br><span class="line">算法步骤：</span><br><span class="line"><span class="number">1</span><span class="selector-class">.XXXXXXXXXXX</span></span><br><span class="line"><span class="number">2</span>.XXXXXXXXXXX</span><br></pre></td></tr></table></figure>

<ul>
<li>注意问题与问题实例的区别。</li>
</ul>
<h3 id="1-2-作为一种技术的算法"><a href="#1-2-作为一种技术的算法" class="headerlink" title="1.2 作为一种技术的算法"></a>1.2 作为一种技术的算法</h3><ul>
<li>考虑效率：时间与空间资源的消耗</li>
</ul>
<h2 id="第二章-算法基础"><a href="#第二章-算法基础" class="headerlink" title="第二章 算法基础"></a>第二章 算法基础</h2><h3 id="2-1-插入排序"><a href="#2-1-插入排序" class="headerlink" title="2.1 插入排序"></a>2.1 插入排序</h3><figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line">输入：n个数的一个序列&lt;<span class="built_in">a1</span>,<span class="built_in">a2</span>,...,an&gt;</span><br><span class="line">输出：输入序列的一个排列&lt;<span class="built_in">a1</span>’,<span class="built_in">a2</span>’,...,an’&gt;，满足<span class="built_in">a1</span>’≤<span class="built_in">a2</span>’≤...≤an’</span><br></pre></td></tr></table></figure>
<ul>
<li>算法：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insertionsort</span><span class="params">(<span class="keyword">int</span> *A,<span class="keyword">int</span> length)</span></span>&#123;</span><br><span class="line">    <span class="comment">//插入排序</span></span><br><span class="line">    <span class="keyword">int</span> key; <span class="comment">//暂存当前位置的值</span></span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j&lt;length;j++)&#123;</span><br><span class="line">        key = A[j]; <span class="comment">//暂存当前位置的值</span></span><br><span class="line">        i= j<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">while</span>(i&gt;=<span class="number">0</span> &amp;&amp; A[i]&gt;key)&#123; <span class="comment">//如果前面的值比key大，则交换</span></span><br><span class="line">            A[i+<span class="number">1</span>]=A[i];</span><br><span class="line">            i=i<span class="number">-1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        A[i+<span class="number">1</span>]=key;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> A[<span class="number">9</span>]=&#123;<span class="number">9</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">8</span>&#125;; <span class="comment">//举了个栗子</span></span><br><span class="line">    <span class="keyword">int</span> length=<span class="built_in"><span class="keyword">sizeof</span></span>(A)/<span class="built_in"><span class="keyword">sizeof</span></span>(A[<span class="number">0</span>]); <span class="comment">//求数组的长度的一种方法</span></span><br><span class="line">    <span class="built_in">insertionsort</span>(A,length);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//输出排序后的序列</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;length;i++)&#123;</span><br><span class="line">        cout&lt;&lt;A[i]&lt;&lt;<span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><img src="https://s2.ax1x.com/2019/09/19/nO9np9.png" alt="nO9np9.png"></li>
<li>伪代码👇</li>
<li><img src="https://s2.ax1x.com/2019/09/23/uPypCV.png" alt="uPypCV.png"></li>
<li><img src="https://s2.ax1x.com/2019/09/23/uPynC6.png" alt="uPynC6.png"></li>
</ul>
<h3 id="2-2-分析算法"><a href="#2-2-分析算法" class="headerlink" title="2.2 分析算法"></a>2.2 分析算法</h3><ul>
<li>时间复杂度：最好的情况下：O(n),最坏的情况下：O(n²),平均情况下：O(n²)</li>
<li><img src="https://s2.ax1x.com/2019/09/23/uP6qTs.png" alt="uP6qTs.png"><h3 id="2-3-设计算法"><a href="#2-3-设计算法" class="headerlink" title="2.3 设计算法"></a>2.3 设计算法</h3><h4 id="2-3-1-分治法"><a href="#2-3-1-分治法" class="headerlink" title="2.3.1 分治法"></a>2.3.1 分治法</h4></li>
<li>分治法：将原问题分解为几个规模较小但类似于原问题的子问题，递归求解这些子问题，然后再合并这些子问题的解来建立原问题的解</li>
<li>归并排序：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">merge</span><span class="params">(<span class="keyword">int</span> arr[],<span class="keyword">int</span> left,<span class="keyword">int</span> mid,<span class="keyword">int</span> right)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> aux[right-left+<span class="number">1</span>];<span class="comment">//开辟一个新的数组，将原数组映射进去</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> m=left;m&lt;=right;m++)</span><br><span class="line">    &#123;</span><br><span class="line">        aux[m-left]=arr[m];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> i=left,j=mid+<span class="number">1</span>;<span class="comment">//i和j分别指向两个子数组开头部分</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> k=left;k&lt;=right;k++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(i&gt;mid)<span class="comment">//右边还有剩余</span></span><br><span class="line">        &#123;</span><br><span class="line">            arr[k]=aux[j-left];</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(j&gt;right)<span class="comment">//左边还有剩余</span></span><br><span class="line">        &#123;</span><br><span class="line">            arr[k]=aux[i-left];</span><br><span class="line">            i++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(aux[i-left]&lt;aux[j-left])<span class="comment">//左边小于右边</span></span><br><span class="line">        &#123;</span><br><span class="line">            arr[k]=aux[i-left];</span><br><span class="line">                i++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span><span class="comment">//右边小于左边</span></span><br><span class="line">        &#123;</span><br><span class="line">            arr[k]=aux[j-left];</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//递归的使用归并排序，对arr[l....right]排序</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">merge_sort</span><span class="params">(<span class="keyword">int</span> arr[],<span class="keyword">int</span> left,<span class="keyword">int</span> right)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(left &gt;=right)</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    <span class="keyword">int</span> mid=(left+right)/<span class="number">2</span>;</span><br><span class="line">    <span class="built_in">merge_sort</span>(arr,left,mid);</span><br><span class="line">    <span class="built_in">merge_sort</span>(arr,mid+<span class="number">1</span>,right);</span><br><span class="line">    <span class="built_in">merge</span>(arr,left,mid,right);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">my_merge_sort</span><span class="params">(<span class="keyword">int</span> arr[],<span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">merge_sort</span>(arr,<span class="number">0</span>,n<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//举个栗子</span></span><br><span class="line">    <span class="keyword">int</span> a[<span class="number">6</span>];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">6</span>;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        cin&gt;&gt;a[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">my_merge_sort</span>(a,<span class="number">6</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">6</span>;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        cout&lt;&lt;a[i]&lt;&lt;<span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><img src="https://s2.ax1x.com/2019/09/23/uPx85n.png" alt="uPx85n.png"></li>
<li><img src="https://s2.ax1x.com/2019/09/23/uPxXqg.png" alt="uPxXqg.png"></li>
</ul>
<h4 id="2-3-2-分析分治算法"><a href="#2-3-2-分析分治算法" class="headerlink" title="2.3.2 分析分治算法"></a>2.3.2 分析分治算法</h4><ul>
<li><img src="https://s2.ax1x.com/2019/09/23/uiBjot.png" alt="uiBjot.png"></li>
<li>时间复杂度：平均情况：O(nlogn),最好情况：O(nlogn),最坏情况：O(nlogn)</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title>学习笔记 | 《算法导论》之从入门到放弃（2）</title>
    <url>/posts/4966.html</url>
    <content><![CDATA[<p>《算法导论》打卡2，主要内容：渐进记号，分治策略，最大子数组问题,矩阵乘法的strassen算法</p>
<span id="more"></span>
<h1 id="第三章-函数的增长"><a href="#第三章-函数的增长" class="headerlink" title="第三章 函数的增长"></a>第三章 函数的增长</h1><ul>
<li>当输入规模足够大，使得只有运行时间的增长量级有关时，我们要研究算法的渐进效率。也就是说，我们关心当输入规模无限增加时，在极限中，算法的运行时间如何随着输入规模的变大而增加。<h2 id="3-1-渐进记号"><a href="#3-1-渐进记号" class="headerlink" title="3.1 渐进记号"></a>3.1 渐进记号</h2></li>
<li>用来描述算法渐进运行时间的记号根据定义于为自然数集N={0，1，2，…}的函数来定义</li>
</ul>
<h3 id="3-1-1-Θ记号"><a href="#3-1-1-Θ记号" class="headerlink" title="3.1.1 Θ记号"></a>3.1.1 Θ记号</h3><ul>
<li><code>Θ记号</code>：对一个给定的函数g(n)，用Θ(g(n))来表示以下函数的集合：<br><code>Θ(g(n))=&#123;f(n):存在正常量c1,c2和n0,使得对所有n≥n0,有0≤c1*g(n)≤f(n)≤c2*g(n)&#125;</code></li>
<li><img src="https://s2.ax1x.com/2019/09/23/uFAyV0.png" alt="uFAyV0.png"></li>
</ul>
<h3 id="3-1-2-O记号"><a href="#3-1-2-O记号" class="headerlink" title="3.1.2 O记号"></a>3.1.2 O记号</h3><ul>
<li><code>O记号</code>：当只有一个渐进上界时，使用O记号，对于一个给定的函数g(n)，用O(g(n))来表示以下函数的集合：<br><code>O(g(n))=&#123;f(n):存在正常量c和n0，使得对所有n≥n0，有0≤f(n)≤c*g(n)&#125;</code></li>
</ul>
<h3 id="3-1-3-Ω记号"><a href="#3-1-3-Ω记号" class="headerlink" title="3.1.3 Ω记号"></a>3.1.3 Ω记号</h3><ul>
<li><p><code>Ω记号</code>：渐进下界。使用Ω记号，对于一个给定的函数g(n)，用Ω(g(n))来表示以下函数的集合：<br><code>Ω(g(n))=&#123;f(n):存在正常量c和n0，使得对所有n≥n0，有0≤c*g(n)≤f(n)&#125;</code></p>
</li>
<li><p>定理：<code>对任意两个函数f(n)和g(n),我们有f(n)=Θ(g(n))，当且仅当f(n)=O(g(n))且f(n)=Ω(g(n))</code></p>
</li>
</ul>
<h3 id="3-1-4-o记号"><a href="#3-1-4-o记号" class="headerlink" title="3.1.4 o记号"></a>3.1.4 o记号</h3><ul>
<li><code>o记号</code>：表示非渐进紧确的上界<br><code>o(g(n))=&#123;f(n):对于任意正常书c&gt;0,存在常量n0＞0，使得对所有n≥n0，有0≤f(n)＜c*g(n)&#125;</code></li>
</ul>
<h3 id="3-1-5-w记号"><a href="#3-1-5-w记号" class="headerlink" title="3.1.5 w记号"></a>3.1.5 w记号</h3><ul>
<li><code>w记号</code>：表示非渐进紧确的下界<br><code>w(g(n))=&#123;f(n):对任意正常量c＞0，存在常量n0＞0，使得对所有n≥n0，有0≤c*g(n)＜f(n)&#125;</code></li>
</ul>
<h2 id="3-2-标准记号与常用函数"><a href="#3-2-标准记号与常用函数" class="headerlink" title="3.2 标准记号与常用函数"></a>3.2 标准记号与常用函数</h2><ul>
<li>单调性</li>
<li>向下取整与向上取整符号</li>
<li>模运算</li>
<li>多项式</li>
<li>指数</li>
<li>对数</li>
<li>阶乘</li>
<li>多重函数</li>
<li>多重对数函数</li>
<li>斐波那契数</li>
</ul>
<h1 id="第四章-分治策略"><a href="#第四章-分治策略" class="headerlink" title="第四章 分治策略"></a>第四章 分治策略</h1><ul>
<li>分治策略的步骤：<code>分解</code>，<code>解决</code>，<code>合并</code></li>
<li>递归情况：子问题足够大，需要递归求解</li>
<li>基本情况：子问题足够小，递归已“触底”</li>
<li>递归式：通过更小的输入上的函数值来描述一个函数</li>
<li>求解递归式的方法：<ul>
<li>代入法</li>
<li>递归树法</li>
<li>主方法</li>
</ul>
</li>
</ul>
<h2 id="4-1-最大子数组问题"><a href="#4-1-最大子数组问题" class="headerlink" title="4.1 最大子数组问题"></a>4.1 最大子数组问题</h2><ul>
<li><img src="https://s2.ax1x.com/2019/09/24/ukpsGd.png" alt="ukpsGd.png"></li>
<li>由于时间原因，最大化利益不一定是最低价格买入，最高价格卖出，因为存在最高价格先于最低价格出现的可能</li>
<li>暴力破解方法：尝试每一对可能的买入卖出，只要卖出时间在买入时间之后即可。</li>
<li>问题交换：</li>
<li><img src="https://s2.ax1x.com/2019/09/24/ukC7D0.png" alt="ukC7D0.png"></li>
<li>只有当数组中包含负数时，最大子数组问题才有意义，如果所有数组元素都是非负的，最大数组问题没有任何难度，因为整个数组的和肯定是最大的。</li>
<li>使用分治策略的求解方法：</li>
<li><img src="https://s2.ax1x.com/2019/09/24/ukFJun.png" alt="ukFJun.png"></li>
<li>python</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#python3</span></span><br><span class="line"><span class="comment">#find max crossing subarray</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f_m_c_s</span>(<span class="params">A,low,mid,high</span>):</span></span><br><span class="line">    left_sum=<span class="built_in">float</span>(<span class="string">&#x27;-inf&#x27;</span>)</span><br><span class="line">    right_sum=<span class="built_in">float</span>(<span class="string">&#x27;-inf&#x27;</span>)</span><br><span class="line">    temp_sum=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(mid,low-<span class="number">1</span>,-<span class="number">1</span>):</span><br><span class="line">        temp_sum=temp_sum+A[i]</span><br><span class="line">        <span class="keyword">if</span> temp_sum&gt;left_sum:</span><br><span class="line">            left_sum=temp_sum</span><br><span class="line">            max_left=i</span><br><span class="line">    temp_sum=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(mid+<span class="number">1</span>,high+<span class="number">1</span>):</span><br><span class="line">        temp_sum=temp_sum+A[i]</span><br><span class="line">        <span class="keyword">if</span> temp_sum&gt;right_sum:</span><br><span class="line">            right_sum=temp_sum</span><br><span class="line">            max_right=i</span><br><span class="line">    <span class="keyword">return</span> max_left,max_right,left_sum+right_sum</span><br><span class="line"></span><br><span class="line"><span class="comment">#find maxmum subarray</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f_m_s</span>(<span class="params">A,low,high</span>):</span></span><br><span class="line">    <span class="keyword">if</span> high==low:</span><br><span class="line">        <span class="keyword">return</span> low,high,A[low]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        mid=(low+high)//<span class="number">2</span></span><br><span class="line">        left_low,left_high,left_sum=f_m_s(A,low,mid)</span><br><span class="line">        right_low,right_high,right_sum=f_m_s(A,mid+<span class="number">1</span>,high)</span><br><span class="line">        cross_low,cross_high,cross_sum=f_m_c_s(A,low,mid,high)</span><br><span class="line">        <span class="keyword">if</span> left_sum&gt;=right_sum <span class="keyword">and</span> left_sum&gt;=cross_sum:</span><br><span class="line">            <span class="keyword">return</span> left_low,left_high,left_sum</span><br><span class="line">        <span class="keyword">elif</span> right_sum&gt;=left_sum <span class="keyword">and</span> right_sum&gt;=cross_sum:</span><br><span class="line">            <span class="keyword">return</span> right_low,right_high,right_sum</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> cross_low,cross_high,cross_sum</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    A=[-<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,-<span class="number">4</span>,<span class="number">7</span>,<span class="number">6</span>,<span class="number">3</span>,-<span class="number">22</span>,<span class="number">33</span>,<span class="number">4</span>]</span><br><span class="line">    <span class="built_in">print</span>(f_m_s(A,<span class="number">0</span>,<span class="built_in">len</span>(A)-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

<ul>
<li>其他解法如：c++解决n个整数的数列，不超过m的最大子数列和</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N 1000000</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> n;</span><br><span class="line"><span class="keyword">int</span> m;</span><br><span class="line"><span class="keyword">int</span> a[N];</span><br><span class="line"><span class="keyword">int</span> sum[N];</span><br><span class="line"><span class="keyword">int</span> x;</span><br><span class="line"><span class="keyword">int</span> ans;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"> </span>&#123;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>,&amp;n,&amp;m);</span><br><span class="line">    <span class="keyword">int</span> l=<span class="number">1</span>;<span class="keyword">int</span> r=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">     &#123;</span><br><span class="line">        <span class="keyword">while</span>(l&lt;=r&amp;&amp;a[l]&lt;i-m)l++;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;x);</span><br><span class="line">        sum[i]=sum[i<span class="number">-1</span>]+x;</span><br><span class="line">        ans=<span class="built_in">max</span>(ans,sum[i]-sum[a[l]]);</span><br><span class="line">        <span class="keyword">while</span>(l&lt;=r&amp;&amp;sum[a[r]]&gt;=sum[i])r--;</span><br><span class="line">        a[++r]=i;</span><br><span class="line">     &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d&quot;</span>,ans);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<h2 id="4-2-矩阵乘法的Strassen算法"><a href="#4-2-矩阵乘法的Strassen算法" class="headerlink" title="4.2 矩阵乘法的Strassen算法"></a>4.2 矩阵乘法的Strassen算法</h2><ul>
<li>c++如何创建动态二维数组：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n;</span><br><span class="line">    cin&gt;&gt;n;</span><br><span class="line">    <span class="keyword">int</span> **a=<span class="keyword">new</span> <span class="keyword">int</span>*[n];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">        a[i]=<span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;n;j++)&#123;</span><br><span class="line">            cin&gt;&gt;a[i][j];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><img src="https://s2.ax1x.com/2019/09/29/u83cb6.png" alt="u83cb6.png"></li>
<li>python矩阵乘法暴力破解算法</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matrixMultiply</span>(<span class="params">A,B</span>):</span></span><br><span class="line">    <span class="comment">#len(A[0])是A的列数，len(A)是A的行数，B同理</span></span><br><span class="line">    C = []</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(A[<span class="number">0</span>]) != <span class="built_in">len</span>(B):</span><br><span class="line">         <span class="keyword">return</span> false</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(A)):</span><br><span class="line">        row=[]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(B[<span class="number">0</span>])):</span><br><span class="line">            s = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(A[<span class="number">0</span>])):</span><br><span class="line">                s += A[i][k]*B[k][j]</span><br><span class="line">            row.append(s)</span><br><span class="line">        C.append(row)</span><br><span class="line">    <span class="keyword">return</span> C </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    A = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]</span><br><span class="line">    B = [[<span class="number">7</span>,<span class="number">8</span>],[<span class="number">9</span>,<span class="number">10</span>],[<span class="number">11</span>,<span class="number">12</span>]]</span><br><span class="line">    C = matrixMultiply(A,B)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(C)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> C[i]:</span><br><span class="line">            <span class="built_in">print</span>(j,end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<ul>
<li>方阵乘法的简单分治算法（前提：<strong>假定A,B都是n等于2的次幂的方阵</strong>）</li>
<li><img src="https://s2.ax1x.com/2019/10/11/ub68Vx.png" alt="ub68Vx.png"></li>
<li>python</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">division</span>(<span class="params">a</span>):</span>    <span class="comment">#矩阵分块函数</span></span><br><span class="line">    n=<span class="built_in">len</span>(a)//<span class="number">2</span></span><br><span class="line">    a11=[[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    a12=[[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    a21=[[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    a22=[[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            a11[i][j]=a[i][j]</span><br><span class="line">            a12[i][j]=a[i][j+n]</span><br><span class="line">            a21[i][j]=a[i+n][j]</span><br><span class="line">            a22[i][j]=a[i+n][j+n]</span><br><span class="line">    <span class="keyword">return</span> (a11,a12,a21,a22)</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matrix_combination</span>(<span class="params">a11,a12,a21,a22</span>):</span></span><br><span class="line">    n2 = <span class="built_in">len</span>(a11)</span><br><span class="line">    n=n2*<span class="number">2</span></span><br><span class="line">    a = [[<span class="number">0</span> <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span> (<span class="number">0</span>,n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span> (<span class="number">0</span>,n):</span><br><span class="line">            <span class="keyword">if</span> i &lt;= (n2-<span class="number">1</span>) <span class="keyword">and</span> j &lt;= (n2-<span class="number">1</span>):</span><br><span class="line">                a[i][j] = a11[i][j]</span><br><span class="line">            <span class="keyword">elif</span> i &lt;= (n2-<span class="number">1</span>) <span class="keyword">and</span> j &gt; (n2-<span class="number">1</span>):</span><br><span class="line">                a[i][j] = a12[i][j-n2]</span><br><span class="line">            <span class="keyword">elif</span> i &gt; (n2-<span class="number">1</span>) <span class="keyword">and</span> j &lt;= (n2-<span class="number">1</span>):</span><br><span class="line">                a[i][j] = a21[i-n2][j]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                a[i][j] = a22[i-n2][j-n2]</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matrix_add</span>(<span class="params">a,b</span>):</span>  <span class="comment">#矩阵相加函数</span></span><br><span class="line">    n = <span class="built_in">len</span>(a)</span><br><span class="line">    c = [[<span class="number">0</span> <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,n):</span><br><span class="line">            c[i][j] = a[i][j]+b[i][j]</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matrix_devision_multiply</span>(<span class="params">a,b</span>):</span>   <span class="comment">#矩阵乘法的简单分治法主程序</span></span><br><span class="line">    n=<span class="built_in">len</span>(a)</span><br><span class="line">    c = [[<span class="number">0</span> <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(n)]<span class="comment">#c=[[0]*n for i in range(n)]</span></span><br><span class="line">    <span class="keyword">if</span> n==<span class="number">1</span>:</span><br><span class="line">        c[<span class="number">0</span>][<span class="number">0</span>]=a[<span class="number">0</span>][<span class="number">0</span>]*b[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        (a11,a12,a21,a22)=division(a)</span><br><span class="line">        (b11,b12,b21,b22)=division(b)</span><br><span class="line">        (c11,c12,c21,c22)=division(c)</span><br><span class="line">        c11=matrix_add(matrix_devision_multiply(a11,b11),matrix_devision_multiply(a12,b21))</span><br><span class="line">        c12=matrix_add(matrix_devision_multiply(a11,b12),matrix_devision_multiply(a12,b22))</span><br><span class="line">        c21=matrix_add(matrix_devision_multiply(a21,b11),matrix_devision_multiply(a22,b21))</span><br><span class="line">        c22=matrix_add(matrix_devision_multiply(a21,b12),matrix_devision_multiply(a22,b22))</span><br><span class="line">        c=matrix_combination(c11,c12,c21,c22)</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"> </span><br><span class="line">a=[[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]]</span><br><span class="line">b=a</span><br><span class="line"><span class="built_in">print</span>(matrix_devision_multiply(a,b))</span><br></pre></td></tr></table></figure>

<ul>
<li>矩阵乘法的Strassen算法<br><img src="https://s2.ax1x.com/2019/10/11/uqgrWT.png" alt="uqgrWT.png"><br><img src="https://s2.ax1x.com/2019/10/11/uq6N9S.png" alt="uq6N9S.png"><br><img src="https://s2.ax1x.com/2019/10/11/uq6yNV.png" alt="uq6yNV.png"><br><img src="https://s2.ax1x.com/2019/10/11/uq6oAx.png" alt="uq6oAx.png"><br><img src="https://s2.ax1x.com/2019/10/11/uq6OjH.png" alt="uq6OjH.png"></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matrix_strassen</span>(<span class="params">a,b</span>):</span></span><br><span class="line">    n=<span class="built_in">len</span>(a)</span><br><span class="line">    c = [[<span class="number">0</span> <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    <span class="keyword">if</span> n==<span class="number">1</span>:</span><br><span class="line">        c[<span class="number">0</span>][<span class="number">0</span>]=a[<span class="number">0</span>][<span class="number">0</span>]*b[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        (a11,a12,a21,a22)=division(a)</span><br><span class="line">        (b11,b12,b21,b22)=division(b)</span><br><span class="line">        (c11,c12,c21,c22)=division(c)</span><br><span class="line">        s1=matrix_add_sub(b12,b22,<span class="number">0</span>)</span><br><span class="line">        s2=matrix_add_sub(a11,a12,<span class="number">1</span>)</span><br><span class="line">        s3=matrix_add_sub(a21,a22,<span class="number">1</span>)</span><br><span class="line">        s4=matrix_add_sub(b21,b11,<span class="number">0</span>)</span><br><span class="line">        s5=matrix_add_sub(a11,a22,<span class="number">1</span>)</span><br><span class="line">        s6=matrix_add_sub(b11,b22,<span class="number">1</span>)</span><br><span class="line">        s7=matrix_add_sub(a12,a22,<span class="number">0</span>)</span><br><span class="line">        s8=matrix_add_sub(b21,b22,<span class="number">1</span>)</span><br><span class="line">        s9=matrix_add_sub(a11,a21,<span class="number">0</span>)</span><br><span class="line">        s10=matrix_add_sub(b11,b12,<span class="number">1</span>)</span><br><span class="line">        p1=matrix_strassen(a11,s1)</span><br><span class="line">        p2=matrix_strassen(s2,b22)</span><br><span class="line">        p3=matrix_strassen(s3,b11)</span><br><span class="line">        p4=matrix_strassen(a22,s4)</span><br><span class="line">        p5=matrix_strassen(s5,s6)</span><br><span class="line">        p6=matrix_strassen(s7,s8)</span><br><span class="line">        p7=matrix_strassen(s9,s10)</span><br><span class="line">        c11=matrix_add_sub(matrix_add_sub(matrix_add_sub(p5,p4,<span class="number">1</span>),p2,<span class="number">0</span>),p6,<span class="number">1</span>)</span><br><span class="line">        c12=matrix_add_sub(p1,p2,<span class="number">1</span>)</span><br><span class="line">        c21=matrix_add_sub(p3,p4,<span class="number">1</span>)</span><br><span class="line">        c22=matrix_add_sub(matrix_add_sub(matrix_add_sub(p5,p1,<span class="number">1</span>),p3,<span class="number">0</span>),p7,<span class="number">0</span>)</span><br><span class="line">        c=matrix_combination(c11,c12,c21,c22)</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"> </span><br><span class="line"><span class="comment">#矩阵的strssen算法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">division</span>(<span class="params">a</span>):</span>                              <span class="comment">#对矩阵进行分解操作</span></span><br><span class="line">    n=<span class="built_in">len</span>(a)//<span class="number">2</span></span><br><span class="line">    a11=[[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    a12=[[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    a21=[[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    a22=[[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            a11[i][j]=a[i][j]</span><br><span class="line">            a12[i][j]=a[i][j+n]</span><br><span class="line">            a21[i][j]=a[i+n][j]</span><br><span class="line">            a22[i][j]=a[i+n][j+n]</span><br><span class="line">    <span class="keyword">return</span> (a11,a12,a21,a22)</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matrix_add_sub</span>(<span class="params">a,b,keys</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(a)</span><br><span class="line">    c = [[<span class="number">0</span> <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    <span class="keyword">if</span> keys==<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                c[i][j] = a[i][j]+b[i][j]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                c[i][j]=a[i][j]-b[i][j]</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matrix_combination</span>(<span class="params">a11,a12,a21,a22</span>):</span>    <span class="comment">#对矩阵进行组合操作</span></span><br><span class="line">    n2 = <span class="built_in">len</span>(a11)</span><br><span class="line">    n=n2*<span class="number">2</span></span><br><span class="line">    a = [[<span class="number">0</span> <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span> (<span class="number">0</span>,n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span> (<span class="number">0</span>,n):</span><br><span class="line">            <span class="keyword">if</span> i &lt;= (n2-<span class="number">1</span>) <span class="keyword">and</span> j &lt;= (n2-<span class="number">1</span>):</span><br><span class="line">                a[i][j] = a11[i][j]</span><br><span class="line">            <span class="keyword">elif</span> i &lt;= (n2-<span class="number">1</span>) <span class="keyword">and</span> j &gt; (n2-<span class="number">1</span>):</span><br><span class="line">                a[i][j] = a12[i][j-n2]</span><br><span class="line">            <span class="keyword">elif</span> i &gt; (n2-<span class="number">1</span>) <span class="keyword">and</span> j &lt;= (n2-<span class="number">1</span>):</span><br><span class="line">                a[i][j] = a21[i-n2][j]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                a[i][j] = a22[i-n2][j-n2]</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"> </span><br><span class="line">a=[[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]]</span><br><span class="line">b=a</span><br><span class="line"><span class="built_in">print</span>(matrix_strassen(a,b))</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>学习笔记 | 《算法导论》之从入门到放弃（4）</title>
    <url>/posts/4582.html</url>
    <content><![CDATA[<p>算法导论打卡4，主要内容：快速排序</p>
<span id="more"></span>
<h1 id="第七章-快速排序"><a href="#第七章-快速排序" class="headerlink" title="第七章 快速排序"></a>第七章 快速排序</h1><h2 id="快速排序的描述"><a href="#快速排序的描述" class="headerlink" title="快速排序的描述"></a>快速排序的描述</h2><ul>
<li><img src="https://s2.ax1x.com/2019/11/02/KqfUOA.png" alt="KqfUOA.png"></li>
<li><img src="https://s2.ax1x.com/2019/11/02/KqhK1g.png" alt="KqhK1g.png"></li>
<li><img src="https://s2.ax1x.com/2019/11/02/KqhwjJ.png" alt="KqhwjJ.png"></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quicksort</span>(<span class="params">arr,low,high</span>):</span></span><br><span class="line">    <span class="keyword">if</span> low&lt;high :</span><br><span class="line">        index=getindex(arr,low,high)</span><br><span class="line">        quicksort(arr,low,index-<span class="number">1</span>)</span><br><span class="line">        quicksort(arr,index+<span class="number">1</span>,high)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getindex</span>(<span class="params">arr,low,high</span>):</span></span><br><span class="line">	<span class="comment">#PARTITION过程</span></span><br><span class="line">    temp=arr[low]</span><br><span class="line">    <span class="keyword">while</span>(low&lt;high):</span><br><span class="line">        <span class="keyword">while</span>((low&lt;high)<span class="keyword">and</span>(arr[high]&gt;=temp)):</span><br><span class="line">            high=high-<span class="number">1</span></span><br><span class="line">        arr[low]=arr[high]</span><br><span class="line">        <span class="keyword">while</span>((low&lt;high)<span class="keyword">and</span>(arr[low]&lt;=temp)):</span><br><span class="line">            low=low+<span class="number">1</span></span><br><span class="line">        arr[high]=arr[low]</span><br><span class="line">    arr[low]=temp</span><br><span class="line">    <span class="keyword">return</span> low</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    arr=<span class="built_in">input</span>(<span class="string">&quot;please input a group of number:&quot;</span>).split()</span><br><span class="line">    n=<span class="built_in">len</span>(arr)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        arr[i]=<span class="built_in">int</span>(arr[i])</span><br><span class="line">    quicksort(arr,<span class="number">0</span>,n-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line">        <span class="built_in">print</span>(i,end=<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>大学课程 | 数据库基础</title>
    <url>/posts/41347.html</url>
    <content><![CDATA[<p>大二数据库课程笔记</p>
<span id="more"></span>

<h2 id="第一章-绪论"><a href="#第一章-绪论" class="headerlink" title="第一章  绪论"></a>第一章  绪论</h2><h3 id="1-1数据库系统概述"><a href="#1-1数据库系统概述" class="headerlink" title="1.1数据库系统概述"></a>1.1数据库系统概述</h3><ul>
<li>应用数据库的主要目的是为了：<strong>共享数据</strong>。</li>
</ul>
<h4 id="1-1-1-数据库的4个基本概念"><a href="#1-1-1-数据库的4个基本概念" class="headerlink" title="1.1.1 数据库的4个基本概念"></a>1.1.1 数据库的4个基本概念</h4><p>1.四个基本概念：<strong>数据</strong>（data），<strong>数据库</strong>（DB），<strong>数据库管理系统</strong>（DBMS）和<strong>数据库系统</strong>（DBS）</p>
<ul>
<li>数据：<ul>
<li><u>定义：描述事物的<strong>符号记录</strong>称为数据</u></li>
<li>数据是数据库中存储的基本对象</li>
<li>数据的含义称为数据的语义，数据与其语义是不可分的</li>
<li>记录是计算机表示和存储数据的一种格式或方法</li>
</ul>
</li>
<li>数据库：<ul>
<li><u>定义： 数据库是<strong>长期存储</strong>在计算机内，<strong>有组织的</strong>，<strong>可共享</strong>的<strong>大量数据</strong>的集合，数据库中的数据按一定的数据模型<strong>组织</strong>，<strong>描述</strong>和<strong>存储</strong>，具有<strong>较小的冗余度</strong>，<strong>较高的数据独立性</strong>和<strong>易扩展性</strong>，并可为各种<strong>用户共享</strong>。</u></li>
</ul>
</li>
<li>数据库管理系统：<ul>
<li>数据库管理系统是位于<u>用户与操作系统</u>之间的一层<u>数据管理软件</u></li>
<li>数据库管理系统和操作系统一样是计算机的<u>基础软件</u></li>
<li>主要功能：<br> （1）数据定义功能：<br>&nbsp; &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  数据定义语言（DDL）<br> （2）数据组织，存储和管理<br>&nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  提高存储空间利用率和方便存取<br> （3）数据操纵功能<br>&nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  数据操纵语言（DML）<br> （4）数据库的事务管理和运行管理<br>&nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  1. 保证安全性完整性，多用户对数据的并发使用<br>&nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  2，发生故障后的系统恢复<br> （5）数据库的建立和维护功能<br>&nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;<br> （6）其他功能<br>&nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  &nbsp;  </li>
</ul>
</li>
<li>数据库系统：<ul>
<li><u>定义：数据库系统是由<strong>数据库</strong>，<strong>数据库管理系统</strong>（及其应用开发工具），<strong>应用程序</strong>和<strong>数据库管理员</strong>（DBA）组成的<strong>存储，管理，处理和维护数据</strong>的系统。</u></li>
</ul>
</li>
</ul>
<h4 id="1-1-2数据管理技术的产生和发展"><a href="#1-1-2数据管理技术的产生和发展" class="headerlink" title="1.1.2数据管理技术的产生和发展"></a>1.1.2数据管理技术的产生和发展</h4><hr>
<ul>
<li>数据管理是指对数据进行分类，组织，编码，存储，检索和维护</li>
<li>数据处理是指对各种数据进行收集，存储，加工和传播的一系列活动的总和</li>
<li>数据库管理的三个阶段</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>人工管理阶段</th>
<th>文件系统阶段</th>
<th>数据库系统极端</th>
</tr>
</thead>
<tbody><tr>
<td>硬件背景</td>
<td>无直接存取存储设备</td>
<td>磁盘，磁鼓</td>
<td>大容量磁盘，磁盘阵列</td>
</tr>
<tr>
<td>软件背景</td>
<td>没有操作系统</td>
<td>有文件系统</td>
<td>有数据库管理系统</td>
</tr>
<tr>
<td>处理方式</td>
<td>批处理</td>
<td>联机实时处理</td>
<td>联机实时处理，分布处理，批处理</td>
</tr>
<tr>
<td>数据的共享程度</td>
<td>无共享，冗余度较大</td>
<td>共享性差，冗余度大</td>
<td>共享性高，冗余度小</td>
</tr>
<tr>
<td>数据的独立性</td>
<td>不独立，完全依赖于程序</td>
<td>独立性差</td>
<td>具有高度的物理独立性和一定的逻辑独立性</td>
</tr>
<tr>
<td>数据的结构化</td>
<td>无结构</td>
<td>记录内有结构，整体无结构</td>
<td>整体结构化，用数据模型描述</td>
</tr>
<tr>
<td>数据控制能力</td>
<td>应用程序自己控制</td>
<td>应用程序自己控制</td>
<td>由数据库管理系统提供数据安全性，完整性，并发控制和恢复能力</td>
</tr>
</tbody></table>
<h4 id="1-1-3-数据库系统的特点"><a href="#1-1-3-数据库系统的特点" class="headerlink" title="1.1.3 数据库系统的特点"></a>1.1.3 数据库系统的特点</h4><hr>
<ul>
<li>数据<strong>结构化</strong>：数据库系统实现整体数据的结构化，这是数据库的主要特征之一，也是数据库系统与文件系统的本质区别。数据之间具有联系</li>
<li>数据的<strong>共享性高</strong>，<strong>冗余度低</strong>且<strong>易扩充</strong></li>
<li>数据独立性高：<strong>物理独立性</strong>（物理存储），<strong>逻辑独立性</strong>（逻辑结构）</li>
<li>数据由数据库管理系统统一管理和控制<br>（1）数据的安全性保护：防止不合法使用造成的数据泄密和破坏<br>（2）数据的完整性保护：正确性，有效性和相容性<br>（3）并发控制<br>（4）数据库的恢复</li>
</ul>
<p>综上所述：</p>
<blockquote>
<p><em>数据库</em>是<strong>长期存储</strong>在计算机内的<strong>有组织，大量，共享</strong>的数据集合。它可以供各种用户<strong>共享</strong>，具有<strong>最小冗余度</strong>和<strong>较高的数据独立性</strong>。数据库管理系统在数据库<u>建立，运算和维护</u>时对数据库进行统一控制，以保证数据的<u>完整性和安全性</u>，并在<u>多用户</u>同时使用数据库时进行<u>并发控制</u>，在发生<u>故障后</u>对数据库进行<u>恢复</u>。</p>
</blockquote>
<h3 id="1-2-数据模型"><a href="#1-2-数据模型" class="headerlink" title="1.2 数据模型"></a>1.2 数据模型</h3><hr>
<ul>
<li>数据模型：是对现实世界数据特征的抽象</li>
<li>数据模型是数据库系统的核心和基础</li>
</ul>
<h4 id="1-2-1-两类数据模型"><a href="#1-2-1-两类数据模型" class="headerlink" title="1.2.1 两类数据模型"></a>1.2.1 两类数据模型</h4><hr>
<ul>
<li><strong>概念模型</strong>：也叫信息模型，是按<strong>用户观点</strong>来对数据和信息建模，主要用于数据库设计</li>
<li><strong>逻辑模型和物理模型</strong>：<br>逻辑模型主要包括层次模型，网状模型，关系模型，面向对象模型和对象关系数据模型，半结构化数据模型等。<br>物理模型是对数据最底层的抽象，描述数据在系统内部的表示方式和存取方法，或在磁盘或磁带上的存储方式和存取方法，是面向<strong>计算机系统</strong>的。按<strong>计算机观点</strong>。</li>
</ul>
<h4 id="1-2-2-概念模型"><a href="#1-2-2-概念模型" class="headerlink" title="1.2.2 概念模型"></a>1.2.2 概念模型</h4><hr>
<ol>
<li>信息世界中的基本概念<br>（1）实体：客观存在并可相互区别的事物。<br>（2）属性：实体所具有的某一特性。<br>（3）码：唯一标识实体的属性集。<br>（4）域：属性的取值范围<br>（5）实体性：用实体名及其属性名集合来抽象和刻画同类实体<br>（6）实体集：同一类型实体的集合<br>（7）联系：分为实体内联系和实体间联系。实体间联系有1对1，1对多，多对多。</li>
</ol>
<ul>
<li>不同实体是根据<strong>属性值</strong>去区分的。</li>
</ul>
<ol start="2">
<li>概念模型的一种表示方法：实体-联系方法（E-R图/E-R模型）</li>
</ol>
<h4 id="1-2-3-数据模型的组成要素"><a href="#1-2-3-数据模型的组成要素" class="headerlink" title="1.2.3 数据模型的组成要素"></a>1.2.3 数据模型的组成要素</h4><hr>
<ul>
<li><u>数据模型</u>通常由<strong>数据结构，数据操作</strong>和<strong>数据的完整性约束条件</strong>三部分组成。</li>
</ul>
<ol>
<li>数据结构：描述数据库的组成对象以及对象之间的联系。是对系统的<strong>静态特性</strong>的描述。</li>
<li>数据操作：是指对数据库中各种对象（型）的实例（值）允许执行的操作的集合，包括操作及有关的操作规则。是对系统的<strong>动态特性</strong>的描述。</li>
<li>数据的完整性约束条件：是一组完整性规则。包括：实体完整性，参照完整性，自定义完整性约束</li>
</ol>
<h4 id="1-2-4-常用的数据模型"><a href="#1-2-4-常用的数据模型" class="headerlink" title="1.2.4 常用的数据模型"></a>1.2.4 常用的数据模型</h4><hr>
<ul>
<li>层次模型</li>
<li>网状模型</li>
<li>关系模型</li>
<li>面向对象数据模型</li>
<li>对象关系数据模型</li>
<li>半结构化数据模型</li>
</ul>
<h4 id="1-2-5-层次模型"><a href="#1-2-5-层次模型" class="headerlink" title="1.2.5 层次模型"></a>1.2.5 层次模型</h4><hr>
<ol>
<li>层次模型的数据结构<br>（1）有且只有一个结点没有双亲结点，这个结点称为根结点<br>（2）根以外的其他结点有且只有一个双亲结点<br>&nbsp;&nbsp;- 层次模型像一颗倒立的树，结点的双亲是唯一的。 </li>
<li>层次结构的数据操纵和完整性约束条件</li>
<li>层次结构的优缺点：<br>优点：<br>（1）层次模型的数据结构比较简单清晰<br>（2）层次数据库的查询效率高<br>（3）提供了良好的完整性支持<br>缺点：<br>（1）显示生活中很多联系是非层次性的<br>（2）可能会引入冗余数据<br>（3）查询子女结合点必须经过双亲结点<br>（4）由于结构严密，层次命令趋于程序化</li>
</ol>
<h4 id="1-2-6-网状模型"><a href="#1-2-6-网状模型" class="headerlink" title="1.2.6 网状模型"></a>1.2.6 网状模型</h4><hr>
<ul>
<li>网状数据模型的典型代表是DBTG系统，亦称CODASYL系统</li>
</ul>
<ol>
<li>网状模型的数据结构：<br>（1）允许一个以上的结点无双亲<br>（2）一个结点可以有多于一个的双亲</li>
</ol>
<ul>
<li>层次模型中子女结点与双亲结点的联系是唯一的而在网状模型中这种联系可以不唯一。</li>
</ul>
<p>2.网状模型的数据操纵与完整性约束<br>3. 网状模型的优缺点：<br>优点：<br>（1）直接描述现实世界<br>（2）良好的性能，存取效率较高<br>缺点：<br>（1）结构比较复杂<br>（2）网状模型的DDL，DML复杂，不易掌握<br>（3）记录之间的联系是通存取路径实现的，加重用户编写负担</p>
<h4 id="1-2-7-关系模型"><a href="#1-2-7-关系模型" class="headerlink" title="1.2.7 关系模型"></a>1.2.7 关系模型</h4><hr>
<ol>
<li>关系模型的数据结构：<br>术语：</li>
</ol>
<ul>
<li>关系：通常来说对应一张表</li>
<li>元组：表中的一行</li>
<li>属性：</li>
<li>码：唯一确定一个元组</li>
<li>域：属性的取值范围</li>
<li>分量：元组的一个属性值</li>
<li>关系模式：关系模式要求关系是规范化的，最基本的一条是每一个分量是一个不可分的数据项。</li>
</ul>
<ol start="2">
<li>关系模型的数据操纵与完整性约束条件：</li>
</ol>
<ul>
<li>数据操纵包括：查询，插入，删除和更新数据（集合操作，操作对象和操作结果都是关系）</li>
<li>完整性约束条件包括三大类：<strong>实体完整性，参照完整性和用户定义的完整性</strong>。</li>
</ul>
<p>3.关系模型的优缺点：<br>优点：<br>（1）严格的数学概念<br>（2）概念单一<br>（3）存取路径对用户透明<br>缺点：<br>（1）存取路径对用户隐蔽<br>（2）查询效率不如格式化数据模型</p>
<h3 id="1-3-数据库系统的结构"><a href="#1-3-数据库系统的结构" class="headerlink" title="1.3 数据库系统的结构"></a>1.3 数据库系统的结构</h3><h4 id="1-3-1-数据库系统模式的概念"><a href="#1-3-1-数据库系统模式的概念" class="headerlink" title="1.3.1 数据库系统模式的概念"></a>1.3.1 数据库系统模式的概念</h4><hr>
<ul>
<li>在数据模型中有“型”和“值”的概念：型是指对某一类数据的结构和属性的说明，值是型的一个具体赋值。</li>
<li>模式（schema）是数据库中全体数据的逻辑结构和特征的描述。它仅仅涉及型的描述，不涉及具体的值</li>
<li>模式相对稳定，实例相对变动</li>
</ul>
<h4 id="1-3-2-数据库系统的三级模式结构"><a href="#1-3-2-数据库系统的三级模式结构" class="headerlink" title="1.3.2 数据库系统的三级模式结构"></a>1.3.2 数据库系统的三级模式结构</h4><ul>
<li>数据的三级模式：<strong>外模式，模式，内模式</strong></li>
</ul>
<ol>
<li>外模式：也称为子模式（subschema）或用户模式，是数据库<strong>用户能够看见和使用的局部数据的逻辑结构和特征的描述</strong>，是数据库<strong>用户的数据视图</strong>，是与某一应用有关的数据的逻辑表示。</li>
<li>模式：模式也称为逻辑模式，是数据库中<strong>全体数据的逻辑结构和特征</strong>的描述，是<strong>所有用户的公共数据视图</strong>。</li>
<li>内模式：内模式也称为存储模式，一个数据库只有一个内模式，它是数据<strong>物理结构和存储方式</strong>的描述，是数据库内部的组织方式。</li>
</ol>
<h4 id="1-3-3-数据库的二级映像功能和数据独立性"><a href="#1-3-3-数据库的二级映像功能和数据独立性" class="headerlink" title="1.3.3 数据库的二级映像功能和数据独立性"></a>1.3.3 数据库的二级映像功能和数据独立性</h4><hr>
<ol>
<li>外模式/模式映像：</li>
</ol>
<ul>
<li>模式描述的是数据的全局逻辑结构，外模式描述的是数据的局部逻辑结构。</li>
<li>同一个模式可以有任意多个外模式。</li>
<li>当模式改变时，由数据库管理员对各个外模式/模式映像作相应的改变，可以使外模式保持不变。</li>
<li>应用程序是依据数据的外模式编写的，从而应用程序不必修改，保证了数据与程序的逻辑独立性，简称数据的逻辑独立性。</li>
</ul>
<ol start="2">
<li>模式/内模式映像：</li>
</ol>
<ul>
<li>数据库中只有一个模式，也只有一个内模式，所以模式/内模式映像是唯一的</li>
<li>当数据库的存储结构改变时，由数据库管理员对模式/内模式映像作相应改变，可以使模式保持不变，从而应用程序也不必改变。保证了数据与程序的物理独立性，简称数据的物理独立性</li>
</ul>
<blockquote>
<p>在数据库的三级模式结构中，数据库模式即全局逻辑结构是数据库的中心和关键</p>
</blockquote>
<h3 id="1-4-数据库系统的组成"><a href="#1-4-数据库系统的组成" class="headerlink" title="1.4 数据库系统的组成"></a>1.4 数据库系统的组成</h3><hr>
<p>1.硬件平台及数据库：<br>要求：<br>（1）足够大的内存，存放操作系统，DBMS的核心模块，数据缓冲区，应用程序<br>（2）足够大磁盘等设备存方数据库，以及备份<br>（3）较高通道能力，提高数据传输率<br>2，软件：<br>（1）DBMS<br>（2）os<br>（3）与数据库接口的高级语言及其编译系统<br>（4）以DBMS为核心的应用开发工具<br>（5）为特定应用环境开发的数据库应用系统<br>3，人员</p>
<ul>
<li>数据库管理员：<br>（1）决定数据库中的信息内容和结构<br>（2）决定数据库的存储结构和存取策略<br>（3）定义数据的安全性要求和完整性约束条件<br>（4）监控数据库的使用和运行<br>（5）数据库的改进和重组，重构</li>
<li>系统分析员：</li>
<li>数据库设计人员：</li>
<li>应用程序员：</li>
<li>最终用户：<br>（1）偶然用户（2）简单用户（3）复杂用户</li>
</ul>
<h2 id="第二章-关系数据库"><a href="#第二章-关系数据库" class="headerlink" title="第二章 关系数据库"></a>第二章 关系数据库</h2><h3 id="2-1-关系数据结构及形式化定义"><a href="#2-1-关系数据结构及形式化定义" class="headerlink" title="2.1 关系数据结构及形式化定义"></a>2.1 关系数据结构及形式化定义</h3><h4 id="2-1-1-关系"><a href="#2-1-1-关系" class="headerlink" title="2.1.1 关系"></a>2.1.1 关系</h4><hr>
<ol>
<li>域：一组具有相同数据类型的值的集合</li>
<li>笛卡儿积：域上的一种集合运算</li>
<li>关系：R（D1，D2 … Dn）</li>
<li>候选码：某一属性组的值能唯一标识一个元组，而其子集不能</li>
<li>主码，全码</li>
<li>关系可以有三种类型：<strong>基本关系（基本表），查询表，视图表</strong></li>
</ol>
<ul>
<li>基本关系的性质：<br>（1）列是同质的，每一列来自同一域<br>（2）不同的列可出自同一域<br>（3）列的顺序无所谓<br>（4）任意两个元组的候选码不能取相同的值<br>（5）行的顺序无所谓<br>（6）分量必须取原子值，即<strong>每一个分量都必须是不可分的数据项</strong></li>
</ul>
<h4 id="2-1-2-关系模式"><a href="#2-1-2-关系模式" class="headerlink" title="2.1.2 关系模式"></a>2.1.2 关系模式</h4><hr>
<ul>
<li>关系模式：关系的描述 R（U，D，DOM，F）<br>R是关系名，U为组成该关系的属性名的集合，D为U中属性所来自的域，DOM为属性向域的映像集合，F为属性间数据的依赖关系</li>
</ul>
<h4 id="2-1-3-关系数据库"><a href="#2-1-3-关系数据库" class="headerlink" title="2.1.3 关系数据库"></a>2.1.3 关系数据库</h4><hr>
<ul>
<li>关系数据库的型也称为关系数据库模式，是对关系数据库的描述</li>
<li>关系数据库的值是这些关系模式在某一时刻对应的关系的集合，通常就称为关系数据库</li>
</ul>
<h4 id="2-1-4-关系模式的存储结构"><a href="#2-1-4-关系模式的存储结构" class="headerlink" title="2.1.4 关系模式的存储结构"></a>2.1.4 关系模式的存储结构</h4><hr>
<ul>
<li>在关系数据库中实体及实体间的联系都用表来表示</li>
<li>表是关系数据库的逻辑模型</li>
<li>在关系数据库的物理组织中，有的物理数据组织由操作系统完成，有的自己申请文件，进行存储管理</li>
</ul>
<h3 id="2-2-关系操作"><a href="#2-2-关系操作" class="headerlink" title="2.2 关系操作"></a>2.2 关系操作</h3><hr>
<h4 id="2-2-1-基本的关系操作"><a href="#2-2-1-基本的关系操作" class="headerlink" title="2.2.1 基本的关系操作"></a>2.2.1 基本的关系操作</h4><hr>
<ul>
<li>常用操作：<strong>查询，插入，删除，修改</strong></li>
<li>查询又包括：<u>选择，投影，连接，除，并，差，交，笛卡儿积</u></li>
</ul>
<h4 id="2-2-2-关系数据语言的分类"><a href="#2-2-2-关系数据语言的分类" class="headerlink" title="2.2.2 关系数据语言的分类"></a>2.2.2 关系数据语言的分类</h4><ul>
<li><strong>关系代数</strong> 和 <strong>关系演算</strong></li>
<li>介于两者之间的结构化查询语言SQL（高度非过程化的语言）</li>
</ul>
<h3 id="2-3-关系的完整性"><a href="#2-3-关系的完整性" class="headerlink" title="2.3 关系的完整性"></a>2.3 关系的完整性</h3><hr>
<ul>
<li>三类完整性约束：实体完整性，参照完整性，用户定义的完整性。</li>
</ul>
<h4 id="2-3-1-实体完整性"><a href="#2-3-1-实体完整性" class="headerlink" title="2.3.1 实体完整性"></a>2.3.1 实体完整性</h4><ul>
<li>主属性不能为空</li>
</ul>
<h4 id="2-3-2-参照完整性"><a href="#2-3-2-参照完整性" class="headerlink" title="2.3.2 参照完整性"></a>2.3.2 参照完整性</h4><ul>
<li><p>若属性F是基本关系R的外码，他与基本关系S的住吗相对应，则对于R中的每一个元组在F上的值：<br>（1）要么，全为空<br>（2）要么，都与S中的元组的主码值相对应</p>
</li>
<li><p>外码：若F是R中的一个或一组属性，但不是关系R的码，K是S的主码，如果F与K相对应，则称F是R的外码，并称基本关系R是参照关系，基本关系S为被参照关系（R与S可为同一个）</p>
</li>
<li><p>外键并不一定要与相应的主键同名</p>
</li>
</ul>
<h3 id="2-4-关系代数"><a href="#2-4-关系代数" class="headerlink" title="2.4 关系代数"></a>2.4 关系代数</h3><hr>
<ul>
<li>关系代数是一种抽象的查询语言，它用对关系的运算来表达查询</li>
</ul>
<h4 id="2-4-1-传统的集合运算"><a href="#2-4-1-传统的集合运算" class="headerlink" title="2.4.1 传统的集合运算"></a>2.4.1 传统的集合运算</h4><ol>
<li>并（union）</li>
<li>差（except）</li>
<li>交（intersection）</li>
<li>笛卡儿积（cartesian product）</li>
</ol>
<ul>
<li>条件：①目相同（属性数相同）②相对应的属性来自同一域</li>
</ul>
<h4 id="2-4-2-专门的关系运算"><a href="#2-4-2-专门的关系运算" class="headerlink" title="2.4.2 专门的关系运算"></a>2.4.2 专门的关系运算</h4><ul>
<li>作为关系数据系统 ，最小应具备的关系运算是 <u><strong>选择、投影、连接</strong></u>  </li>
<li>数据库中五种基本运算：交，并，投影，选择，笛卡儿积</li>
</ul>
<ol>
<li><p>选择σ</p>
</li>
<li><p>投影Π</p>
</li>
<li><p>连接▷◁<br>（1）等值连接<br>（2）非等值连接<br>（3）自然连接：两个关系中进行比较的分量必须是<strong>同名的属性组</strong>，并且在结果中把<strong>重复的属性列去掉</strong>。<br>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp;- 悬浮元组：被舍弃的元组<br>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp;- 外连接：连接结果不仅包含符合连接条件的行同时也包含自身不符合条件的行。包括左外连接、右外连接和全外连接。<br>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp;- 自动去重</p>
</li>
<li><p>除运算（÷）</p>
</li>
</ol>
<h3 id="2-5-元组演算"><a href="#2-5-元组演算" class="headerlink" title="2.5 元组演算*"></a>2.5 元组演算*</h3><h2 id="第三章-关系数据库标准语言SQL"><a href="#第三章-关系数据库标准语言SQL" class="headerlink" title="第三章 关系数据库标准语言SQL"></a>第三章 关系数据库标准语言SQL</h2><h3 id="3-1-SQL概述"><a href="#3-1-SQL概述" class="headerlink" title="3.1 SQL概述"></a>3.1 SQL概述</h3><h4 id="3-1-1-SQL的产生和发展"><a href="#3-1-1-SQL的产生和发展" class="headerlink" title="3.1.1 SQL的产生和发展"></a>3.1.1 SQL的产生和发展</h4><ul>
<li>不同软件厂商对SQL的基本命令集进行了不同程度的扩充和修改</li>
</ul>
<h4 id="3-1-2-SQL的特点"><a href="#3-1-2-SQL的特点" class="headerlink" title="3.1.2 SQL的特点"></a>3.1.2 SQL的特点</h4><ol>
<li>综合统一：SQL集<strong>数据定义语言，数据操纵语言，数据控制语言</strong>的功能于一体。</li>
<li>高度非过程化</li>
<li>面向集合的操作方式</li>
<li>以同一种语言结构提供多种使用方式（既独立又可嵌入）</li>
<li>功能简洁，易学易用</li>
</ol>
<h4 id="3-1-3-SQL的基本概念"><a href="#3-1-3-SQL的基本概念" class="headerlink" title="3.1.3 SQL的基本概念"></a>3.1.3 SQL的基本概念</h4><hr>
<ul>
<li><u>外模式包括若干视图和部分基本表，模式包括若干基本表，内模式包括若干存储文件</u>。</li>
<li>基本表是本身独立存在的表。在关系数据库管理系统中，一个关系就对应一个基本表，一个或多个基本表对应一个存储文件，一个表可以带若干个索引，索引也可以放在存储文件中</li>
<li><strong>存储文件的逻辑结构组成了关系数据库的内模式</strong>。存储文件的物理结构对最终用户隐蔽</li>
<li>视图是从一个或多个基本表导出的虚表。它本身不独立存在数据库中，即<strong>数据库中只存放视图的定义</strong>而不存放视图的数据。</li>
<li>视图建立后，在<strong>数据字典</strong>中存放的是 <u><strong>产生视图的表定义</strong></u> </li>
<li>在SQL中，视图是由<strong>基本表或视图</strong>产生的虚表。</li>
</ul>
<h3 id="3-2-学生-课程数据库实例"><a href="#3-2-学生-课程数据库实例" class="headerlink" title="3.2 学生-课程数据库实例"></a>3.2 学生-课程数据库实例</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> database S_T;</span><br><span class="line">use S_T;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> Student</span><br><span class="line">(Sno <span class="type">char</span>(<span class="number">9</span>) <span class="keyword">primary</span> key,</span><br><span class="line">Sname <span class="type">char</span>(<span class="number">20</span>) <span class="keyword">unique</span>,</span><br><span class="line">Ssex <span class="type">char</span>(<span class="number">2</span>),</span><br><span class="line">Sage <span class="type">smallint</span>,</span><br><span class="line">Sdept <span class="type">char</span>(<span class="number">20</span>)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> Course</span><br><span class="line">(Cno <span class="type">char</span>(<span class="number">4</span>) <span class="keyword">primary</span> key,</span><br><span class="line">Cname <span class="type">char</span>(<span class="number">40</span>) <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">Cpno <span class="type">char</span>(<span class="number">4</span>),</span><br><span class="line">Ccredit <span class="type">smallint</span>,</span><br><span class="line"><span class="keyword">foreign</span> key(Cpno) <span class="keyword">references</span> Course(Cno)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> SC</span><br><span class="line">(Sno <span class="type">char</span>(<span class="number">9</span>),</span><br><span class="line">Cno <span class="type">char</span>(<span class="number">4</span>),</span><br><span class="line">Grade <span class="type">smallint</span>,</span><br><span class="line"><span class="keyword">primary</span> key (Sno,Cno),</span><br><span class="line"><span class="keyword">foreign</span> key (Sno) <span class="keyword">references</span> Student(Sno),</span><br><span class="line"><span class="keyword">foreign</span> key (Cno) <span class="keyword">references</span> Course(Cno)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<h3 id="3-3-数据定义"><a href="#3-3-数据定义" class="headerlink" title="3.3 数据定义"></a>3.3 数据定义</h3><h4 id="3-3-1-模式的定义与删除"><a href="#3-3-1-模式的定义与删除" class="headerlink" title="3.3.1 模式的定义与删除"></a>3.3.1 模式的定义与删除</h4><ol>
<li>定义模式<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> schema <span class="operator">&lt;</span>模式名<span class="operator">&gt;</span> <span class="keyword">authorization</span> <span class="operator">&lt;</span>用户名<span class="operator">&gt;</span>;</span><br></pre></td></tr></table></figure>
若没指定模式名，隐含为用户名<br>在模式定义后可以紧接表定义<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> schema test <span class="keyword">authorization</span> xiemingjie</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> tab1</span><br><span class="line">(<span class="keyword">no</span> <span class="type">char</span>(<span class="number">9</span>) <span class="keyword">primary</span> key,</span><br><span class="line">name <span class="type">char</span>(<span class="number">20</span>) <span class="keyword">unique</span>,</span><br><span class="line">sex <span class="type">char</span>(<span class="number">2</span>),</span><br><span class="line">age <span class="type">smallint</span>,</span><br><span class="line">);</span><br></pre></td></tr></table></figure></li>
<li>删除模式<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> schema <span class="operator">&lt;</span>模式名<span class="operator">&gt;</span> <span class="operator">&lt;</span>CASCADE <span class="operator">|</span> RESTRICT<span class="operator">&gt;</span>；</span><br></pre></td></tr></table></figure>
CASCADE为级联，表示在删除时同时把该模式下所有数据对象全部删除<br>RESTRICT为限制，表示只有没有任何向下属的对象时才执行删除操作</li>
</ol>
<h4 id="3-3-2-基本表的定义，删除与修改"><a href="#3-3-2-基本表的定义，删除与修改" class="headerlink" title="3.3.2 基本表的定义，删除与修改"></a>3.3.2 基本表的定义，删除与修改</h4><ul>
<li>数据类型</li>
</ul>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>char(n),character(n)</td>
<td>长度为n的定长字符串</td>
</tr>
<tr>
<td>varchar(n),charactervarying(n)</td>
<td>最大长度为n的变长字符串</td>
</tr>
<tr>
<td>clob</td>
<td>字符串大对象</td>
</tr>
<tr>
<td>blob</td>
<td>二进制大对象</td>
</tr>
<tr>
<td>int，integer</td>
<td>长整数（4字节）</td>
</tr>
<tr>
<td>smallint</td>
<td>短整数（2字节）</td>
</tr>
<tr>
<td>bigint</td>
<td>大整数（8字节）</td>
</tr>
<tr>
<td>numeric（p，d）</td>
<td>定点数，由p位数字（不包括符号，小数点）组成，小数点后面有d位数字</td>
</tr>
<tr>
<td>decimal（p，d），dec（p，d）</td>
<td>同numeric</td>
</tr>
<tr>
<td>double precision</td>
<td>取决于机器精度的双精度浮点数</td>
</tr>
<tr>
<td>real</td>
<td>取决于机器精度的单精度浮点数</td>
</tr>
<tr>
<td>float（n）</td>
<td>可选精度的浮点数，精度至少为n位数字</td>
</tr>
<tr>
<td>boolean</td>
<td>逻辑布尔量</td>
</tr>
<tr>
<td>date</td>
<td>日期，格式YYYY-MM-DD</td>
</tr>
<tr>
<td>time</td>
<td>时间，格式 HH：MM：SS</td>
</tr>
<tr>
<td>timestamp</td>
<td>时间戳类型</td>
</tr>
<tr>
<td>interval</td>
<td>时间间隔类型</td>
</tr>
</tbody></table>
<ol>
<li><p>定义基本表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="operator">&lt;</span>表名<span class="operator">&gt;</span></span><br><span class="line">(col1 类型 条件</span><br><span class="line">col2 .........</span><br><span class="line">)；</span><br></pre></td></tr></table></figure></li>
<li><p>修改基本表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span><span class="operator">&lt;</span>表名<span class="operator">&gt;</span></span><br><span class="line">[<span class="keyword">ADD</span> [<span class="keyword">COLUMN</span>]<span class="operator">&lt;</span>新列名<span class="operator">&gt;</span><span class="operator">&lt;</span>数据类型<span class="operator">&gt;</span>[完整性约束]]</span><br><span class="line">[<span class="keyword">ADD</span> <span class="operator">&lt;</span>表级完整性约束<span class="operator">&gt;</span>]</span><br><span class="line">[<span class="keyword">DROP</span> [<span class="keyword">COLUMN</span>]<span class="operator">&lt;</span>列名<span class="operator">&gt;</span>[ CASCADE <span class="operator">|</span> RESTRICT ]]</span><br><span class="line">[<span class="keyword">DROP</span> <span class="keyword">CONSTRAINT</span><span class="operator">&lt;</span>完整性约束名<span class="operator">&gt;</span>[ RESTRICT <span class="operator">|</span> CASCADE ]]</span><br><span class="line">[<span class="keyword">ALTER</span> <span class="keyword">COLUMN</span><span class="operator">&lt;</span>列名<span class="operator">&gt;</span><span class="operator">&lt;</span>数据类型<span class="operator">&gt;</span>];</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>删除基本表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DROP</span>　<span class="keyword">TABLE</span><span class="operator">&lt;</span>表名<span class="operator">&gt;</span>[RESTRICE<span class="operator">|</span>CASCADE]；</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="3-3-3-索引的建立与删除"><a href="#3-3-3-索引的建立与删除" class="headerlink" title="3.3.3 索引的建立与删除"></a>3.3.3 索引的建立与删除</h4><ul>
<li>建立索引：加快查询速度的有效手段</li>
<li>类型：顺序文件索引，B+树索引，散列索引，位图索引</li>
</ul>
<ol>
<li><p>建立索引：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">UNIQUE</span>] [CLUSTER] INDEX <span class="operator">&lt;</span>索引名<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">ON</span> <span class="operator">&lt;</span>表名<span class="operator">&gt;</span>（<span class="operator">&lt;</span>列名<span class="operator">&gt;</span>[<span class="operator">&lt;</span>次序<span class="operator">&gt;</span>][,<span class="operator">&lt;</span>列名<span class="operator">&gt;</span>[<span class="operator">&lt;</span>次序<span class="operator">&gt;</span>]]…）;</span><br></pre></td></tr></table></figure>
<p>次序有：ASC（升序），DESC（降序）<br>unique指此索引的每一个索引值只对应唯一的数据记录<br>cluster 建立的索引是聚簇索引</p>
</li>
<li><p>修改索引</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> INDEX　<span class="operator">&lt;</span>旧索引名<span class="operator">&gt;</span> RENAMA <span class="keyword">TO</span> <span class="operator">&lt;</span>新索引名<span class="operator">&gt;</span>；</span><br></pre></td></tr></table></figure></li>
<li><p>删除索引</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DROP</span> INDEX <span class="operator">&lt;</span>索引名<span class="operator">&gt;</span>；</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>删除索引时，系统会同时从数据字典中删去有关该索引的描述</li>
<li><strong>数据字典：记录了数据库中所有的定义信息</strong></li>
</ul>
<h3 id="3-4-数据查询"><a href="#3-4-数据查询" class="headerlink" title="3.4 数据查询"></a>3.4 数据查询</h3><h4 id="3-4-1-单表查询"><a href="#3-4-1-单表查询" class="headerlink" title="3.4.1 单表查询"></a>3.4.1 单表查询</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  [ <span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span> ] <span class="operator">&lt;</span>目标列表达式<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>目标列表达式<span class="operator">&gt;</span>]…</span><br><span class="line"><span class="keyword">FROM</span> <span class="operator">&lt;</span>表名或视图名<span class="operator">&gt;</span> [（<span class="operator">&lt;</span><span class="keyword">SELECT</span>语句<span class="operator">&gt;</span>）[<span class="keyword">AS</span>]<span class="operator">&lt;</span>别名<span class="operator">&gt;</span> ]</span><br><span class="line">[<span class="keyword">WHERE</span> <span class="operator">&lt;</span>条件表达式<span class="operator">&gt;</span>]</span><br><span class="line">[<span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="operator">&lt;</span>列名<span class="number">1</span><span class="operator">&gt;</span>[ <span class="keyword">HAVING</span> <span class="operator">&lt;</span>条件表达式<span class="operator">&gt;</span> ] ]</span><br><span class="line">[<span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="operator">&lt;</span>列名<span class="number">2</span><span class="operator">&gt;</span>[ <span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span> ] ];</span><br></pre></td></tr></table></figure>

<ul>
<li>用户可以指定别名来改变查询结果的列标题</li>
<li>select不仅可以是表中属性列，也可以是表达式</li>
<li>在select语句中使用group by Sno  时， Sno 必须出现在<u> <strong>select</strong>  </u>子句中</li>
</ul>
<p>1.where子句 常用的查询条件</p>
<table>
<thead>
<tr>
<th>查询条件</th>
<th>谓词</th>
</tr>
</thead>
<tbody><tr>
<td>比较</td>
<td>=,&gt;,&lt;,&gt;=,&lt;=,!=,&lt;&gt;,!&gt;,!&lt;; not+上述比较运算符</td>
</tr>
<tr>
<td>确定范围</td>
<td>between（下限）and（上限），not between and</td>
</tr>
<tr>
<td>确定集合</td>
<td>in ，not in</td>
</tr>
<tr>
<td>字符匹配</td>
<td>like， not like（通配符%:任意长度，_ ：单个字符）（若本身含有通配符需要 ：ESCAPE转义）</td>
</tr>
<tr>
<td>空值</td>
<td>is null ，is not null</td>
</tr>
<tr>
<td>多重条件（逻辑运算）</td>
<td>and，or，not</td>
</tr>
</tbody></table>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> Cno,Ccredit</span><br><span class="line"><span class="keyword">from</span> Course</span><br><span class="line"><span class="keyword">where</span> Cname <span class="keyword">like</span> <span class="string">&#x27;DB\_Design&#x27;</span> <span class="keyword">ESCAPE</span> <span class="string">&#x27;\&#x27;</span> ;</span><br></pre></td></tr></table></figure>
<ul>
<li>ESCAPE ‘&#39; ：表示“\”为转码字符</li>
<li>注：%可代表任意长度的字符串，例：a%b（aghjgb，avb，ab…）<pre><code> _可代表任意单个字符，例：a_b   (acb，aob… )
 
</code></pre>
</li>
</ul>
<p>2.选择若干元组</p>
<ul>
<li>消除取消重复的行： <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> Sno</span><br><span class="line"><span class="keyword">FROM</span> SC；</span><br></pre></td></tr></table></figure></li>
</ul>
<p>3.order by子句</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> Sno,Grade</span><br><span class="line"><span class="keyword">from</span> SC</span><br><span class="line"><span class="keyword">where</span> Cno<span class="operator">=</span><span class="string">&#x27;3&#x27;</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> Grade <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>对于空值，排列时的次序由具体系统实现决定</li>
</ul>
<p>4.聚集函数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">COUNT（<span class="operator">*</span>）                                 <span class="comment">/* 统计元组个数*/</span></span><br><span class="line">COUNT（[<span class="keyword">DISTINCT</span><span class="operator">|</span><span class="keyword">ALL</span>]<span class="operator">&lt;</span>列名<span class="operator">&gt;</span>）    <span class="comment">/*统计一列中值的个数*/</span></span><br><span class="line">SUM（[<span class="keyword">DISTINCT</span><span class="operator">|</span><span class="keyword">ALL</span>]<span class="operator">&lt;</span>列名<span class="operator">&gt;</span>）        <span class="comment">/*计算一列值的总和*/</span></span><br><span class="line">AVG  （[<span class="keyword">DISTINCT</span><span class="operator">|</span><span class="keyword">ALL</span>]<span class="operator">&lt;</span>列名<span class="operator">&gt;</span>）       <span class="comment">/*计算一列值的平均值*/</span></span><br><span class="line">MAX  （[<span class="keyword">DISTINCT</span><span class="operator">|</span><span class="keyword">ALL</span>]<span class="operator">&lt;</span>列名<span class="operator">&gt;</span>）      <span class="comment">/*求一列值中的最大值*/</span></span><br><span class="line">MIN    （[<span class="keyword">DISTINCT</span><span class="operator">|</span><span class="keyword">ALL</span>]<span class="operator">&lt;</span>列名<span class="operator">&gt;</span>）     <span class="comment">/*求一列值中的最小值*/</span></span><br></pre></td></tr></table></figure>
<p>注：where 子句中是不能用聚集函数作为条件表达式</p>
<p>但可以用having：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> Sno，AVG（Grade）</span><br><span class="line"><span class="keyword">FROM</span> SC</span><br><span class="line"><span class="keyword">GROUP</span> 　<span class="keyword">BY</span>　Ｓｎｏ</span><br><span class="line"><span class="keyword">HAVING</span> AVG（Grade）<span class="operator">&gt;=</span><span class="number">90</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li><u><strong>聚集函数只能用在select子句和group by 中的having子句</strong></u></li>
<li><u>当聚集函数遇到空值时，除了count（*）外，都跳过空值只处理非空值</u></li>
</ul>
<h4 id="3-4-2-连接查询"><a href="#3-4-2-连接查询" class="headerlink" title="3.4.2 连接查询"></a>3.4.2 连接查询</h4><ol>
<li>等值与非等值连接查询：<br>连接查询的where 子句用来连接两个表的条件称为  <u>连接条件</u> 或  <u>连接谓词</u> 连接谓词中的列名 称为 <u>连接字段</u></li>
</ol>
<ul>
<li>一般格式：[&lt;表名1&gt;.]&lt;列名1&gt;&lt;比较运算符&gt;[&lt;表名2&gt;.]&lt;列名2&gt;</li>
</ul>
<ol start="2">
<li>自身连接：一个表与自己连接，取别名</li>
<li>外连接：</li>
</ol>
<ul>
<li>连接结果不仅包含符合连接条件的行同时也包含自身不符合条件的行。包括左外连接、右外连接和全外连接。<br><code>select Student.Sno,Sname,Ssex,Sage,Cno,Grade from Student left outer join SC on (Student.Sno=SC.Sno)</code></li>
</ul>
<ol start="4">
<li>多表连接<br><code>select Student,Sno,Sname,Cname,Grade from Student,SC,Course where Student.Sno=SC.Sno and SC.Cno = Course.Cno</code></li>
</ol>
<h4 id="3-4-3-嵌套查询"><a href="#3-4-3-嵌套查询" class="headerlink" title="3.4.3 嵌套查询"></a>3.4.3 嵌套查询</h4><ul>
<li>查询块：一个select-from-where 语句</li>
</ul>
<ol>
<li>带IN谓词的子查询：<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> Sname</span><br><span class="line"><span class="keyword">FROM</span> Student </span><br><span class="line"><span class="keyword">WHERE</span> Sno <span class="keyword">IN</span></span><br><span class="line">                   （<span class="keyword">SELECT</span> Sno</span><br><span class="line">                      <span class="keyword">FROM</span>  SC</span><br><span class="line">                      <span class="keyword">WHERE</span> Cno<span class="operator">=</span>‘<span class="number">2</span>’ ）；</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>父查询，子查询</li>
<li>子查询的select语句中不能使用order by 子句（只能最终查询结果使用）</li>
<li>不相关子查询：子查询条件不依赖于父查询</li>
<li>相关子查询：子查询条件依赖于父查询</li>
</ul>
<ol start="2">
<li>带有比较运算符的子查询：</li>
<li>带有any（some）或all谓词的子查询<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> Sname</span><br><span class="line"><span class="keyword">from</span> Student</span><br><span class="line"><span class="keyword">where</span> Sage<span class="operator">&lt;</span><span class="keyword">ALL</span></span><br><span class="line">(<span class="keyword">select</span> Sage </span><br><span class="line"><span class="keyword">from</span> Student</span><br><span class="line"><span class="keyword">where</span> Sdept<span class="operator">=</span><span class="string">&#x27;CS&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure></li>
<li>带有exists谓词的子查询：exists谓词的子查询不返回任何数据，只产生逻辑真值或逻辑假值。<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> Sname</span><br><span class="line"><span class="keyword">from</span> Student</span><br><span class="line"><span class="keyword">where</span> <span class="keyword">exists</span></span><br><span class="line">(<span class="keyword">select</span> <span class="operator">*</span> </span><br><span class="line"><span class="keyword">from</span> sc</span><br><span class="line"><span class="keyword">where</span> Sno<span class="operator">=</span>Student.Sno <span class="keyword">and</span> Cno<span class="operator">=</span><span class="string">&#x27;1&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="3-4-4-集合查询"><a href="#3-4-4-集合查询" class="headerlink" title="3.4.4 集合查询"></a>3.4.4 集合查询</h4><ul>
<li>并UNION</li>
<li>交INTERSECT</li>
<li>差EXCEPT</li>
</ul>
<p>Select 。。。<br>From。。。<br>Where。。。<br><strong>Union</strong><br>Select。。。<br>From。。。<br>where。。。;</p>
<h4 id="3-4-5-基于派生表的查询"><a href="#3-4-5-基于派生表的查询" class="headerlink" title="3.4.5 基于派生表的查询"></a>3.4.5 基于派生表的查询</h4><ul>
<li>派生表：出现在from子句中的子查询<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> Sno,Cno</span><br><span class="line"><span class="keyword">from</span> SC,(<span class="keyword">select</span> Sno,<span class="built_in">Avg</span>(Grade) <span class="keyword">from</span> SC <span class="keyword">group</span> <span class="keyword">by</span> Sno) <span class="keyword">as</span> Avg_sc(avg_sno,avg_grade)</span><br><span class="line"><span class="keyword">where</span> SC.Sno <span class="operator">=</span> Avg_sc.avg_sno <span class="keyword">and</span> SC.Grade <span class="operator">&gt;</span> Avg_sc.avg_grade</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="3-5-数据更新"><a href="#3-5-数据更新" class="headerlink" title="3.5 数据更新"></a>3.5 数据更新</h3><h4 id="3-5-1-插入数据"><a href="#3-5-1-插入数据" class="headerlink" title="3.5.1 插入数据"></a>3.5.1 插入数据</h4><ol>
<li>插入<br>（1）插入元组：<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span><span class="operator">&lt;</span>表名<span class="operator">&gt;</span>[(<span class="operator">&lt;</span>属性列<span class="number">1</span><span class="operator">&gt;</span>[,<span class="operator">&lt;</span>属性列<span class="number">2</span><span class="operator">&gt;</span>]…)]</span><br><span class="line"><span class="keyword">VALUES</span>（<span class="operator">&lt;</span>常量<span class="number">1</span><span class="operator">&gt;</span>[,<span class="operator">&lt;</span>常量<span class="number">2</span><span class="operator">&gt;</span>]…）;</span><br></pre></td></tr></table></figure>
（2）插入子查询结果：<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="operator">&lt;</span>表名<span class="operator">&gt;</span>[(<span class="operator">&lt;</span>属性列<span class="number">1</span><span class="operator">&gt;</span>[,<span class="operator">&lt;</span>属性列<span class="number">2</span><span class="operator">&gt;</span>…])]</span><br><span class="line">子查询；</span><br></pre></td></tr></table></figure></li>
<li>修改数据（更新）<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">UPDATE<span class="operator">&lt;</span>表名<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">SET</span><span class="operator">&lt;</span>列名<span class="operator">&gt;=</span><span class="operator">&lt;</span>表达式<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>列名<span class="operator">&gt;=</span><span class="operator">&lt;</span>表达式<span class="operator">&gt;</span>]…</span><br><span class="line">[<span class="keyword">WHERE</span><span class="operator">&lt;</span>条件<span class="operator">&gt;</span>]；</span><br></pre></td></tr></table></figure></li>
<li>删除数据<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DELETE</span></span><br><span class="line"><span class="keyword">FROM</span> <span class="operator">&lt;</span>表名<span class="operator">&gt;</span></span><br><span class="line">[<span class="keyword">WHERE</span> <span class="operator">&lt;</span>条件<span class="operator">&gt;</span>]；</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="3-6-空值的处理"><a href="#3-6-空值的处理" class="headerlink" title="3.6 空值的处理"></a>3.6 空值的处理</h3><ol>
<li>空值的产生</li>
<li>空值的判断（is null ，is not null）</li>
<li>空值的约束条件（定义中有<strong>not null</strong>或<strong>unique</strong>或<strong>码属性</strong>不能为空）</li>
<li>空值的算术运算，比较运算和逻辑运算</li>
</ol>
<h3 id="3-7-视图"><a href="#3-7-视图" class="headerlink" title="3.7 视图"></a>3.7 视图</h3><h4 id="3-7-1-定义视图"><a href="#3-7-1-定义视图" class="headerlink" title="3.7.1 定义视图"></a>3.7.1 定义视图</h4><ol>
<li>建立视图：<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span><span class="operator">&lt;</span>视图名<span class="operator">&gt;</span>[(<span class="operator">&lt;</span>列名<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>列名<span class="operator">&gt;</span>]…)]</span><br><span class="line"><span class="keyword">AS</span> <span class="operator">&lt;</span>子查询<span class="operator">&gt;</span></span><br><span class="line">[<span class="keyword">WITH</span> <span class="keyword">CHECK</span> OPTION];</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li><p>WITH CHECK OPTION；加上这句话后，以后对该视图进行插入，修改，删除操作时，自动加上满足视图定义的条件。</p>
</li>
<li><p><strong>行列子集视图</strong>：<u>从单个基本表导出的，并且只去掉某些行和某些列，但保留了主码的视图</u></p>
</li>
<li><p>带表达式的视图：带虚拟列，如2019-Sage</p>
</li>
<li><p>分组视图：带有聚集函数和group by 子句</p>
</li>
</ul>
<ol start="2">
<li>删除视图<br><code>DROP VIEW&lt;视图名&gt;[CASCADE]；</code></li>
</ol>
<h4 id="3-7-2-查询视图"><a href="#3-7-2-查询视图" class="headerlink" title="3.7.2 查询视图"></a>3.7.2 查询视图</h4><ul>
<li>与基本表的查询相似</li>
<li>视图消解：对视图查询时进行有效性检查，若存在，则从数据字典中取出视图的定义，把定义中的子查询和用户的查询结合起来，转换成对基本表的查询，然后再执行修正了的查询</li>
</ul>
<h4 id="3-7-3-更新视图"><a href="#3-7-3-更新视图" class="headerlink" title="3.7.3 更新视图"></a>3.7.3 更新视图</h4><ul>
<li>视图是不实际存储数据的虚表</li>
<li>并不是所有的视图都是可更新的，一般的，行列子集视图是可更新的</li>
<li>DB2规定：<br>(1)若视图是由两个以上基本表导出的,则此视图不允许更新<br>(2)若视图的字段来自字段表达式或常数,则不允许对此视图执行 INSERT和 UPDATE操作,但允许执行 DELETE操作。<br>(3)若视图的字段来自聚集函数,则此视图不允许更新。<br>(4)若视图定义中含有 GROUP BY子句,则此视图不允许更新。<br>(5)若视图定义中含有 DISTINCT短语,则此视图不允许更新<br>(6)若视图定义中有嵌套查询,并且内层查询的FROM子句中涉及的表也是导出该视图的基本表,则此视图不允许更新。</li>
</ul>
<h4 id="3-7-4-视图的作用"><a href="#3-7-4-视图的作用" class="headerlink" title="3.7.4 视图的作用"></a>3.7.4 视图的作用</h4><ol>
<li>视图能简化用户的操作</li>
<li>视图使用户能以多个角度看待统一数据</li>
<li>视图对重构数据库提供了一定程度的逻辑独立性</li>
<li>视图能够对机密数据提供安全保护</li>
<li>适当利用视图可以更清晰地表达查询</li>
</ol>
<h2 id="第四章-数据库安全性"><a href="#第四章-数据库安全性" class="headerlink" title="第四章 数据库安全性"></a>第四章 数据库安全性</h2><h3 id="4-1-数据库安全性概述"><a href="#4-1-数据库安全性概述" class="headerlink" title="4.1 数据库安全性概述"></a>4.1 数据库安全性概述</h3><ul>
<li>数据库的安全性是指保护数据库以防止不合法使用所造成的数据泄露，更改或破坏</li>
</ul>
<h4 id="4-1-1-数据库的不安全因素"><a href="#4-1-1-数据库的不安全因素" class="headerlink" title="4.1.1 数据库的不安全因素"></a>4.1.1 数据库的不安全因素</h4><ol>
<li>非授权用户对数据库的恶意存取和破坏<br>措施：（1）用户身份鉴别（2）存取控制（3）视图</li>
<li>数据库中重要或敏感的数据被泄露<br>措施：（1）强制存取控制（2）数据加密存储（3）加密传输（4）审计日志</li>
<li>安全环境的脆弱性</li>
</ol>
<h4 id="4-1-2-安全标准简介"><a href="#4-1-2-安全标准简介" class="headerlink" title="4.1.2 安全标准简介"></a>4.1.2 安全标准简介</h4><ul>
<li>TCSEC和CC</li>
<li>四个方面描述安全性级别：安全策略，责任，保证，文档</li>
</ul>
<h3 id="4-2-数据库安全性控制"><a href="#4-2-数据库安全性控制" class="headerlink" title="4.2 数据库安全性控制"></a>4.2 数据库安全性控制</h3><h4 id="4-2-1-用户身份鉴别"><a href="#4-2-1-用户身份鉴别" class="headerlink" title="4.2.1 用户身份鉴别"></a>4.2.1 用户身份鉴别</h4><ol>
<li>静态口令鉴别</li>
<li>动态口令鉴别</li>
<li>生物特征鉴别</li>
<li>智能卡鉴别</li>
</ol>
<h4 id="4-2-2-存取控制"><a href="#4-2-2-存取控制" class="headerlink" title="4.2.2 存取控制"></a>4.2.2 存取控制</h4><ul>
<li>存取控制机制包括<strong>定义用户权限</strong>和<strong>合法权限检查</strong>两部分<br>（1）定义用户权限：<br>权限：用户对数据对象的操作权力称为权限，用户权限定义后经过编译存储再数据字典中，被称为安全规则或授权规则<br>（2）合法权限检查：<br>每当用户发出存取数据库的操作请求后(请求一般应包括操作类型、操作对象和操作用户等信息)数据库管理系统查找数据字典,根据<u>安全规则</u>进行<u>合法权限检查</u>,若用户的操作请求<u>超出了定义的权限</u>,系统将<u>拒绝</u>执行此操作。<br>定义用户权限和合法权限检查机制一起组成了数据库管理系统的<u>存取控制子系统</u></li>
<li>在<strong>自主存取控制</strong>方法中,用户对于不同的数据库对象有不同的存取权限,不同的用户对同一对象也有不同的权限,而且用户还可将其拥有的存取权限转授给其他用户。因此自主存取控制非常灵活。</li>
<li>在<strong>强制存取控制</strong>方法中,每一个数据库对象被标以一定的密级,每一个用户也被授予某一个级别的许可证。对于任意一个对象,只有具有合法许可证的用户才可以存取。强制存取控制因此相对比较严格。</li>
</ul>
<h4 id="4-2-3-自主存取控制方法"><a href="#4-2-3-自主存取控制方法" class="headerlink" title="4.2.3 自主存取控制方法"></a>4.2.3 自主存取控制方法</h4><ul>
<li>用户权限是由两个要素组成的：<strong>数据库对象</strong>和<strong>操作类型</strong></li>
<li>在数据库系统内，定义存取权限称为<strong>授权</strong></li>
<li>在关系数据库中，存取控制的对象不仅有数据本身，还有数据库模式</li>
<li>关系数据库系统中的<u><strong>存取权限</strong></u>：</li>
</ul>
<p>（1）对于数据库模式：</p>
<table>
<thead>
<tr>
<th>对象</th>
<th>操作类型</th>
</tr>
</thead>
<tbody><tr>
<td>模式</td>
<td>create schema</td>
</tr>
<tr>
<td>基本表</td>
<td>create table，alter table</td>
</tr>
<tr>
<td>视图</td>
<td>create view</td>
</tr>
<tr>
<td>索引</td>
<td>create index</td>
</tr>
</tbody></table>
<p>（2）对于数据：</p>
<table>
<thead>
<tr>
<th>对象</th>
<th>操作类型</th>
</tr>
</thead>
<tbody><tr>
<td>基本表和视图</td>
<td>select，insert，update，delete，references，all privileges</td>
</tr>
<tr>
<td>属性列</td>
<td>select，insert，update，references，all privileges</td>
</tr>
</tbody></table>
<h4 id="4-2-4-授权：授予与收回"><a href="#4-2-4-授权：授予与收回" class="headerlink" title="4.2.4 授权：授予与收回"></a>4.2.4 授权：授予与收回</h4><ul>
<li>在SQL中使用grant 和revoke语句向用户授予或收回对数据的操作权限</li>
</ul>
<ol>
<li>GRANT</li>
</ol>
<ul>
<li>一般格式为：<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GRANT</span>  <span class="operator">&lt;</span>权限<span class="operator">&gt;</span>[，<span class="operator">&lt;</span>权限<span class="operator">&gt;</span>]...</span><br><span class="line"><span class="keyword">on</span> <span class="operator">&lt;</span>对象类型<span class="operator">&gt;</span> <span class="operator">&lt;</span>对象名<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>对象类型<span class="operator">&gt;</span><span class="operator">&lt;</span>对象名<span class="operator">&gt;</span>]...</span><br><span class="line"><span class="keyword">to</span> <span class="operator">&lt;</span>用户<span class="operator">&gt;</span> [，<span class="operator">&lt;</span>用户<span class="operator">&gt;</span>]...</span><br><span class="line">[<span class="keyword">with</span> <span class="keyword">grant</span> option]；</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="keyword">select</span></span><br><span class="line"><span class="keyword">on</span> <span class="keyword">table</span> Student</span><br><span class="line"><span class="keyword">to</span> user1;</span><br></pre></td></tr></table></figure>
将指定操作对象的指定操作权限授予指定的用户。<br>如果指定了with grant option子句，则获取某种权限的用户还可以把这种权限再授予其他的用户，没有则只能使用该权限。</li>
</ul>
<ol start="2">
<li>REVOKE</li>
</ol>
<ul>
<li>一般格式：<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">REVOKE</span> <span class="operator">&lt;</span>权限<span class="operator">&gt;</span> [,<span class="operator">&lt;</span>权限<span class="operator">&gt;</span>]...</span><br><span class="line"><span class="keyword">on</span> <span class="operator">&lt;</span>对象类型<span class="operator">&gt;</span><span class="operator">&lt;</span>对象名<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>对象类型<span class="operator">&gt;</span><span class="operator">&lt;</span>对象名<span class="operator">&gt;</span>]...</span><br><span class="line"><span class="keyword">from</span> <span class="operator">&lt;</span>用户<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>用户<span class="operator">&gt;</span>]...[cascade<span class="operator">|</span>restrict]；</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">revoke</span> <span class="keyword">select</span> </span><br><span class="line"><span class="keyword">on</span> <span class="keyword">table</span> Student</span><br><span class="line"><span class="keyword">from</span> public;     <span class="comment">/*收回所有用户对Student表的查询权限*/</span></span><br></pre></td></tr></table></figure></li>
<li>用户可以“自主”地决定将数据的存取权限授予何人，决定是否也将“授权”的权限授予他人。因而称这样的存取控制是自主存取控制。</li>
</ul>
<ol start="3">
<li>创建数据库模式的权限</li>
</ol>
<ul>
<li>一般格式：<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">user</span> <span class="operator">&lt;</span>username<span class="operator">&gt;</span> [ <span class="keyword">with</span> ] [ DBA <span class="operator">|</span> RESOURCE <span class="operator">|</span> <span class="keyword">CONNECT</span> ]</span><br></pre></td></tr></table></figure></li>
<li>只有系统的超级用户才有权建立一个新的数据库用户</li>
<li>新创建的数据库用户有三种权限：connect，resource，dba</li>
<li>若没有指明权限，则默认该用户connect权限，不能创建新用户，不能创建模式，基本表，只能登陆数据库。</li>
<li>拥有resource权限的用户能创建基本表和视图，并成为其属主，不能创建模式与新用户，属主可以使用grant语句</li>
<li>拥有DBA权限的用户是系统中的超级用户</li>
</ul>
<h4 id="4-2-5-数据库角色"><a href="#4-2-5-数据库角色" class="headerlink" title="4.2.5 数据库角色"></a>4.2.5 数据库角色</h4><ul>
<li>数据库角色是被命名的一组与数据库操作相关的的权限，角色是权限的集合。</li>
</ul>
<ol>
<li>角色创建<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> role <span class="operator">&lt;</span>角色名<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>给角色授权<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="operator">&lt;</span>权限<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>权限<span class="operator">&gt;</span>]...</span><br><span class="line"><span class="keyword">on</span> <span class="operator">&lt;</span>对象类型<span class="operator">&gt;</span> 对象名</span><br><span class="line"><span class="keyword">to</span> <span class="operator">&lt;</span>角色<span class="operator">&gt;</span> [,<span class="operator">&lt;</span>角色<span class="operator">&gt;</span>]</span><br></pre></td></tr></table></figure></li>
<li>将一个角色授予其他的角色或用户<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="operator">&lt;</span>角色<span class="number">1</span><span class="operator">&gt;</span>[,<span class="operator">&lt;</span>角色<span class="number">2</span><span class="operator">&gt;</span>]</span><br><span class="line"><span class="keyword">to</span> <span class="operator">&lt;</span>角色<span class="number">3</span><span class="operator">&gt;</span>[,<span class="operator">&lt;</span>用户<span class="number">1</span><span class="operator">&gt;</span>]</span><br><span class="line">[<span class="keyword">with</span> admin option]</span><br></pre></td></tr></table></figure></li>
<li>角色权限收回<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">revoke</span> <span class="operator">&lt;</span>权限<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>权限<span class="operator">&gt;</span>]...</span><br><span class="line"><span class="keyword">on</span> <span class="operator">&lt;</span>对象类型<span class="operator">&gt;</span> <span class="operator">&lt;</span>对象名<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">from</span> <span class="operator">&lt;</span>角色<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>角色<span class="operator">&gt;</span>]...</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="4-2-6-强制存取控制方法"><a href="#4-2-6-强制存取控制方法" class="headerlink" title="4.2.6 强制存取控制方法"></a>4.2.6 强制存取控制方法</h4><ul>
<li>在强制存取控制中，数据库管理系统所管理的全部实体被分为主体和客体。</li>
<li>主体：系统中的活动实体，包括实际用户和用户的各进程</li>
<li>客体：系统中的被动实体，包括文件，表，索引等</li>
<li>敏感度标记：绝密→机密→可信→公开</li>
<li>主体的敏感度标记：许可证级别</li>
<li>客体的敏感度标记：密级</li>
</ul>
<h3 id="4-3-视图机制"><a href="#4-3-视图机制" class="headerlink" title="4.3 视图机制"></a>4.3 视图机制</h3><ul>
<li>通过视图机制把要保密的数据对无权存取的用户隐藏</li>
</ul>
<h3 id="4-4-审计"><a href="#4-4-审计" class="headerlink" title="4.4 审计"></a>4.4 审计</h3><ul>
<li>审计是数据库管理系统达到c2以上安全级别必不可少的一项指标。</li>
<li>审计功能把用户对数据库的所有操作自动记录下来放入审计日志，审计员可以利用审计日志监控数据库的各种行为，重现导致现状的一系列事件。</li>
<li>审计事件：（1）服务器事件（2）系统权限（3）语句事件（4）模式对象事件</li>
<li>审计功能：（1）基本功能（2）多套审计规则（3）审计分析和报表（4）审计日志管理（5）查询审计设置及审计记录信息的专门视图</li>
<li>AUDIT语句和NOAUDIT语句<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">audit <span class="keyword">alter</span>,update</span><br><span class="line"><span class="keyword">on</span> SC;</span><br><span class="line"></span><br><span class="line">noaudit <span class="keyword">alter</span>,update</span><br><span class="line"><span class="keyword">on</span> SC;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="4-5-数据加密"><a href="#4-5-数据加密" class="headerlink" title="4.5 *数据加密"></a>4.5 *数据加密</h3><ul>
<li>加密的基本思想是根据一定算法将<strong>明文</strong>变换为<strong>密文</strong></li>
<li>数据加密包括：<br>（1）存储加密<br>（2）传输加密</li>
</ul>
<h3 id="4-6-其他安全性保护"><a href="#4-6-其他安全性保护" class="headerlink" title="4.6 *其他安全性保护"></a>4.6 *其他安全性保护</h3><ul>
<li>除<strong>自主存取控制</strong>和<strong>强制存取控制</strong>外，还有<strong>推理控制</strong>，以及数据库应用中<strong>隐蔽信道</strong>和<strong>数据隐私保护</strong>等技术</li>
</ul>
<h2 id="第五章-数据库完整性"><a href="#第五章-数据库完整性" class="headerlink" title="第五章 数据库完整性"></a>第五章 数据库完整性</h2><ul>
<li>数据库的<strong>完整性</strong>是指<u>数据的<strong>正确性</strong>和<strong>相容性。</strong></u><br>（1）正确性：数据符合现实世界语义<br>（2）相容性：同一对象在不同关系表中符合逻辑</li>
<li>注意完整性和安全性的联系与区别！</li>
<li>如何维护完整性：<br>（1）提供定义完整性约束条件的机制<br>（2）提供完整性检查的方法<br>（3）进行违约处理</li>
</ul>
<h3 id="5-1-实体完整性"><a href="#5-1-实体完整性" class="headerlink" title="5.1 实体完整性"></a>5.1 实体完整性</h3><h4 id="5-1-1-定义实体完整性"><a href="#5-1-1-定义实体完整性" class="headerlink" title="5.1.1 定义实体完整性"></a>5.1.1 定义实体完整性</h4><ul>
<li>主码不能为空<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student</span><br><span class="line">(<span class="keyword">no</span> <span class="type">char</span>(<span class="number">9</span>) <span class="keyword">primary</span> key,     <span class="comment">/*列级定义主码*/</span></span><br><span class="line">name <span class="type">char</span>(<span class="number">20</span>) <span class="keyword">not</span> <span class="keyword">null</span></span><br><span class="line">);</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student</span><br><span class="line">(<span class="keyword">no</span> <span class="type">char</span>(<span class="number">9</span>),</span><br><span class="line">name <span class="type">char</span>(<span class="number">20</span>) <span class="keyword">not</span> <span class="keyword">null</span>，</span><br><span class="line"><span class="keyword">primary</span> key（<span class="keyword">no</span>）            <span class="comment">/*表级定义主码*/</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure></li>
<li><strong>定义属性组为主码只能在表级定义</strong></li>
</ul>
<h4 id="5-1-2-实体完整性检查和违约处理"><a href="#5-1-2-实体完整性检查和违约处理" class="headerlink" title="5.1.2 实体完整性检查和违约处理"></a>5.1.2 实体完整性检查和违约处理</h4><ol>
<li>检查主码值是否唯一</li>
<li>检查主码的各个属性是否为空</li>
</ol>
<h3 id="5-2-参照完整性"><a href="#5-2-参照完整性" class="headerlink" title="5.2 参照完整性"></a>5.2 参照完整性</h3><h4 id="5-2-1-定义参照完整性"><a href="#5-2-1-定义参照完整性" class="headerlink" title="5.2.1 定义参照完整性"></a>5.2.1 定义参照完整性</h4><ul>
<li>使用references 指明外码参照的主码<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> sc</span><br><span class="line">（<span class="keyword">no</span> <span class="type">char</span>（<span class="number">9</span>） <span class="keyword">not</span> <span class="keyword">null</span>，</span><br><span class="line">name <span class="type">char</span>（<span class="number">20</span>）<span class="keyword">not</span> <span class="keyword">null</span>，</span><br><span class="line">grade <span class="type">smallint</span>，</span><br><span class="line"><span class="keyword">primary</span> key（<span class="keyword">no</span>，name）</span><br><span class="line"><span class="keyword">foreign</span> key（<span class="keyword">no</span>）<span class="keyword">references</span> student（<span class="keyword">no</span>），</span><br><span class="line">）;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="5-2-2-参照完整性检查和违约处理"><a href="#5-2-2-参照完整性检查和违约处理" class="headerlink" title="5.2.2 参照完整性检查和违约处理"></a>5.2.2 参照完整性检查和违约处理</h4><ol>
<li>拒绝操作</li>
<li>级联操作</li>
<li>设置为空值</li>
</ol>
<h3 id="5-3-用户定义的完整性"><a href="#5-3-用户定义的完整性" class="headerlink" title="5.3 用户定义的完整性"></a>5.3 用户定义的完整性</h3><h4 id="5-3-1-属性上的约束条件的定义"><a href="#5-3-1-属性上的约束条件的定义" class="headerlink" title="5.3.1 属性上的约束条件的定义"></a>5.3.1 属性上的约束条件的定义</h4><ul>
<li>包括：<br>（1）列值非空（not null）<br>（2）列值唯一（unique）<br>（3）检查是否满足一个表达式（check）<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> sc</span><br><span class="line">(<span class="keyword">no</span> <span class="type">char</span>(<span class="number">9</span>) <span class="keyword">unique</span> <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">name <span class="type">char</span>(<span class="number">20</span>),</span><br><span class="line">sex <span class="type">char</span>(<span class="number">2</span>) <span class="keyword">check</span>(sex <span class="keyword">in</span> (<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;女&#x27;</span>))</span><br><span class="line">);</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="5-3-2-元组上的约束条件"><a href="#5-3-2-元组上的约束条件" class="headerlink" title="5.3.2 元组上的约束条件"></a>5.3.2 元组上的约束条件</h4><ul>
<li>定义：<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> sc</span><br><span class="line">(<span class="keyword">no</span> <span class="type">char</span>(<span class="number">9</span>) <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">name <span class="type">char</span>(<span class="number">20</span>),</span><br><span class="line">sex <span class="type">char</span>(<span class="number">2</span>),</span><br><span class="line"><span class="keyword">primary</span> key (<span class="keyword">no</span>),</span><br><span class="line"><span class="keyword">check</span> (sex<span class="operator">=</span><span class="string">&#x27;女&#x27;</span> <span class="keyword">or</span> name <span class="keyword">not</span> <span class="keyword">like</span> <span class="string">&#x27;Ms.%&#x27;</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="5-4-完整性约束命名子句"><a href="#5-4-完整性约束命名子句" class="headerlink" title="5.4 完整性约束命名子句"></a>5.4 完整性约束命名子句</h3><ol>
<li>完整性约束名命子句<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student</span><br><span class="line">（</span><br><span class="line"><span class="keyword">no</span> <span class="type">char</span>(<span class="number">9</span>)</span><br><span class="line">  <span class="keyword">constraint</span> C1 <span class="keyword">check</span> (<span class="keyword">no</span> <span class="keyword">between</span> <span class="number">90000</span> <span class="keyword">and</span> <span class="number">99999</span>),</span><br><span class="line">name <span class="type">char</span>(<span class="number">20</span>)</span><br><span class="line">  <span class="keyword">constraint</span> C2 <span class="keyword">check</span> <span class="keyword">not</span> <span class="keyword">null</span></span><br><span class="line">）；</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>constraint &lt;完整性约束条件名&gt; &lt;完整性约束条件&gt;</li>
</ul>
<ol start="2">
<li>修改表中的完整性约束条件：<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> student</span><br><span class="line">    <span class="keyword">drop</span> <span class="keyword">constraint</span> C1;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> student</span><br><span class="line">    <span class="keyword">add</span> <span class="keyword">constraint</span> C2 <span class="keyword">check</span>(<span class="keyword">no</span> <span class="keyword">between</span> <span class="number">100</span> <span class="keyword">and</span> <span class="number">100000</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="5-6-断言"><a href="#5-6-断言" class="headerlink" title="5.6 断言"></a>5.6 断言</h3><ul>
<li>通过声明性断言来指定更具一般性的约束。</li>
</ul>
<ol>
<li>创建断言的语句格式<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> assertion <span class="operator">&lt;</span>断言名<span class="operator">&gt;</span> <span class="operator">&lt;</span><span class="keyword">check</span> 子句<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="5-7-触发器"><a href="#5-7-触发器" class="headerlink" title="5.7 *触发器"></a>5.7 *触发器</h3><ul>
<li>触发器：是用户定义在关系表上的一类由事件驱动的特殊过程。<h4 id="5-7-1-定义触发器"><a href="#5-7-1-定义触发器" class="headerlink" title="5.7.1 定义触发器"></a>5.7.1 定义触发器</h4></li>
<li>触发器又叫事件-条件-动作 规则</li>
<li>一般格式：<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TRIGGER</span><span class="operator">&lt;</span>触发器名<span class="operator">&gt;</span>  <span class="comment">/*每当触发事件发生时,该触发器被激活*/</span></span><br><span class="line">&#123;BEFORE<span class="operator">|</span> AFTER&#125;<span class="operator">&lt;</span>触发事件<span class="operator">&gt;</span><span class="keyword">ON</span><span class="operator">&lt;</span>表名<span class="operator">&gt;</span>   </span><br><span class="line">                            <span class="comment">/*指明触发器激活的时间是在执行触发事件前或后*/</span></span><br><span class="line"><span class="keyword">REFERENCING</span> NEWOLD <span class="type">ROW</span> <span class="keyword">AS</span><span class="operator">&lt;</span>变量<span class="operator">&gt;</span></span><br><span class="line">                                <span class="comment">/* REFERENCING指出引用的变量*/</span></span><br><span class="line"><span class="keyword">FOR</span> <span class="keyword">EACH</span> &#123;<span class="type">ROW</span> I STATEMENT&#125;</span><br><span class="line">                                <span class="comment">/*定义触发器的类型,指明动作体执行的频率*/</span></span><br><span class="line">[ <span class="keyword">WHEN</span> <span class="operator">&lt;</span>触发条件<span class="operator">&gt;</span>]<span class="operator">&lt;</span>触发动作体<span class="operator">&gt;</span></span><br><span class="line">                                <span class="comment">/*仅当触发条件为真时才执行触发动作体*/</span></span><br></pre></td></tr></table></figure></li>
</ul>
<blockquote>
<p>(1)只有表的拥有者,即创建表的用户才可以在表上创建触发器,并且一个表上只能创建一定数量的触发器。触发器的具体数量由具体的关系数据库管理系统在设计时确定。<br>(2)触发器名<br>触发器名可以包含模式名,也可以不包含模式名。同一模式下,触发器名必须是唯一的,并且触发器名和表名必须在同一模式下。<br>(3)表名<br>触发器只能定义在基本表上,不能定义在视图上。当基本表的数据发生变化时,将激活定义在该表上相应触发事件的触发器,因此该表也称为触发器的目标表<br>(4)触发事件<br>触发事件可以是 INSERT、 DELETE或 UPDATE,也可以是这几个事件的组如<br>INSERT OR DELETE等,还可以是 UPDATE OF&lt;触发列,…&gt;,即进一步指明修改哪些列时激活触发器。 AFTER/BEFORE是触发的时机。 AFTER表示在触发事件的操作执行之后激活触发器; BEFORE表示在触发事件的操作执行之前激活触发器。<br>(5)触发器类型<br>触发器按照所触发动作的间隔尺寸可以分为行级触发器( FOR EACH ROW)和语句级触发器( FOR EACH STATEMENT)<br>6)触发条件<br>触发器被激活时,只有当触发条件为真时触发动作体才执行,否则触发动作体不执行。如果省略WHEN触发条件,则触发动作体在触发器激活后立即执行。<br>(7)触发动作体<br>触发动作体既可以是一个匿名 PLSQL过程块也可以是对已创建存储过程的调用,如果是行级触发器,用户可以在过程体中使用NEW和OLD引用 UPDATE/INSERT事件之后的新值和 UPDATE/DELETE事件之前的旧值;如果是语句级触发器,则不能在触发动作体中使用NEW或OLD进行引用。<br>如果触发动作体执行失败,激活触发器的事件(即对数据库的增、删、改操作)就会终止执行,触发器的目标表或触发器可能影响的其他对象不发生任何变化。</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">trigger</span> insert_or_update_sal <span class="comment">/*插入或更新时激活触发器*/</span></span><br><span class="line">before <span class="keyword">insert</span> <span class="keyword">or</span> update <span class="keyword">on</span> Teacher <span class="comment">/*before触发事件*/</span></span><br><span class="line"><span class="keyword">referencing</span> <span class="keyword">new</span> <span class="type">row</span> <span class="keyword">as</span> newTuple </span><br><span class="line"><span class="keyword">for</span> <span class="keyword">each</span> <span class="type">row</span>                              <span class="comment">/*这是行级触发器*/</span></span><br><span class="line"><span class="keyword">begin</span>                                       <span class="comment">/*定义触发动作体*/</span></span><br><span class="line">    if(newtuple.Job<span class="operator">=</span><span class="string">&#x27;教授&#x27;</span>)<span class="keyword">and</span>(newtuple.Sal<span class="operator">&lt;</span><span class="number">4000</span>)</span><br><span class="line">        <span class="keyword">then</span> newtuple.Sal :<span class="operator">=</span><span class="number">4000</span>;</span><br><span class="line">    <span class="keyword">end</span> if;</span><br><span class="line"><span class="keyword">end</span>;                                         <span class="comment">/*触发动作体结束*/</span></span><br></pre></td></tr></table></figure>
<ul>
<li>删除触发器<br>drop trigger &lt;触发器名&gt; on &lt;表名&gt;;</li>
</ul>
<h2 id="第六章-关系数据理论"><a href="#第六章-关系数据理论" class="headerlink" title="第六章 关系数据理论"></a>第六章 关系数据理论</h2><h3 id="6-1-问题的提出"><a href="#6-1-问题的提出" class="headerlink" title="6.1 问题的提出"></a>6.1 问题的提出</h3><ul>
<li>1NF：每一个分量必须时不可分的数据项</li>
<li>关系是关系模式在某一时刻的状态或内容</li>
<li>关系模式是静态的</li>
</ul>
<h3 id="6-2-规范化"><a href="#6-2-规范化" class="headerlink" title="6.2 规范化"></a>6.2 规范化</h3><h4 id="6-2-1-函数依赖"><a href="#6-2-1-函数依赖" class="headerlink" title="6.2.1 函数依赖"></a>6.2.1 函数依赖</h4><ol>
<li><strong>函数依赖</strong>：<br>某个属性集决定另一个属性集时，称另一属性集依赖于该属性集，Y函数依赖于X，X函数决定Y记作：X→Y</li>
<li>函数依赖属于语义范畴</li>
<li>非平凡的函数依赖：X→Y，但Y不包含于X</li>
<li>平凡的函数依赖：X→Y，但Y包含于X</li>
<li>若X→Y，则称X为<strong>决定因素</strong></li>
<li><strong>完全函数依赖</strong>：若X→Y，并且对于任意X的一个真子集x’，都有Y不函数依赖于x’,则称Y完全函数依赖于X，<br>否则为<strong>部分函数依赖</strong></li>
<li>传递函数依赖：<br>若X→Y（Y不包含于X），Y-/-&gt;X，Y→Z（Z不包含于Y），则称 Z对X<strong>传递函数依赖</strong></li>
</ol>
<ul>
<li>当B属性函数依赖于A属性是，属性A对B的联系是 <u><strong>多对1</strong></u> .</li>
</ul>
<h4 id="6-2-2-码"><a href="#6-2-2-码" class="headerlink" title="6.2.2 码"></a>6.2.2 码</h4><ol>
<li>设K是R&lt;U，F&gt;中的属性或属性组，若U完全函数依赖于K，则K为R的候选码。</li>
<li>如果U函数依赖于K，即：K→U，则K称为超码</li>
<li>包含在任何一个候选码中的属性称为主属性<br>，否则为非主（码）属性</li>
<li>整个属性组是码，称为全码</li>
</ol>
<h4 id="6-2-3-范式"><a href="#6-2-3-范式" class="headerlink" title="6.2.3 范式"></a>6.2.3 范式</h4><ul>
<li>规范化：一个低一级范式的关系模式通过模式分解可以转化为若干个高一级范式的关系模式的集合</li>
<li>规范化的过程主要是为了克服：<strong>插入异常，删除异常，修改复杂</strong></li>
</ul>
<ol>
<li><strong>1NF</strong>：每一个分量必须是不可分的数据项</li>
<li><strong>2NF</strong>：若R∈1NF，且每一个非主属性完全函数依赖于任何我一个候选码</li>
<li><strong>3NF</strong>：在2NF基础上，任何非主属性不依赖于其它非主属性(在2NF基础上消除传递依赖)</li>
<li><strong>BCNF</strong>：<br>（1）每一个决定因素都包含码<br>（2）所有非主属性对每一个码都是完全函数依赖<br>（3）所有主属性对每一个不包含它的码也是完全函数依赖<br>（4）没有任何属性完全函数依赖于非码的任何一组属性</li>
<li>多值依赖：<br>设R(U)是一个属性集U上的一个关系模式， X、 Y和Z是U的子集，并且Z＝U－X－Y，多值依赖 X→→Y成立当且仅当对R的任一关系r，r在（X，Z）上的每个值对应一组Y的值，这组值仅仅决定于X值而与Z值无关</li>
</ol>
<ul>
<li>多值依赖具有对称性，传递性</li>
</ul>
<ol start="6">
<li><strong>4NF</strong>：关系模式R&lt;U，F&gt;∈1NF，如果对于R的每个非平凡多值依赖X→→Y（Y 不包含于 X），X都含有候选码，则R∈4NF。</li>
</ol>
<ul>
<li>4NF就是限制关系模式的属性之间不允许有非平凡且非函数依赖的多值依赖</li>
</ul>
<h3 id="6-3-数据依赖的公理系统"><a href="#6-3-数据依赖的公理系统" class="headerlink" title="6.3 数据依赖的公理系统"></a>6.3 数据依赖的公理系统</h3><ol>
<li><strong>逻辑蕴含</strong><br> 对于满足一组函数依赖 F 的关系模式R &lt;U，F&gt;，其任何一个关系r，若函数依赖X→Y都成立, 则称 F逻辑蕴含X →Y .</li>
<li> <strong>Armstrong 公理系统</strong>：<br>关系模式R &lt;U，F &gt;来说有以下的推理规则：<br>Al.自反律（Reflexivity）： 若Y ≦ X ≦ U，则X →Y为F所蕴含。<br>A2.增广律（Augmentation）：若X→Y为F所蕴含，且Z ≦ U，则XZ→YZ为F所蕴含。<br>A3.传递律（Transitivity）：若X→Y及Y→Z为F所蕴含，则X→Z为F所蕴含。</li>
</ol>
<ul>
<li>注意：由自反律所得到的函数依赖均是平凡的函数依赖，自反律的使用并不依赖于F</li>
<li>根据A1，A2，A3这三条推理规则可以得到下面三条<strong>推理规则</strong>：<br>合并规则：由X→Y，X→Z，有X→YZ。<pre><code> （A2， A3）
</code></pre>
伪传递规则：由X→Y，WY→Z，有XW→Z。<pre><code> （A2， A3）
</code></pre>
分解规则：由X→Y及 Z ≦ Y，有X→Z。<pre><code> （A1， A3）
</code></pre>
</li>
</ul>
<ol start="3">
<li> <strong>闭包</strong>:<br>(1) 在关系模式R&lt;U，F&gt;中为F所逻辑蕴含的函数依赖的全体叫作 F的闭包，记为F+。<br>(2) 设F为属性集U上的一组函数依赖，X ≦ U， XF+ ={ A|X→A能由F 根据Armstrong公理导出}，XF+称为属性集X关于函数依赖集F 的闭包。</li>
</ol>
<ul>
<li>设F为属性集U上的一组函数依赖，X，Y ≦ U，X→Y能由F 根据Armstrong公理导出的充分必要条件是Y ≦ XF+</li>
</ul>
<ol start="4">
<li><strong>最小依赖集</strong>：</li>
</ol>
<ul>
<li><u>覆盖</u>：如果G+=F+，就说函数依赖集F覆盖G（F是G的覆盖，或G是F的覆盖），或F与G等价。</li>
<li>F+ = G+ 的充分必要条件是     ：F ≦ G+ ，和G  ≦  F+ </li>
<li>如果函数依赖集F满足下列条件，则称F为一个极小函数依赖集。亦称为最小依赖集或最小覆盖。<br>   (1) F中任一函数依赖的右部仅含有一个属性。<br>  (2) F中不存在这样的函数依赖X→A，使得F与F-{X→A}等价。<br>  (3) F中不存在这样的函数依赖X→A， X有真子集Z使得F-{X→A∪{Z→A}与F等价。</li>
</ul>
<h3 id="6-4-模式分解"><a href="#6-4-模式分解" class="headerlink" title="6.4 模式分解"></a>6.4 模式分解</h3><ul>
<li>模式分解的等价定义<br>（⒈）分解具有无损连接性<br>（⒉）分解要保持函数依赖<br>（⒊）分解既要保持函数依赖，又要具有无损连接性</li>
<li>关系模式R&lt;U,F&gt;的一个分解：<br>ρ={ R1&lt;U1,F1&gt;，R2&lt;U2,F2&gt;，…，Rn&lt;Un,Fn&gt;}<br>  U=U1∪U2∪…∪Un，且不存在  Ui  Uj，Fi 为 F在 Ui 上的投影</li>
<li>函数依赖集合{X→Y | X→Y ≦ F+∧XY ≦Ui} 的一个覆盖 Fi 叫作 F 在属性 Ui 上的投影</li>
<li>设关系模式R&lt;U,F&gt;被分解为若干个关系模式<pre><code>R1&lt;U1,F1&gt;，R2&lt;U2,F2&gt;，…，Rn&lt;Un,Fn&gt; 
</code></pre>
（其中U=U1∪U2∪…∪Un，且不存在Ui  Uj，Fi为F在Ui上的投影）。<br>若F所逻辑蕴含的函数依赖一定也由分解得到的某个关系模式中的函数依赖Fi所逻辑蕴含，则称关系模式R的这个分解是保持函数依赖的(Preserve Dependency）</li>
<li>判别一个分解的无损连接性</li>
<li>转换为3NF的保持函数依赖的分解。（合成法）</li>
<li>转换为3NF既有无损连接性又保持函数依赖的分解</li>
<li>转换为BCNF的无损连接分解（分解法）</li>
<li>达到4NF的具有无损连接性的分解</li>
</ul>
<ul>
<li>对关系模式进行分解时，要求保持<strong>函数依赖</strong>，最高可以达到   <u><strong>3NF</strong></u> 。</li>
<li><u>关系模式分解为BCNF后，<strong>函数依赖关系可能被破坏</strong>。</u></li>
<li>模式分解具有无损连接性和保持函数依赖的<strong>两个互相独立的标准</strong>。具有无损连接性的分解不一定保持函数依赖，保持函数依赖的分解不一定具有无损连接性</li>
</ul>
<h2 id="第七章-数据库设计"><a href="#第七章-数据库设计" class="headerlink" title="第七章 数据库设计"></a>第七章 数据库设计</h2><h3 id="7-1-数据库设计概述"><a href="#7-1-数据库设计概述" class="headerlink" title="7.1 数据库设计概述"></a>7.1 数据库设计概述</h3><ol>
<li>数据库设计：数据库设计是指对于一个给定的应用环境，构造（设计）优化的数据库逻辑模式和物理结构，并据此建立数据库及其应用系统，使之能够有效的存储和管理数据，满足各种用户的应用需求，包括信息管理要求和数据操作要求。</li>
</ol>
<h4 id="7-1-1-数据库设计的特点"><a href="#7-1-1-数据库设计的特点" class="headerlink" title="7.1.1 数据库设计的特点"></a>7.1.1 数据库设计的特点</h4><ol>
<li>数据库建设的基本规律：<br>“三分技术，七分管理，十二分基础数据”</li>
</ol>
<ul>
<li>强调了数据的收集，整理，组织和不断更新是数据库建设中的重要一环。</li>
</ul>
<p>2.结构（数据）设计和行为（处理）设计相结合</p>
<h4 id="7-1-2-数据库设计方法"><a href="#7-1-2-数据库设计方法" class="headerlink" title="7.1.2 数据库设计方法"></a>7.1.2 数据库设计方法</h4><ul>
<li>计算机的基础知识</li>
<li>软件工程的原理和方法</li>
<li>程序设计的方法和技巧</li>
<li>数据库的基础知识</li>
<li>数据库设计技术</li>
<li>应用领域的知识</li>
</ul>
<h4 id="7-1-3-数据库设计的基本步骤"><a href="#7-1-3-数据库设计的基本步骤" class="headerlink" title="7.1.3 数据库设计的基本步骤"></a>7.1.3 数据库设计的基本步骤</h4><ol>
<li>需求分析：最困难，最耗时，设计过程的基础</li>
<li>概念设计：数据库设计的关键</li>
<li>逻辑结构设计：</li>
<li>物理结构设计：</li>
<li>数据库实施</li>
<li>数据库运行和维护</li>
</ol>
<table>
<thead>
<tr>
<th>设计阶段</th>
<th>设计描述</th>
</tr>
</thead>
<tbody><tr>
<td>需求分析</td>
<td>数据字典，全系统数据项，数据结构，数据流，数据存储的描述</td>
</tr>
<tr>
<td>概念结构设计</td>
<td>概念模型（E-R图），数据字典</td>
</tr>
<tr>
<td>逻辑结构设计</td>
<td>某种数据模型</td>
</tr>
<tr>
<td>物理结构设计</td>
<td>存储安排，存取方法选择，存取路径建立</td>
</tr>
<tr>
<td>数据库实施</td>
<td>创建数据库模式，数据载入，应用程序的编码和调试，运行</td>
</tr>
<tr>
<td>数据库运行和维护</td>
<td>性能监测，转储/恢复，数据库重组，重构</td>
</tr>
</tbody></table>
<h3 id="7-2-需求分析"><a href="#7-2-需求分析" class="headerlink" title="7.2 需求分析"></a>7.2 需求分析</h3><h4 id="7-2-1-需求分析的任务"><a href="#7-2-1-需求分析的任务" class="headerlink" title="7.2.1 需求分析的任务"></a>7.2.1 需求分析的任务</h4><ul>
<li>详细调查现实世界要处理的对象，充分了解工作概况，明确用户各种需求，在此基础上确定功能。</li>
<li>调查重点是数据和处理，通过调查，收集，分析，获取用户对数据库的如下要求：<br>（1）信息要求（内容和性质）<br>（2）处理要求（处理性能）<br>（3）安全性与完整性要求</li>
</ul>
<h4 id="7-2-2-需求分析的方法"><a href="#7-2-2-需求分析的方法" class="headerlink" title="7.2.2 需求分析的方法"></a>7.2.2 需求分析的方法</h4><ol>
<li>调查机构情况</li>
<li>调查业务活动</li>
<li>协助用户明确要求</li>
<li>确定新系统边界</li>
</ol>
<h4 id="7-2-3-数据字典"><a href="#7-2-3-数据字典" class="headerlink" title="7.2.3 数据字典"></a>7.2.3 数据字典</h4><ul>
<li>数据字典是进行详细的数据收集和数据分析所获得的主要成果。</li>
<li>数据字典是关于数据库中数据的描述，即元数据，而不是数据本身。</li>
<li>数据字典是在需求分析阶段建立，在数据库设计过程中不断修改，充实，完善的，在数据库设计中占有很重要的地位</li>
<li>数据字典通常包括：数据项，数据结构，数据流，数据存储和处理过程。<br>（1）数据项是<strong>数据的最小组成单位</strong>，数据项是<strong>不可再分的数据单位</strong>，若干数据项可以组成数据结构。<br>（2）数据结构反映了数据之间的组合关系<br>（3）数据流是数据结构在系统内传输的路径<br>（4）数据存储是数据结构停留或保存的地方，也是数据流的来源和去向之一。<br>（5）处理过程的具体处理逻辑一般用判定表，判定树来描述</li>
</ul>
<h3 id="7-3-概念结构设计"><a href="#7-3-概念结构设计" class="headerlink" title="7.3 概念结构设计"></a>7.3 概念结构设计</h3><h4 id="7-3-1-概念模型"><a href="#7-3-1-概念模型" class="headerlink" title="7.3.1 概念模型"></a>7.3.1 概念模型</h4><ul>
<li>特点：<br>（1）真实，充分反映现实世界<br>（2）易于理解<br>（3）易于更改<br>（4）易于向关系，网状，层次等转化</li>
</ul>
<h4 id="7-3-2-E-R模型"><a href="#7-3-2-E-R模型" class="headerlink" title="7.3.2 E-R模型"></a>7.3.2 E-R模型</h4><ul>
<li>从数据流图构造E-R图时，选择实体一般应先考虑数据流图中的<u> <strong>数据存储</strong></u> 。</li>
</ul>
<ol>
<li>实体之间的联系：1对1，1对多，多对多</li>
<li>E-R图：<br>（1）实体型用矩形<br>（2）属性用椭圆形<br>（3）联系用菱形</li>
<li>作为属性，不能再具有需要描述的性质</li>
<li>属性不能与其他实体具有联系</li>
<li>E-R图之间的冲突有三类：<br>（1）属性冲突：①属性域冲突②属性取值单位冲突<br>（2）命名冲突：①同名异义②异名同义<br>（3）结构冲突：<ul>
<li>①同一对象在不同应用种具有不同的抽象</li>
<li>②同一实体在不同子系统的E-R图中所包含的属性个数和属性排列次序不完全相同</li>
<li>③实体间的联系在不同的E-R图中为不同的类型。</li>
</ul>
</li>
</ol>
<h3 id="7-4-逻辑结构设计"><a href="#7-4-逻辑结构设计" class="headerlink" title="7.4 逻辑结构设计"></a>7.4 逻辑结构设计</h3><h4 id="7-4-1-E-R图向关系模型的转化"><a href="#7-4-1-E-R图向关系模型的转化" class="headerlink" title="7.4.1 E-R图向关系模型的转化"></a>7.4.1 E-R图向关系模型的转化</h4><ul>
<li>1:1联系的转换方法<br>联系转换为一个独立的关系：与该联系相连的各实体的码以及联系<br>本身的属性均转换为关系的属性，且每个实体的码均是该关系的候选码。<br>将1:1联系与某一端实体集所对应的关系合并，则需要在被合并关系中增<br>加属性，其新增的属性为联系本身的属性和与联系相关的另一个实体集的码。</li>
</ul>
<blockquote>
<p>联系形成的关系独立存在：<br>职工表（职工号，姓名，年龄）主码：职工号<br>产品表（产品号，产品名，价格）主码：产品号<br>负责（职工号，产品号）主码：职工号或产品号</p>
</blockquote>
<ul>
<li>1:n联系的转换方法<br>一种方法是将联系转换为一个独立的关系，其关系的属性由与该联系相连的各实体集的码以及联系本身的属性组成，而该关系的码为n端实体集的码；另一种方法是在n端实体集中增加新属性，新属性由联系对应的1端实体集的码和联系自身的属性构成，新增属性后原关系的码不变</li>
</ul>
<blockquote>
<p>联系形成的关系独立存在。<br>仓库（仓库号，地点，面积）主码：仓库号<br>产品（产品号，产品名，价格）主码：产品号<br>仓储（仓库号，产品号，数量）主码：产品号<br>合并后方案：联系形成的关系与n端对象合并。<br>仓库（仓库号，地点，面积）<br>产品（产品号，产品名，价格，仓库号，数量）</p>
</blockquote>
<ul>
<li>m:n联系的转换方法<br>在向关系模型转换时，一个m:n联系转换为一个关系。转换方法为：与该联系相连的各实体集的码以及联系本身的属性均转换为关系的属性，新关系的码为两个相连实体码的组合（该码为多属性构成的组合码）。</li>
</ul>
<blockquote>
<p>选课<br>•该模型包含两个实体集（学生、课程）和一个m:n联系<br>•该模型可转换为三个关系模式：<br>学生（学号，姓名，性别，年龄）主码：学号<br>课程（课程号，课程名，学分）主码：课程号<br>选课（学号，课程号，成绩）主码：学号+课程号</p>
</blockquote>
<h4 id="7-4-2-数据模型的优化"><a href="#7-4-2-数据模型的优化" class="headerlink" title="7.4.2 数据模型的优化"></a>7.4.2 数据模型的优化</h4><ul>
<li>并不是规范化程度越高的关系就越优</li>
</ul>
<h4 id="7-4-3-设计用户子模式"><a href="#7-4-3-设计用户子模式" class="headerlink" title="7.4.3 设计用户子模式"></a>7.4.3 设计用户子模式</h4><h3 id="7-5-物理结构设计"><a href="#7-5-物理结构设计" class="headerlink" title="7.5 物理结构设计"></a>7.5 物理结构设计</h3><ul>
<li>物理结构设计：为一个给定的逻辑数据模型选取一个最适合应用要求的物理结构的过程</li>
<li>步骤：（1）确定数据库的物理结构（2）对物理结构进行评价</li>
</ul>
<h4 id="7-5-1-数据库物理设计的内容和方法"><a href="#7-5-1-数据库物理设计的内容和方法" class="headerlink" title="7.5.1 数据库物理设计的内容和方法"></a>7.5.1 数据库物理设计的内容和方法</h4><ul>
<li>内容主要包括：关系模式选择存取方法 ，以及设计关系，索引等数据库文件的物理存储结构</li>
</ul>
<h4 id="7-5-2-关系模式存取方法选择"><a href="#7-5-2-关系模式存取方法选择" class="headerlink" title="7.5.2 关系模式存取方法选择"></a>7.5.2 关系模式存取方法选择</h4><ul>
<li>常用方法：索引方法和聚簇方法<br>（1）B+树索引存取方法：索引并不是越多越好，会降低更新的效率<br>（2）hash索引存取方法：选择条件①关系的大小不可知②关系大小动态改变<br>（3）聚簇存取方法：  <ul>
<li>聚簇：把这个或这些属性上具有相同值的元组集中放在连续的物理块中</li>
<li>该属性（组）称为聚簇码</li>
<li>建立和维护聚簇的开销相当大。聚簇码值要相对稳定，以减小开销</li>
</ul>
</li>
</ul>
<h4 id="7-5-3确定数据库的存储结构"><a href="#7-5-3确定数据库的存储结构" class="headerlink" title="7.5.3确定数据库的存储结构"></a>7.5.3确定数据库的存储结构</h4><ul>
<li>考虑：存取时间，存储空间利用率，维护代价</li>
</ul>
<ol>
<li>确定数据存放位置</li>
<li>确定系统配置</li>
</ol>
<h3 id="7-6-数据库的实施和维护"><a href="#7-6-数据库的实施和维护" class="headerlink" title="7.6 数据库的实施和维护"></a>7.6 数据库的实施和维护</h3><h4 id="7-6-1-数据的载入和应用程序的调试"><a href="#7-6-1-数据的载入和应用程序的调试" class="headerlink" title="7.6.1 数据的载入和应用程序的调试"></a>7.6.1 数据的载入和应用程序的调试</h4><ul>
<li>两项重要工作：数据的载入，应用程序的编码和调试</li>
<li>数据库应用程序的设计应该与数据库设计同时进行</li>
</ul>
<h4 id="7-6-2-数据库的试运行"><a href="#7-6-2-数据库的试运行" class="headerlink" title="7.6.2 数据库的试运行"></a>7.6.2 数据库的试运行</h4><ul>
<li>先输入小批量数据作调试用，带试运行基本合格后再大批量输入数据</li>
<li>做好数据库的转储和恢复工作</li>
</ul>
<h4 id="7-6-3-数据库的运行和维护"><a href="#7-6-3-数据库的运行和维护" class="headerlink" title="7.6.3 数据库的运行和维护"></a>7.6.3 数据库的运行和维护</h4><ol>
<li>数据库的转储和恢复</li>
<li>数据库的安全性，完整性控制</li>
<li>数据库性能的监督，分析和改造</li>
<li>数据库的重组织与重构造</li>
</ol>
<ul>
<li>重组织不修改原设计的逻辑和物理结构</li>
<li>重构造部分修改数据库的模式和内模式</li>
</ul>
<h2 id="第八章-数据库编程（无）"><a href="#第八章-数据库编程（无）" class="headerlink" title="第八章 数据库编程（无）"></a>第八章 数据库编程（无）</h2><h2 id="第九章-关系查询处理和查询优化"><a href="#第九章-关系查询处理和查询优化" class="headerlink" title="第九章 关系查询处理和查询优化"></a>第九章 关系查询处理和查询优化</h2><h3 id="9-1-关系数据库系统的查询处理"><a href="#9-1-关系数据库系统的查询处理" class="headerlink" title="9.1 关系数据库系统的查询处理"></a>9.1 关系数据库系统的查询处理</h3><h4 id="9-1-1-查询处理步骤"><a href="#9-1-1-查询处理步骤" class="headerlink" title="9.1.1 查询处理步骤"></a>9.1.1 查询处理步骤</h4><ul>
<li>四个阶段：<strong>查询分析，查询检查，查询优化，查询执行</strong></li>
</ul>
<ol>
<li>查询分析：<strong>语法检查</strong>，对查询语句进行扫描，词法分析，语法分析</li>
<li>查询检查：<br>（1）<strong>语义检查</strong>，根据数据字典中的模式定义和用户权限和完整性约束定义<br>（2）检查通过后转化为等价的关系代数表达式<br>（3）关系数据库管理系统一般都用<strong>查询树</strong>，也叫<strong>语法分析树</strong></li>
<li>查询优化：<br>（1）按照优化层次分为：代数优化，物理优化<br>（2）代数优化策略是通过对<u>关系代数表达式</u>的<u><strong>等价变换</strong></u>来提高查询效率。<br>（3）物理优化则是指存取路径和底层操作算法的选择。选择的依据：①基于规则②基于代价③基于语义</li>
<li>查询执行：依据优化器得到的执行策略生成查询执行计划</li>
</ol>
<h4 id="9-1-2-实现查询操作"><a href="#9-1-2-实现查询操作" class="headerlink" title="9.1.2 实现查询操作"></a>9.1.2 实现查询操作</h4><ol>
<li>选择操作的实现：一般采用全表扫描或者基于索引的算法</li>
<li>连接操作的实现：是查询处理中最常用也最耗时的操作之一，一般采用：嵌套循环算法，排序-合并算法，索引连接算法，hash join算法</li>
</ol>
<h3 id="9-2-关系数据库系统的查询优化"><a href="#9-2-关系数据库系统的查询优化" class="headerlink" title="9.2 关系数据库系统的查询优化"></a>9.2 关系数据库系统的查询优化</h3><ul>
<li>查询优化的优点不仅在于用户不必考虑如何更好的表达查询以获得较高效的效率，而且在于系统可以比用户程序的优化做得更好</li>
</ul>
<h3 id="9-3-代数优化"><a href="#9-3-代数优化" class="headerlink" title="9.3 代数优化"></a>9.3 代数优化</h3><h4 id="9-3-1-关系代数表达式等价变换规则"><a href="#9-3-1-关系代数表达式等价变换规则" class="headerlink" title="9.3.1 关系代数表达式等价变换规则"></a>9.3.1 关系代数表达式等价变换规则</h4><ul>
<li><u>代数优化策略是通过对关系代数表达式的<strong>等价变换</strong>来提高查询效率</u>。</li>
<li>常用代数优化策略：<br>（1）连接，笛卡儿积的交换律<br>（2）连接，笛卡儿积的结合律<br>（3）投影的串接定律<br>（4）选择的串接定律<br>（5）选择与投影操作的交换律<br>（6）选择与笛卡儿积的交换律<br>（7）选择与并的分配律<br>（8）选择与差运算的分配律<br>（9）选择对自然连接的分配律<br>（10）投影与笛卡儿积的分配律<br>（11）投影与并的分配律</li>
</ul>
<h4 id="9-3-2-查询树的启发式优化"><a href="#9-3-2-查询树的启发式优化" class="headerlink" title="9.3.2 查询树的启发式优化"></a>9.3.2 查询树的启发式优化</h4><ol>
<li><u>选择运算应尽可能先做</u></li>
<li><u>把投影运算和选择运算同时进行</u></li>
<li>把投影同其前或后的双目运算结合</li>
<li>把某些选择同它前面要执行的笛卡儿积结合起来成为一个连接运算</li>
<li>找出公共子表达式</li>
</ol>
<h3 id="9-4-物理优化"><a href="#9-4-物理优化" class="headerlink" title="9.4 物理优化"></a>9.4 物理优化</h3><ul>
<li>选择的方法：（1）基于规则的启发式优化（2）基于代价估算的优化（3）两者结合的优化</li>
</ul>
<h2 id="第十章-数据库恢复技术"><a href="#第十章-数据库恢复技术" class="headerlink" title="第十章 数据库恢复技术"></a>第十章 数据库恢复技术</h2><h3 id="10-1-事务的基本概念"><a href="#10-1-事务的基本概念" class="headerlink" title="10.1 事务的基本概念"></a>10.1 事务的基本概念</h3><ol>
<li>事务</li>
</ol>
<ul>
<li>事务：用户定义的一个<strong>数据库操作序列</strong>，这些<u>操作要么全做，要么全不做</u>，是一个不可分割的<strong>工作单位</strong></li>
<li>事务可以是一条或多条sql语句，一个或多个程序</li>
<li>定义事务的语句：<br>（1）begin transaction<br>（2）commit<br>（3）rollback</li>
<li>事务以begin transaction 开始，以commit或rollback结束</li>
<li>commit 表示提交事务的所有操作，将事务中所有对象对数据库的更新写回到磁盘上的物理数据库中去</li>
<li>rollback 表示回滚，系统将事务中对数据库的所有已完成的操作全部撤销，回滚到事务开始时的状态</li>
</ul>
<ol start="2">
<li>事务的ACID特性</li>
</ol>
<ul>
<li>四个特性：原子性，一致性，隔离性，持续性</li>
<li>原子性：事务是数据库的逻辑工作单位</li>
<li>一致性</li>
<li>隔离性：一个事务的执行不被其他事务打扰</li>
<li>持续性：<strong>事务一旦提交，改变即永久</strong>，也叫永久性</li>
</ul>
<h3 id="10-2-数据库恢复概述"><a href="#10-2-数据库恢复概述" class="headerlink" title="10.2 数据库恢复概述"></a>10.2 数据库恢复概述</h3><ul>
<li>从错误状态恢复到某一已知正确状态</li>
</ul>
<h3 id="10-3-故障的种类"><a href="#10-3-故障的种类" class="headerlink" title="10.3 故障的种类"></a>10.3 故障的种类</h3><ol>
<li><strong>事务故障</strong>：例如：并发事务发生<strong>死锁</strong>，<strong>违反完整性</strong>约束而被终止，<strong>运算溢出</strong><br>（1）多是非预期的，不能由应用程序处理的。<br>（2）这类恢复操作成为事务撤销</li>
<li><strong>系统故障</strong>：例如：<strong>cpu故障，os故障，DBMS代码故障，断电</strong><br>（1）造成系统停止运转的任何事件<br>（2）需要<strong>重做</strong>所有已提交的事务</li>
<li><strong>介质故障</strong>：例如：<strong>磁盘损坏，磁头碰撞，瞬时强磁场干扰</strong></li>
</ol>
<ul>
<li>系统故障称为软故障，介质故障称为硬故障，如外存故障</li>
</ul>
<ol start="4">
<li><strong>计算机病毒</strong></li>
</ol>
<hr>
<ul>
<li>恢复的基本原理：<strong>数据冗余</strong></li>
</ul>
<h3 id="10-4-恢复的实现技术、"><a href="#10-4-恢复的实现技术、" class="headerlink" title="10.4 恢复的实现技术、"></a>10.4 恢复的实现技术、</h3><ul>
<li>建立<strong>冗余数据</strong>最常用的技术就是<strong>数据转储</strong>和<strong>登记日志文件</strong></li>
</ul>
<h4 id="10-4-1-数据转储"><a href="#10-4-1-数据转储" class="headerlink" title="10.4.1 数据转储"></a>10.4.1 数据转储</h4><ul>
<li>转储：数据库管理员定期地将数据库复制到其他存储介质上保存起来</li>
<li>这些备用的数据叫做：<strong>后备副本</strong></li>
<li>转储分为静态转储和动态转储，还可分为海量转储和增量转储</li>
<li>为恢复到某一时刻的正确状态需要把转储期间的<u>各事务对数据库的修改活动</u>登记下来，即建立：<strong>日志文件</strong></li>
</ul>
<h4 id="10-4-2-登记日志文件"><a href="#10-4-2-登记日志文件" class="headerlink" title="10.4.2 登记日志文件"></a>10.4.2 登记日志文件</h4><ol>
<li>日志文件：用来记录事务对数据库的更新操作的文件</li>
<li>登记内容：事务的开始，结束，所有更新操作</li>
<li>内容：事务标记，操作类型，操作对象，更新前旧值，更新后新值</li>
<li>作用：事务故障恢复，系统故障恢复，协助后备副本进行介质故障恢复</li>
<li>登记日志文件注意：<br>（1）登记次序严格按并发事务执行的事件次序<br>（2）必须先写日志文件，后写数据库</li>
</ol>
<h3 id="10-5-恢复策略"><a href="#10-5-恢复策略" class="headerlink" title="10.5 恢复策略"></a>10.5 恢复策略</h3><h4 id="10-5-1-事务故障的恢复"><a href="#10-5-1-事务故障的恢复" class="headerlink" title="10.5.1 事务故障的恢复"></a>10.5.1 事务故障的恢复</h4><ol>
<li>务故故障是指事务在运行至正常终止点前被终止,这时恢复子系统应<strong>利用日志文件撤销(UNDO)此事务已对数据库进行的修改</strong>。事务故障的恢复是由系统自动完成的,对用户是透明的。</li>
</ol>
<ul>
<li>系统的恢复步骤是：<br>(1)反向扫描日志文件(即从最后向前扫描日志文件),查找该事务的更新操作。<br>(2)对该事务的更新操作执行逆操作,即将日志记录中“更新前的值”写入数据库<br>(3)继续反向扫描目志文佚,查找该事务的其他更新操作,并做同样处理。<br>(4)如此处理下去,直至读到此事务的开始标记,事务故障恢复就完成了。</li>
</ul>
<h4 id="10-5-2-系统故障的恢复"><a href="#10-5-2-系统故障的恢复" class="headerlink" title="10.5.2 系统故障的恢复"></a>10.5.2 系统故障的恢复</h4><ul>
<li>系统故障造成数据库不一致状态的原因有两个,一是未完成事务对数据<br>库的更新可能已写入数据库,二是已提交事务对数据库的更新可能还留在缓冲区没来得及写入数据库。因此恢复操作就是要<strong>撤销故障发生时未完成的事务,重做已完成的事务</strong>。</li>
<li>系统故障的恢复是由系统在重新启动时自动完成的,不需要用户干预。</li>
<li>系统的恢复步骤是:<br>(1)正向扫描日志文件(即从头扫描日志文件),找出在故障发生前已经提交的事务，将其事务标记入重做队列( REDO-LIST)，同时找出故障发生时尚完成的事务（只有BEGIN 无commit），将其事务标识记撤销队列(UNDO-LIST)。<br>(2)对撤销队列中的各个事务进行撤销(UNDO)处理<br>进行撤销处理的方法是,反向扫描日志文件,对每个撤销事务的更新操作执行逆操作,即将日志记录中“更新前的值”写入数据库。<br>(3)对重做队列中的各个事务进行重做处理<br>进行重做处理的方法是:正向扫描日志文件,对每个重做事务重新执行日志文件登记的操作,即将日志记录中“更新后的值”写入数据库。</li>
</ul>
<h4 id="10-5-3-介质故障的恢复"><a href="#10-5-3-介质故障的恢复" class="headerlink" title="10.5.3 介质故障的恢复"></a>10.5.3 介质故障的恢复</h4><ul>
<li>发生介质故障后,磁盘上的物理数据和日志文件被破坏,这是最严重的一种故障,恢复方法是<strong>重装数据库,然后重做已完成的事务</strong>。<br>(1)装入最新的数据库后备副本(离故障发生时刻最近的转储副本),使数据库恢复到最近一次转储时的一致性状态</li>
<li>对于动态转储的数据库副本,还需同时装入转储开始时刻的日志文件副本,利用恢复系统故障的方法(即REDO+UNDO),才能将数据库恢复到一致性状态。<br>(2)装入相应的日志文件副本(转储结束时刻的日志文件副本),重做已完成的<br>即首先扫描日志文件,找出故障发生时已提交的事务的标识,将其记入重做队列:然后正向扫描日志文件,对重做队列中的所有事务进行重做处理。即将日志记录中“更新后的值”写入数据库。这样就可以将数据库恢复至故障前某一时刻的一致状态了。</li>
<li>介质故障的恢复需要数据库管理员介入,但数据库管理员只需要重装最近转储的数据库副本和有关的各日志文件副本,然后执行系统提供的恢复命令即可,具体的恢复操作仍由数据库管理系统完成。</li>
</ul>
<h3 id="10-6-具有检查点的恢复技术"><a href="#10-6-具有检查点的恢复技术" class="headerlink" title="10.6 具有检查点的恢复技术"></a>10.6 具有检查点的恢复技术</h3><ul>
<li>记录检查点( checkpoint)记录：增加一个重新开始文件,并让恢复子系统在登录日志文件期间动态地维护日志</li>
<li>检查点记录内容：<br>（1）建立检查点时刻所有正在执行的事务清单<br>（2）这些事务最近一个日志记录的地址</li>
<li>动态维护日志文件方法：周期性地执行建立检查点保存数据库状态的操作</li>
<li>使用检查点的方法可以改善恢复效率</li>
</ul>
<h3 id="10-7-数据库镜像"><a href="#10-7-数据库镜像" class="headerlink" title="10.7 *数据库镜像"></a>10.7 *数据库镜像</h3><ul>
<li>通过复制数据实现，用于数据库恢复</li>
</ul>
<h2 id="第十一章-并发控制"><a href="#第十一章-并发控制" class="headerlink" title="第十一章 并发控制"></a>第十一章 并发控制</h2><ul>
<li>事务可以一个一个地串行执行，即每个时刻只有一个事务运行</li>
<li>多处理机下，事务可以实现多个事务并行运行，即同时并发方式</li>
<li>为保证多用户环境中数据的完整性和一致性，DBMS采用的控制称为<strong>并发控制</strong></li>
</ul>
<h3 id="11-1-并发控制概述"><a href="#11-1-并发控制概述" class="headerlink" title="11.1 并发控制概述"></a>11.1 并发控制概述</h3><ol>
<li><strong>事务</strong>是并发控制的基本单位</li>
<li>并发控制是对用户的<strong>并发操作</strong>加以控制和协调 </li>
<li>并发操作造成 <u>不一致性</u> 的问题包括：<br>（1）<strong>丢失修改</strong>：<ul>
<li>考虑飞机订票系统中的一个活动序列:<blockquote>
<p>甲售票点（甲事务）读出某航班的机票余额A,设A=16.<br>乙售票点（乙事务）读出同一航班的机票余额A,也为16.<br>甲售票点卖出一张机票,修改余额A←A-1.所以A为15,把A写回数据库.<br>乙售票点也卖出一张机票,修改余额A←A-1.所以A为15,把A写回数据库.<br>结果明明卖出两张机票，数据库中机票余额只减少1。<br>归纳起来就是：两个事务T1和T2读入同一数据并修改，T2提交的结果破坏了T1提交的结果，导致T1的修改被丢失。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<p>（2）<strong>不可重复读</strong>：</p>
<ul>
<li>不可重复读是指事务T1读取数据后，事务T2执行更新操作，使T1无法再现前一次读取结果。具体地讲，不可重复读包括三种情况：<br>事务T1读取某一数据后，事务T2对其做了修改，当事务1再次读该数据时，得到与前一次不同的值。<blockquote>
<p>例如，T1读取B=100进行运算，T2读取同一数据B，对其进行修改后将B=200写回数据库。T1为了对读取值校对重读B，B已为200，与第一次读取值不一致。<br>事务T1按一定条件从数据库中读取了某些数据记录后，事务T2删除了其中部分记录，当T1再次按相同条件读取数据时，发现某些记录神密地消失了。<br>事务T1按一定条件从数据库中读取某些数据记录后，事务T2插入了一些记录，当T1再次按相同条件读取数据时，发现多了一些记录。（这也叫做幻影读） </p>
</blockquote>
</li>
</ul>
<p>（3）<strong>读“脏”数据</strong>:</p>
<ul>
<li>读”脏”数据是指事务T1修改某一数据，并将其写回磁盘，事务T2读取同一数据后，T1由于某种原因被撤消，这时T1已修改过的数据恢复原值，T2读到的数据就与数据库中的数据不一致，则T2读到的数据就为”脏”数据，即不正确的数据。</li>
</ul>
<ol start="4">
<li>产生上述数据不一致性的<strong>主要原因</strong>是，<strong>并发操作破坏了事务的隔离性</strong></li>
</ol>
<ul>
<li>产生数据不一致性的<strong>根本原因</strong>是：<strong>数据冗余</strong></li>
</ul>
<ol start="5">
<li>并发控制的主要技术：<br>（1）封锁<br>（2）时间戳<br>（3）乐观控制法<br>（4）多版本并发控制</li>
</ol>
<h3 id="11-2-封锁"><a href="#11-2-封锁" class="headerlink" title="11.2 封锁"></a>11.2 封锁</h3><ol>
<li>封锁是实现并发控制的一个重要技术</li>
<li>封锁的类型：<strong>排他锁（写锁），共享锁（读锁）</strong></li>
</ol>
<h3 id="11-3-封锁协议"><a href="#11-3-封锁协议" class="headerlink" title="11.3 封锁协议"></a>11.3 封锁协议</h3><ul>
<li>三级封锁协议</li>
</ul>
<h3 id="11-4-活锁和死锁"><a href="#11-4-活锁和死锁" class="headerlink" title="11.4 活锁和死锁"></a>11.4 活锁和死锁</h3><h4 id="11-4-1-活锁"><a href="#11-4-1-活锁" class="headerlink" title="11.4.1 活锁"></a>11.4.1 活锁</h4><ul>
<li>避免活锁的简单方法是采用<strong>先来先服务</strong>的策略</li>
</ul>
<h4 id="11-4-2-死锁"><a href="#11-4-2-死锁" class="headerlink" title="11.4.2 死锁"></a>11.4.2 死锁</h4><ol>
<li>死锁的预防：<br>（1）一次封锁法<br>（2）顺序封锁法</li>
<li>死锁的诊断与解除：<br>诊断：<br>（1）超时法<br>（2）等待图法（DBMS普遍采用）<br>解除：选择一个代价最小的事务，进行撤销</li>
</ol>
<h3 id="11-5-并发调度的可串行性"><a href="#11-5-并发调度的可串行性" class="headerlink" title="11.5 并发调度的可串行性"></a>11.5 并发调度的可串行性</h3><ul>
<li>可串行化调度：多个事务的并发执行是正确的，当且仅当其结果与按某一次序串行地执行这些事务时的结果相同。</li>
<li>可串行性：是并发事务正确调度的准则</li>
<li><strong>冲突可串行化调度</strong>是可串行化调度的<strong>充分条件</strong></li>
<li><strong>事务遵守两段锁协议</strong>是可串行化调度的<strong>充分条件</strong></li>
<li>冲突操作是指不同的事物对同一数据的读写操作和写写操作</li>
<li><u>遵守两段锁协议的事务也可能会死锁</u></li>
</ul>
<h3 id="11-6-两段锁协议"><a href="#11-6-两段锁协议" class="headerlink" title="11.6 两段锁协议"></a>11.6 两段锁协议</h3><ul>
<li>第一阶段：封锁（扩展阶段）</li>
<li>第二阶段：释放封锁（收缩阶段）</li>
<li>事物遵守<strong>两段锁协议</strong>是可串行化调度的充分条件，而不是必要条件</li>
</ul>
<h3 id="11-7-封锁的粒度"><a href="#11-7-封锁的粒度" class="headerlink" title="11.7 封锁的粒度"></a>11.7 封锁的粒度</h3><ul>
<li>封锁粒度：封锁对象的大小</li>
<li>封锁对象可以是逻辑单元，也可以是物理单元</li>
<li>封锁粒度与系统的<strong>并发度</strong>和并发控制的<strong>开销</strong>密切相关</li>
<li>多粒度封锁：<br>（1）显式封锁<br>（2）隐式封锁</li>
<li>意向锁：如果对一个结点加意向锁，则说明该节点的下层结点正在被加锁。<br>分类：<br>（1）意向共享锁（IS锁）<br>（2）意向排他锁（IX锁）<br>（3）共享意向排他锁（SIX锁）</li>
</ul>
<h2 id="第十二章-数据库管理系统（无）"><a href="#第十二章-数据库管理系统（无）" class="headerlink" title="第十二章 *数据库管理系统（无）"></a>第十二章 *数据库管理系统（无）</h2>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>大学课程</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>大学课程 | 《算法分析与设计》笔记</title>
    <url>/posts/16050.html</url>
    <content><![CDATA[<p>大三算法设计与分析笔记总结与知识点整理</p>
<span id="more"></span>
<h1 style="text-align: center;">笔记总结</h1>

<h1 id="第一章-算法引论"><a href="#第一章-算法引论" class="headerlink" title="第一章 算法引论"></a>第一章 算法引论</h1><h2 id="1-1-算法与程序"><a href="#1-1-算法与程序" class="headerlink" title="1.1 算法与程序"></a>1.1 算法与程序</h2><ul>
<li>算法定义：解决问题的方法或过程</li>
<li>算法的性质：<ul>
<li>（1）输入：有零个或多个外部量作为算法的输入</li>
<li>（2）输出：算法产生至少一个量作为输出</li>
<li>（3）确定性：组成算法的每条指令是清晰的，无歧义的</li>
<li>（4）有限性：算法中每条指令的执行次数有限，执行每条指令的时间也有限</li>
<li>有时还会加入通用性或可行性</li>
</ul>
</li>
<li>程序的定义：是算法用某种程序设计语言的具体实现。</li>
<li>程序与算法的区别：程序可以不满足算法的第四点性质即有限性。例如操作系统，是在无限循环中执行的程序。</li>
</ul>
<h2 id="1-2-表达算法的抽象机制"><a href="#1-2-表达算法的抽象机制" class="headerlink" title="1.2 表达算法的抽象机制"></a>1.2 表达算法的抽象机制</h2><ul>
<li>为了将顶层算法与底层算法隔开，使二者在设计时不互相牵制，互相影响，必须对二者的接口进行抽象。让底层只通过接口为顶层服务，顶层也只通过接口调用底层运算。这个接口就是<strong>抽象数据类型</strong>(ADT)。</li>
</ul>
<h2 id="1-3-描述算法"><a href="#1-3-描述算法" class="headerlink" title="1.3 描述算法"></a>1.3 描述算法</h2><ul>
<li>有多种方式，如：自然语言方式，表格方式，高级程序语言方式等…</li>
</ul>
<h2 id="1-4-算法复杂性分析"><a href="#1-4-算法复杂性分析" class="headerlink" title="1.4 算法复杂性分析"></a>1.4 算法复杂性分析</h2><ul>
<li>算法分析的目的：分析算法占用计算机资源的情况，对算法做出比较和评价，设计出更好的算法</li>
<li>算法的复杂性是算法运行时所需的计算机资源的量，需要时间资源的量称为<strong>时间复杂性</strong>，需要空间资源的量称为<strong>空间复杂性</strong>。</li>
<li>C=F(N,I,A)，用N，I，A分别表示算法要解的问题的规模，算法的输入和算法本身，F表示是上诉N，I，A的确定的三元函数，C表示复杂性</li>
<li>一般只考虑3种情况下的时间复杂性，即最坏情况，最好情况，平均情况</li>
<li>实践表明，可操作性最好且最有实际价值的是<strong>最坏情况下的时间复杂性</strong>。</li>
<li>复杂性渐进性态：<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">对于<span class="built_in">T</span>(<span class="built_in">N</span>)，如果存在~<span class="built_in">T</span>(<span class="built_in">N</span>)，使得当<span class="built_in">N</span>→∞时有(<span class="built_in">T</span>(<span class="built_in">N</span>)-~<span class="built_in">T</span>(<span class="built_in">N</span>))/<span class="built_in">T</span>(<span class="built_in">N</span>)→<span class="number">0</span>，那么就说~<span class="built_in">T</span>(<span class="built_in">N</span>)是<span class="built_in">T</span>(<span class="built_in">N</span>)当<span class="built_in">N</span>→∞时的渐进性态。</span><br></pre></td></tr></table></figure></li>
<li>如果存在正的常数C和自然数N0，使得当N≥N0时有f(N)≤Cg(N)，则称函数f(N)当N充分大时上有界，且g(N)是它的一个上界，记为f(N)=O(g(N))。这时还说f(N)的阶不高于g(N)的阶。</li>
<li>对于符号O，有如下运算规则：<ul>
<li>O(f)+O(g)=O(max(f,g))</li>
<li>O(f)+O(g)=O(f+g)</li>
<li>O(f)O(g)=O(fg)</li>
<li>如果g(N)=O(f(N)),则O(f)+O(g)=O(f)</li>
<li>O(Cf(N))=O(f(N)),其中C是一个正的常数</li>
<li>f=O(f)</li>
</ul>
</li>
</ul>
<h1 id="第二章-递归与分治策略"><a href="#第二章-递归与分治策略" class="headerlink" title="第二章 递归与分治策略"></a>第二章 递归与分治策略</h1><h2 id="2-1-递归的概念"><a href="#2-1-递归的概念" class="headerlink" title="2.1 递归的概念"></a>2.1 递归的概念</h2><ul>
<li><p>直接或间接地调用自身的算法称为<strong>递归算法</strong>。用函数自身给出定义的函数称为<code>递归函数</code></p>
</li>
<li><p>递归函数的两个要素：<code>边界条件</code>和<code>递归方程</code></p>
</li>
<li><p>阶乘函数：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">factorial</span><span class="params">(<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(n==<span class="number">0</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> n*<span class="built_in">factorial</span>(n<span class="number">-1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>Fibonacci数列：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">fibonacci</span><span class="params">(<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(n&lt;=<span class="number">1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> <span class="built_in">fibonacci</span>(n<span class="number">-1</span>)+<span class="built_in">fibonacci</span>(n<span class="number">-2</span>);</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li>
<li><p>hanoi塔：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hanoi</span>(<span class="params">n,a,b,c</span>):</span></span><br><span class="line">    <span class="comment">#将a上的n个圆盘经过c移动到b</span></span><br><span class="line">    <span class="keyword">if</span>(n&gt;<span class="number">0</span>):</span><br><span class="line">        hanoi(n-<span class="number">1</span>,a,c,b)</span><br><span class="line">        move(a,b)</span><br><span class="line">        hanoi(n-<span class="number">1</span>,c,b,a)</span><br></pre></td></tr></table></figure></li>
<li><p>递归算法的优点：结构清晰，可读性强，容易用数学归纳法来证明算法的正确性</p>
</li>
<li><p>递归算法的缺点：运行效率低，无论是耗费的计算时间还是占用的存储空间都比非递归算法多。</p>
</li>
<li><p>消除递归的方法：①采用一个用户定义的栈来模拟系统的递归调用工作栈，从而达到将递归算法改为非递归算法的目的②用递推来实现递归函数</p>
</li>
</ul>
<h2 id="2-2-分治法的基本思想"><a href="#2-2-分治法的基本思想" class="headerlink" title="2.2 分治法的基本思想"></a>2.2 分治法的基本思想</h2><ul>
<li>分治法的基本思想：将一个规模为n的问题<code>分解</code>为k个规模较小的子问题，这些子问题<code>相互独立</code>且与原问题<code>相同</code>。递归地解这些子问题，然后将各子问题的解<code>合并</code>得到原问题的解。</li>
<li>分治法的适用条件：<ul>
<li>①该问题的规模缩小到一定程度容易解决。</li>
<li>②该问题可以分解为若干个规模较小的相同问题。即该问题具有最优子结构性质。</li>
<li>③该问题分解出的子问题的解可以合并为该问题的解。</li>
<li>④子问题间不包含公共的子问题（各子问题相互独立）</li>
</ul>
</li>
<li>分治法的步骤：<ul>
<li>划分</li>
<li>解决</li>
<li>合并</li>
</ul>
</li>
</ul>
<h2 id="2-3-二分搜索技术"><a href="#2-3-二分搜索技术" class="headerlink" title="2.3 二分搜索技术"></a>2.3 二分搜索技术</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binarySearch</span>(<span class="params">a,x</span>):</span></span><br><span class="line">	<span class="comment">#a是数组,x是要搜索的数</span></span><br><span class="line">	a=<span class="built_in">sorted</span>(a)</span><br><span class="line">	<span class="comment">#a要求有序（从小到大）</span></span><br><span class="line">	n=<span class="built_in">len</span>(a)</span><br><span class="line">	left,right=<span class="number">0</span>,n-<span class="number">1</span></span><br><span class="line">	<span class="keyword">while</span>(left&lt;=right):</span><br><span class="line">		middle=(left+right)//<span class="number">2</span></span><br><span class="line">		<span class="keyword">if</span>(x==a[middle]):</span><br><span class="line">			<span class="keyword">return</span> middle</span><br><span class="line">		<span class="keyword">elif</span>(x&gt;a[middle]):</span><br><span class="line">			left=middle+<span class="number">1</span></span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			right=middle-<span class="number">1</span></span><br><span class="line">	<span class="comment">#未找到</span></span><br><span class="line">	<span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure>
<ul>
<li>最坏情况下，时间复杂度是O(logn)</li>
</ul>
<h2 id="2-4-大整数乘法"><a href="#2-4-大整数乘法" class="headerlink" title="2.4 大整数乘法"></a>2.4 大整数乘法</h2><ul>
<li>设x和y都是n位的二进制整数，现在要计算他们的乘积xy。如果直接相乘，需要O(n^2)步，而其分治法是：将n位二进制整数X和Y都分为2段，每段的长为n/2位：<figure class="highlight mathematica"><table><tr><td class="code"><pre><span class="line"><span class="variable">X</span><span class="operator">=</span><span class="punctuation">[</span><span class="variable">A</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="variable">B</span><span class="punctuation">]</span><span class="operator">,</span><span class="variable">Y</span><span class="operator">=</span><span class="punctuation">[</span><span class="built_in">C</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="built_in">D</span><span class="punctuation">]</span><span class="operator">,</span>其中<span class="variable">X</span>，<span class="variable">Y</span>有<span class="variable">n</span>位；<span class="variable">A</span>，<span class="variable">B</span>，<span class="built_in">C</span>，<span class="built_in">D</span>均有<span class="variable">n</span><span class="operator">/</span><span class="number">2</span>位</span><br><span class="line">由此可以得到：</span><br><span class="line"><span class="variable">X</span><span class="operator">=</span><span class="variable">A</span><span class="operator">*</span><span class="number">2</span><span class="operator">^</span><span class="punctuation">(</span><span class="variable">n</span><span class="operator">/</span><span class="number">2</span><span class="punctuation">)</span><span class="operator">+</span><span class="variable">B</span> <span class="operator">,</span> <span class="variable">Y</span><span class="operator">=</span><span class="built_in">C</span><span class="operator">*</span><span class="number">2</span><span class="operator">^</span><span class="punctuation">(</span><span class="variable">n</span><span class="operator">/</span><span class="number">2</span><span class="punctuation">)</span><span class="operator">+</span><span class="built_in">D</span></span><br><span class="line"></span><br><span class="line"><span class="variable">XY</span><span class="operator">=</span><span class="punctuation">(</span><span class="variable">A</span><span class="operator">*</span><span class="number">2</span><span class="operator">^</span><span class="punctuation">(</span><span class="variable">n</span><span class="operator">/</span><span class="number">2</span><span class="punctuation">)</span><span class="operator">+</span><span class="variable">B</span><span class="punctuation">)</span><span class="punctuation">(</span><span class="built_in">C</span><span class="operator">*</span><span class="number">2</span><span class="operator">^</span><span class="punctuation">(</span><span class="variable">n</span><span class="operator">/</span><span class="number">2</span><span class="punctuation">)</span><span class="operator">+</span><span class="built_in">D</span><span class="punctuation">)</span></span><br><span class="line">  <span class="operator">=</span><span class="variable">A</span><span class="operator">*</span><span class="built_in">C</span><span class="operator">*</span><span class="number">2</span><span class="operator">^</span><span class="variable">n</span><span class="operator">+</span><span class="punctuation">(</span><span class="variable">A</span><span class="operator">*</span><span class="built_in">D</span><span class="operator">+</span><span class="built_in">C</span><span class="operator">*</span><span class="variable">B</span><span class="punctuation">)</span><span class="operator">*</span><span class="number">2</span><span class="operator">^</span><span class="punctuation">(</span><span class="variable">n</span><span class="operator">/</span><span class="number">2</span><span class="punctuation">)</span><span class="operator">+</span><span class="variable">B</span><span class="operator">*</span><span class="built_in">D</span></span><br><span class="line">  <span class="operator">=</span><span class="variable">A</span><span class="operator">*</span><span class="built_in">C</span><span class="operator">*</span><span class="number">2</span><span class="operator">^</span><span class="variable">n</span><span class="operator">+</span><span class="punctuation">(</span><span class="punctuation">(</span><span class="variable">A</span><span class="operator">-</span><span class="variable">B</span><span class="punctuation">)</span><span class="punctuation">(</span><span class="built_in">D</span><span class="operator">-</span><span class="built_in">C</span><span class="punctuation">)</span><span class="operator">+</span><span class="variable">A</span><span class="operator">*</span><span class="built_in">C</span><span class="operator">+</span><span class="variable">B</span><span class="operator">*</span><span class="built_in">D</span><span class="punctuation">)</span><span class="operator">*</span><span class="number">2</span><span class="operator">^</span><span class="punctuation">(</span><span class="variable">n</span><span class="operator">/</span><span class="number">2</span><span class="punctuation">)</span><span class="operator">+</span><span class="variable">B</span><span class="operator">*</span><span class="built_in">D</span></span><br><span class="line"></span><br><span class="line">最后一个式子看起来似乎复杂了，但是它仅需做<span class="number">3</span>次<span class="variable">n</span><span class="operator">/</span><span class="number">2</span>位整数的乘法，<span class="number">6</span>次加减法和<span class="number">2</span>次移位</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-5-Strassen矩阵乘法"><a href="#2-5-Strassen矩阵乘法" class="headerlink" title="2.5 Strassen矩阵乘法"></a>2.5 Strassen矩阵乘法</h2><ul>
<li>对于方阵（n*n）A,B,C，有C=A*B,将它们都分块成4个大小相等的子矩阵，每个子矩阵都是<code>(n/2)*(n/2)</code>的方阵</li>
<li><img src="https://s2.ax1x.com/2019/11/20/MhaKxS.png" alt="MhaKxS.png"></li>
</ul>
<h2 id="2-7-合并排序"><a href="#2-7-合并排序" class="headerlink" title="2.7 合并排序"></a>2.7 合并排序</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge</span>(<span class="params">arr,left,mid,right</span>):</span></span><br><span class="line">    <span class="comment">#left，right为需要合并的数组范围</span></span><br><span class="line">    <span class="comment">#mid为中间下标，左边比中值小，右边比中值大</span></span><br><span class="line">    i=left</span><br><span class="line">    j=mid+<span class="number">1</span></span><br><span class="line">    <span class="comment">#复制一个临时数组</span></span><br><span class="line">    aux=arr[:]</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(left,right+<span class="number">1</span>):</span><br><span class="line">        <span class="comment">#如果左指针超过mid，即右边还有剩余</span></span><br><span class="line">        <span class="keyword">if</span>(i&gt;mid):</span><br><span class="line">            arr[k]=aux[j]</span><br><span class="line">            j=j+<span class="number">1</span></span><br><span class="line">        <span class="comment">#如果右指针超过right，即左边还有剩余</span></span><br><span class="line">        <span class="keyword">elif</span>(j&gt;right):</span><br><span class="line">            arr[k]=aux[i]</span><br><span class="line">            i=i+<span class="number">1</span></span><br><span class="line">        <span class="comment">#如果左边小，则左边合并</span></span><br><span class="line">        <span class="keyword">elif</span>(aux[i]&lt;aux[j]):</span><br><span class="line">            arr[k]=aux[i]</span><br><span class="line">            i=i+<span class="number">1</span></span><br><span class="line">        <span class="comment">#如果右边小</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            arr[k]=aux[j]</span><br><span class="line">            j=j+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mergeSort</span>(<span class="params">arr,left,right</span>):</span></span><br><span class="line">    <span class="comment">#如果已经遍历完</span></span><br><span class="line">    <span class="keyword">if</span>(left&gt;=right):</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    <span class="comment">#取中值，拆成左右两边</span></span><br><span class="line">    mid=(left+right)//<span class="number">2</span></span><br><span class="line">    <span class="comment">#对左半边进行归并排序</span></span><br><span class="line">    mergeSort(arr,left,mid)</span><br><span class="line">    <span class="comment">#对右半边进行归并排序</span></span><br><span class="line">    mergeSort(arr,mid+<span class="number">1</span>,right)</span><br><span class="line">    <span class="comment">#合并算法</span></span><br><span class="line">    merge(arr,left,mid,right)</span><br></pre></td></tr></table></figure>
<ul>
<li>最坏情况下的时间复杂度为O(nlogn)</li>
</ul>
<h2 id="2-8-快速排序"><a href="#2-8-快速排序" class="headerlink" title="2.8 快速排序"></a>2.8 快速排序</h2><ul>
<li><p>步骤：分解，递归求解，合并</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quicksort</span>(<span class="params">arr,low,high</span>):</span></span><br><span class="line">    <span class="keyword">if</span> low&lt;high :</span><br><span class="line">        index=getindex(arr,low,high)</span><br><span class="line">        quicksort(arr,low,index-<span class="number">1</span>)</span><br><span class="line">        quicksort(arr,index+<span class="number">1</span>,high)</span><br><span class="line"></span><br><span class="line"><span class="comment">#快速排序算法核心</span></span><br><span class="line"><span class="comment">#作用：将小于基准值的数放在其左边，大于在右边</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getindex</span>(<span class="params">arr,low,high</span>):</span></span><br><span class="line">    <span class="comment">#默认第一个数字为标准值</span></span><br><span class="line">    temp=arr[low]</span><br><span class="line">    <span class="comment">#当未遍历完，即左右指针未相遇</span></span><br><span class="line">    <span class="keyword">while</span>(low&lt;high):</span><br><span class="line">        <span class="comment">#如果右边大于标准值，右指针左移</span></span><br><span class="line">        <span class="keyword">while</span>((low&lt;high)<span class="keyword">and</span>(arr[high]&gt;=temp)):</span><br><span class="line">            high=high-<span class="number">1</span></span><br><span class="line">        <span class="comment">#此时右指针对应值小于标准值，将其复制给左指针位置</span></span><br><span class="line">        arr[low]=arr[high]</span><br><span class="line">        <span class="comment">#当左边小于标准值，左指针右移</span></span><br><span class="line">        <span class="keyword">while</span>((low&lt;high)<span class="keyword">and</span>(arr[low]&lt;=temp)):</span><br><span class="line">            low=low+<span class="number">1</span></span><br><span class="line">        <span class="comment">#此时左指针对应值大于标准值，将其复制给右指针位置</span></span><br><span class="line">        arr[high]=arr[low]</span><br><span class="line">    <span class="comment">#将标准值赋值给左右指针相遇的位置</span></span><br><span class="line">    arr[low]=temp</span><br><span class="line">    <span class="comment">#此时low左边全部小于等于arr[low],low右边全部大于等于arr[low]</span></span><br><span class="line">    <span class="keyword">return</span> low</span><br></pre></td></tr></table></figure></li>
<li><p>快排平均情况下的时间复杂度是O(nlogn)，最坏情况下的时间复杂度是O(n^2)</p>
</li>
</ul>
<h2 id="2-9-线性时间选择"><a href="#2-9-线性时间选择" class="headerlink" title="2.9 线性时间选择"></a>2.9 线性时间选择</h2><ul>
<li>找出一组数中，第X大（小）的数</li>
<li>采用了随机划分算法</li>
</ul>
<h2 id="2-10-最近点对问题"><a href="#2-10-最近点对问题" class="headerlink" title="2.10 最近点对问题"></a>2.10 最近点对问题</h2><ul>
<li>时间复杂度分析O(nlogn)</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Copyright: Copyright (c) 2019</span></span><br><span class="line"><span class="string">Author: Justlovesmile</span></span><br><span class="line"><span class="string">Title: 最近点对问题</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#按x坐标排序的点</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point1</span>:</span></span><br><span class="line">    <span class="comment">#x,y为坐标，id为序号</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,xx,yy,index</span>):</span></span><br><span class="line">        self.x=xx</span><br><span class="line">        self.y=yy</span><br><span class="line">        self.<span class="built_in">id</span>=index</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#按y坐标排序的点</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point2</span>(<span class="params">Point1</span>):</span></span><br><span class="line">    <span class="comment">#x，y为坐标，id为该点按x排序时的序号</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,xx,yy,index</span>):</span></span><br><span class="line">        self.x=xx</span><br><span class="line">        self.y=yy</span><br><span class="line">        self.<span class="built_in">id</span>=index</span><br><span class="line">        </span><br><span class="line"><span class="comment">#表示输出的平面点对</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pair</span>:</span></span><br><span class="line">    <span class="comment">#a，b为点，dist为距离</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, aa, bb,dd</span>):</span></span><br><span class="line">        self.a=aa</span><br><span class="line">        self.b=bb</span><br><span class="line">        self.dist=dd</span><br><span class="line">    </span><br><span class="line"><span class="comment">#求平面上任意两点u,v的距离</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dist</span>(<span class="params">u,v</span>):</span></span><br><span class="line">    dx=u.x-v.x</span><br><span class="line">    dy=u.y-v.y</span><br><span class="line">    <span class="keyword">return</span> dx*dx+dy*dy</span><br><span class="line"></span><br><span class="line"><span class="comment">#归并排序</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge</span>(<span class="params">S,order,left,mid,right</span>):</span></span><br><span class="line">    i=left</span><br><span class="line">    j=mid+<span class="number">1</span></span><br><span class="line">    aux=S[:]</span><br><span class="line">    <span class="comment">#按x排序</span></span><br><span class="line">    <span class="keyword">if</span>(order==<span class="string">&#x27;x&#x27;</span>):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(left,right+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span>(i&gt;mid):</span><br><span class="line">                S[k]=aux[j]</span><br><span class="line">                j=j+<span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span>(j&gt;right):</span><br><span class="line">                S[k]=aux[i]</span><br><span class="line">                i=i+<span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span>(S[i].x&lt;aux[j].x):</span><br><span class="line">                S[k]=aux[i]</span><br><span class="line">                i=i+<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                S[k]=aux[j]</span><br><span class="line">                j=j+<span class="number">1</span></span><br><span class="line">    <span class="comment">#按y排序</span></span><br><span class="line">    <span class="keyword">elif</span>(order==<span class="string">&#x27;y&#x27;</span>):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(left,right+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span>(i&gt;mid):</span><br><span class="line">                S[k]=aux[j]</span><br><span class="line">                j=j+<span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span>(j&gt;right):</span><br><span class="line">                S[k]=aux[i]</span><br><span class="line">                i=i+<span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span>(S[i].y&lt;aux[j].y):</span><br><span class="line">                S[k]=aux[i]</span><br><span class="line">                i=i+<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                S[k]=aux[j]</span><br><span class="line">                j=j+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#归并排序</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mergeSort</span>(<span class="params">S,x,left,right</span>):</span></span><br><span class="line">    <span class="keyword">if</span>(left&gt;=right):</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    mid=(left+right)//<span class="number">2</span></span><br><span class="line">    mergeSort(S,x,left,mid)</span><br><span class="line">    mergeSort(S,x,mid+<span class="number">1</span>,right)</span><br><span class="line">    merge(S,x,left,mid,right)</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算最接近点对</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">closePair</span>(<span class="params">S,Y,Z,l,r</span>):</span></span><br><span class="line">    <span class="comment">#两个点</span></span><br><span class="line">    <span class="keyword">if</span>(r-l==<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">return</span> Pair(S[l],S[r],dist(S[l],S[r]))</span><br><span class="line">    <span class="comment">#三个点</span></span><br><span class="line">    <span class="keyword">if</span>(r-l==<span class="number">2</span>):</span><br><span class="line">        d1=dist(S[l],S[l+<span class="number">1</span>])</span><br><span class="line">        d2=dist(S[l+<span class="number">1</span>],S[r])</span><br><span class="line">        d3=dist(S[l],S[r])</span><br><span class="line">        <span class="keyword">if</span>((d1&lt;=d2)<span class="keyword">and</span>(d1&lt;=d3)):</span><br><span class="line">            <span class="keyword">return</span> Pair(S[l],S[l+<span class="number">1</span>],d1)</span><br><span class="line">        <span class="keyword">if</span>(d2&lt;=d3):</span><br><span class="line">            <span class="keyword">return</span> Pair(S[l+<span class="number">1</span>],S[r],d2)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> Pair(S[l],S[r],d3)</span><br><span class="line">    <span class="comment">#多于三个点</span></span><br><span class="line">    m=(l+r)//<span class="number">2</span></span><br><span class="line">    f=l</span><br><span class="line">    g=m+<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l,r+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span>(Y[i].<span class="built_in">id</span>&gt;m):</span><br><span class="line">            Z[g]=Y[i] </span><br><span class="line">            g=g+<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            Z[f]=Y[i]</span><br><span class="line">            f=f+<span class="number">1</span></span><br><span class="line">    <span class="comment">#递归求解</span></span><br><span class="line">    best = closePair(S,Z,Y,l,m)</span><br><span class="line">    right = closePair(S,Z,Y,m+<span class="number">1</span>,r)</span><br><span class="line">    <span class="comment">#选最近的点对</span></span><br><span class="line">    <span class="keyword">if</span>(right.dist&lt;best.dist):</span><br><span class="line">        best=right</span><br><span class="line">    merge(Y,<span class="string">&quot;y&quot;</span>,l,m,r)</span><br><span class="line"></span><br><span class="line">    k=l</span><br><span class="line">    <span class="comment">#距离中线最近的</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l,r+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">abs</span>(S[m].x-Y[i].x)&lt;best.dist):</span><br><span class="line">            Z[k]=Y[i]</span><br><span class="line">            k=k+<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l,k):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>,k):</span><br><span class="line">            <span class="keyword">if</span>(Z[j].y-Z[i].y&lt;best.dist):</span><br><span class="line">                dp=dist(Z[i],Z[j])</span><br><span class="line">                <span class="keyword">if</span>(dp&lt;best.dist):</span><br><span class="line">                    best=Pair(S[Z[i].<span class="built_in">id</span>],S[Z[j].<span class="built_in">id</span>],dp)</span><br><span class="line">    <span class="comment">#返回最近点对</span></span><br><span class="line">    <span class="keyword">return</span> best</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#一维点集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cpair1</span>(<span class="params">S</span>):</span></span><br><span class="line">    <span class="comment">#先设为正无穷</span></span><br><span class="line">    min_d=<span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>)</span><br><span class="line">    S=<span class="built_in">sorted</span>(S)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(S)):</span><br><span class="line">        dist=<span class="built_in">abs</span>(S[i]-S[i-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span>(dist&lt;min_d):</span><br><span class="line">            pair=[]</span><br><span class="line">            min_d=dist</span><br><span class="line">            pair.append([S[i-<span class="number">1</span>],S[i]])</span><br><span class="line">        <span class="keyword">elif</span>(dist==min_d):</span><br><span class="line">            pair.append([S[i-<span class="number">1</span>],S[i]])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Closest point:&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> pair:</span><br><span class="line">        <span class="built_in">print</span>(i,end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nMin_dist:&quot;</span>,min_d)</span><br><span class="line"></span><br><span class="line"><span class="comment">#二维点集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cpair2</span>(<span class="params">S</span>):</span></span><br><span class="line">    Y=[]</span><br><span class="line">    n=<span class="built_in">len</span>(S)</span><br><span class="line">    <span class="keyword">if</span>(n&lt;<span class="number">2</span>):</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    <span class="comment">#按X坐标排序</span></span><br><span class="line">    mergeSort(S,<span class="string">&quot;x&quot;</span>,<span class="number">0</span>,n-<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#以Point2类型赋值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        p=Point2(S[i].x,S[i].y,i)</span><br><span class="line">        Y.append(p)</span><br><span class="line">    <span class="comment">#按y坐标排序</span></span><br><span class="line">    mergeSort(Y,<span class="string">&quot;y&quot;</span>,<span class="number">0</span>,n-<span class="number">1</span>)</span><br><span class="line">    Z=Y[:]</span><br><span class="line">    <span class="keyword">return</span> closePair(S,Y,Z,<span class="number">0</span>,n-<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment">#输入一维还是二维点平面</span></span><br><span class="line">    model=<span class="built_in">input</span>(<span class="string">&quot;Please choose model of &#x27;1&#x27; or &#x27;2&#x27;:&quot;</span>).split()[<span class="number">0</span>]</span><br><span class="line">    S=[]</span><br><span class="line">    <span class="comment">#一维点对</span></span><br><span class="line">    <span class="keyword">if</span>(model == <span class="string">&#x27;1&#x27;</span>):</span><br><span class="line">        point=<span class="built_in">input</span>(<span class="string">&quot;Please input a group of number in order:\n&quot;</span>).split()</span><br><span class="line">        <span class="comment">#如果输入空点对</span></span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">len</span>(point)==<span class="number">0</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;您输入了空点对！&quot;</span>)</span><br><span class="line">        <span class="comment">#转换类型</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(point)):</span><br><span class="line">            S.append(<span class="built_in">int</span>(point[i]))</span><br><span class="line">        <span class="comment">#输出最近点对</span></span><br><span class="line">        cpair1(S)</span><br><span class="line">    <span class="comment">#二维点对</span></span><br><span class="line">    <span class="keyword">elif</span>(model == <span class="string">&#x27;2&#x27;</span>):</span><br><span class="line">        <span class="comment">#输入点数</span></span><br><span class="line">        n=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;Please input how many points:\n&quot;</span>))</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">0</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;您输入了0个点！&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            words=<span class="string">f&quot;please input the No.<span class="subst">&#123;i+<span class="number">1</span>&#125;</span> point (like: x y) in x order:&quot;</span></span><br><span class="line">            point=<span class="built_in">input</span>(words).split()</span><br><span class="line">            p=Point1(<span class="built_in">int</span>(point[<span class="number">0</span>]),<span class="built_in">int</span>(point[<span class="number">1</span>]),i)</span><br><span class="line">            S.append(p)</span><br><span class="line">        <span class="comment">#找到最近的一对点对</span></span><br><span class="line">        best=cpair2(S)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;The closest points are (<span class="subst">&#123;best.a.x&#125;</span>,<span class="subst">&#123;best.a.y&#125;</span>) and (<span class="subst">&#123;best.b.x&#125;</span>,<span class="subst">&#123;best.b.y&#125;</span>).&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;And the distance is <span class="subst">&#123;best.dist**<span class="number">0.5</span>&#125;</span>.&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;没有这个选项！&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment">#异常处理</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入不合法！出错信息如下：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>

<h1 id="第三章-动态规划"><a href="#第三章-动态规划" class="headerlink" title="第三章 动态规划"></a>第三章 动态规划</h1><ul>
<li>动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解，但与分治法不同的是，适用于动态规划法求解的问题，经分解得到的子问题往往不是相互独立的。</li>
<li>动态规划算法的步骤：<ul>
<li>①找出最优解的性质，并刻画其结构特征</li>
<li>②递归地定义最优值</li>
<li>③以自底向上的方式计算出最优值</li>
<li>④根据计算最优值时得到的信息，构造最优解</li>
</ul>
</li>
<li>动态规划算法的两个基本要素：<code>最优子结构</code>与<code>重叠子问题</code><ul>
<li>最优子结构性质：问题的最优解包含子问题的最优解</li>
<li>重叠子问题：在用递归算法自顶向下求解问题时，每次产生的子问题并不总是新问题，有些子问题被反复计算多次</li>
<li>无后效性：一个问题被划分阶段后，阶段I中的状态只能由I+1中的状态通过状态转移方程得来，与其他状态没有关系，特别是与未发生的状态没有关系</li>
</ul>
</li>
<li>动态规划算法有一个变形方法——备忘录方法，这种方法不同于动态规划算法“自底向上”的填充方向，而是“自顶向下”的递归方向，为每一个解过的子问题建立一个记录项（备忘录）以备需要时查看，也可以避免相同子问题的重复求解</li>
</ul>
<h2 id="3-1-矩阵连乘问题"><a href="#3-1-矩阵连乘问题" class="headerlink" title="3.1 矩阵连乘问题"></a>3.1 矩阵连乘问题</h2><ul>
<li><img src="https://s2.ax1x.com/2019/11/21/MIK2dK.png" alt="MIK2dK.png"></li>
<li>m(i,j)是指从A[i]到A[j]（1≤i≤j≤n）的最少数乘次数</li>
<li>矩阵可乘条件：A的列数等于B的行数，若A是一个p×q矩阵，B是一个q×r矩阵，则AB总共需要pqr次数乘。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Copyright: Copyright (c) 2019</span></span><br><span class="line"><span class="string">Author: Justlovesmile</span></span><br><span class="line"><span class="string">Title: 矩阵连乘问题</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#计算最优值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matrixChain</span>(<span class="params">p,m,s</span>):</span></span><br><span class="line">    <span class="comment">#m[i][j]表示A[i]到A[j]所需的最少数乘次数</span></span><br><span class="line">    <span class="comment">#s[i][j]表示A[i]到A[j]所需的最少数乘法对应的分隔位置</span></span><br><span class="line">    n=<span class="built_in">len</span>(p)-<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,n+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n-r+<span class="number">2</span>):</span><br><span class="line">            <span class="comment">#沿斜线方向递进</span></span><br><span class="line">            j=r+i-<span class="number">1</span></span><br><span class="line">            m[i][j]=m[i+<span class="number">1</span>][j]+p[i-<span class="number">1</span>]*p[i]*p[j]</span><br><span class="line">            s[i][j]=i</span><br><span class="line">            k=i+<span class="number">1</span></span><br><span class="line">            <span class="comment">#寻找i到j间最优分隔k</span></span><br><span class="line">            <span class="keyword">while</span>(k&lt;j):</span><br><span class="line">                t=m[i][k]+m[k+<span class="number">1</span>][j]+p[i-<span class="number">1</span>]*p[k]*p[j]</span><br><span class="line">                <span class="keyword">if</span>(t&lt;m[i][j]):</span><br><span class="line">                    m[i][j]=t</span><br><span class="line">                    s[i][j]=k</span><br><span class="line">                k=k+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#根据S递归输出</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">traceback</span>(<span class="params">s,i,j</span>):</span></span><br><span class="line">    <span class="keyword">if</span>(i==j):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;A[<span class="subst">&#123;i&#125;</span>]&quot;</span>,end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;(&quot;</span>,end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">    traceback(s,i,s[i][j])</span><br><span class="line">    traceback(s,s[i][j]+<span class="number">1</span>,j)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;)&quot;</span>,end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    p=[]</span><br><span class="line">    y=<span class="number">0</span></span><br><span class="line">    <span class="comment">#输入矩阵个数</span></span><br><span class="line">    n=<span class="built_in">input</span>(<span class="string">&quot;Please iuput the number of matrix:&quot;</span>).split()</span><br><span class="line">    <span class="comment">#异常处理</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">len</span>(n)==<span class="number">0</span>):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;您输入了空矩阵！&quot;</span>)</span><br><span class="line">    n=<span class="built_in">int</span>(n[<span class="number">0</span>])</span><br><span class="line">    <span class="comment">#输入每个矩阵的信息</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        s=<span class="built_in">input</span>(<span class="string">f&quot;Input No.<span class="subst">&#123;i+<span class="number">1</span>&#125;</span> Matrix size,eg:5 5\n&quot;</span>).split()</span><br><span class="line">        <span class="comment">#判断是否能与前一项相乘</span></span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">len</span>(p)&gt;=<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span>(y!=<span class="built_in">int</span>(s[<span class="number">0</span>])):</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;您输入的矩阵不能相乘！&quot;</span>)</span><br><span class="line">        x,y=<span class="built_in">int</span>(s[<span class="number">0</span>]),<span class="built_in">int</span>(s[<span class="number">1</span>])</span><br><span class="line">        p.append(x)</span><br><span class="line">    p.append(y)</span><br><span class="line">    m=[]</span><br><span class="line">    s=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>):</span><br><span class="line">        m.append([<span class="number">0</span>]*(n+<span class="number">1</span>))</span><br><span class="line">        s.append([<span class="number">0</span>]*(n+<span class="number">1</span>))</span><br><span class="line">    matrixChain(p,m,s)  </span><br><span class="line">    traceback(s,<span class="number">1</span>,n)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nCount times:&quot;</span>,m[<span class="number">1</span>][n])</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment">#异常处理</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入不合法！出错信息如下：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>

<h2 id="3-3-最长公共子序列"><a href="#3-3-最长公共子序列" class="headerlink" title="3.3 最长公共子序列"></a>3.3 最长公共子序列</h2><ul>
<li><img src="https://s2.ax1x.com/2019/11/21/MI179S.png" alt="MI179S.png"><br>建立递归关系：</li>
<li><img src="https://s2.ax1x.com/2019/11/21/MI399U.png" alt="MI399U.png"></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Copyright: Copyright (c) 2019</span></span><br><span class="line"><span class="string">Author: Justlovesmile</span></span><br><span class="line"><span class="string">Title: 最长公共子序列问题</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">IcsLength</span>(<span class="params">x,y,b</span>):</span></span><br><span class="line">    m=<span class="built_in">len</span>(x)</span><br><span class="line">    n=<span class="built_in">len</span>(y)</span><br><span class="line">    <span class="comment">#初始化</span></span><br><span class="line">    c=[]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(m+<span class="number">1</span>):</span><br><span class="line">        c.append([<span class="number">0</span>]*(n+<span class="number">1</span>))</span><br><span class="line">    <span class="comment">#逐个比较</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,m+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">            <span class="comment">#如果相等那么此时的最长公共长度为去除该位置的最长公共长度+1</span></span><br><span class="line">            <span class="keyword">if</span>(x[i-<span class="number">1</span>]==y[j-<span class="number">1</span>]):</span><br><span class="line">                c[i][j]=c[i-<span class="number">1</span>][j-<span class="number">1</span>]+<span class="number">1</span></span><br><span class="line">                <span class="comment">#记录c[i][j]的值是第一类子问题的解得到的</span></span><br><span class="line">                b[i][j]=<span class="number">1</span></span><br><span class="line">            <span class="comment">#如果对应位置不相等，则比较两个序列去掉这个不等值后哪边的最长子序列会更长</span></span><br><span class="line">            <span class="keyword">elif</span>(c[i-<span class="number">1</span>][j]&gt;=c[i][j-<span class="number">1</span>]):</span><br><span class="line">                c[i][j]=c[i-<span class="number">1</span>][j]</span><br><span class="line">                b[i][j]=<span class="number">2</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                c[i][j]=c[i][j-<span class="number">1</span>]</span><br><span class="line">                b[i][j]=<span class="number">3</span></span><br><span class="line">    <span class="keyword">return</span> c[m][n]</span><br><span class="line"></span><br><span class="line"><span class="comment">#根据b[i][j]输出最长子序列</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Ics</span>(<span class="params">i,j,x,b</span>):</span></span><br><span class="line">    <span class="keyword">if</span>(i==<span class="number">0</span> <span class="keyword">or</span> j==<span class="number">0</span>):</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    <span class="comment">#如果是第一类子问题的解，则说明该位置是公共部分</span></span><br><span class="line">    <span class="keyword">if</span>(b[i][j]==<span class="number">1</span>):</span><br><span class="line">        Ics(i-<span class="number">1</span>,j-<span class="number">1</span>,x,b)</span><br><span class="line">        <span class="built_in">print</span>(x[i-<span class="number">1</span>],end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="comment">#如果是第二类子问题的解，则说明此时Zk≠Xm</span></span><br><span class="line">    <span class="keyword">elif</span>(b[i][j]==<span class="number">2</span>):</span><br><span class="line">        Ics(i-<span class="number">1</span>,j,x,b)</span><br><span class="line">    <span class="comment">#Zk≠Yn</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        Ics(i,j-<span class="number">1</span>,x,b)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment">#输入字符串</span></span><br><span class="line">    A=<span class="built_in">input</span>(<span class="string">&quot;Please input No.1 Ics:&quot;</span>).split()</span><br><span class="line">    B=<span class="built_in">input</span>(<span class="string">&quot;Please input No.2 Ics:&quot;</span>).split()</span><br><span class="line">    b=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(A)+<span class="number">1</span>):</span><br><span class="line">        b.append([<span class="number">0</span>]*(<span class="built_in">len</span>(B)+<span class="number">1</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The longest length:&quot;</span>,IcsLength(A,B,b))</span><br><span class="line">    Ics(<span class="built_in">len</span>(A),<span class="built_in">len</span>(B),A,b)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment">#异常处理</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入不会合法！出错信息如下：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>


<h2 id="3-4-凸多边形最优三角剖分"><a href="#3-4-凸多边形最优三角剖分" class="headerlink" title="3.4 凸多边形最优三角剖分"></a>3.4 凸多边形最优三角剖分</h2><ul>
<li>和矩阵连乘相似</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Copyright: Copyright (c) 2019</span></span><br><span class="line"><span class="string">Author: Justlovesmile</span></span><br><span class="line"><span class="string">Title: 凸多边形最优三角剖分问题</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> isConvex <span class="keyword">import</span> isConvex</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算最优值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minWeightTriangulation</span>(<span class="params">n,t,s,v</span>):</span></span><br><span class="line">    <span class="comment">#t[i][j]是凸子多边形vi-1,vi,...,vj的最优三角剖分对应的权函数值</span></span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,n+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n-r+<span class="number">2</span>):</span><br><span class="line">            j=r+i-<span class="number">1</span></span><br><span class="line">            t[i][j]=t[i+<span class="number">1</span>][j]+weight(i-<span class="number">1</span>,i,j,v)</span><br><span class="line">            s[i][j]=i</span><br><span class="line">            k=i+<span class="number">1</span></span><br><span class="line">            <span class="comment">#遍历i到j的所有边</span></span><br><span class="line">            <span class="keyword">while</span>(k&lt;j):</span><br><span class="line">                u=t[i][k]+t[k+<span class="number">1</span>][j]+weight(i-<span class="number">1</span>,k,j,v)</span><br><span class="line">                <span class="keyword">if</span>(u&lt;t[i][j]):</span><br><span class="line">                    t[i][j]=u</span><br><span class="line">                    s[i][j]=k</span><br><span class="line">                k=k+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#根据s输出划分结果</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">traceback</span>(<span class="params">s,i,j</span>):</span></span><br><span class="line">    <span class="keyword">if</span>(i==j):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;B[<span class="subst">&#123;i&#125;</span>]&quot;</span>,end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;(&quot;</span>,end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">    traceback(s,i,s[i][j])</span><br><span class="line">    traceback(s,s[i][j]+<span class="number">1</span>,j)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;)&quot;</span>,end=<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#根据距离计算权重</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight</span>(<span class="params">i,j,k,v</span>):</span></span><br><span class="line">    <span class="keyword">return</span> dist(i,j,v)+dist(i,k,v)+dist(k,j,v)</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算距离</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dist</span>(<span class="params">i,j,v</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (v[i][<span class="number">0</span>]-v[j][<span class="number">0</span>])**<span class="number">2</span>+(v[i][<span class="number">1</span>]-v[j][<span class="number">1</span>])**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    v=[]</span><br><span class="line">    <span class="comment">#可选择手动输入和使用默认值</span></span><br><span class="line">    ans=<span class="built_in">input</span>(<span class="string">&quot;Do you want to use default v[]:(y / n )&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span>(ans==<span class="string">&quot;y&quot;</span> <span class="keyword">or</span> ans==<span class="string">&quot;Y&quot;</span>):</span><br><span class="line">        v=[[<span class="number">6</span>,<span class="number">1</span>],[<span class="number">13</span>,<span class="number">1</span>],[<span class="number">16</span>,<span class="number">4</span>],[<span class="number">13</span>,<span class="number">7</span>],[<span class="number">6</span>,<span class="number">7</span>],[<span class="number">3</span>,<span class="number">4</span>]]</span><br><span class="line">        graph=<span class="string">&quot;&quot;&quot;-----@######@-------\n----#--------#------\n---#----------#-----\n--@------------@----\n---#----------#-----\n----#--------#------\n-----@######@-------\n&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(graph)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> v:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;(<span class="subst">&#123;i[<span class="number">0</span>]&#125;</span>,<span class="subst">&#123;i[<span class="number">1</span>]&#125;</span>)&quot;</span>,end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">elif</span>(ans==<span class="string">&quot;n&quot;</span> <span class="keyword">or</span> ans==<span class="string">&quot;N&quot;</span>):</span><br><span class="line">        n=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;Please input the number of points:\n&quot;</span>))</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">0</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;您输入了0！&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            a=<span class="built_in">input</span>(<span class="string">f&quot;Input X and Y of No.<span class="subst">&#123;i+<span class="number">1</span>&#125;</span> point:(eg:X Y)\n&quot;</span>).split()</span><br><span class="line">            v.append([<span class="built_in">int</span>(a[<span class="number">0</span>]),<span class="built_in">int</span>(a[<span class="number">1</span>])])</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;对不起没有这个选项！&quot;</span>)</span><br><span class="line">    <span class="comment">#判断是不是图多边形</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="keyword">not</span> isConvex(v)):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;您输入的不是凸多边形！请确认是否按顺序输入！&quot;</span>)</span><br><span class="line">    t=[]</span><br><span class="line">    s=[]</span><br><span class="line">    n=<span class="built_in">len</span>(v)</span><br><span class="line">    <span class="comment">#初始化</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        t.append([<span class="number">0</span>]*(n))</span><br><span class="line">        s.append([<span class="number">0</span>]*(n))</span><br><span class="line">    minWeightTriangulation(n-<span class="number">1</span>,t,s,v)</span><br><span class="line">    traceback(s,<span class="number">0</span>,n-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment">#异常处理</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入不合法！出错信息如下：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>

<p>判断是否为凸多边形</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#判断是否为凸多边形</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">计算直线表达式</span></span><br><span class="line"><span class="string">param vertex1: 前一个顶点</span></span><br><span class="line"><span class="string">param vertex2: 后一个顶点</span></span><br><span class="line"><span class="string">return (type, param): 返回直线的类别及其描述参数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kb</span>(<span class="params">vertex1, vertex2</span>):</span></span><br><span class="line">    x1 = vertex1[<span class="number">0</span>]</span><br><span class="line">    y1 = vertex1[<span class="number">1</span>]</span><br><span class="line">    x2 = vertex2[<span class="number">0</span>]</span><br><span class="line">    y2 = vertex2[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> x1==x2:</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">0</span>, x1)      <span class="comment"># 0-垂直直线</span></span><br><span class="line">    <span class="keyword">if</span> y1==y2:              </span><br><span class="line">        <span class="keyword">return</span> (<span class="number">1</span>, y1)      <span class="comment"># 1-水平直线</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        k = (y1-y2)/(x1-x2)</span><br><span class="line">        b = y1 - k*x1</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">2</span>, k, b)    <span class="comment"># 2-倾斜直线</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">判断是否为凸多边形</span></span><br><span class="line"><span class="string">param vertexes: 构成多边形的所有顶点坐标列表，如[[0，0], [50, 0], [0, 50]]</span></span><br><span class="line"><span class="string">return convex: 布尔类型，为True说明该多边形为凸多边形，否则为凹多边形</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isConvex</span>(<span class="params">vertexes</span>):</span></span><br><span class="line">    <span class="comment"># 默认为凸多边形</span></span><br><span class="line">    convex = <span class="literal">True</span>   </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 多边形至少包含三个顶点</span></span><br><span class="line">    l = <span class="built_in">len</span>(vertexes)</span><br><span class="line">    <span class="keyword">if</span> l&lt;<span class="number">3</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;多边形至少包含三个顶点！&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 对每两个点组成的直线做判断</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l):</span><br><span class="line">        pre = i</span><br><span class="line">        nex = (i+<span class="number">1</span>)%l</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 得到直线</span></span><br><span class="line">        line = kb(vertexes[pre], vertexes[nex])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算所有点和直线的距离（可能为正也可能为负）</span></span><br><span class="line">        <span class="keyword">if</span> line[<span class="number">0</span>]==<span class="number">0</span>:</span><br><span class="line">            offset = [vertex[<span class="number">0</span>]-vertexes[pre][<span class="number">0</span>] <span class="keyword">for</span> vertex <span class="keyword">in</span> vertexes]</span><br><span class="line">        <span class="keyword">elif</span> line[<span class="number">0</span>]==<span class="number">1</span>:</span><br><span class="line">            offset = [vertex[<span class="number">1</span>]-vertexes[pre][<span class="number">1</span>] <span class="keyword">for</span> vertex <span class="keyword">in</span> vertexes]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            k, b = line[<span class="number">1</span>], line[<span class="number">2</span>]</span><br><span class="line">            offset = [k*vertex[<span class="number">0</span>]+b-vertex[<span class="number">1</span>] <span class="keyword">for</span> vertex <span class="keyword">in</span> vertexes]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算两两距离的乘积，如果出现负数则存在两个点位于直线两侧，因此为凹多边形</span></span><br><span class="line">        <span class="keyword">for</span> o <span class="keyword">in</span> offset:</span><br><span class="line">            <span class="keyword">for</span> s <span class="keyword">in</span> offset:</span><br><span class="line">                <span class="keyword">if</span> o*s&lt;<span class="number">0</span>:</span><br><span class="line">                    convex = <span class="literal">False</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> convex==<span class="literal">False</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">                    </span><br><span class="line">        <span class="keyword">if</span> convex==<span class="literal">False</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">    <span class="comment"># 打印判断结果</span></span><br><span class="line">    <span class="keyword">if</span> convex==<span class="literal">True</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;该多边形为凸多边形！&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;该多边形为凹多边形！&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> convex</span><br></pre></td></tr></table></figure>

<h2 id="3-9-0-1背包问题"><a href="#3-9-0-1背包问题" class="headerlink" title="3.9 0-1背包问题"></a>3.9 0-1背包问题</h2><ul>
<li><img src="https://s2.ax1x.com/2019/11/21/MIGH1O.png" alt="MIGH1O.png"></li>
<li>其中m(i,j)是指背包容量为j，可选择物品为i，i+1，···，n时0-1背包问题的最优值</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Copyright: Copyright (c) 2019</span></span><br><span class="line"><span class="string">Author: Justlovesmile</span></span><br><span class="line"><span class="string">Title: 0-1背包问题--动态规划</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#跳跃点法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knapsack_Pro</span>(<span class="params">n,v,w,C,p,x</span>):</span></span><br><span class="line">    <span class="comment">#head指向每一阶段跳跃点集合的开始</span></span><br><span class="line">    head=[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>)]</span><br><span class="line">    p[<span class="number">0</span>][<span class="number">0</span>],p[<span class="number">0</span>][<span class="number">1</span>]=<span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    left,right,pnext,head[<span class="number">1</span>]=<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        k=left</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(left,right+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span>(p[j][<span class="number">0</span>]+w[i]&gt;C):</span><br><span class="line">                <span class="keyword">break</span> </span><br><span class="line">            y=p[j][<span class="number">0</span>]+w[i]</span><br><span class="line">            m=p[j][<span class="number">1</span>]+v[i]</span><br><span class="line">            <span class="comment">#重量小于此数的跳跃点直接加进来，不会被支配</span></span><br><span class="line">            <span class="keyword">while</span>(k&lt;=right <span class="keyword">and</span> p[k][<span class="number">0</span>]&lt;y):</span><br><span class="line">                p[pnext][<span class="number">0</span>]=p[k][<span class="number">0</span>]</span><br><span class="line">                p[pnext][<span class="number">1</span>]=p[k][<span class="number">1</span>]</span><br><span class="line">                pnext+=<span class="number">1</span></span><br><span class="line">                k+=<span class="number">1</span></span><br><span class="line">            <span class="comment">#两个if判断新产生的点能否加入p</span></span><br><span class="line">            <span class="keyword">if</span>(k&lt;=right <span class="keyword">and</span> p[k][<span class="number">0</span>]==y):</span><br><span class="line">                <span class="keyword">if</span>(m&lt;p[k][<span class="number">1</span>]):</span><br><span class="line">                    m=p[k][<span class="number">1</span>]</span><br><span class="line">                k+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span>(m&gt;p[pnext-<span class="number">1</span>][<span class="number">1</span>]):</span><br><span class="line">                p[pnext][<span class="number">0</span>]=y</span><br><span class="line">                p[pnext][<span class="number">1</span>]=m</span><br><span class="line">                pnext+=<span class="number">1</span></span><br><span class="line">            <span class="comment">#取出可以支配的点</span></span><br><span class="line">            <span class="keyword">while</span>(k&lt;=right <span class="keyword">and</span> p[k][<span class="number">1</span>]&lt;=p[pnext-<span class="number">1</span>][<span class="number">1</span>]):</span><br><span class="line">                k+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#上面break后</span></span><br><span class="line">        <span class="keyword">while</span>(k&lt;=right):</span><br><span class="line">            p[pnext][<span class="number">0</span>]=p[k][<span class="number">0</span>]</span><br><span class="line">            p[pnext][<span class="number">1</span>]=p[k][<span class="number">1</span>]</span><br><span class="line">            pnext+=<span class="number">1</span></span><br><span class="line">            k+=<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        left=right+<span class="number">1</span></span><br><span class="line">        right=pnext-<span class="number">1</span></span><br><span class="line">        head[i+<span class="number">1</span>]=pnext</span><br><span class="line">    traceback_Pro(n,w,v,p,head,x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">traceback_Pro</span>(<span class="params">n,w,v,p,head,x</span>):</span></span><br><span class="line">    j=p[head[n]-<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line">    m=p[head[n]-<span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;max value:&quot;</span>,m,<span class="string">&quot;max weight:&quot;</span>,j)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)[::-<span class="number">1</span>]:</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(head[i],head[i+<span class="number">1</span>]-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span>(p[k][<span class="number">0</span>]+w[i]==j <span class="keyword">and</span> p[k][<span class="number">1</span>]+v[i]==m):</span><br><span class="line">                x[i]=<span class="number">1</span></span><br><span class="line">                j=p[k][<span class="number">0</span>]</span><br><span class="line">                m=p[k][<span class="number">1</span>]</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knapsack</span>(<span class="params">v,w,C,m</span>):</span></span><br><span class="line">    <span class="comment">#m[i][j]指背包容量为j，可选择物品为i，i+1，...，n时的0-1背包问题的最优值</span></span><br><span class="line">    n=<span class="built_in">len</span>(v)-<span class="number">1</span></span><br><span class="line">    <span class="comment">#只剩一个物品的情况</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(C):</span><br><span class="line">        m[n][j] = v[n] <span class="keyword">if</span> j&gt;=<span class="built_in">min</span>(w[n]-<span class="number">1</span>,C) <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="comment">#普通情况</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n)[::-<span class="number">1</span>]:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(C):</span><br><span class="line">            m[i][j] = <span class="built_in">max</span>(m[i+<span class="number">1</span>][j],m[i+<span class="number">1</span>][j-w[i]]+v[i]) <span class="keyword">if</span> j&gt;w[i]-<span class="number">1</span> <span class="keyword">else</span> m[i+<span class="number">1</span>][j]</span><br><span class="line">    <span class="comment">#第一件物品</span></span><br><span class="line">    <span class="keyword">if</span>(n&gt;<span class="number">0</span>):</span><br><span class="line">        m[<span class="number">0</span>][C-<span class="number">1</span>]=m[<span class="number">1</span>][C-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> C-<span class="number">1</span>&gt;=w[<span class="number">0</span>]:</span><br><span class="line">            m[<span class="number">0</span>][C-<span class="number">1</span>]=<span class="built_in">max</span>(m[<span class="number">0</span>][C-<span class="number">1</span>],m[<span class="number">1</span>][C-<span class="number">1</span>-w[<span class="number">0</span>]]+v[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">traceback</span>(<span class="params">m,w,C,x</span>):</span></span><br><span class="line">    c=C-<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(w)-<span class="number">1</span>):</span><br><span class="line">        <span class="comment">#没选物品i则x[i]=0</span></span><br><span class="line">        <span class="keyword">if</span> (m[i][c]==m[i+<span class="number">1</span>][c]):</span><br><span class="line">            x[i]=<span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            x[i]=<span class="number">1</span></span><br><span class="line">            c -= w[i]</span><br><span class="line">    <span class="comment">#对于最后一个物品</span></span><br><span class="line">    x[<span class="built_in">len</span>(w)-<span class="number">1</span>]=<span class="number">1</span> <span class="keyword">if</span> m[<span class="built_in">len</span>(w)-<span class="number">1</span>][c]&gt;<span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#输出格式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cout</span>(<span class="params">x,v,w</span>):</span></span><br><span class="line">    total_v=<span class="number">0</span></span><br><span class="line">    total_w=<span class="number">0</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Choose:&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(v)):</span><br><span class="line">        <span class="keyword">if</span> x[i]==<span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;No.<span class="subst">&#123;i+<span class="number">1</span>&#125;</span> item: value is <span class="subst">&#123;v[i]&#125;</span> , weight is <span class="subst">&#123;w[i]&#125;</span>&quot;</span>)</span><br><span class="line">            total_v +=v[i]</span><br><span class="line">            total_w +=w[i]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;total value: <span class="subst">&#123;total_v&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;total weight: <span class="subst">&#123;total_w&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    v=[]    <span class="comment">#物品的价值列表</span></span><br><span class="line">    w=[]    <span class="comment">#物品的重量列表</span></span><br><span class="line">    <span class="comment">#输入物品数量</span></span><br><span class="line">    n=<span class="built_in">input</span>(<span class="string">&quot;Please input the number of items:\n&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span>(n==<span class="string">&quot;&quot;</span> <span class="keyword">or</span> n==<span class="string">&quot;0&quot;</span>):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;您输入了空值或0！&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        n=<span class="built_in">int</span>(n)</span><br><span class="line">    x=[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>)]</span><br><span class="line">    <span class="comment">#选择两种算法（课本上的）</span></span><br><span class="line">    ans=<span class="built_in">input</span>(<span class="string">&quot;Choose Knapsack or Knapsack_Pro?(1 or 2)\n&quot;</span>).split()[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> ans==<span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">        m=[]    <span class="comment">#m(i,j)指背包容量为j，可选择物品为i，i+1，...，n时的0-1背包问题的最优值</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            item=<span class="built_in">input</span>(<span class="string">f&quot;please input No.<span class="subst">&#123;i+<span class="number">1</span>&#125;</span> item&#x27;s value(v) and weight(w):(eg:v w)\n&quot;</span>).split()</span><br><span class="line">            v.append(<span class="built_in">int</span>(item[<span class="number">0</span>]))</span><br><span class="line">            w.append(<span class="built_in">int</span>(item[<span class="number">1</span>]))</span><br><span class="line">        C=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;Please input the max weight of bag:\n&quot;</span>))</span><br><span class="line">        <span class="keyword">if</span>(C&lt;=<span class="number">0</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;背包容量不能≤0&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            m.append([<span class="number">0</span>]*C)</span><br><span class="line">        knapsack(v,w,C,m)</span><br><span class="line">        traceback(m,w,C,x)</span><br><span class="line">        cout(x,v,w)</span><br><span class="line">    <span class="keyword">elif</span> ans==<span class="string">&#x27;2&#x27;</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            item=<span class="built_in">input</span>(<span class="string">f&quot;please input No.<span class="subst">&#123;i+<span class="number">1</span>&#125;</span> item&#x27;s value(v) and weight(w):(eg:v w)\n&quot;</span>).split()</span><br><span class="line">            v.append(<span class="built_in">float</span>(item[<span class="number">0</span>]))</span><br><span class="line">            w.append(<span class="built_in">float</span>(item[<span class="number">1</span>]))</span><br><span class="line">        <span class="comment">#初始化</span></span><br><span class="line">        p=[[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)]<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n*n)]</span><br><span class="line">        C=<span class="built_in">float</span>(<span class="built_in">input</span>(<span class="string">&quot;Please input the max weight of bag:\n&quot;</span>))</span><br><span class="line">        <span class="keyword">if</span>(C&lt;=<span class="number">0</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;背包容量不能小于等于0&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span>(w[<span class="number">0</span>]&lt;=C):</span><br><span class="line">                x[<span class="number">0</span>]=<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                x[<span class="number">0</span>]=<span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            knapsack_Pro(n,v,w,C,p,x)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">if</span>(x[i]==<span class="number">1</span>):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;choose: value:&quot;</span>,v[i],<span class="string">&quot;weight:&quot;</span>,w[i])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">f&quot;您输入了<span class="subst">&#123;ans&#125;</span>没有该选项！&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment">#异常处理</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入不合法！出错信息如下：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>

<h2 id="3-10-最优二叉搜索树"><a href="#3-10-最优二叉搜索树" class="headerlink" title="3.10 最优二叉搜索树"></a>3.10 最优二叉搜索树</h2><ul>
<li>二叉搜索树：存储于每个结点中的元素x大于其左子树中任一结点所存储的元素，小于其右子树中任一结点所存储的元素</li>
</ul>
<h1 id="第四章-贪心算法"><a href="#第四章-贪心算法" class="headerlink" title="第四章 贪心算法"></a>第四章 贪心算法</h1><ul>
<li>贪心算法：总是做出在当前看来最好的选择，也就是说贪心算法并不从整体最优考虑它所作出的选择只是在某种意义上的局部最优选择。</li>
<li>使用贪心算法需满足：<ul>
<li>贪心选择性：指所求问题的整体最优解可以通过一系列局部最优的选择，即贪心选择来达到</li>
<li>最优子结构性质：当一个问题的最优解包含其子问题的最优解时，称此问题具有最优子结构性质</li>
</ul>
</li>
<li>贪心算法适合的问题：有n个输入，其解就由这n个输入满足某些事先给定的约束条件的某个子集组成，而把满足约束条件的子集称为该问题的可行解。显然可行解一般来说是不唯一的。那些使目标函数取极值的可行解，成为最优解。</li>
<li>贪心算法是一种分级处理方法，它首先根据题意，选取一种度量标准，然后按这种度量标准对这n个的输入排序，并按序依次输入，如果不满足条件，则不把此输入加到解当中。</li>
<li>贪心算法设计求解的核心问题：选择能产生问题最优解的最优量度标准。</li>
<li>贪心算法正确性的证明：<ul>
<li>①证明算法所求的问题具有优化子结构</li>
<li>②证明算法所求解的问题具有贪心选择性</li>
<li>③算法按照②种的贪心选择性进行局部最优选择</li>
</ul>
</li>
</ul>
<h2 id="4-2-活动安排问题"><a href="#4-2-活动安排问题" class="headerlink" title="4.2 活动安排问题"></a>4.2 活动安排问题</h2><ul>
<li>为了选择最多的相容活动，每次选择fi最小的活动，使能够选择更多的活动</li>
<li>度量标准：按照结束时间的非减序排列</li>
<li>如果有序，则O(n)，如果无序，O(nlogn)</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Copyright: Copyright (c) 2019</span></span><br><span class="line"><span class="string">Author: Justlovesmile</span></span><br><span class="line"><span class="string">Title: 活动安排问题</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#活动类，每个活动包括开始时间和结束时间</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">activity</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,ss,ff</span>):</span></span><br><span class="line">        self.s=ss</span><br><span class="line">        self.f=ff</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greedySelector</span>(<span class="params">arr,a</span>):</span></span><br><span class="line">    n=<span class="built_in">len</span>(arr)-<span class="number">1</span></span><br><span class="line">    a[<span class="number">0</span>]=<span class="literal">True</span></span><br><span class="line">    j=<span class="number">0</span></span><br><span class="line">    count=<span class="number">1</span></span><br><span class="line">    <span class="comment">#满足开始时间大于上一个活动的结束时间的加入（设为True）</span></span><br><span class="line">    <span class="comment">#O(n)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span>(arr[i].s&gt;=arr[j].f):</span><br><span class="line">            a[i]=<span class="literal">True</span></span><br><span class="line">            j=i</span><br><span class="line">            count+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            a[i]=<span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    activities=[]</span><br><span class="line">    <span class="comment">#输入数据</span></span><br><span class="line">    n=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;please input the number of activities:\n&quot;</span>))</span><br><span class="line">    <span class="comment">#异常处理</span></span><br><span class="line">    <span class="keyword">if</span>(n==<span class="number">0</span>):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;您输入了0！&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Use greedy selector , activities should be ordered by the end_time.&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        item=<span class="built_in">input</span>(<span class="string">&quot;please input the begin-time and end-time:(eg: 3 6)\n&quot;</span>).split()</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">len</span>(item)!=<span class="number">2</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;您输入的数据个数不合法！&quot;</span>)</span><br><span class="line">        s=activity(<span class="built_in">float</span>(item[<span class="number">0</span>]),<span class="built_in">float</span>(item[<span class="number">1</span>])) </span><br><span class="line">        activities.append(s)</span><br><span class="line">    <span class="comment">#以结束时间非减序排序</span></span><br><span class="line">    activities=<span class="built_in">sorted</span>(activities,key=<span class="keyword">lambda</span> x:x.f)</span><br><span class="line">    <span class="comment">#初始化选择集合a</span></span><br><span class="line">    a=[<span class="literal">False</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    count=greedySelector(activities,a)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Maximum number of activities:&quot;</span>,count)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Choose:&quot;</span>,a)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入不合法！出错信息如下：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>

<h2 id="4-3-最优装载问题"><a href="#4-3-最优装载问题" class="headerlink" title="4.3 最优装载问题"></a>4.3 最优装载问题</h2><ul>
<li>O(nlogn)</li>
</ul>
<h2 id="4-4-哈夫曼编码"><a href="#4-4-哈夫曼编码" class="headerlink" title="4.4 哈夫曼编码"></a>4.4 哈夫曼编码</h2><ul>
<li>循环地选择具有最低频率的两个结点，生成一棵子树，直至形成树</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#构建二叉树类型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinaryTree</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,data,left,right,code</span>):</span></span><br><span class="line">        self.data=data</span><br><span class="line">        self.left=left</span><br><span class="line">        self.right=right</span><br><span class="line">        self.code=code</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getdata</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.data</span><br><span class="line"></span><br><span class="line"><span class="comment">#哈夫曼树</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Huffman</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,tree,ww</span>):</span></span><br><span class="line">        self.tree=tree</span><br><span class="line">        self.w=ww</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getweight</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.w</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">huffmanTree</span>(<span class="params">f</span>):</span></span><br><span class="line">    <span class="comment">#f是出现频率权值字典</span></span><br><span class="line">    H=[]</span><br><span class="line">    n=<span class="built_in">len</span>(f)</span><br><span class="line">    <span class="comment">#根据value对键进行从大到小排序</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">sorted</span>(f,key=f.__getitem__,reverse=<span class="literal">True</span>):</span><br><span class="line">        tree = BinaryTree(i,<span class="number">0</span>,<span class="number">0</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line">        w = Huffman(tree,f[i])</span><br><span class="line">        H.append(w)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n):</span><br><span class="line">        <span class="comment">#取出最后两位</span></span><br><span class="line">        x=H.pop()</span><br><span class="line">        y=H.pop()</span><br><span class="line">        <span class="comment">#取权重小的做左孩子，大的是右孩子</span></span><br><span class="line">        t=BinaryTree(i,x.tree <span class="keyword">if</span> x.w&lt;y.w <span class="keyword">else</span> y.tree,y.tree <span class="keyword">if</span> y.w&gt;x.w <span class="keyword">else</span> x.tree,<span class="string">&quot;&quot;</span>)</span><br><span class="line">        h=Huffman(t,x.w+y.w)</span><br><span class="line">        H.append(h)</span><br><span class="line">        <span class="comment">#根据权重从大到小排序</span></span><br><span class="line">        H=<span class="built_in">sorted</span>(H,key=<span class="keyword">lambda</span> x:x.w,reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> H.pop()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Copyright: Copyright (c) 2019</span></span><br><span class="line"><span class="string">Author: Justlovesmile </span></span><br><span class="line"><span class="string">Title: 哈夫曼编码</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#构建二叉树类型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinaryTree</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,data,left,right,code</span>):</span></span><br><span class="line">        self.data=data</span><br><span class="line">        self.left=left</span><br><span class="line">        self.right=right</span><br><span class="line">        self.code=code</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getdata</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.data</span><br><span class="line"></span><br><span class="line"><span class="comment">#哈夫曼树</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Huffman</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,tree,ww</span>):</span></span><br><span class="line">        self.tree=tree</span><br><span class="line">        self.w=ww</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getweight</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.w</span><br><span class="line">    </span><br><span class="line"><span class="comment">#计算权重</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makedict</span>(<span class="params">s</span>):</span></span><br><span class="line">    dic=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> s:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> dic.keys():</span><br><span class="line">            dic[i]=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dic[i]+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> dic</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">huffmanTree</span>(<span class="params">f</span>):</span></span><br><span class="line">    <span class="comment">#f是出现频率权值字典</span></span><br><span class="line">    H=[]</span><br><span class="line">    n=<span class="built_in">len</span>(f)</span><br><span class="line">    <span class="comment">#根据value对键进行从大到小排序</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">sorted</span>(f,key=f.__getitem__,reverse=<span class="literal">True</span>):</span><br><span class="line">        tree = BinaryTree(i,<span class="number">0</span>,<span class="number">0</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line">        w = Huffman(tree,f[i])</span><br><span class="line">        H.append(w)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n):</span><br><span class="line">        <span class="comment">#取出最后两位</span></span><br><span class="line">        x=H.pop()</span><br><span class="line">        y=H.pop()</span><br><span class="line">        <span class="comment">#取权重小的做左孩子，大的是右孩子</span></span><br><span class="line">        t=BinaryTree(i,x.tree <span class="keyword">if</span> x.w&lt;y.w <span class="keyword">else</span> y.tree,y.tree <span class="keyword">if</span> y.w&gt;x.w <span class="keyword">else</span> x.tree,<span class="string">&quot;&quot;</span>)</span><br><span class="line">        h=Huffman(t,x.w+y.w)</span><br><span class="line">        H.append(h)</span><br><span class="line">        <span class="comment">#根据权重从大到小排序</span></span><br><span class="line">        H=<span class="built_in">sorted</span>(H,key=<span class="keyword">lambda</span> x:x.w,reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> H.pop()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">listall</span>(<span class="params">h</span>):</span></span><br><span class="line">    m=[]</span><br><span class="line">    k=[]</span><br><span class="line">    left,right=h.tree.left,h.tree.right</span><br><span class="line">    rcode=<span class="string">&quot;1&quot;</span></span><br><span class="line">    lcode=<span class="string">&quot;0&quot;</span></span><br><span class="line">    m.append(right)</span><br><span class="line">    right.code+=rcode</span><br><span class="line">    m.append(left)</span><br><span class="line">    left.code+=lcode</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">len</span>(m)&gt;<span class="number">0</span>):</span><br><span class="line">        <span class="comment">#如果存在左孩子（左右必同时存在）</span></span><br><span class="line">        <span class="keyword">if</span>(m[-<span class="number">1</span>].left):</span><br><span class="line">            a=m.pop()</span><br><span class="line">            c=a.code</span><br><span class="line">            m.append(a.right)</span><br><span class="line">            a.right.code=c+rcode</span><br><span class="line">            m.append(a.left)</span><br><span class="line">            a.left.code=c+lcode</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            b=m.pop()</span><br><span class="line">            k.append(b)</span><br><span class="line">    <span class="keyword">return</span> k</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">back</span>(<span class="params">hfmcode,filename</span>):</span></span><br><span class="line">    ans=<span class="built_in">input</span>(<span class="string">f&quot;Do you want to decode &#x27;<span class="subst">&#123;filename&#125;</span>&#x27;?（y/n）\n&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span>(ans!=<span class="string">&quot;y&quot;</span> <span class="keyword">and</span> ans!=<span class="string">&#x27;Y&#x27;</span>):</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    <span class="comment">#读取要解压缩的文件</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        s=f.read()</span><br><span class="line">    st=<span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="comment">#键和值交换形成新字典</span></span><br><span class="line">    new_dict = &#123;v:k <span class="keyword">for</span> k,v <span class="keyword">in</span> hfmcode.items()&#125;</span><br><span class="line">    <span class="comment">#写入新文件</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;解压缩.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> s:</span><br><span class="line">            st+=i</span><br><span class="line">            <span class="keyword">if</span>(st <span class="keyword">in</span> hfmcode.values()):</span><br><span class="line">                f.write(new_dict[st])</span><br><span class="line">                st=<span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;==&quot;</span>*<span class="number">10</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;ok!Please check the file: &#x27;解压缩.txt&#x27;&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;==&quot;</span>*<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    filename1=<span class="string">&quot;测试用例.txt&quot;</span></span><br><span class="line">    filename2=<span class="string">&#x27;编码后.txt&#x27;</span></span><br><span class="line">    <span class="comment">#可以选择读文件和输入字符串</span></span><br><span class="line">    s=<span class="built_in">input</span>(<span class="string">f&quot;Do you want to search <span class="subst">&#123;filename1&#125;</span>！（y/n）\n&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span>(s==<span class="string">&quot;y&quot;</span> <span class="keyword">or</span> s==<span class="string">&quot;Y&quot;</span>):</span><br><span class="line">        <span class="comment">#读文件</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename1,<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            s=f.read()</span><br><span class="line">        <span class="comment">#权值字典</span></span><br><span class="line">        dic=makedict(s)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;权值：&quot;</span>,dic)</span><br><span class="line">        <span class="comment">#构建哈夫曼树</span></span><br><span class="line">        hTree=huffmanTree(dic)</span><br><span class="line">        <span class="comment">#编码</span></span><br><span class="line">        k=listall(hTree)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;哈夫曼编码：&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> k:</span><br><span class="line">            <span class="built_in">print</span>(i.data,i.code)</span><br><span class="line">        <span class="comment">#存储值对应的编码</span></span><br><span class="line">        hfmcode=&#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> k:</span><br><span class="line">            hfmcode[i.data]=i.code</span><br><span class="line">        <span class="comment">#写入哈夫曼编码</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename2,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> s:</span><br><span class="line">                string=hfmcode[i]</span><br><span class="line">                f.write(string)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;==&quot;</span>*<span class="number">10</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;ok!Please check the file: &#x27;<span class="subst">&#123;filename2&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;==&quot;</span>*<span class="number">10</span>)</span><br><span class="line">        back(hfmcode,filename2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        s=<span class="built_in">input</span>(<span class="string">&quot;Please input the string:&quot;</span>)</span><br><span class="line">        dic=makedict(s)</span><br><span class="line">        <span class="built_in">print</span>(dic)</span><br><span class="line">        hTree=huffmanTree(dic)</span><br><span class="line">        k=listall(hTree)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> k:</span><br><span class="line">            <span class="built_in">print</span>(i.data,i.code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入不合法！出错信息如下：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>


<h2 id="4-5-单源最短路径"><a href="#4-5-单源最短路径" class="headerlink" title="4.5 单源最短路径"></a>4.5 单源最短路径</h2><ul>
<li>设置顶点集合S并不断地作贪心选择来扩充这个集合，一个顶点属于集合S当且仅当从源到该顶点的最短路径长度已知，初始时，S中仅含有源。设u是G的某一个顶点，把从源到u且中间只经过S中顶点的路称为从源到u的特殊路径，并用数组dist记录当前每个顶点所对应的最短特殊路径长度。Dijkstra算法每次从V-S中取出具有最短特殊路径长度的顶点u，将u添加到S中，同时对数组dist作必要的修改。一旦S包含了所有V中顶点，dist就记录了从源到所有其他顶点之间的最短路径长度</li>
</ul>
<h2 id="4-6-最小生成树"><a href="#4-6-最小生成树" class="headerlink" title="4.6 最小生成树"></a>4.6 最小生成树</h2><ul>
<li>设G =(V,E)是无向连通带权图，即一个网络。E中每条边(v,w)的权为<code>c[v][w]</code>。如果G的子图G’是一棵包含G的所有顶点的树，则称G’为G的生成树。生成树上各边权的总和称为该生成树的耗费。在G的所有生成树中，耗费最小的生成树称为G的最小生成树</li>
<li>最小生成树性质（MST性质）：设G=(V,E)是连通带权图，U是V的真子集。如果(u,v)∈E，且u∈U，v∈V-U，且在所有这样的边中，(u,v)的权为<code>c[u][v]</code>最小，那么一定存在G的一颗最小生成树，它以(u,v)为其中一条边</li>
<li>Prim算法：<ul>
<li>首先置S={1}，然后，只要S是V的真子集，就作如下的贪心选择：</li>
<li>选取满足条件i∈S，j∈V-S，且<code>c[i][j]</code>最小的边，将顶点j添加到S中。这个过程一直进行到S=V时为止。</li>
<li>在这个过程中选取到的所有边恰好构成G的一棵最小生成树。<br><img src="https://s2.ax1x.com/2019/11/21/MIjycj.png" alt="MIjycj.png"></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Copyright: Copyright (c) 2019</span></span><br><span class="line"><span class="string">Author: Justlovesmile</span></span><br><span class="line"><span class="string">Title: 最小生成树-Prim算法</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prim</span>(<span class="params">n,c</span>):</span></span><br><span class="line">    <span class="comment">#初始化Prim算法的数组</span></span><br><span class="line">    s=[<span class="number">1</span>]</span><br><span class="line">    p=[<span class="number">1</span>]</span><br><span class="line">    lowcost=[<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    m=<span class="number">1</span></span><br><span class="line">    <span class="comment">#遍历S中的点</span></span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n):</span><br><span class="line">        ns=<span class="built_in">len</span>(s)</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(ns):</span><br><span class="line">            i=s[t]</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">                <span class="comment">#如果不在S中，且最短则记录</span></span><br><span class="line">                <span class="keyword">if</span>(j <span class="keyword">not</span> <span class="keyword">in</span> s) <span class="keyword">and</span> (c[i][j]&lt;lowcost[m]):</span><br><span class="line">                    lowcost[m]=c[i][j]</span><br><span class="line">                    k=j</span><br><span class="line">                    u=i</span><br><span class="line">        m+=<span class="number">1</span></span><br><span class="line">        s.append(k)</span><br><span class="line">        p.append(u)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(s)):</span><br><span class="line">        <span class="built_in">print</span>(s[i],p[i],c[s[i]][p[i]])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment">#输入点数</span></span><br><span class="line">    n=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;Please input the number of points:\n&quot;</span>))</span><br><span class="line">    <span class="comment">#初始化边长</span></span><br><span class="line">    c=[[<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>)] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">        c[i][i]=<span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span>(n&lt;=<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">f&quot;You input <span class="subst">&#123;n&#125;</span> point.&quot;</span>)</span><br><span class="line">    <span class="comment">#输入边长</span></span><br><span class="line">    g=<span class="built_in">input</span>(<span class="string">&quot;Please input the p1,p2 and weight,like: 1 2 4\nInput end to end.\n&quot;</span>)</span><br><span class="line">    <span class="keyword">while</span>(g!=<span class="string">&#x27;end&#x27;</span>):</span><br><span class="line">        a=g.split()</span><br><span class="line">        i=<span class="built_in">int</span>(a[<span class="number">0</span>])</span><br><span class="line">        j=<span class="built_in">int</span>(a[<span class="number">1</span>])</span><br><span class="line">        w=<span class="built_in">float</span>(a[<span class="number">2</span>])</span><br><span class="line">        c[i][j]=w</span><br><span class="line">        c[j][i]=w</span><br><span class="line">        g=<span class="built_in">input</span>(<span class="string">&quot;Please input the p1,p2 and weight,like: 1 2 4\nInput end to end.\n&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    prim(n,c)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入不合法！出错信息如下：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>

<ul>
<li>Kruskal算法：<ul>
<li>首先，将G的n个顶点看成n个孤立的连通分支。将所有的边按权从小到大排序。</li>
<li>然后，从第一条边开始，依边权递增的顺序查看每一条边，并按下述方法连接2个不同的连通分支：<ul>
<li>当查看到第k条边(v,w)时，如果端点v和w分别是当前2个不同的连通分支T1和T2中的顶点时，就用边(v,w)将T1和T2连接成一个连通分支，然后继续查看第k+1条边；</li>
<li>如果端点v和w在当前的同一个连通分支中，就直接再查看第k+1条边。</li>
<li>这个过程一直进行到只剩下一个连通分支时为止。<br><img src="https://s2.ax1x.com/2019/11/21/MIvIdP.png" alt="MIvIdP.png"></li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Copyright: Copyright (c) 2019</span></span><br><span class="line"><span class="string">Author: Justlovesmile</span></span><br><span class="line"><span class="string">Title: 最小生成树-Kruskal算法</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Edge</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,u,v,w</span>):</span></span><br><span class="line">        self.u=u</span><br><span class="line">        self.v=v</span><br><span class="line">        self.w=w</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EdgeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,p,g</span>):</span></span><br><span class="line">        self.<span class="built_in">id</span>=p</span><br><span class="line">        self.g=g</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kruskal</span>(<span class="params">n,e</span>):</span></span><br><span class="line">    e=<span class="built_in">sorted</span>(e,key=<span class="keyword">lambda</span> x: x.w)</span><br><span class="line">    en=<span class="built_in">len</span>(e)</span><br><span class="line">    s=[<span class="number">0</span>]</span><br><span class="line">    e[<span class="number">0</span>].u.g,e[<span class="number">0</span>].v.g=<span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(en):</span><br><span class="line">        <span class="keyword">if</span>(j <span class="keyword">not</span> <span class="keyword">in</span> s) <span class="keyword">and</span> (e[j].u.g!=e[j].v.g):</span><br><span class="line">            m=e[j].u.g <span class="keyword">if</span> e[j].u.g&lt;e[j].v.g <span class="keyword">else</span> e[j].v.g</span><br><span class="line">            <span class="keyword">for</span> eachedge <span class="keyword">in</span> e:</span><br><span class="line">                <span class="keyword">if</span> (eachedge.u==e[j].u <span class="keyword">or</span> eachedge.v==e[j].v <span class="keyword">or</span> eachedge.u==e[j].v <span class="keyword">or</span> eachedge.v==e[j].u) <span class="keyword">and</span> (eachedge.u.g==eachedge.v.g):</span><br><span class="line">                    m=<span class="built_in">min</span>(eachedge.u.g,eachedge.v.g,m)</span><br><span class="line">                    eachedge.u.g=eachedge.v.g=m</span><br><span class="line">            e[j].u.g=e[j].v.g=m</span><br><span class="line">            s.append(j)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">        <span class="built_in">print</span>(e[s[i]].u.<span class="built_in">id</span>,e[s[i]].v.<span class="built_in">id</span>,e[s[i]].w)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment">#输入点数</span></span><br><span class="line">    n=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;Please input the number of points:\n&quot;</span>))</span><br><span class="line">    <span class="keyword">if</span>(n&lt;=<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">f&quot;You input <span class="subst">&#123;n&#125;</span> point.&quot;</span>)</span><br><span class="line">    <span class="comment">#输入边长</span></span><br><span class="line">    e=[]</span><br><span class="line">    p=&#123;&#125;</span><br><span class="line">    g=<span class="built_in">input</span>(<span class="string">&quot;Please input the p1,p2 and weight,like: 1 2 4\nInput end to end.\n&quot;</span>)</span><br><span class="line">    aa,bb=n,n+<span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span>(g!=<span class="string">&#x27;end&#x27;</span>):</span><br><span class="line">        a=g.split()</span><br><span class="line">        i,j,w=<span class="built_in">int</span>(a[<span class="number">0</span>]),<span class="built_in">int</span>(a[<span class="number">1</span>]),<span class="built_in">float</span>(a[<span class="number">2</span>])</span><br><span class="line">        <span class="keyword">if</span>(i <span class="keyword">not</span> <span class="keyword">in</span> p.keys()):</span><br><span class="line">            p[i]=EdgeNode(i,aa)</span><br><span class="line">        <span class="keyword">if</span>(j <span class="keyword">not</span> <span class="keyword">in</span> p.keys()):</span><br><span class="line">            p[j]=EdgeNode(j,bb)</span><br><span class="line">        e.append(Edge(p[i],p[j],w))</span><br><span class="line">        g=<span class="built_in">input</span>(<span class="string">&quot;Please input the p1,p2 and weight,like: 1 2 4\nInput end to end.\n&quot;</span>)</span><br><span class="line">        aa+=<span class="number">1</span></span><br><span class="line">        bb+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    kruskal(n,e)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入不合法！出错信息如下：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>

<h1 id="第五章-回溯法"><a href="#第五章-回溯法" class="headerlink" title="第五章 回溯法"></a>第五章 回溯法</h1><ul>
<li><p>回溯法是一个既带有系统性又带有跳跃性的搜索算法。它在问题的解空间树中，按深度优先策略，从根结点出发搜索解空间树。算法搜索至解空间树的任一结点时，先判断该结点是否包含问题的解。如果肯定不包含，则跳过对该节点为根的子树的搜索，逐层向其祖先结点回溯，否则，进入该子树，继续按深度优先策略搜索</p>
</li>
<li><p>具有剪枝函数的深度优先生成法</p>
</li>
<li><p>扩展结点：正在产生儿子的结点称为扩展结点</p>
</li>
<li><p>活结点：自身已生成但其儿子还没有全部生成的结点</p>
</li>
<li><p>回溯法的步骤：</p>
<ul>
<li>(1)针对所给问题，定义问题的解空间；</li>
<li>(2)确定易于搜索的解空间结构；</li>
<li>(3)以深度优先方式搜索解空间，并在搜索过程中用剪枝函数避免无效搜索</li>
</ul>
</li>
<li><p>子集树：当所给的问题是从n个元素的集合S中找出满足某种性质的子集时，相应的解空间树称为子集树。通常有2n个叶子节点，其节点总个数为2n+1-1。如：0-1背包问题</p>
</li>
<li><p>排列树：当所给的问题是确定n个元素满足某种性质的排列时，相应的解空间树称为排列树。排列树通常有n！个叶子节点。如：旅行售货员问题。</p>
</li>
<li><p>回溯算法的效率在很大程度上依赖于以下因素：</p>
<ul>
<li>(1)产生x[k]的时间；</li>
<li>(2)满足显约束的x[k]值的个数；</li>
<li>(3)计算约束函数constraint的时间；</li>
<li>(4)计算上界函数bound的时间；</li>
<li>(5)满足约束函数和上界函数约束的所有x[k]的个数。好的约束函数能显著地减少所生成的结点数。但这样的约束函数往往计算量较大。因此，在选择约束函数时通常存在生成结点数与约束函数计算量之间的折衷。</li>
</ul>
</li>
</ul>
<h2 id="5-2-装载问题"><a href="#5-2-装载问题" class="headerlink" title="5.2 装载问题"></a>5.2 装载问题</h2><ul>
<li>如果一个给定装载问题有解，则采用下面的策略可得到最优装载方案。<ul>
<li>(1)首先将第一艘轮船尽可能装满；</li>
<li>(2)将剩余的集装箱装上第二艘轮船。</li>
</ul>
</li>
<li>解空间：子集树</li>
<li>可行性约束函数(选择当前元素)：</li>
<li>上界函数(不选择当前元素)：当前载重量cw+剩余集装箱的重量r≤当前最优载重量bestw</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Copyright: Copyright (c) 2019</span></span><br><span class="line"><span class="string">Author: Justlovesmile</span></span><br><span class="line"><span class="string">Title: 装载问题（回溯法）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backtrack</span>(<span class="params">i,c</span>):</span></span><br><span class="line">    <span class="keyword">global</span> w,bestx,x,bestw,r,cw</span><br><span class="line">    <span class="keyword">if</span>(i&gt;<span class="built_in">len</span>(w)-<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span>(cw&gt;bestw):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(w)):</span><br><span class="line">                bestx[j]=x[j]</span><br><span class="line">            bestw=cw</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#逐层搜索子树</span></span><br><span class="line">    r-=w[i]</span><br><span class="line">    <span class="keyword">if</span>(cw+w[i]&lt;=c):</span><br><span class="line">        x[i]=<span class="number">1</span></span><br><span class="line">        cw+=w[i]</span><br><span class="line">        backtrack(i+<span class="number">1</span>,c)</span><br><span class="line">        cw-=w[i]</span><br><span class="line">    <span class="keyword">if</span>(cw+r&gt;bestw):</span><br><span class="line">        x[i]=<span class="number">0</span></span><br><span class="line">        backtrack(i+<span class="number">1</span>,c)</span><br><span class="line">    r+=w[i]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="keyword">global</span> w,bestx,x,bestw,r,cw</span><br><span class="line">    w=[<span class="number">0</span>]</span><br><span class="line">    m=<span class="built_in">input</span>(<span class="string">&quot;Please input the weight of each items:(eg:1 2 3 4 5)\n&quot;</span>).split()</span><br><span class="line">    n=<span class="built_in">len</span>(m)    <span class="comment">#物品数量</span></span><br><span class="line">    <span class="keyword">if</span>(n==<span class="number">0</span>):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;物品数量不能为空！&quot;</span>)</span><br><span class="line">    r=<span class="number">0</span>         <span class="comment">#剩余的物品容量</span></span><br><span class="line">    <span class="comment">#转换w类型并初始化r</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        w.append(<span class="built_in">int</span>(m[i]))</span><br><span class="line">        r+=w[i+<span class="number">1</span>]</span><br><span class="line">    c1=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;Please input the size of No.1 ship:\n&quot;</span>))      <span class="comment">#第一艘船载重量</span></span><br><span class="line">    c2=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;Please input the size of No.2 ship:\n&quot;</span>))      <span class="comment">#第二艘船载重量</span></span><br><span class="line"></span><br><span class="line">    x=[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>)]         <span class="comment">#记录路径</span></span><br><span class="line">    bestx=x[:]                      <span class="comment">#最优路径</span></span><br><span class="line">    bestw,cw=<span class="number">0</span>,<span class="number">0</span>                    <span class="comment">#最优载重量，当前载重量</span></span><br><span class="line">    <span class="comment">#尽可能的装满第一个</span></span><br><span class="line">    backtrack(<span class="number">1</span>,c1)</span><br><span class="line">    <span class="comment">#print(bestx)</span></span><br><span class="line">    cw2=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(bestx)):</span><br><span class="line">        <span class="keyword">if</span>(bestx[i]==<span class="number">0</span>):</span><br><span class="line">            cw2+=w[i]</span><br><span class="line">    <span class="keyword">if</span>(cw2&gt;c2):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;不能由两艘船装完！&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(bestx)):</span><br><span class="line">            <span class="keyword">if</span>(bestx[i]==<span class="number">1</span>):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;第<span class="subst">&#123;i&#125;</span>个物品，重量<span class="subst">&#123;w[i]&#125;</span>,装入第1艘船&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;第<span class="subst">&#123;i&#125;</span>个物品，重量<span class="subst">&#123;w[i]&#125;</span>,装入第2艘船&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入不合法！出错信息如下：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>

<h2 id="5-6-0-1背包问题"><a href="#5-6-0-1背包问题" class="headerlink" title="5.6 0-1背包问题"></a>5.6 0-1背包问题</h2><ul>
<li>n=3, C=30, w={16, 15, 15}, v={45, 25, 25}</li>
<li><img src="https://s2.ax1x.com/2019/11/21/Mo9ygU.png" alt="Mo9ygU.png"></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Copyright: Copyright (c) 2019</span></span><br><span class="line"><span class="string">Author: Justlovesmile</span></span><br><span class="line"><span class="string">Title: 0-1背包问题（回溯法）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Q</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,_id,qq</span>):</span></span><br><span class="line">        self.<span class="built_in">id</span>=_<span class="built_in">id</span></span><br><span class="line">        self.d=qq</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bound</span>(<span class="params">i</span>):</span></span><br><span class="line">    <span class="keyword">global</span> bestp,cw,cp,n,p,c,w,x,bestx</span><br><span class="line">    cleft=c-cw</span><br><span class="line">    bound=cp</span><br><span class="line">    <span class="keyword">while</span>(i&lt;=n <span class="keyword">and</span> w[i]&lt;=cleft):</span><br><span class="line">        cleft-=w[i]</span><br><span class="line">        bound+=p[i]</span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line">    <span class="comment">#贪心</span></span><br><span class="line">    <span class="keyword">if</span>(i&lt;=n):</span><br><span class="line">        bound+=p[i]*cleft/w[i]</span><br><span class="line">    <span class="keyword">return</span> bound </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backtrack</span>(<span class="params">i</span>):</span></span><br><span class="line">    <span class="keyword">global</span> bestp,cw,cp,n,p,c,w,x,bestx</span><br><span class="line">    <span class="comment">#到达叶结点</span></span><br><span class="line">    <span class="keyword">if</span>(i&gt;n):</span><br><span class="line">        <span class="keyword">if</span>(cp&gt;bestp):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">                bestx[j]=x[j]</span><br><span class="line">        bestp=cp</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    <span class="keyword">if</span>(cw+w[i]&lt;c):</span><br><span class="line">        x[i]=<span class="number">1</span></span><br><span class="line">        cw+=w[i]</span><br><span class="line">        cp+=p[i]</span><br><span class="line">        backtrack(i+<span class="number">1</span>)</span><br><span class="line">        cp-=p[i]</span><br><span class="line">        cw-=w[i]</span><br><span class="line">    <span class="keyword">if</span>(bound(i+<span class="number">1</span>)&gt;bestp):</span><br><span class="line">        x[i]=<span class="number">0</span></span><br><span class="line">        backtrack(i+<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="keyword">global</span> bestp,cw,cp,n,p,c,w,x,bestx</span><br><span class="line">    pp=<span class="built_in">input</span>(<span class="string">&quot;Please input the price of each items.(eg:1 2 3 4 5)\n&quot;</span>).split()</span><br><span class="line">    ww=<span class="built_in">input</span>(<span class="string">&quot;Please input the weight of each items.(eg:1 2 3 4 5)\n&quot;</span>).split()</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">len</span>(pp)!=<span class="built_in">len</span>(ww)):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;您的输入长度不一致！&quot;</span>)</span><br><span class="line">    n=<span class="built_in">len</span>(pp)</span><br><span class="line">    c=<span class="built_in">float</span>(<span class="built_in">input</span>(<span class="string">&quot;Please input the size of bag:\n&quot;</span>))</span><br><span class="line">    cw=<span class="number">0</span>        <span class="comment">#当前重量</span></span><br><span class="line">    cp=<span class="number">0</span>        <span class="comment">#当前价值</span></span><br><span class="line">    bestp=<span class="number">0</span>     <span class="comment">#当前最优价值</span></span><br><span class="line">    x=[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>)]       <span class="comment">#初始化临时选择方案</span></span><br><span class="line">    bestx=x[:]                      <span class="comment">#初始化最优选择方案</span></span><br><span class="line">    p=[<span class="number">0</span>]       <span class="comment">#价值列表</span></span><br><span class="line">    w=[<span class="number">0</span>]       <span class="comment">#重量列表</span></span><br><span class="line">    <span class="comment">#单位重量价值</span></span><br><span class="line">    <span class="comment">#初始化</span></span><br><span class="line">    q=[Q(<span class="number">0</span>,<span class="number">0</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]     </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        pp[i]=<span class="built_in">float</span>(pp[i])</span><br><span class="line">        ww[i]=<span class="built_in">float</span>(ww[i])</span><br><span class="line">        q[i].d=pp[i]/ww[i]</span><br><span class="line">        q[i].<span class="built_in">id</span>=i</span><br><span class="line">    q=<span class="built_in">sorted</span>(q,key=<span class="keyword">lambda</span> x:x.d)[::-<span class="number">1</span>]                 <span class="comment">#从大到小排序</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        p.append(pp[q[i].<span class="built_in">id</span>])</span><br><span class="line">        w.append(ww[q[i].<span class="built_in">id</span>])</span><br><span class="line">    <span class="comment">#回溯</span></span><br><span class="line">    backtrack(<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#打印输出</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Max price:&quot;</span>,bestp,<span class="string">&quot;包括：&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(bestx)):</span><br><span class="line">        <span class="keyword">if</span>(bestx[i]==<span class="number">1</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;第<span class="subst">&#123;q[i-<span class="number">1</span>].<span class="built_in">id</span>+<span class="number">1</span>&#125;</span>个,价值：<span class="subst">&#123;pp[q[i-<span class="number">1</span>].<span class="built_in">id</span>]&#125;</span>,重量：<span class="subst">&#123;ww[q[i-<span class="number">1</span>].<span class="built_in">id</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入不合法！出错信息如下：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>

<h1 id="第六章-分支限界法"><a href="#第六章-分支限界法" class="headerlink" title="第六章 分支限界法"></a>第六章 分支限界法</h1><ul>
<li>分支限界法以<code>广度优先</code>或以<code>最小耗费(最大效益)优先</code>的方式搜索解空间树。其搜索策略是：在扩展结点处，先生成其所有儿子结点，然后再从当前的活结点表中选择下一个扩展结点。为了有效地选择下一扩展结点，加速搜索的进程，在每一格活结点处，计算一个函数值（限界），并根据函数值，从当前活结点表中，选择一个最有利的结点作为扩展结点，使搜索朝着解空间上最优解的分支推进，以便尽快找出一个最优解。</li>
<li>常见两种分支限界法：①队列式（FIFO/LIFO）分支限界法②优先队列式分支限界法</li>
<li>与回溯法对比：<ul>
<li>（1）求解目标：回溯法的求解目标是找出解空间树中满足约束条件的所有解，而分支限界法的求解目标则是找出满足约束条件的一个解，或是在满足约束条件的解中找出在某种意义下的最优解。 </li>
<li>（2）搜索方式的不同：回溯法以深度优先的方式搜索解空间树，而分支限界法则以广度优先或以最小耗费优先的方式搜索解空间树。<br><img src="https://s2.ax1x.com/2019/11/21/MoPuFI.png" alt="MoPuFI.png"></li>
</ul>
</li>
</ul>
<h2 id="6-5-0-1背包问题"><a href="#6-5-0-1背包问题" class="headerlink" title="6.5 0-1背包问题"></a>6.5 0-1背包问题</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Q</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,_id,qq</span>):</span></span><br><span class="line">        self.<span class="built_in">id</span>=_<span class="built_in">id</span></span><br><span class="line">        self.d=qq</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BBnode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,par,ch</span>):</span></span><br><span class="line">        self.par=par</span><br><span class="line">        self.ch=ch</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HeapNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,bNode,up,pp,ww,lev</span>):</span></span><br><span class="line">        self.liveNode=bNode</span><br><span class="line">        self.up=up</span><br><span class="line">        self.p=pp</span><br><span class="line">        self.w=ww</span><br><span class="line">        self.lev=lev</span><br><span class="line"></span><br><span class="line"><span class="comment">#插入队列</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addlivenode</span>(<span class="params">heap,up,pp,ww,lev,par,ch</span>):</span></span><br><span class="line">    b=BBnode(par,ch)</span><br><span class="line">    node=HeapNode(b,up,pp,ww,lev)</span><br><span class="line">    heap.append(node)</span><br><span class="line"></span><br><span class="line"><span class="comment">#上界函数，贪心</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bound</span>(<span class="params">i</span>):</span></span><br><span class="line">    <span class="keyword">global</span> cw,cp,n,p,c,w</span><br><span class="line">    cleft=c-cw</span><br><span class="line">    bound=cp</span><br><span class="line">    <span class="keyword">while</span>(i&lt;=n <span class="keyword">and</span> w[i]&lt;=cleft):</span><br><span class="line">        cleft-=w[i]</span><br><span class="line">        bound+=p[i]</span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(i&lt;=n):</span><br><span class="line">        bound+=p[i]*cleft/w[i]</span><br><span class="line">    <span class="keyword">return</span> bound</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knapsack</span>():</span></span><br><span class="line">    <span class="keyword">global</span> bestp,cw,cp,n,p,c,w,bestx</span><br><span class="line">    i=<span class="number">1</span></span><br><span class="line">    up=bound(i)</span><br><span class="line">    heap=[]</span><br><span class="line">    cnode=BBnode(<span class="literal">None</span>,<span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">while</span>(i!=n+<span class="number">1</span>):</span><br><span class="line">        <span class="comment">#左孩子</span></span><br><span class="line">        cleft=cw+w[i]</span><br><span class="line">        <span class="keyword">if</span>(cleft&lt;c):</span><br><span class="line">            <span class="keyword">if</span>(cp+p[i]&gt;bestp):</span><br><span class="line">                bestp=cp+p[i]</span><br><span class="line">            addlivenode(heap,up,cp+p[i],cw+w[i],i+<span class="number">1</span>,cnode,<span class="literal">True</span>)</span><br><span class="line">        <span class="comment">#右孩子</span></span><br><span class="line">        up=bound(i+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span>(up&gt;=bestp):</span><br><span class="line">            addlivenode(heap,up,cp+p[i],cw+w[i],i+<span class="number">1</span>,cnode,<span class="literal">False</span>)</span><br><span class="line">        <span class="comment">#取下一扩展结点</span></span><br><span class="line">        node=heap.pop(<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#更新数据</span></span><br><span class="line">        cnode=node.liveNode</span><br><span class="line">        cw=node.w</span><br><span class="line">        cp=node.p</span><br><span class="line">        up=node.up</span><br><span class="line">        i=node.lev</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最优解</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>)[::-<span class="number">1</span>]:</span><br><span class="line">        bestx[j]=<span class="number">1</span> <span class="keyword">if</span> cnode.ch==<span class="literal">True</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        cnode=cnode.par</span><br></pre></td></tr></table></figure>

<p>实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Copyright: Copyright (c) 2019</span></span><br><span class="line"><span class="string">Author: Justlovesmile</span></span><br><span class="line"><span class="string">Title: 0-1背包问题（分支限界法）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Q</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,_id,qq</span>):</span></span><br><span class="line">        self.<span class="built_in">id</span>=_<span class="built_in">id</span></span><br><span class="line">        self.d=qq</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BBnode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,par,ch</span>):</span></span><br><span class="line">        self.par=par</span><br><span class="line">        self.ch=ch</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HeapNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,bNode,up,pp,ww,lev</span>):</span></span><br><span class="line">        self.liveNode=bNode</span><br><span class="line">        self.up=up</span><br><span class="line">        self.p=pp</span><br><span class="line">        self.w=ww</span><br><span class="line">        self.lev=lev</span><br><span class="line"></span><br><span class="line"><span class="comment">#插入队列</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addlivenode</span>(<span class="params">heap,up,pp,ww,lev,par,ch</span>):</span></span><br><span class="line">    b=BBnode(par,ch)</span><br><span class="line">    node=HeapNode(b,up,pp,ww,lev)</span><br><span class="line">    heap.append(node)</span><br><span class="line"></span><br><span class="line"><span class="comment">#上界函数，贪心</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bound</span>(<span class="params">i</span>):</span></span><br><span class="line">    <span class="keyword">global</span> cw,cp,n,p,c,w</span><br><span class="line">    cleft=c-cw</span><br><span class="line">    bound=cp</span><br><span class="line">    <span class="keyword">while</span>(i&lt;=n <span class="keyword">and</span> w[i]&lt;=cleft):</span><br><span class="line">        cleft-=w[i]</span><br><span class="line">        bound+=p[i]</span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(i&lt;=n):</span><br><span class="line">        bound+=p[i]*cleft/w[i]</span><br><span class="line">    <span class="keyword">return</span> bound</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knapsack</span>():</span></span><br><span class="line">    <span class="keyword">global</span> bestp,cw,cp,n,p,c,w,bestx</span><br><span class="line">    i=<span class="number">1</span></span><br><span class="line">    up=bound(i)</span><br><span class="line">    heap=[]</span><br><span class="line">    cnode=BBnode(<span class="literal">None</span>,<span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">while</span>(i!=n+<span class="number">1</span>):</span><br><span class="line">        <span class="comment">#左孩子</span></span><br><span class="line">        cleft=cw+w[i]</span><br><span class="line">        <span class="keyword">if</span>(cleft&lt;c):</span><br><span class="line">            <span class="keyword">if</span>(cp+p[i]&gt;bestp):</span><br><span class="line">                bestp=cp+p[i]</span><br><span class="line">            addlivenode(heap,up,cp+p[i],cw+w[i],i+<span class="number">1</span>,cnode,<span class="literal">True</span>)</span><br><span class="line">        <span class="comment">#右孩子</span></span><br><span class="line">        up=bound(i+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span>(up&gt;=bestp):</span><br><span class="line">            addlivenode(heap,up,cp+p[i],cw+w[i],i+<span class="number">1</span>,cnode,<span class="literal">False</span>)</span><br><span class="line">        <span class="comment">#取下一扩展结点</span></span><br><span class="line">        node=heap.pop(<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#更新数据</span></span><br><span class="line">        cnode=node.liveNode</span><br><span class="line">        cw=node.w</span><br><span class="line">        cp=node.p</span><br><span class="line">        up=node.up</span><br><span class="line">        i=node.lev</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最优解</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>)[::-<span class="number">1</span>]:</span><br><span class="line">        bestx[j]=<span class="number">1</span> <span class="keyword">if</span> cnode.ch==<span class="literal">True</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        cnode=cnode.par</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="keyword">global</span> bestp,cw,cp,n,p,c,w,bestx</span><br><span class="line">    <span class="comment">#输入</span></span><br><span class="line">    pp=<span class="built_in">input</span>(<span class="string">&quot;Please input the price of each items.(eg:1 2 3 4 5)\n&quot;</span>).split()</span><br><span class="line">    ww=<span class="built_in">input</span>(<span class="string">&quot;Please input the weight of each items.(eg:1 2 3 4 5)\n&quot;</span>).split()</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">len</span>(pp)!=<span class="built_in">len</span>(ww)):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;您的输入长度不一致！&quot;</span>)</span><br><span class="line">    n=<span class="built_in">len</span>(pp)</span><br><span class="line">    c=<span class="built_in">float</span>(<span class="built_in">input</span>(<span class="string">&quot;Please input the size of bag:\n&quot;</span>))</span><br><span class="line">    cw=<span class="number">0</span>        <span class="comment">#当前重量</span></span><br><span class="line">    cp=<span class="number">0</span>        <span class="comment">#当前价值</span></span><br><span class="line">    bestp=<span class="number">0</span>     <span class="comment">#当前最优价值</span></span><br><span class="line">    bestx=[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>)]   <span class="comment">#最优解初始化</span></span><br><span class="line">    p=[<span class="number">0</span>]</span><br><span class="line">    w=[<span class="number">0</span>]</span><br><span class="line">    q=[Q(<span class="number">0</span>,<span class="number">0</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]     <span class="comment">#单位重量价值</span></span><br><span class="line">    allp=<span class="number">0</span>    <span class="comment">#总价值</span></span><br><span class="line">    allw=<span class="number">0</span>    <span class="comment">#总重量</span></span><br><span class="line">    <span class="comment">#单位重量价值列表</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        pp[i]=<span class="built_in">float</span>(pp[i])</span><br><span class="line">        ww[i]=<span class="built_in">float</span>(ww[i])</span><br><span class="line">        allp+=pp[i]</span><br><span class="line">        allw+=ww[i]</span><br><span class="line">        q[i].d=pp[i]/ww[i]</span><br><span class="line">        q[i].<span class="built_in">id</span>=i</span><br><span class="line">    q=<span class="built_in">sorted</span>(q,key=<span class="keyword">lambda</span> x:x.d)[::-<span class="number">1</span>]                 <span class="comment">#从大到小排序</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        p.append(pp[q[i].<span class="built_in">id</span>])</span><br><span class="line">        w.append(ww[q[i].<span class="built_in">id</span>])</span><br><span class="line">    <span class="comment">#如果能直接全装</span></span><br><span class="line">    <span class="keyword">if</span>(allw&lt;c):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;All in! Total price is <span class="subst">&#123;allp&#125;</span>!&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line"></span><br><span class="line">    knapsack()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Max price:&quot;</span>,bestp,<span class="string">&quot;包括：&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(bestx)):</span><br><span class="line">        <span class="keyword">if</span>(bestx[i]==<span class="number">1</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;第<span class="subst">&#123;q[i-<span class="number">1</span>].<span class="built_in">id</span>+<span class="number">1</span>&#125;</span>个,价值：<span class="subst">&#123;pp[q[i-<span class="number">1</span>].<span class="built_in">id</span>]&#125;</span>,重量：<span class="subst">&#123;ww[q[i-<span class="number">1</span>].<span class="built_in">id</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入不合法!出错信息如下：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>

<h2 id="6-6-装载问题"><a href="#6-6-装载问题" class="headerlink" title="6.6 装载问题"></a>6.6 装载问题</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Copyright: Copyright (c) 2019</span></span><br><span class="line"><span class="string">Author: Justlovesmile</span></span><br><span class="line"><span class="string">Title: 装载问题（分支限界法）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,parent,isleftchild,weight</span>):</span></span><br><span class="line">        self.parent=parent</span><br><span class="line">        self.islchild=isleftchild</span><br><span class="line">        self.weight=weight</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxloading</span>(<span class="params">c</span>):</span></span><br><span class="line">    <span class="keyword">global</span> w,bestx,bestw,r,cw,n</span><br><span class="line">    i=<span class="number">1</span></span><br><span class="line">    r-=w[i]</span><br><span class="line">    cnode=Node(<span class="literal">None</span>,<span class="literal">None</span>,-<span class="number">1</span>)    <span class="comment">#当前结点</span></span><br><span class="line">    q=[cnode]</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        <span class="comment">#左结点</span></span><br><span class="line">        cleft=cw+w[i]</span><br><span class="line">        <span class="keyword">if</span>(cleft&lt;=c):</span><br><span class="line">            enode=Node(cnode,<span class="literal">True</span>,cleft)</span><br><span class="line">            <span class="keyword">if</span>(cleft&gt;bestw):</span><br><span class="line">                bestw=cleft    </span><br><span class="line">                bestx=enode</span><br><span class="line">            <span class="keyword">if</span>(i&lt;n):</span><br><span class="line">                q.append(enode)</span><br><span class="line">            <span class="keyword">if</span>(i==n):</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">        <span class="comment">#右结点</span></span><br><span class="line">        <span class="keyword">if</span>(cw+r&gt;bestw <span class="keyword">and</span> i&lt;n):</span><br><span class="line">            enode=Node(cnode,<span class="literal">False</span>,cw)</span><br><span class="line">            q.append(enode)</span><br><span class="line">        <span class="comment">#出队列</span></span><br><span class="line">        cnode=q.pop(<span class="number">0</span>)</span><br><span class="line">        cw=cnode.weight</span><br><span class="line">        <span class="keyword">if</span>(cw==-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">len</span>(q)==<span class="number">0</span>):</span><br><span class="line">                <span class="keyword">return</span> ;</span><br><span class="line">            q.append(Node(<span class="literal">None</span>,<span class="literal">None</span>,-<span class="number">1</span>))</span><br><span class="line">            cnode=q.pop(<span class="number">0</span>)</span><br><span class="line">            cw=cnode.weight</span><br><span class="line">            i+=<span class="number">1</span></span><br><span class="line">            r-=w[i]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="keyword">global</span> w,bestx,bestw,r,cw,n</span><br><span class="line">    w=[<span class="number">0</span>]</span><br><span class="line">    m=<span class="built_in">input</span>(<span class="string">&quot;Please input the weight of each items:(eg:1 2 3 4 5)\n&quot;</span>).split()</span><br><span class="line">    n=<span class="built_in">len</span>(m)    <span class="comment">#物品数量</span></span><br><span class="line">    <span class="keyword">if</span>(n==<span class="number">0</span>):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;物品数量不能为空！&quot;</span>)</span><br><span class="line">    r=<span class="number">0</span>         <span class="comment">#剩余的物品容量</span></span><br><span class="line">    bestw,cw=<span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    <span class="comment">#转换w类型并初始化r</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        w.append(<span class="built_in">int</span>(m[i]))</span><br><span class="line">        r+=w[i+<span class="number">1</span>]</span><br><span class="line">    allweight=r    <span class="comment">#总重量</span></span><br><span class="line">    x=[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>)]</span><br><span class="line">    tx=[]</span><br><span class="line">    c1=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;Please input the size of No.1 ship:\n&quot;</span>))      <span class="comment">#第一艘船载重量</span></span><br><span class="line">    c2=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;Please input the size of No.2 ship:\n&quot;</span>))      <span class="comment">#第二艘船载重量</span></span><br><span class="line"></span><br><span class="line">    maxloading(c1)</span><br><span class="line">    <span class="keyword">if</span>(bestw+c2&lt;allweight):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;不能由两艘船装完！&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>)[::-<span class="number">1</span>]:</span><br><span class="line">        <span class="keyword">if</span>(bestx.islchild==<span class="literal">True</span>):</span><br><span class="line">            tx.append(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">elif</span>(bestx.islchild==<span class="literal">False</span>):</span><br><span class="line">            tx.append(<span class="number">0</span>)</span><br><span class="line">        bestx=bestx.parent</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(tx)):</span><br><span class="line">        x[i+<span class="number">1</span>]=tx[::-<span class="number">1</span>][i]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;第一艘船载重量<span class="subst">&#123;bestw&#125;</span>，包括：&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span>(x[i]==<span class="number">1</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;第<span class="subst">&#123;i&#125;</span>个集装箱&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;第二艘船载重量<span class="subst">&#123;allweight-bestw&#125;</span>,包括：&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span>(x[i]==<span class="number">0</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;第<span class="subst">&#123;i&#125;</span>个集装箱&quot;</span>)    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入不合法！出错信息如下：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure>


<h1 style="text-align: center;">知识点整理</h1>

<ul>
<li><p>算法的特征：<code>输入，输出，确定性，有限性</code></p>
</li>
<li><p>θ记号在算法复杂性的表示法中表示<code>紧致界</code></p>
</li>
<li><p>由分治法产生的子问题往往是<code>原问题的较小模式</code>，这就为使用<code>递归</code>提供了方便</p>
</li>
<li><p>建立计算模型的目的：<code>为了使问题的计算复杂性分析有一个共同的客观尺度</code></p>
</li>
<li><p>基本计算模型：<code>RAM</code>,<code>RASP</code>,<code>TM</code></p>
</li>
<li><p>拉斯维加斯算法找到的解一定是<code>正确</code>的</p>
</li>
<li><p>贪心算法常采用<code>自顶向下</code>的方式求解最优解</p>
</li>
<li><p>采用高级语言的主要好处：</p>
<blockquote>
<p>①更接近算法语言，易学，易掌握②提供了结构化程序设计的环境和工具，使得设计出的程序可读性高，可维护性强，可靠性高③不依赖于机器语言，因此写出的程序可移植性好，重用率高③自动化程度高，开发周期短，程序员可以集中精力从事更重要的创造性劳动，提高程序质量</p>
</blockquote>
</li>
<li><p>贪心算法的特点：</p>
<blockquote>
<p>①不能保证最后求得的解是最优的②策略易发现，运用简单，被广泛运用③策略多样，结果也多样④常用到辅助算法：排序</p>
</blockquote>
</li>
<li><p><code>平衡子问题</code>思想：通常分治法在分割原问题，形成若干子问题时，这些子问题的规模都大致相同</p>
</li>
<li><p>Prim算法采用<code>贪心策略</code>求解<code>最小生成树问题</code>，其时间复杂度是O(n^2)。</p>
</li>
<li><p>动态规划算法适用于解具有<code>某种最优性质</code>的问题。</p>
</li>
<li><p>贪心算法做出的选择只是适用于在某种意义上的<code>局部最优</code>选择</p>
</li>
<li><p>在动态规划算法中，通常不同子问题的个数随问题规模呈<code>多项式</code>级增长</p>
</li>
<li><p>动态规划是解决<code>多阶段决策过程</code>的最优化问题</p>
</li>
<li><p><code>选择能产生最优解的贪心准则</code>是设计贪心算法的核心问题 </p>
</li>
<li><p>分支限界法常以<code>广度优先</code>或以<code>最小耗费（最大效益）优先</code>的方式搜索问题的解空间树</p>
</li>
<li><p>为什么用分治法设计的算法一般有递归调用？因为子问题的规模还很大时，必须继续使用分治法，反复分治，必然要用到递归</p>
</li>
<li><p>请简述分支限界法找最优解比回溯法高的原因：在分支限界法中，每一个点只有一次机会称为扩展结点。</p>
</li>
<li><p>回溯法的算法框架按照问题的解空间一般分为<code>子集树</code>算法框架（如解0-1背包问题）和<code>排列树</code>算法框架（如解批处理作业调度问题）</p>
</li>
<li><p><img src="https://s2.ax1x.com/2019/11/21/MIEmhn.png" alt="MIEmhn.png"></p>
</li>
<li><p>常见的多项式阶：<code>O(1) &lt; O(logn) &lt; O(n) &lt; O(nlogn) &lt; O(n^2) &lt; O(n^3) &lt; O(2^n) &lt; O(n!) &lt; O(n^n)</code></p>
</li>
<li><p>回溯和分支限界：</p>
<ul>
<li>相同点：都是以构造一颗状态空间树为基础的，树的结点反映了对一部分解所作的特定选择</li>
<li>不同点：①他们处理的问题类型不同，回溯法的求解目标是找出T中满足约束条件的所有解，而分支限界法的求解目标则是找出满足约束条件的一个解，或是在满足约束条件的解中找出使某一目标函数值达到极大或极小的解，即在某种意义下的最优解。②生成状态空间树的顺序不同③对节点存储的常用数据结构以及节点存储特性也各不相同，除由搜索方式决定的不同的存储结构外，分支限界法通常需要存储一些额外的信息以利于进一步地展开搜索</li>
</ul>
</li>
<li><p><img src="https://s2.ax1x.com/2019/11/21/MoFWQK.png" alt="MoFWQK.png"></p>
</li>
<li><p><img src="https://s2.ax1x.com/2019/11/21/MoFHJI.png" alt="MoFHJI.png"></p>
</li>
<li><p>NP问题是指还未被证明是否存在多项式算法能够解决的问题，而其中NP完全问题又是最有可能不是P问题的问题类型。所有的NP问题都可以用多项式时间划归到他们中的一个。所以显然NP完全的问题具有如下性质：它可以在多项式时间内求解，当且仅当所有的其他的NP－完全问题也可以在多项式时间内求解。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学课程</tag>
      </tags>
  </entry>
  <entry>
    <title>大学课程 | 编译原理知识点</title>
    <url>/posts/50753.html</url>
    <content><![CDATA[<p>大三编译原理复习知识点</p>
<span id="more"></span>

<p>问题？</p>
<ul>
<li>什么是解释器？什么是编辑器？什么是前端后端？分析和综合？遍？翻译过程的输入输出？T型图的意义描述？</li>
<li>词法分析：什么是正则表达式？什么是有穷自动机？DFA？NFA？区别，特点？基本概念？正则表达式到NFA到DFA，再最小化。构建方法。扫描器功能的输入输出？什么是字母表，元符号，正则表达式的三种基本操作</li>
<li>0/1/2/3型文法？什么是最左推导？最右推导？什么是终结符，非终结符？什么是产生式？如何识别二义性，消除方法？语言到文法？</li>
<li>递归下降？LL(1)判断是不是？消除左递归，提取左公因子，First集follow集，构造分析表，对一个句子分析。LL(1)三种基本动作：生成（最左推导），匹配，接受。</li>
<li>自底向上？</li>
<li>语义分析：什么是属性？什么是属性文法？什么是联编？联编的时间？静态语义和动态语义？常见的静态语义？什么是符号表？作用,内容?描述–&gt;属性文法？综合属性，基本属性</li>
<li>了解几种运行环境的特点：Fortran77 完全静态，不允许递归调用。基于栈的C，C++，Pascal。LISP完全动态</li>
<li>中间代码：种类，三元式，四元式，控制表达式，逆波兰，波兰。</li>
</ul>
<h1 id="第一章-概论"><a href="#第一章-概论" class="headerlink" title="第一章 概论"></a>第一章 概论</h1><h2 id="什么是编译器？"><a href="#什么是编译器？" class="headerlink" title="什么是编译器？"></a>什么是编译器？</h2><p>（1）</p>
<ul>
<li>编译器是将一种语言翻译为另一种语言的计算机程序。</li>
<li>编译器将编写的程序作为输入，而产生用目标语言编写的等价程序</li>
<li>源程序→{编译器}→目标程序<br>（2）</li>
<li>编译器是将便于人编写，阅读，维护的高阶计算机语言翻译为计算机能解读，运行的低阶机器语言的程序。</li>
<li>编译器将原始程序作为输入，翻译产生使用目标的等价程序。源代码一般为高阶语言，而目标语言则是汇编语言或目标机器的目标代码，有时也称作机器代码。</li>
</ul>
<h2 id="编译器分类结构"><a href="#编译器分类结构" class="headerlink" title="编译器分类结构"></a>编译器分类结构</h2><ul>
<li>根据<code>语言文法的难易程度</code>以及<code>识别它们所需要的算法</code>分类：如<code>乔姆斯基分类结构</code>：</li>
<li>4类：分为0型，1型，2型，3型文法<ul>
<li>0型文法为：无限制文法</li>
<li>1型文法为：上下文有关文法</li>
<li>2型文法为：上下文无关文法</li>
<li>3型文法为：正则文法</li>
</ul>
</li>
<li>4个文法的定义是逐渐增加限制的</li>
</ul>
<h2 id="与编译器相关的程序"><a href="#与编译器相关的程序" class="headerlink" title="与编译器相关的程序"></a>与编译器相关的程序</h2><ul>
<li>（1）解释程序</li>
<li>如同编译器的一种语言翻译程序。与编译器的不同在于：它立即执行源程序而不是在翻译完成之后才执行目标代码。</li>
<li>（2）汇编程序</li>
<li>用于特定计算机上的汇编语言的翻译程序</li>
<li>（3）连接程序</li>
<li>将分别在不同的目标文件中编译或汇编的代码收集到一个可直接执行的文件中</li>
<li>（4）装入程序</li>
<li>可处理所有与指定的基地址或起始地址有关的可重定位的地址</li>
<li>（5）预处理器</li>
<li>在真正的翻译开始之前由编译器调用的独立程序</li>
<li>（6）编辑器</li>
<li>编译器通常接受由任何生成标准文件 ( 例如  ASCII  文件 ) 的编辑器编写的源程序。编译器如今常与编辑器和其他程序捆绑进一个交互的开发环境–IDE中。</li>
<li>（7）调试程序</li>
<li>可在被编译了的程序中判定执行错误的程序。编译器必须为调试程序提供恰当的符号信息。</li>
<li>（8）描述器</li>
<li>在执行中搜集目标程序行为统计的程序</li>
<li>（9）项目管理程序</li>
</ul>
<h2 id="翻译步骤"><a href="#翻译步骤" class="headerlink" title="翻译步骤"></a>翻译步骤</h2><ul>
<li>编译器内部包括了许多步骤或称为阶段。</li>
<li><img src="https://s2.ax1x.com/2019/10/13/uvUU4U.png" alt="uvUU4U.png"></li>
<li>（1）扫描程序：编译器阅读源程序。扫描程序会执行词法分析，将字符序列收集到称作<code>记号</code>的单元中。</li>
<li>（2）语法分析程序：从扫描程序获取记号形式的源代码，并完成定义程序结构的语法分析。通常将语法分析的结果表示为<code>分析树</code>或者<code>语法树</code>。</li>
<li>（3）语义分析程序：程序的语义确定程序的运行。但是大多数的程序设计语言都具有在执行前被确定而不易有语法表示和由分析程序分析的特征。这些特征被称为<code>静态语义</code>。而语义分析程序的任务就是分析这些语义。由语义分析程序计算的额外信息被称为属性，输出结果为<code>注释树</code></li>
<li>（4）源代码优化程序：源代码优化程序可能通过将其输出称为<code>中间代码</code>来使用三元式代码。</li>
<li>（5）代码生成器：代码生成器得到中间代码，生成<code>目标机器的代码</code>。</li>
<li>（6）目标代码优化程序：优化目标代码</li>
</ul>
<h2 id="编译器中的主要数据结构"><a href="#编译器中的主要数据结构" class="headerlink" title="编译器中的主要数据结构"></a>编译器中的主要数据结构</h2><ul>
<li>记号</li>
<li>语法树</li>
<li>符号表</li>
<li>常数表</li>
<li>中间代码</li>
<li>临时文件</li>
</ul>
<h2 id="什么是遍？"><a href="#什么是遍？" class="headerlink" title="什么是遍？"></a>什么是遍？</h2><ul>
<li>编译过程的几个阶段仅仅是逻辑功能上的一种划分，具体实现时，受不同源语言，设计要求，使用对象和计算机条件（如主存容量）的限制，往往将编译程序组织为若干遍。所谓“遍”就是对源程序或源程序的中间结果从头到尾扫描一次，并作有关的加工处理，生成新的中间结果或目标程序。</li>
<li>通常，每遍的工作由从外存上获得的前一遍的中间结果开始，完成它所含的有关工作之后，再把结果记录于外存，既可以将几个不同阶段合为一遍，也可以把一个阶段的工作分为若干遍。当一遍中包含若干阶段时，各阶段的工作是穿插进行的。</li>
</ul>
<h2 id="什么是前端后端？"><a href="#什么是前端后端？" class="headerlink" title="什么是前端后端？"></a>什么是前端后端？</h2><ul>
<li>通常认为，只依赖于源语言的的操作为前端，只依赖于目标语言的操作为后端。</li>
<li>如：扫描程序，分析程序，语义分析程序为前端。代码生成器为后端。</li>
<li>便于编译器的可移植性</li>
<li><img src="https://s2.ax1x.com/2019/10/25/KwRZlD.png" alt="KwRZlD.png"></li>
</ul>
<h2 id="什么是分析与综合？"><a href="#什么是分析与综合？" class="headerlink" title="什么是分析与综合？"></a>什么是分析与综合？</h2><ul>
<li>分析：分析源程序以计算其特性的编译器操作</li>
<li>综合：生成翻译代码时所涉及到的操作</li>
</ul>
<h2 id="什么是扫描器？"><a href="#什么是扫描器？" class="headerlink" title="什么是扫描器？"></a>什么是扫描器？</h2><ul>
<li>扫描器就是词法分析程序</li>
<li>其主要功能是依据词法规则，分析由字符组成的源程序，把它分割为一个一个具有独立意义的最小语法单位，即单词。</li>
</ul>
<h2 id="汇编语言的优缺点"><a href="#汇编语言的优缺点" class="headerlink" title="汇编语言的优缺点"></a>汇编语言的优缺点</h2><ul>
<li>优点：汇编语言大大提高了编程的速度和准确度</li>
<li>缺点：编写起来也不容易 , 阅读和理解很难；而且汇编语言的编写严格依赖于特定的机器，所以为一台计算机编写的代码在应用于另一台计算机时必须完全重写。</li>
</ul>
<h2 id="什么是静态语义"><a href="#什么是静态语义" class="headerlink" title="什么是静态语义"></a>什么是静态语义</h2><ul>
<li>程序的语义确定程序的运行，但是大多数的程序设计语言都具有在执行之前被确定而不易由语法表示和由分析程序分析的特征。这些特征被称作<code>静态语义</code>。</li>
<li>一般的程序设计语言的典型静态语义包括<code>声明</code>和<code>类型检查</code>。由语义分析程序计算的额外信息 ( 诸如数据类型 ) 被称为属性，它们通常是作为注释或 “ 装饰 ” 增加到树中 ( 还可将属性添加到符号表中 ) 。</li>
</ul>
<h2 id="编译器中第一个考虑目标机的物理特性的模块是：-代码生成器"><a href="#编译器中第一个考虑目标机的物理特性的模块是：-代码生成器" class="headerlink" title="编译器中第一个考虑目标机的物理特性的模块是： 代码生成器"></a>编译器中第一个考虑目标机的物理特性的模块是： 代码生成器</h2><h2 id="T-型图中S-T-H-分别代表什么？"><a href="#T-型图中S-T-H-分别代表什么？" class="headerlink" title="T 型图中S,T,H 分别代表什么？"></a>T 型图中S,T,H 分别代表什么？</h2><p>| S T|<br>|  H |</p>
<ul>
<li>语言H( 代表宿主语言 ) 编写的编译器将语言S( 代表源语言 ) 翻译为语言T( 代表目标语言 )</li>
</ul>
<h2 id="T-型图描述自举及移植的过程"><a href="#T-型图描述自举及移植的过程" class="headerlink" title="T 型图描述自举及移植的过程"></a>T 型图描述自举及移植的过程</h2><ul>
<li><img src="https://s2.ax1x.com/2019/10/25/KwWwKe.png" alt="KwWwKe.png"></li>
</ul>
<h1 id="第二章-词法分析"><a href="#第二章-词法分析" class="headerlink" title="第二章 词法分析"></a>第二章 词法分析</h1><h2 id="什么是词法分析"><a href="#什么是词法分析" class="headerlink" title="什么是词法分析"></a>什么是词法分析</h2><ul>
<li>将源程序读作字符文件并将其分为若干记号</li>
</ul>
<h2 id="记号分类"><a href="#记号分类" class="headerlink" title="记号分类"></a>记号分类</h2><ul>
<li>关键字： 如if，while</li>
<li>标识符：用户定义的串</li>
<li>特殊符号：算术符号，一些多字符符号等</li>
</ul>
<h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><ul>
<li>是一种表示字符串的格式</li>
<li>三种基本操作：选择，连结，重复（闭包）</li>
<li>元字符/元符号：正则表达式中有特殊含义的字符</li>
</ul>
<h2 id="什么是有穷自动机"><a href="#什么是有穷自动机" class="headerlink" title="什么是有穷自动机"></a>什么是有穷自动机</h2><ul>
<li>是描述特定类型算法的数学方法。</li>
<li>圆圈表示状态，带有箭头的线表示记录一个状态向另一个状态的转换。</li>
</ul>
<h2 id="DFA（确定性有穷自动机）"><a href="#DFA（确定性有穷自动机）" class="headerlink" title="DFA（确定性有穷自动机）"></a>DFA（确定性有穷自动机）</h2><ul>
<li><img src="https://s2.ax1x.com/2019/10/25/Kw4VUA.png" alt="Kw4VUA.png"></li>
<li>给出一个状态和字符，通常肯定会有一个指向单个新状态的唯一转换</li>
</ul>
<h2 id="NFA（非确定性有穷自动机）"><a href="#NFA（非确定性有穷自动机）" class="headerlink" title="NFA（非确定性有穷自动机）"></a>NFA（非确定性有穷自动机）</h2><ul>
<li><img src="https://s2.ax1x.com/2019/10/25/Kw4Bb4.png" alt="Kw4Bb4.png"></li>
</ul>
<h1 id="第三章-上下文无关文法"><a href="#第三章-上下文无关文法" class="headerlink" title="第三章 上下文无关文法"></a>第三章 上下文无关文法</h1><h2 id="上下文无关文法与正则表达式的主要区别："><a href="#上下文无关文法与正则表达式的主要区别：" class="headerlink" title="上下文无关文法与正则表达式的主要区别："></a>上下文无关文法与正则表达式的主要区别：</h2><ul>
<li>上下文无关文法的规则是递归的</li>
</ul>
<h2 id="终结符和非终结符"><a href="#终结符和非终结符" class="headerlink" title="终结符和非终结符"></a>终结符和非终结符</h2><ul>
<li>非终结符：在推导中必须被进一步替换的结构名</li>
<li>终结符：终结推导的字母表中的符号</li>
</ul>
<h2 id="什么是推导"><a href="#什么是推导" class="headerlink" title="什么是推导"></a>什么是推导</h2><ul>
<li>推导是在文法规则的右边进行选择的一个结构名字的替换序列。推导以一个结构名字开始并以记号符号串结束。</li>
<li>最左推导：它的每一步中最左的非终结符都要被替换的推导。</li>
<li>最右推导：它的每一步中最右的非终结符都要被替换的推导。</li>
<li>最左推导和与其相关的分析树的内部节点的前序编号相对应；而最右推导则和后序编号相对应。</li>
</ul>
<h2 id="产生式"><a href="#产生式" class="headerlink" title="产生式"></a>产生式</h2><ul>
<li>文法规则也被称为产生式。</li>
</ul>
<h2 id="二义性文法"><a href="#二义性文法" class="headerlink" title="二义性文法"></a>二义性文法</h2><ul>
<li>可生成两个不同分析树的串的文法</li>
<li>解决方法：一，设置规则，即消除二义性规则。二，将文法改变成一个强制正确分析树构造的格式</li>
</ul>
<h2 id="语法分析器的作用"><a href="#语法分析器的作用" class="headerlink" title="语法分析器的作用"></a>语法分析器的作用</h2><ul>
<li>编译过程中，语法分析器的任务是<br>(1)   分析单词串是如何构成语句和说明的<br>(2)   分析语句和说明是如何构成程序的<br>(3)   分析程序的结构</li>
</ul>
<h1 id="第四章-自顶向下的分析"><a href="#第四章-自顶向下的分析" class="headerlink" title="第四章 自顶向下的分析"></a>第四章 自顶向下的分析</h1><h2 id="自顶向下的分析"><a href="#自顶向下的分析" class="headerlink" title="自顶向下的分析"></a>自顶向下的分析</h2><ul>
<li>两类程序：回溯分析程序；预测分析程序</li>
<li>两类算法：递归下降分析；LL(1)分析</li>
</ul>
<h2 id="LL-1-文法"><a href="#LL-1-文法" class="headerlink" title="LL(1)文法"></a>LL(1)文法</h2><ul>
<li>LL(1)分析：第一个<code>L</code>指由左向右处理输入，第二个<code>L</code>为输入串描绘出一个最左推导，<code>1</code>是指先行一个符号</li>
<li>使用显示栈来完成分析</li>
<li>是非二义性的文法</li>
<li>对于文法G，其相关的LL(1)分析表的每个项目中至多只有一个产生式，则该文法就是LL(1)文法。</li>
<li>LL(1)三种基本动作：生成（最左推导），匹配，接受</li>
</ul>
<h2 id="将BNF写为LL-1-分析算法"><a href="#将BNF写为LL-1-分析算法" class="headerlink" title="将BNF写为LL(1)分析算法"></a>将BNF写为LL(1)分析算法</h2><ul>
<li>消除左递归：<img src="https://s2.ax1x.com/2019/10/26/K0df54.png" alt="K0df54.png"><img src="https://s2.ax1x.com/2019/10/26/K0dLVO.png" alt="K0dLVO.png"></li>
<li>提取左公因子：<img src="https://s2.ax1x.com/2019/10/26/K0dOaD.png" alt="K0dOaD.png"><img src="https://s2.ax1x.com/2019/10/26/K0dvPH.png" alt="K0dvPH.png"></li>
</ul>
<h2 id="FIRST集-定义："><a href="#FIRST集-定义：" class="headerlink" title="FIRST集 定义："></a>FIRST集 定义：</h2><p>令 X 为一个文法符号（一个终结符或非终结符）或 ε ，则集合 First (X)  由终结符组成，此外可能还有 ε ，它的定义如下：</p>
<ol>
<li> 若 X 是终结符或 ε ，则 First (X) = {X} 。</li>
<li> 若 X 是非终结符，则对于每个产生式  X → X1 X2 . . . Xn  ， First (X) 都包含了 First (X1 ) - { ε } 。若对于某个 i &lt; n ，所有的集合 First (X1 ), . . . , First (Xi )  都包括了 ε ，则 First (X)  也包括了 First (X i + 1 ) -  { ε } 。若所有集合 First (X1 ), . . . , First (Xn ) 包括了 ε ，则 First (X) 也包括 ε 。</li>
</ol>
<h2 id="FOLLOW集-定义："><a href="#FOLLOW集-定义：" class="headerlink" title="FOLLOW集 定义："></a>FOLLOW集 定义：</h2><p>给出一个非终结符 A ，那么集合 Follow (A) 则是由终结符组成，此外可能还有 $ 。<br>集合 Follo w (A) 的定义如下：</p>
<ol>
<li> 若 A 是开始符号，则 $ 就在 Follo w (A) 中。</li>
<li> 若存在产生式 B →α A γ，则 First ( γ ) - { ε } 在 Follo w (A) 中。</li>
<li> 若存在产生式 B →α A γ，且在 Firs t  ( γ ) 中，则 F ollo w (A) 包括 Follow (B) 。</li>
</ol>
<h2 id="SELECT集"><a href="#SELECT集" class="headerlink" title="SELECT集"></a>SELECT集</h2><ol>
<li>定义：<br>给定上下文无关文法的产生式A→α, A∈VN,α∈V*, 若α不能推导出ε,则SELECT(A→α)=FIRST(α);如果α能推导出ε则：SELECT(A→α)=（FIRST(α) –{ε}）∪FOLLOW(A)。需要注意的是，SELECT集是针对<code>产生式</code>而言的。</li>
<li>LL(1)文法：<br>一个上下文无关文法是LL(1)文法的充分必要条件是：对每个非终结符A的两个不同产生式，A→α, A→β,满足SELECT(A→α)∩SELECT(A→β)=空集  其中α，β不同时能推导出ε。</li>
</ol>
<h2 id="LL-1-证明定理"><a href="#LL-1-证明定理" class="headerlink" title="LL(1) 证明定理"></a>LL(1) 证明定理</h2><ol>
<li> 在每个产生式 A →α 1  |  α 2  | . . . | α n 中，对于所有的 i  和 j ： 1 ≤ i ， j ≤ n ， i ≠ j ， First ( α i  )  ∩ First ( α j ) 为空。</li>
<li> 若对于每个非终结符 A 都有 First (A)  包含了 ε ，那么 First (A) ∩ Follow (A) 为空。</li>
</ol>
<h2 id="构造LL-1-预测分析表"><a href="#构造LL-1-预测分析表" class="headerlink" title="构造LL(1)预测分析表"></a>构造LL(1)预测分析表</h2><ol>
<li>对于文法G的每一个产生式A→α执行第2，3步</li>
<li>对每个终结符a∈FIRST(α)，把A→α加到M[A,a]中</li>
<li>若ε∈FIRST(α)，则对任何b∈FOLLOW(A)把A→α加入[A,b]中</li>
<li>其余无定义为出错</li>
</ol>
<ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200722173126.png"></li>
</ul>
<h1 id="第五章-自底向上的分析"><a href="#第五章-自底向上的分析" class="headerlink" title="第五章 自底向上的分析"></a>第五章 自底向上的分析</h1><h2 id="LR-1"><a href="#LR-1" class="headerlink" title="LR(1)"></a>LR(1)</h2><ul>
<li>LR(1)分析：L表示由左向右处理输入，R表示生成了最右推导，数字1表示先行一个符号</li>
<li>移进规约分析程序：主要任务是判断分析中的下一个句柄</li>
</ul>
<h1 id="第六章-语义分析"><a href="#第六章-语义分析" class="headerlink" title="第六章 语义分析"></a>第六章 语义分析</h1><h2 id="什么是语义分析"><a href="#什么是语义分析" class="headerlink" title="什么是语义分析"></a>什么是语义分析</h2><ul>
<li>语义分析也可称为<code>静态语义分析</code></li>
<li>语义分析包括：构造符号表，记录声明中建立的名字的含义，在表达式和语句中进行类型推断和类型检查，以及在语言的类型规则作用域内判断正确性</li>
<li>语义分析分为：程序的分析；由编译程序执行的分析</li>
</ul>
<h2 id="什么是属性"><a href="#什么是属性" class="headerlink" title="什么是属性"></a>什么是属性</h2><ul>
<li>属性： 属性是编程语言结构的任意特性。属性在其包含的信息和复杂性等方面变化很大，特别是当它们能确定时翻译 / 执行过程的时间。属性的典型例子有：<br>•变量的数据类型。<br>•表达式的值。<br>•存储器中变量的位置。<br>•程序的目标代码。<br>•数的有效位数。</li>
</ul>
<h2 id="什么是属性文法"><a href="#什么是属性文法" class="headerlink" title="什么是属性文法"></a>什么是属性文法</h2><ul>
<li>确定语言实体的属性或特性，它们必须进行计算并写成属性等式或语义规则，并描述这些属性的计算如何与语言的文法规则相关。这样的一组属性和等式称作<code>属性文法</code>。</li>
</ul>
<h2 id="什么是联编"><a href="#什么是联编" class="headerlink" title="什么是联编"></a>什么是联编</h2><ul>
<li>联编： 属性的计算及将计算值与正在讨论的语言结构联系的过程称作属性的联编。</li>
<li>联编时间： 联编属性发生时编译 / 执行过程的时间称作联编时间 。</li>
<li>执行之前联编的属性是<code>静态</code>的，</li>
<li>执行期间联编的属性是<code>动态</code>的。</li>
</ul>
<h2 id="静态动态"><a href="#静态动态" class="headerlink" title="静态动态"></a>静态动态</h2><ul>
<li>在如 C 或 Pascal 这样的静态类型的语言中，变量或表达式的数据类型是一个重要的编译时属性。</li>
<li>FORTRAN7 7 中所有的变量都是静态分配。</li>
<li>程序的目标代码无疑是一个静态属性。</li>
<li>表达式的值通常是动态的，编译程序要在执行时生成代码来计算这些值。</li>
<li>变量的分配可以是静态的也可以是动态的，这依赖于语言和变量自身的特性</li>
<li>LIS P 中所有的变量是动态分配的。</li>
<li>C 和 Pasca l 语言混合了静态和动态的两种变量分配。</li>
<li>数 的有效位数在编译期间是一个不被明确探讨的属性。</li>
</ul>
<h2 id="符号表"><a href="#符号表" class="headerlink" title="符号表"></a>符号表</h2><ul>
<li>是一种目录数据结构</li>
<li>符号表的主要操作：插入，查找，删除。</li>
<li>符号表的功能：<br>（1）   建立存储信息<br>（2）   类型检查<br>（3）   数据地址</li>
</ul>
<h1 id="第七章-运行时的环境"><a href="#第七章-运行时的环境" class="headerlink" title="第七章 运行时的环境"></a>第七章 运行时的环境</h1><h2 id="运行环境"><a href="#运行环境" class="headerlink" title="运行环境"></a>运行环境</h2><ul>
<li>完全静态环境：FORTRAN77，所有数据都是静态的，执行期间保持固定。这样的环境可用来实现没有指针或动态分配，且过程不可递归调用的语言。</li>
<li>基于栈的环境：C，C++，Pascal，Ada。在允许递归调用以及每一个调用中都重新分配局部变量的语言中，不能静态地分配活动记录。相反地，必须以一个基于栈的风格来分配活动记录，即当进行一个新的过程调用 ( 活动记录的压入时，每个新的活动记录都分配在栈的顶部，而当调用退出时则再次解除分配 。</li>
<li>完全动态环境：LISP。因为活动记录仅在对它们所有的引用都消失了才再重新分配，而且这又要求活动记录在执行时可动态地释放任意次，所以称这个环境为完全动态的 。</li>
</ul>
<h1 id="第八章-代码生成"><a href="#第八章-代码生成" class="headerlink" title="第八章 代码生成"></a>第八章 代码生成</h1><h2 id="中间代码"><a href="#中间代码" class="headerlink" title="中间代码"></a>中间代码</h2><ul>
<li>两种形式：三地址码，P代码</li>
<li>中间代码应具备的特性<br>1）便于语法制导翻译<br>2）既与机器指令的结构相近,又与具体机器无关.</li>
</ul>
<h2 id="控制语句"><a href="#控制语句" class="headerlink" title="控制语句"></a>控制语句</h2><ul>
<li>控制语句的分类：①无条件转移、②条件转移、③循环语句、④分支语句</li>
</ul>
<h2 id="代码优化"><a href="#代码优化" class="headerlink" title="代码优化"></a>代码优化</h2><ul>
<li>代码优化：对程序进行各种等价变换，使得从变换后的程序出发，能产生更有效的目标代码。</li>
<li>目的：产生高效的目标代码。</li>
<li>级别：局部优化、循环优化、全局优化。</li>
</ul>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><ul>
<li>活前缀：右句型的前缀，而且其右端不会超过该句型的最右边句柄的末端。<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200722172904.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200722172937.png"></li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>大学课程</tag>
        <tag>编译原理</tag>
      </tags>
  </entry>
  <entry>
    <title>学习笔记 | 《算法导论》之从入门到放弃（3）</title>
    <url>/posts/54183.html</url>
    <content><![CDATA[<p>算法导论打卡3，主要内容：堆排序</p>
<h1 id="第六章-堆排序"><a href="#第六章-堆排序" class="headerlink" title="第六章 堆排序"></a>第六章 堆排序</h1><h2 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h2><ul>
<li>二叉堆是一个数组，它可以被看成一个近似的完全二叉树。树上的每一个结点对应数组中的一个元素。除了最底层外，该树是完全充满的，而且是从左向右填充。</li>
<li>表示堆的数组A包括两个属性：A.length(通常)给出数组元素的个数，A.heap-size表示有多少个堆元素存储在该数组中。也就是说虽然A[1..A.length]可能都存有数据，但只有A[1..A.heap-size]中存放的是堆的有效元素，这里0≤A.heap-size≤A.length。树的根节点是A[1]，这样给定一个结点的下标i，我们很容易计算得到它的父结点，左孩子和右孩子的下标：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parent</span>(<span class="params">i</span>):</span></span><br><span class="line">	<span class="keyword">return</span> i//<span class="number">2</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">left</span>(<span class="params">i</span>):</span></span><br><span class="line">	<span class="keyword">return</span> <span class="number">2</span>*i</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">right</span>(<span class="params">i</span>):</span></span><br><span class="line">	<span class="keyword">return</span> <span class="number">2</span>*i+<span class="number">1</span></span><br></pre></td></tr></table></figure>

<ul>
<li><img src="https://s2.ax1x.com/2019/10/31/Ko9IoQ.md.png" alt="Ko9IoQ.md.png"></li>
<li>二叉堆可以分为两种形式：最大堆和最小堆。在这两种堆中，结点的值都要满足堆的性质。区别在于：<ul>
<li>最大堆中，最大堆性质是指除了根以外的所有结点i都要满足：A[PARENT(i)]≥A[i]，即在任一子树中，该子树所包含的所有结点的值都不大于该子树根节点的值。</li>
<li>最小堆中，最小堆性质是指除了根以外的所有结点i都要满足：A[PARENT(i)]≤A[i]</li>
</ul>
</li>
<li>在堆排序算法中，我们使用最大堆。最小堆通常用于构造优先队列。</li>
<li>如果把堆看成一棵树，我们定义一个堆中的结点的高度是该节点到叶结点最长简单路径上<code>边的数目</code>。既然一个包含n个元素的堆可以看作是一颗完全二叉树，那么该堆的高度是<code>O(lgn)</code></li>
<li>堆结构上的一些基本操作的运行时间至多与树的高度成正比，即时间复杂度为O(lgn).</li>
</ul>
<h2 id="维护堆的性质"><a href="#维护堆的性质" class="headerlink" title="维护堆的性质"></a>维护堆的性质</h2><ul>
<li>通过让A[i]的值在最大堆中“逐级下降”，从而使得以下标i为根结点的子树重新遵循最大堆的性质：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_heapify</span>(<span class="params">A,i</span>):</span></span><br><span class="line">    l,r=<span class="number">2</span>*i,<span class="number">2</span>*i+<span class="number">1</span></span><br><span class="line">    heap_size=<span class="built_in">len</span>(A)-<span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span>(l&lt;=heap_size <span class="keyword">and</span> A[l]&gt;A[i]):</span><br><span class="line">        largest=l</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        largest=i</span><br><span class="line">    <span class="keyword">if</span>(r&lt;=heap_size <span class="keyword">and</span> A[r]&gt;A[largest]):</span><br><span class="line">        largest=r</span><br><span class="line">    <span class="keyword">if</span>(largest!=i):</span><br><span class="line">        temp=A[i]</span><br><span class="line">        A[i]=A[largest]</span><br><span class="line">        A[largest]=temp</span><br><span class="line">        max_heapify(A,largest)</span><br></pre></td></tr></table></figure>
<ul>
<li>对于一个高为h的结点来说，max_heapify的时间复杂度是O(h)。</li>
</ul>
<h2 id="建堆"><a href="#建堆" class="headerlink" title="建堆"></a>建堆</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_max_heap</span>(<span class="params">A</span>):</span></span><br><span class="line">	<span class="comment">#A[0]存储堆元数个数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,A[<span class="number">0</span>]//<span class="number">2</span>+<span class="number">1</span>)[::-<span class="number">1</span>]:</span><br><span class="line">        max_heapify(A,i)</span><br></pre></td></tr></table></figure>
<ul>
<li>完整代码：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_heapify</span>(<span class="params">A,i</span>):</span></span><br><span class="line">    l,r=<span class="number">2</span>*i,<span class="number">2</span>*i+<span class="number">1</span></span><br><span class="line">    heap_size=A[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span>(l&lt;=heap_size <span class="keyword">and</span> A[l]&gt;A[i]):</span><br><span class="line">        largest=l</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        largest=i</span><br><span class="line">    <span class="keyword">if</span>(r&lt;=heap_size <span class="keyword">and</span> A[r]&gt;A[largest]):</span><br><span class="line">        largest=r</span><br><span class="line">    <span class="keyword">if</span>(largest!=i):</span><br><span class="line">        temp=A[i]</span><br><span class="line">        A[i]=A[largest]</span><br><span class="line">        A[largest]=temp</span><br><span class="line">        max_heapify(A,largest)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_max_heap</span>(<span class="params">A</span>):</span></span><br><span class="line">	<span class="comment">#A[0]存储堆元数个数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,A[<span class="number">0</span>]//<span class="number">2</span>+<span class="number">1</span>)[::-<span class="number">1</span>]:</span><br><span class="line">        max_heapify(A,i)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">	<span class="comment">#数组的第一个位置存储堆元素个数，并用于占位</span></span><br><span class="line">    A=[<span class="number">9</span>,<span class="number">50</span>, <span class="number">16</span>, <span class="number">30</span>, <span class="number">10</span>, <span class="number">60</span>,  <span class="number">90</span>,  <span class="number">2</span>, <span class="number">80</span>, <span class="number">70</span>]</span><br><span class="line">    build_max_heap(A)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,A[<span class="number">0</span>]+<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(A[i])</span><br></pre></td></tr></table></figure>

<h2 id="堆排序算法"><a href="#堆排序算法" class="headerlink" title="堆排序算法"></a>堆排序算法</h2><ul>
<li>因为数组的最大元素总是在根结点A[1]中，通过把它与A[n]进行互换，我们可以把该元素放到正确的位置上(如从小到大排列)</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_heapify</span>(<span class="params">A,i</span>):</span></span><br><span class="line">    l,r=<span class="number">2</span>*i,<span class="number">2</span>*i+<span class="number">1</span></span><br><span class="line">    heap_size=A[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span>(l&lt;=heap_size <span class="keyword">and</span> A[l]&gt;A[i]):</span><br><span class="line">        largest=l</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        largest=i</span><br><span class="line">    <span class="keyword">if</span>(r&lt;=heap_size <span class="keyword">and</span> A[r]&gt;A[largest]):</span><br><span class="line">        largest=r</span><br><span class="line">    <span class="keyword">if</span>(largest!=i):</span><br><span class="line">        temp=A[i]</span><br><span class="line">        A[i]=A[largest]</span><br><span class="line">        A[largest]=temp</span><br><span class="line">        max_heapify(A,largest)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_max_heap</span>(<span class="params">A</span>):</span></span><br><span class="line">	<span class="comment">#A[0]存储堆元数个数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,A[<span class="number">0</span>]//<span class="number">2</span>+<span class="number">1</span>)[::-<span class="number">1</span>]:</span><br><span class="line">        max_heapify(A,i)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heapsort</span>(<span class="params">A</span>):</span></span><br><span class="line">	build_max_heap(A)</span><br><span class="line">	n=A[<span class="number">0</span>]</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,n+<span class="number">1</span>)[::-<span class="number">1</span>]:</span><br><span class="line">		temp=A[<span class="number">1</span>]</span><br><span class="line">		A[<span class="number">1</span>]=A[i]</span><br><span class="line">		A[i]=temp</span><br><span class="line">		A[<span class="number">0</span>]-=<span class="number">1</span></span><br><span class="line">		max_heapify(A,<span class="number">1</span>)</span><br><span class="line">	A[<span class="number">0</span>]=n</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">	<span class="comment">#数组的第一个位置存储堆元素个数，并用于占位</span></span><br><span class="line">    A=[<span class="number">9</span>,<span class="number">50</span>, <span class="number">16</span>, <span class="number">30</span>, <span class="number">10</span>, <span class="number">60</span>,  <span class="number">90</span>,  <span class="number">2</span>, <span class="number">80</span>, <span class="number">70</span>]</span><br><span class="line">    heapsort(A)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,A[<span class="number">0</span>]+<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(A[i])</span><br></pre></td></tr></table></figure>

<ul>
<li>heapsort的时间复杂度是O(nlgn),因为每次调用build_max_heap的时间复杂度是O(n)，而n-1次调用max_heapify，每次的时间是O(lgn)。</li>
</ul>
<h2 id="优先队列"><a href="#优先队列" class="headerlink" title="优先队列"></a>优先队列</h2><ul>
<li>优先队列是一种用来维护由一组元素构成的集合S的数据结构，其中的每一个元素都有一个相关的值，称为关键字。</li>
<li>一个最大优先队列支持以下操作：<ul>
<li>insert(S,x)：把元素x插入集合S中。</li>
<li>maximum(S)：返回S中具有最大关键字的元素。</li>
<li>extract-max(S)：去掉并返回S中具有最大关键字的元素。</li>
<li>increase-key(S,x,k)：将元素x的关键字值增加到k，这里假设k的值不小于x的原关键字值。</li>
</ul>
</li>
<li>最小优先队列同理</li>
<li>实现：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heap_maximum</span>(<span class="params">A</span>):</span></span><br><span class="line">    <span class="keyword">return</span> A[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heap_extract_max</span>(<span class="params">A</span>):</span></span><br><span class="line">    heap_size=<span class="built_in">len</span>(A)-<span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span>(heap_size&lt;<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">raise</span> IndexError(<span class="string">&quot;heap underflow&quot;</span>)</span><br><span class="line">    Max=A[<span class="number">1</span>]</span><br><span class="line">    A[<span class="number">1</span>]=A[heap_size]</span><br><span class="line">    heap_size-=<span class="number">1</span></span><br><span class="line">    max_heapify(A,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> Max</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heap_increase_key</span>(<span class="params">A,i,key</span>):</span></span><br><span class="line">    <span class="keyword">if</span>(key&lt;A[i]):</span><br><span class="line">        <span class="keyword">raise</span> Exception,<span class="string">&quot;new key is small than current key&quot;</span></span><br><span class="line">    A[i]=key</span><br><span class="line">    <span class="keyword">while</span>(i&gt;<span class="number">1</span> <span class="keyword">and</span> A[parent[i]]&lt;A[i]):</span><br><span class="line">        temp=A[i]</span><br><span class="line">        A[i]=A[parent[i]]</span><br><span class="line">        A[parent[i]]=temp</span><br><span class="line">        i=parent[i]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_heap_insert</span>(<span class="params">A,key</span>):</span></span><br><span class="line">    heap_size+=<span class="number">1</span></span><br><span class="line">    A[heap_size]=<span class="built_in">float</span>(<span class="string">&#x27;-inf&#x27;</span>)</span><br><span class="line">    heap_increase_key(A,heap_size,key)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>大学课程 | 计算机操作系统</title>
    <url>/posts/8398.html</url>
    <content><![CDATA[<p>大二计算机操作系统课程笔记</p>
<h1 id="计算机操作系统"><a href="#计算机操作系统" class="headerlink" title="计算机操作系统"></a>计算机操作系统</h1><h2 id="第一章-操作系统引论"><a href="#第一章-操作系统引论" class="headerlink" title="第一章 操作系统引论"></a>第一章 操作系统引论</h2><ul>
<li>操作系统是配置在计算机硬件上的第一层软件，是对硬件系统的首次扩充。</li>
</ul>
<h3 id="1-1-操作系统的目标和作用"><a href="#1-1-操作系统的目标和作用" class="headerlink" title="1.1 操作系统的目标和作用"></a>1.1 操作系统的目标和作用</h3><ul>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109080914112.png" alt="Image [4]"></li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109080911146.png" alt="Image [3]"></li>
<li>操作系统的地位：紧贴于系统硬件之上，所有其他软件之下（是其他软件的共同环境）。</li>
</ul>
<h4 id="1-1-1-操作系统的目标"><a href="#1-1-1-操作系统的目标" class="headerlink" title="1.1.1 操作系统的目标"></a>1.1.1 操作系统的目标</h4><hr>
<ol>
<li><strong>方便性</strong>：对<strong>用户</strong>方便，提供良好的，一致的用户接口</li>
<li><strong>有效性</strong>：对<strong>系统管理人员</strong>方便<br> （1）提高了系统资源的利用率<br> （2）提高系统吞吐量</li>
<li><strong>可扩充性</strong>：与OS结构相关，方便添加新的功能和模块<br> 早期无结构→模块化结构→层次结构→微内核结构和客户服务器模式</li>
<li><strong>开放性</strong>：开放系统互连OSI国际标准，实现应用的可移植性和互操作性</li>
</ol>
<h4 id="1-1-2-操作系统的作用"><a href="#1-1-2-操作系统的作用" class="headerlink" title="1.1.2 操作系统的作用"></a>1.1.2 操作系统的作用</h4><hr>
<blockquote>
<p>操作系统的非形式化定义（关键点）：<strong>系统软件，程序模块的集合，资源管理和用户接口功能</strong></p>
</blockquote>
<ol>
<li>OS作为用户与计算机硬件系统之间的接口</li>
</ol>
<ul>
<li>通过三种方式使用计算机：<strong>命令方式</strong>，<strong>系统调用方式</strong>，<strong>图标—窗口方式</strong></li>
</ul>
<ol start="2">
<li>OS作为计算机系统资源的管理者</li>
</ol>
<ul>
<li>对这些资源：<u style="line-height: 160%; box-sizing: content-box;">处理机，存储器，I/O设备以及文件（数据和程序）</u><strong>有效的管理</strong>。</li>
</ul>
<ol start="3">
<li>OS实现了对计算机资源的抽象（OS是扩展机，是虚拟机器）</li>
</ol>
<ul>
<li>在裸机上添加：设备管理、文件管理、存储管理（针对内存和外存）、处理机管理（针对CPU）</li>
<li>合理组织工作流程：作业管理、进程管理。</li>
</ul>
<h4 id="1-1-3-推动操作系统发展的主要动力"><a href="#1-1-3-推动操作系统发展的主要动力" class="headerlink" title="1.1.3 推动操作系统发展的主要动力"></a>1.1.3 推动操作系统发展的主要动力</h4><ol>
<li>不断提高计算机资源利用率和系统性能</li>
<li>方便用户</li>
<li>器件的不断更新换代</li>
<li>计算机体系结构的不断发展</li>
<li>不断提出新的应用需求</li>
</ol>
<h3 id="1-2-操作系统的发展过程"><a href="#1-2-操作系统的发展过程" class="headerlink" title="1.2 操作系统的发展过程"></a>1.2 操作系统的发展过程</h3><h4 id="1-2-1-未配置操作系统的计算机系统"><a href="#1-2-1-未配置操作系统的计算机系统" class="headerlink" title="1.2.1 未配置操作系统的计算机系统"></a>1.2.1 未配置操作系统的计算机系统</h4><p>一， 人工操作方式：</p>
<ol>
<li>计算机的工作特点</li>
</ol>
<ul>
<li><strong>用户独占全机</strong><br>  （用户是程序元，计算机专业人员）<br>  （编程语言是机器语言）<br>  （输入/输出：纸带或卡片）</li>
<li><strong>CPU等待人工操作</strong>：严重降低计算机资源的利用率，存在人机矛盾</li>
</ul>
<ol start="2">
<li>主要矛盾（<strong>人机矛盾</strong>）：</li>
</ol>
<ul>
<li>计算机处理能力的提高，手工操作的低效率（造成浪费）</li>
<li>用户独占全机的所有资源</li>
</ul>
<ol start="3">
<li>提高效率的途径：<br> 专门的操作员，批处理</li>
</ol>
<p>二，脱机输入/输出方式：</p>
<ol>
<li>工作方式：</li>
</ol>
<ul>
<li>程序和数据的输入输出都是在外围机的控制下完成的，或者说，是在脱离主机的情况下进行的</li>
</ul>
<ol start="2">
<li>优点：</li>
</ol>
<ul>
<li>减少了CPU空闲时间</li>
<li>提高了I/O速度</li>
</ul>
<h4 id="1-2-2-单道批处理系统"><a href="#1-2-2-单道批处理系统" class="headerlink" title="1.2.2 单道批处理系统"></a>1.2.2 单道批处理系统</h4><ol>
<li>单道批处理系统的处理过程：</li>
</ol>
<ul>
<li>通过作业控制语言将磁带（或卡片）上的若干个作业编成作业执行序列，自动实现作业间的自动转换。每个批作业由一个专门的<strong>监督程序</strong>自动依次处理。</li>
<li>程序和数据虽然是成组成批提交，但是<u style="line-height: 160%; box-sizing: content-box;">任一时间只有一个作业运行</u>，因此称为单道批处理。</li>
<li>批处理中的作业的组成：包括用户程序、数据和作业说明书（作业控制语言）</li>
</ul>
<ol start="2">
<li>单道批处理系统的特征：</li>
</ol>
<ul>
<li>自动性</li>
<li>顺序性</li>
<li>单道性</li>
</ul>
<ol start="3">
<li>优点：</li>
</ol>
<ul>
<li>同一批内各作业的自动依次更替，改善了主机CPU和I/O设备的使用效率，提高了吞吐量。</li>
</ul>
<ol start="4">
<li>缺点：</li>
</ol>
<ul>
<li>主要缺点：系统的<strong>资源得不到充分的利用</strong>。CPU和I/O设备使用忙闲不均</li>
<li>磁带或磁盘需要人工装卸，作业需要人工分类</li>
<li>监督程序易遭到用户程序的破坏（由人工干预才可恢复）。</li>
<li>I/O与CPU之间的速差造成的CPU空闲</li>
</ul>
<h4 id="1-2-3-多道批处理系统"><a href="#1-2-3-多道批处理系统" class="headerlink" title="1.2.3 多道批处理系统"></a>1.2.3 多道批处理系统</h4><ol>
<li>多道批处理系统的概念：在系统中，用户所提交的作业先存放在外存上，并排列成一个队列，称为“后备队列”，然后由作业调度程序按一定的算法，从后备队列中选出若干个作业调入内存，使它们共享CPU和系统中的各种资源。在程序A因I/O操作而空闲CPU时，运行程序B，使<strong>多道程序交替运行</strong>。</li>
</ol>
<ul>
<li>内存中同时存放几个作业：<br>  （1）<strong>宏观上并行运算</strong><br>  （2）<strong>微观上串行运算</strong></li>
<li>特点：<br>  （1）<strong>多道性</strong>：<br>  多道程序驻留内存：提高了资源的利用率；<br>  程序并发执行：提高了系统的吞吐量<br>  （2）<strong>无序性</strong>：<br>  作业进入内存先后顺序和完成的先后顺序无对应性<br>  （3）<strong>调度性</strong>：<br>  作业调度<br>  进程调度</li>
</ul>
<ol start="2">
<li>优点：<br> （1）资源利用率高：<strong>并发执行</strong><br> （2）系统吞吐量大：①保持忙碌②系统开销小</li>
<li>缺点：<br> （1）平均周转时间长<br> （2）无交互能力</li>
<li>多道批处理系统需要解决的问题：<br> （1）处理机争用问题<br> （2）内存分配和保护问题<br> （3）I/O设备分配问题<br> （4）文件的组织和管理问题<br> （5）作业管理问题<br> （6）用户与系统的接口问题</li>
</ol>
<ul>
<li>操作系统是一组控制和管理计算机硬件和软件资源，合理地对各类作业进调度，以及方便用户使用的程序集合</li>
<li>单道与多道的区别：</li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109080906669.png" alt="Image"></li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109080859830.png" alt="下载"></li>
</ul>
<h4 id="1-2-4-分时系统"><a href="#1-2-4-分时系统" class="headerlink" title="1.2.4 分时系统"></a>1.2.4 分时系统</h4><ol>
<li>分时系统的引入，用户需求具体表现在：<br> （1）人机交互<br> （2）共享主机<br> （3）便于用户上机</li>
<li>分时系统实现中的关键问题：<br> （1）及时接收<br> （2）及时处理：<ul>
<li>  作业直接进入内存</li>
<li>  采用轮转运行方式：引入<strong>时间片</strong></li>
<li>  分为抢先式和非抢先式的OS（CPU让出OS的方式是自动还是强迫）</li>
</ul>
</li>
<li>分时系统的特征：<br> （1）多路性：共享主机<br> （2）独立性：感觉像是用户独占主机<br> （3）交互性<br> （4）及时性</li>
</ol>
<h4 id="1-2-5-实时系统"><a href="#1-2-5-实时系统" class="headerlink" title="1.2.5 实时系统"></a>1.2.5 实时系统</h4><ul>
<li>主要特征：将<strong>时间</strong>作为关键参数</li>
<li>特点：（1）<strong>可靠性强</strong>（2）<strong>响应时间短</strong></li>
</ul>
<ol>
<li>实时系统的类型：<br> 工业（武器）控制系统，信息查询系统，多媒体系统，嵌入式系统</li>
<li>实时任务的类型：<br> （1）周期性，非周期性：截至时间：①开始截止时间②完成截止时间<br> （2）硬实时，软实时：<ul>
<li>  硬实时：满足对截止时间的要求</li>
<li>  软实时：不严格要求截止时间</li>
<li>  <img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109080908858.png" alt="Image [2]"></li>
</ul>
</li>
</ol>
<h4 id="1-2-6-微机操作系统的发展"><a href="#1-2-6-微机操作系统的发展" class="headerlink" title="1.2.6 *微机操作系统的发展"></a>1.2.6 *微机操作系统的发展</h4><ul>
<li>软件工程的出现：<br>  操作系统在结构、规模、数量、接口等方面都得到了简化：结构从复杂到简单，规模从大到小，核心外移。<br>  实际系统的数量由于通用、开放和标准化而大量减少。</li>
<li>小型化与网络：<br>  微机操作系统和个人操作系统</li>
<li>网络操作系统：<br>  （1）通过通信设施将物理上分散的具有自治功能的多个计算机系统互连起来的实现信息交换、资源共享、可互操作和协作处理的系统。<br>  （2）在各种计算机操作系统上，按网络体系结构协议标准开发的软件<br>  （3）包括网络管理、通信、安全、资源共享和各种网络应用<br>  （4）目标：是相互通信及资源共享</li>
<li>分布式操作系统：<br>  1）特征：<br>  （1）是一个统一的操作系统<br>  （2）资源进一步共享<br>  （3）透明性：资源共享与分布对用户是透明的<br>  （4）自治性：处于分布式系统的多个主机处于平等地位，无主从关系<br>  （5）处理能力增强、速度更快、可靠性增强<br>  2）网络和分布式的区别：<br>  （1）分布式具有各个计算机间相互通讯，无主从关系；网络有主从关系<br>  （2）分布式系统资源为所有用户共享；而网络有限制地共享<br>  （3）分布式系统中若干个计算机可相互协作共同完成一项任务</li>
<li>嵌入式系统：<br>  （1）在各种设备、装置或系统中，完成特定功能的软硬件系统。它们是一个大设备、装置或系统中的一部分，这个大设备、装置或系统可以不是“计算机”。由于它们被嵌入在各种设备、装置或系统中，因此称为嵌入式系统<br>  （2）EOS（Embedded Operating System）在嵌入式系统中的OS，运行在嵌入式智能芯片环境中<br>  （3）典型嵌入式操作系统的特性：<ul>
<li>  完成某一项或有限项功能；不是通用型的</li>
<li>  在性能和实时性方面有严格的限制</li>
<li>  能源、成本和可靠性通常是影响设计的重要因素</li>
<li>  占有资源少、易于连接</li>
<li>  系统功能可针对需求进行裁剪、调整和生成，以便满足最终产品的设计要求</li>
</ul>
</li>
</ul>
<hr>
<ol>
<li>单用户单任务操作系统：</li>
</ol>
<ul>
<li>只允许一个用户上机，且只允许用户程序作为一个任务运行</li>
<li>CP/M ， MS-DOS</li>
</ul>
<ol start="2">
<li>单用户多任务操作系统：</li>
</ol>
<ul>
<li>只允许一个用户上机，但允许用户把程序分为若干个任务，并使他们并发执行</li>
<li>Windows</li>
</ul>
<ol start="3">
<li>多用户多任务操作系统：</li>
</ol>
<ul>
<li>允许多个用户通过各自的终端，使用同一台机器，共享系统中的各种资源，而每个用户程序又可进一步分为几个任务，使它们能并发执行</li>
<li>UNIX OS</li>
</ul>
<hr>
<blockquote>
<p>操作系统的发展规律:<br>操作系统的发展是由底层硬件、软件技术与上层应用需求的发展推动的。<br>操作系统的每一步发展都是权衡的结果：可能性与必要性的权衡，性能与代价的权衡，方便和效率的权衡。</p>
</blockquote>
<table>
<thead>
<tr>
<th>项目</th>
<th>网络OS</th>
<th>分布式OS</th>
<th>多处理机OS</th>
</tr>
</thead>
<tbody><tr>
<td>单处理机</td>
<td>不像</td>
<td>像</td>
<td>像</td>
</tr>
<tr>
<td>相同OS（同质）</td>
<td>不需要</td>
<td>需要</td>
<td>需要</td>
</tr>
<tr>
<td>有多少个OS</td>
<td>n个</td>
<td>n个</td>
<td>1个</td>
</tr>
<tr>
<td>通信</td>
<td>共享文件</td>
<td>通讯协议</td>
<td>共享存储器</td>
</tr>
<tr>
<td>网络协议</td>
<td>不需要</td>
<td>不需要</td>
<td>需要</td>
</tr>
<tr>
<td>运行队列</td>
<td>不需要</td>
<td>不需要</td>
<td>需要</td>
</tr>
<tr>
<td>文件共享是否有限制</td>
<td>没有</td>
<td>有，需要特殊文件说明</td>
<td>有限制，需特殊文件</td>
</tr>
</tbody></table>
<h3 id="1-3-操作系统的基本特性"><a href="#1-3-操作系统的基本特性" class="headerlink" title="1.3 操作系统的基本特性"></a>1.3 操作系统的基本特性</h3><ul>
<li>四个基本特性：<strong>并发，共享，虚拟，异步</strong></li>
</ul>
<h4 id="1-3-1-并发"><a href="#1-3-1-并发" class="headerlink" title="1.3.1 并发"></a>1.3.1 并发</h4><ol>
<li>并行与并发：</li>
</ol>
<ul>
<li>并行性：两个或多个时间在<strong>同一时刻</strong>发生</li>
<li>并发性：两个或多个时间在<strong>同一时间间隔内</strong>发生</li>
</ul>
<ol start="2">
<li>引入进程</li>
</ol>
<ul>
<li>进程：<strong>在系统中能独立运行并作为资源分配的基本单位</strong></li>
<li>引入线程是现代操作系统的重要标志</li>
</ul>
<h4 id="1-3-2-共享"><a href="#1-3-2-共享" class="headerlink" title="1.3.2 共享"></a>1.3.2 共享</h4><ul>
<li>OS环境下的资源共享或称资源复用，是指系统中的资源可供内存中多个并发执行的进程共同使用</li>
</ul>
<ol>
<li><strong>互斥共享方式</strong></li>
</ol>
<ul>
<li>资源可以提供给多个进程，但应规定在一段时间内，只允许访问一个进程访问该资源</li>
<li>资源分配后到释放之前，不能被其他进程所用</li>
<li>临界资源：一段时间内只允许一个进程访问的资源</li>
</ul>
<ol start="2">
<li><strong>同时访问方式</strong></li>
</ol>
<ul>
<li>资源允许在一段时间内由多个进程“同时”对它们进行访问</li>
<li>可重入代码，磁盘文件</li>
<li><strong>并发和共享是多用户OS的两个最基本的特征</strong></li>
<li>资源分配难以达到最优化</li>
</ul>
<h4 id="1-3-3-虚拟"><a href="#1-3-3-虚拟" class="headerlink" title="1.3.3 虚拟"></a>1.3.3 虚拟</h4><ul>
<li>一个物理实体映射为若干个对应的逻辑实体</li>
<li><strong>虚拟是操作系统管理系统资源的重要手段，可提高资源利用率</strong>。</li>
<li>CPU－－每个用户（进程）的“虚处理机”</li>
<li>存储器－－每个进程都占有的地址空间（指令＋数据＋堆栈）</li>
<li>显示设备－－多窗口或虚拟终端(virtual terminal)</li>
</ul>
<ol>
<li><strong>时分复用技术</strong>：<br> （1）虚拟处理机技术<br> （2）虚拟设备技术</li>
<li><strong>空分复用技术</strong>：</li>
</ol>
<blockquote>
<p>虚拟的实现：如果是采用分时复用的方法，即对某一物理设备进行分时使用，设N是某物理设备所对应的虚拟的逻辑设备数，则每台虚拟设备的平均速度必然等于或低于物理设备速度的1/N。类似的如果是采用空分复用技术，此时一台虚拟设备平均占用的空间必然也等于或小于物理设备所拥有的空间的1/N</p>
</blockquote>
<h4 id="1-3-4-异步"><a href="#1-3-4-异步" class="headerlink" title="1.3.4 异步"></a>1.3.4 异步</h4><ul>
<li>也称不确定性，指进程的执行顺序和执行时间的不确定性；</li>
<li><strong>进程的运行速度不可预知</strong>：分时系统中，多个进程并发执行，“时走时停”，不可预知每个进程的运行推进快慢</li>
<li>判据：无论快慢，应该结果相同， 通过进程互斥和同步手段来保证</li>
<li><strong>难以重现</strong>系统在某个时刻的状态（包括重现运行中的错误）</li>
<li>性能保证：实时系统与分时系统相似，但通过资源预留以保证性能</li>
</ul>
<h3 id="1-4-操作系统的主要功能"><a href="#1-4-操作系统的主要功能" class="headerlink" title="1.4 操作系统的主要功能"></a>1.4 操作系统的主要功能</h3><h4 id="1-4-1-处理机管理功能"><a href="#1-4-1-处理机管理功能" class="headerlink" title="1.4.1 处理机管理功能"></a>1.4.1 处理机管理功能</h4><ul>
<li>处理机管理的主要功能：创建和撤销进程，对诸进程的运行进行协调，实现进程之间的信息交换以及按照一定的算法把处理机分配给进程</li>
</ul>
<ol>
<li><strong>进程控制</strong>：为作业创建进程，撤销（终止）已结束的进程以及控制进程在运行过程中的状态转换</li>
<li><strong>进程同步</strong>：</li>
</ol>
<ul>
<li><strong>重要功能</strong></li>
<li>主要功能：为多个进程的运行进行协调</li>
<li>常用的协调方式：<br>  （1）进程互斥方式<br>  （2）进程同步方式：常用信号量机制</li>
</ul>
<ol start="3">
<li>进程通信</li>
<li>调度：<br> （1）作业调度：从后备队列中按照一定的算法选择除若干个作业，为它们分配资源，将其调入内存后，为其建立进程，将它们插入就绪队列<br> （2）进程调度：从进程的就绪队列中按照一定的算法选出一个进程，将处理机分配給它，并为它设置运行现场，使其投入执行</li>
</ol>
<h4 id="1-4-2-存储器管理功能"><a href="#1-4-2-存储器管理功能" class="headerlink" title="1.4.2 存储器管理功能"></a>1.4.2 存储器管理功能</h4><ul>
<li>为多道程序的运行提供良好的环境，提高存储器的利用率，方便用户使用，并能从逻辑上扩充内存</li>
</ul>
<ol>
<li><strong>内存分配</strong><br> （1）静态分配方式：每个作业的内存空间是在作业装入时确定的，在作业装入后的整个运行期间不允许作业再次申请新的内存空间，也不允许在内存中移动<br> （2）动态分配方式：允许作业在运行期间继续申请新的附加内存空间，以适应程序和数据的动态增长，也允许作业在内存中移动。</li>
<li><strong>内存保护</strong>：保证进程间互不干扰、相互保密；如：访问合法性检查、甚至要防止从“垃圾”中窃取其他进程的信息</li>
<li><strong>地址映射</strong>：</li>
</ol>
<ul>
<li><strong>主要功能</strong></li>
<li>进程逻辑地址到内存物理地址的映射；</li>
</ul>
<ol start="4">
<li><strong>内存扩充</strong>：</li>
</ol>
<ul>
<li>从<strong>逻辑上</strong>扩充内存容量</li>
<li>设置内存扩充机制，以实现请求调入功能和置换功能</li>
</ul>
<h4 id="1-4-3-设备管理功能"><a href="#1-4-3-设备管理功能" class="headerlink" title="1.4.3 设备管理功能"></a>1.4.3 设备管理功能</h4><ul>
<li>主要任务：<br>  （1）完成用户进程提出的I/O请求<br>  （2）提高CPU和I/O设备的利用率</li>
</ul>
<ol>
<li><strong>缓冲管理</strong>：单缓冲机制，双缓冲机制，公用缓冲池机制</li>
<li><strong>设备分配</strong>：</li>
<li><strong>设备处理</strong>：</li>
</ol>
<ul>
<li>设备处理程序又叫：设备驱动程序，实现CPU和设备控制器之间的通信</li>
<li>根据中断请求的类型，调用相对应的中断处理程序</li>
</ul>
<h4 id="1-4-4-文件管理功能"><a href="#1-4-4-文件管理功能" class="headerlink" title="1.4.4 文件管理功能"></a>1.4.4 文件管理功能</h4><ul>
<li>主要任务：是对用户文件和系统文件进行管理以方便用户使用，并保证文件的安全性</li>
</ul>
<ol>
<li><strong>文件存储空间的管理</strong>：为每一个文件分配必要的外存空间，提高外存的利用率，进而提高文件系统的存取速度</li>
<li><strong>目录管理</strong>：方便存取，实现共享，提高文件检索的速度</li>
<li><strong>文件的读/写管理和保护</strong>：<br> （1）文件的读写/管理<br> （2）文件保护：防止未经核准的用户存取文件，防止冒名顶替存取文件，防止以不正确的方式使用文件</li>
<li><strong>软件管理</strong>：软件的版本、相互依赖关系、安装和拆除等</li>
</ol>
<h4 id="1-4-5-操作系统与用户之间的接口"><a href="#1-4-5-操作系统与用户之间的接口" class="headerlink" title="1.4.5 操作系统与用户之间的接口"></a>1.4.5 操作系统与用户之间的接口</h4><ol>
<li><strong>用户接口</strong>：用户通过该接口直接或间接地控制自己的作业<br> （1）联机用户接口<br> （2）脱机用户接口<br> （3）图形用户接口</li>
<li><strong>程序接口</strong>：为用户程序在执行中访问系统资源而设定的，是用户程序取得操作系统服务的唯一途径</li>
</ol>
<h4 id="1-4-6-现代操作系统的新功能"><a href="#1-4-6-现代操作系统的新功能" class="headerlink" title="1.4.6 现代操作系统的新功能"></a>1.4.6 现代操作系统的新功能</h4><ol>
<li>系统安全：<br> （1）认证技术<br> （2）密码技术<br> （3）访问技术<br> （4）反病毒技术</li>
<li>网络的功能和服务<br> （1）网络通信<br> （2）资源管理<br> （3）应用互操作<br> （4）支持多媒体<br> （1）接纳控制功能<br> （2）实施调度<br> （3）多媒体文件的存储</li>
</ol>
<h3 id="1-5-OS结构设计"><a href="#1-5-OS结构设计" class="headerlink" title="1.5 OS结构设计"></a>1.5 OS结构设计</h3><h4 id="1-5-1-传统操作系统结构"><a href="#1-5-1-传统操作系统结构" class="headerlink" title="1.5.1 传统操作系统结构"></a>1.5.1 传统操作系统结构</h4><ol>
<li>无结构操作系统</li>
<li>模块化结构OS<br> （1）基本概念：按功能精心地划分为若干个具有一定独立性和大小的模块，并仔细规定好各模块的间的接口，使各模块之间能通过接口实现交互。然后再细分为子模块，这种设计方法称为模块-接口法<br> （2）模块独立性：<ul>
<li>  内聚性：子模块内部各部分间联系的紧密程度，内聚性越高，模块独立性高</li>
<li>  耦合度，指模块间相互联系和相互影响的程度，耦合度越低，模块独立性越好</li>
</ul>
 （3） 模块接口法的优缺点：<br> 优点：<br> ①提高OS设计的正确性，可理解性，可维护性<br> ②增强OS的可适应性<br> ③加速OS的开发过程<br> 缺点：<br> ①接口很难满足实际需求<br> ②无序模块法，无法寻找一个可靠的决定顺序</li>
<li>分层式结构OS<br> （1）基本概念：有序分层法，每一步设计都建立在可靠的基础上，<strong>高层仅依赖于紧邻它的底层</strong><br> （2）优点：<br> ①易保证系统的正确性<br> ②易扩充和易维护性<br> （3）缺点：系统效率低</li>
</ol>
<h4 id="1-5-2-客户-服务器模式"><a href="#1-5-2-客户-服务器模式" class="headerlink" title="1.5.2 客户/服务器模式"></a>1.5.2 客户/服务器模式</h4><ol>
<li>客户/服务器模式的由来：<br> （1）客户机（2）服务器（3）网络系统</li>
<li>交互：<br> （1）客户发送请求消息<br> （2）服务器接受消息<br> （3）服务器回送消息<br> （4）客户机接受消息</li>
<li>优点：<br> （1）数据的分布式处理和存储<br> （2）便于集中管理<br> （3）灵活性和可扩充性<br> （4）易于改编应用软件</li>
<li>缺点：</li>
</ol>
<ul>
<li>不可靠性和瓶颈问题</li>
</ul>
<h4 id="1-5-3-面向对象的程序设计"><a href="#1-5-3-面向对象的程序设计" class="headerlink" title="1.5.3 面向对象的程序设计"></a>1.5.3 面向对象的程序设计</h4><ol>
<li>基本概念：（1）对象（2）对象类（3）继承</li>
<li>优点：（1）通过“重用”提高质量和效率（2）易修改性和易扩展性<br> （3）易于保证正确性和可靠性</li>
</ol>
<h4 id="1-5-4-微内核OS结构"><a href="#1-5-4-微内核OS结构" class="headerlink" title="1.5.4 微内核OS结构"></a>1.5.4 微内核OS结构</h4><ul>
<li>适用于分布式系统环境</li>
</ul>
<ol>
<li>基本概念：<br> （1）足够小的内核：最基本的部分：①与硬件处理紧密相关部分②较基本功能③C/S之间的通信<br> （2）基于C/S模式<br> （3）应用“机制和策略分离”原理：机制在低层，策略在系统高层<br> （4）采用面向对象编程</li>
<li>微内核的功能：<br> （1）进程（线程）管理：进程（线程）之间的通信是微内核OS最基本的功能<br> （2）低级存储器管理：实现用户空间的逻辑地址变换为内存空间的物理地址的页表机制和地址变换机制<br> （3）中断和陷入处理</li>
<li>微内核操作系统的优点：<br> （1）提高可扩展性<br> （2）增强系统可靠性<br> （3）可移植性增强<br> （4）支持分布式系统<br> （5）融入面向对象技术</li>
<li>微内核操作系统存在的问题</li>
</ol>
<ul>
<li>运行效率降低</li>
</ul>
<h2 id="第二章-进程的描述与控制"><a href="#第二章-进程的描述与控制" class="headerlink" title="第二章 进程的描述与控制"></a>第二章 进程的描述与控制</h2><h3 id="2-1-前趋图和程序执行"><a href="#2-1-前趋图和程序执行" class="headerlink" title="2.1 前趋图和程序执行"></a>2.1 前趋图和程序执行</h3><h4 id="2-1-1-前趋图"><a href="#2-1-1-前趋图" class="headerlink" title="2.1.1 前趋图"></a>2.1.1 前趋图</h4><ul>
<li><strong>有向无循环</strong>图，可记为DAG，用于描述进程之间的先后顺序。</li>
<li>图中结点：进程或程序段</li>
<li>有向边：结点之间的偏序或前趋关系</li>
<li>权值：每个结点的重量</li>
</ul>
<h4 id="2-1-2-程序的顺序执行"><a href="#2-1-2-程序的顺序执行" class="headerlink" title="2.1.2 程序的顺序执行"></a>2.1.2 程序的顺序执行</h4><ol>
<li>程序的顺序执行</li>
<li>程序的顺序执行时的特征：<br> （1）顺序性：每一个操作必须在下一个操作开始之前结束<br> （2）封闭性：程序运行时独占全机资源，程序一旦开始执行，其执行结果不受外界因素影响<br> （3）可再现性：只要程序执行时的环境和初始条件相同，当程序重复执行时。都可以得到相同的结果</li>
</ol>
<h4 id="2-1-3-程序并发执行"><a href="#2-1-3-程序并发执行" class="headerlink" title="2.1.3 程序并发执行"></a>2.1.3 程序并发执行</h4><ul>
<li>只有在<strong>不存在前驱关系</strong>的程序之间才有可能并发执行，否则无法并发执行</li>
<li>程序并发执行时的特征：<br>  （1）间断性<br>  （2）失去封闭性<br>  （3）不可在现性</li>
</ul>
<h3 id="2-2-进程的描述"><a href="#2-2-进程的描述" class="headerlink" title="2.2 进程的描述"></a>2.2 进程的描述</h3><h4 id="2-2-1-进程的定义和特征"><a href="#2-2-1-进程的定义和特征" class="headerlink" title="2.2.1 进程的定义和特征"></a>2.2.1 进程的定义和特征</h4><ol>
<li>进程的定义：<br> （1）进程是程序的一次执行<br> （2）进程是一个程序及其数据在处理机上顺序执行时所发生的活动<br> （3）进程是具有<strong>独立功能</strong>的<strong>程序</strong>在一个<strong>数据集合</strong>上<strong>运行的过程</strong>，它是系统进行资源分配和调度的一个独立单位。【数据集合说明：需要数据，运行的过程说明：有生命周期】</li>
</ol>
<ul>
<li>进程控制块（PCB）：描述进程的基本情况和活动过程，进而控制和管理进程</li>
<li>进程实体（进程映像）：包括：程序段，数据段，PCB</li>
<li>一个程序可能对应多个进程（程序的多次执行）</li>
<li>一个进程也可能对应多个程序（进程的多次调用）</li>
</ul>
<ol start="2">
<li>进程的特征：<br> （1）动态性：进程动，程序静<br> （2）并发性<br> （3）独立性<br> （4）异步性：进程暂时的，程序永久的<br> （5）结构性：程序段，数据段，PCB</li>
</ol>
<h4 id="2-2-2-进程的基本状态和转换"><a href="#2-2-2-进程的基本状态和转换" class="headerlink" title="2.2.2 进程的基本状态和转换"></a>2.2.2 进程的基本状态和转换</h4><ol>
<li><p>进程的三种基本状态：<br> （1）<strong>就绪状态</strong>：n个进程最多n-1个，多个就绪状态的进程排成就绪队列<br> （2）<strong>执行状态</strong>：单处理机只有一个，多处理机多个<br> （3）<strong>阻塞状态</strong>：最多n个，正在执行的进程由于发生某事件（如I/O请求，申请缓冲区失败等）暂时无法继续执行时的状态</p>
</li>
<li><p>三种基本状态的转换：  </p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109080910959.png" alt="1"></p>
</li>
<li><p>创建状态和终止状态  </p>
<p> <img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109080916841.png" alt="1 [2]"></p>
<p> （1）创建状态：进程由创建而产生，创建一个进程的步骤：首先，进程申请一个空白PCB，并向PCB中填写用于控制和管理进程的信息；然后为进程分配运行时所必须的资源；最后，把该进程转入就绪状态并插入就绪队列之中。如果进程所需的资源得不到满足，比如系统尚无足够的内存使进程无法装入其中 ，此时<u style="line-height: 160%; box-sizing: content-box;">创建工作尚未完成，进程不能被调度运行</u>，此时进程所处的状态被称为<strong>创建状态</strong><br> （2）终止状态<br> 首先，等待操作系统进行善后处理，最后将其PCB清零，并将PCB空间返回系统。当一个进程到达了自然结束点，或是出现了无法克服的错误清零，或是被操作系统所终结，或是被其他有终止权的进程所终结，它将进入<strong>终止状态</strong>。<u style="line-height: 160%; box-sizing: content-box;">进入终止态的进程以后不能再执行，但在操作系统中依然保留一个记录</u>，其中保存状态码和一些计时统计数据，供其他进程收集。</p>
</li>
</ol>
<h4 id="2-2-3-挂起操作和进程状态的转换"><a href="#2-2-3-挂起操作和进程状态的转换" class="headerlink" title="2.2.3 挂起操作和进程状态的转换"></a>2.2.3 挂起操作和进程状态的转换</h4><ul>
<li>当操作作用于某个进程时，该进程将被<strong>挂起</strong>，意味着此时此刻进程处于静止状态</li>
</ul>
<ol>
<li>挂起操作的引入：<br> （1）终端用户的需要<br> （2）父进程的请求<br> （3）负荷调节的需要<br> （4）操作系统的需要</li>
<li>引入挂起原语操作后三个进程状态的转换<br> （1）活动就绪→静止就绪<br> （2）活动阻塞→静止阻塞<br> （3）静止就绪→活动就绪<br> （4）静止阻塞→活动阻塞   <img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109080916635.png" alt="3BB2EF998AF2EEF84F0F3C41F998429D"></li>
<li>引入挂起操作后五个进程状态的转换<br> （1）NULL→创建：<br> （2）创建→活动就绪<br> （3）创建→静止就绪<br> （4）执行→终止</li>
</ol>
<h4 id="2-2-4-进程管理中的数据结构"><a href="#2-2-4-进程管理中的数据结构" class="headerlink" title="2.2.4 进程管理中的数据结构"></a>2.2.4 进程管理中的数据结构</h4><ol>
<li>操作系统中用于管理控制的数据结构</li>
</ol>
<ul>
<li>内存表</li>
<li>设备表</li>
<li>文件表</li>
<li>进程表PCB，进程控制块。有总数限制，</li>
</ul>
<ol start="2">
<li>进程控制块PCB的作用</li>
</ol>
<ul>
<li>在OS的核心为每一个进程专门定义了一个PCB，记录了操作系统所需的，用于描述进程的当前情况以及管理进程运行的全部信息，是操作系统中最重要的记录型数据结构。</li>
<li>PCB的作用是<strong>使一个在多道程序环境下不能独立运行的程序（含数据）成为一个能独立运行的基本单位，一个能与其他进程并发执行的进程</strong><br>  （1）<strong>作为独立运行的基本单位的标志</strong>：系统使通过PCB感知进程的存在的，PCB已成为进程存在的唯一标志<br>  （2）<strong>能实现间断性运行方式</strong>：将CPU现场信息保存在中断进程的PCB中，供该进程再次被调度执行时恢复CPU现场时使用<br>  （3）<strong>提供进程管理所需要的信息</strong><br>  （4）<strong>提供进程调度所需要的信息</strong><br>  （5）<strong>实现与其他进程的同步与通信</strong></li>
</ul>
<ol start="3">
<li>进程控制块中的信息：<br> （1）进程标识符：唯一地标识一个进程<ul>
<li>  ①外部标识符：由数字，字母构成</li>
<li>②内部标识符：为每一个进程赋予唯一的数字标识符，是一个进程的序号<br>  （2）处理机状态：</li>
<li>  处理机状态信息：①通用寄存器②指令计数器③程序状态字PSW④用户栈指针</li>
<li>CPU现场保护结构：寄存器值，主要由CPU的各种寄存器组成<br>  （3）进程调度信息：①进程状态②进程优先级③进程调度所需其他信息，与进程调度算法有关④事件，即阻塞原因<br>  （4）进程控制信息：①程序和数据的地址②进程同步和通信机制③资源清单④链接指针</li>
</ul>
</li>
<li>进程控制块的组织方式：<br> （1）线性方式<br> （2）链接方式<br> （3）索引方式</li>
</ol>
<h3 id="2-3-进程控制"><a href="#2-3-进程控制" class="headerlink" title="2.3 进程控制"></a>2.3 进程控制</h3><ul>
<li>进程控制一般是由OS内核中的原语来实现的</li>
</ul>
<h4 id="2-3-1-操作系统内核"><a href="#2-3-1-操作系统内核" class="headerlink" title="2.3.1 操作系统内核"></a>2.3.1 操作系统内核</h4><ul>
<li>OS内核：一般将OS划分为若干层次,将紧靠硬件的软件层次常驻内存</li>
<li>处理机的执行状态分为系统态和用户态：<ul>
<li>  系统态：又称管态，内核态，具有较高特权，能执行一切指令，访问所有的寄存器和存储区</li>
<li>  用户态：又称目态，具有较低权限</li>
</ul>
</li>
</ul>
<ol>
<li>支撑功能：<br> （1）<strong>中断处理</strong>：内核中最基本的功能，是整个操作系统赖以活动的基础<br> （2）<strong>时钟管理</strong><br> （3）<strong>原语操作</strong>：原语：<u style="line-height: 160%; box-sizing: content-box;">是由若干条指令组成的，用于完成一定功能的一个过程</u>，是<strong>原子操作</strong>，即要么都做，要么都不做</li>
<li>资源管理功能：<br> （1）进程管理<br> （2）存储器管理<br> （3）设备管理</li>
</ol>
<h4 id="2-3-2-进程的创建"><a href="#2-3-2-进程的创建" class="headerlink" title="2.3.2 进程的创建"></a>2.3.2 进程的创建</h4><ol>
<li>进程的层次结构</li>
</ol>
<ul>
<li>把创建进程的进程称为父进程，而把被创建的进程称为子进程，子进程还可以创建孙进程</li>
</ul>
<ol start="2">
<li>进程图：描述进程间关系的一颗有向树</li>
<li>引起创建进程的事件：<br> （1）用户登陆<br> （2）作业调度<br> （3）提供服务<br> （4）应用请求</li>
<li>进程的创建：<br> 步骤：<br> （1）申请空白PCB，为新进程获取唯一的数字标识符<br> （2）为其分配运行时所需的资源，包括物理和逻辑<br> （3）初始化进程控制块PCB：①初始化标识信息②初始化处理机状态信息③初始化处理机控制信息<br> （4）如果进程就绪队列能够接纳新进程，便将新进程插入就绪队列</li>
</ol>
<h4 id="2-3-3-进程的终止"><a href="#2-3-3-进程的终止" class="headerlink" title="2.3.3 进程的终止"></a>2.3.3 进程的终止</h4><ol>
<li>引起进程终止的事件：<br> （1）正常结束：通常会在程序的最后安排一条Halt指令，用于向OS表示运行已结束<br> （2）异常结束：<ul>
<li>  越界错</li>
<li>  保护错</li>
<li>  非法指令</li>
<li>  特权指令错</li>
<li>  运行超时</li>
<li>  等待超时</li>
<li>  算术超时</li>
<li>I/O故障<br>  （3）外界干预：</li>
<li>  操作员或操作系统干预</li>
<li>  父进程请求</li>
<li>  因父进程终止</li>
</ul>
</li>
<li>进程的终止过程：<br> （1）根据被终止进程的标识符，从PCB集合中检索该进程的PCB，从中读出该进程的状态<br> （2）若被终止进程正处于执行状态，应立即终止该进程的执行，并置调度标志为真，用于指示该进程被终止后应重新进行调度<br> （3）若该进程还有子孙进程，还应将其所有子孙进程也都给予终止，以防他们成为不可控进程<br> （4）将被终止进程所拥有的全部资源或者归还其父进程，或者归还系统<br> （5）将被终止进程（PCB）从所在队列（或链表）中移除，等待其他程序来搜集信息</li>
</ol>
<h4 id="2-3-4-进程的阻塞与唤醒"><a href="#2-3-4-进程的阻塞与唤醒" class="headerlink" title="2.3.4 进程的阻塞与唤醒"></a>2.3.4 进程的阻塞与唤醒</h4><ol>
<li>引起进程阻塞和唤醒的事件：<br> （1）向系统请求共享资源失败<br> （2）等待某种操作的完成<br> （3）新数据尚未到达<br> （4）等待新任务的到达</li>
<li>进程阻塞过程</li>
</ol>
<ul>
<li>进程主动调用阻塞原语block将自己阻塞</li>
</ul>
<ol start="3">
<li>进程唤醒过程</li>
</ol>
<ul>
<li>当被阻塞进程所期待的事件已经发生时，有关程序调用唤醒原语wakeup</li>
<li>wakeup：首先从阻塞队列中移除，将其PCB中的现行状态改为就绪，然后将该PCB插入到就绪队列</li>
</ul>
<h4 id="2-3-5-进程的挂起与激活"><a href="#2-3-5-进程的挂起与激活" class="headerlink" title="2.3.5 进程的挂起与激活"></a>2.3.5 进程的挂起与激活</h4><ol>
<li>进程的挂起：</li>
</ol>
<ul>
<li>原语suspend：检查被挂起进程的状态，若处于活动就绪状态→静止就绪，对于活动阻塞状态→静止阻塞，为方便用户或父进程考察进程的运行情况，把该进程PCB复制到某指定的内存区域，若被挂起的进程正在执行，则转向调度程序重新调度</li>
</ul>
<ol start="2">
<li>进程的激活过程</li>
</ol>
<ul>
<li>OS利用激活原语active：将进程从外存调入内存，检查该进程的现行状态，若静止就绪→活动就绪，若静止阻塞→活动阻塞</li>
</ul>
<h3 id="2-4-进程同步"><a href="#2-4-进程同步" class="headerlink" title="2.4 进程同步"></a>2.4 进程同步</h3><ul>
<li>使程序的执行具有可再现性</li>
</ul>
<h4 id="2-4-1-进程同步的基本概念"><a href="#2-4-1-进程同步的基本概念" class="headerlink" title="2.4.1 进程同步的基本概念"></a>2.4.1 进程同步的基本概念</h4><ol>
<li>两种形式的制约关系<br> （1）间接相互制约关系：多个进程互斥访问资源<br> （2）直接相互制约关系：多个进程相互合作</li>
<li>临界资源</li>
</ol>
<ul>
<li><strong>硬件或软件，多个进程在对其访问时，必须互斥进行</strong></li>
</ul>
<ol start="3">
<li>临界区</li>
</ol>
<ul>
<li><strong>临界区</strong>：每个进程中<strong>访问临界资源的那段代码</strong></li>
<li>进入区：临界区前面增加一段用于进行检查的代码</li>
<li>退出区：临界区后面用于将临界区正在被访问的标志恢复为未被访问的标志</li>
<li>剩余区：除了上诉区外的其他部分代码</li>
</ul>
<ol start="4">
<li>同步机制应遵循的规则<br> （1）<strong>空闲让进</strong>：临界资源空闲，应当允许一个请求进入临界区的进程立即进入自己的临界区，若有多个请求，必须挑一个<br> （2）<strong>忙则等待</strong>：若有临界资源正在被使用，其他进程需要等待。每次最多一个进程<br> （3）<strong>有限等待</strong>：每一个进程逗留有限时间<br> （4）<strong>让权等待</strong>：让出CPU竞争（不参与就绪，参与阻塞状态）</li>
</ol>
<h4 id="2-4-2-硬件同步机制"><a href="#2-4-2-硬件同步机制" class="headerlink" title="2.4.2 硬件同步机制"></a>2.4.2 硬件同步机制</h4><ol>
<li>关中断：</li>
</ol>
<ul>
<li>实现互斥的最简单的方法之一</li>
<li>在进入锁测试之前关闭中断，直到完成锁测试并上锁之后才能打开中断</li>
</ul>
<ol start="2">
<li>利用Test-and-Set指令实现互斥<br> 该指令读出标志后设标志置为TRUE<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="type">boolean</span> TS(<span class="type">boolean</span> *<span class="keyword">lock</span>) &#123;</span><br><span class="line">   <span class="type">boolean</span> <span class="built_in">old</span>;</span><br><span class="line">   <span class="built_in">old</span> = *<span class="keyword">lock</span>;</span><br><span class="line">   *<span class="keyword">lock</span> = <span class="keyword">TRUE</span>;</span><br><span class="line">   <span class="keyword">return</span> <span class="built_in">old</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>lock表示资源的两种状态：TRUE表示正被占用，FALSE表示空闲</li>
<li>利用TS实现进程互斥：每个临界资源设置一个公共布尔变量lock，初值为FALSE</li>
<li>在进入区利用TS进行检查：有进程在临界区时，重复检查；直到其它进程退出时，检查通过；<figure class="highlight sqf"><table><tr><td class="code"><pre><span class="line"><span class="keyword">do</span>&#123;</span><br><span class="line">...</span><br><span class="line">    <span class="keyword">while</span> TS(&amp;<span class="built_in">lock</span>);</span><br><span class="line">    critical section;   </span><br><span class="line">    <span class="built_in">lock</span> = <span class="literal">FALSE</span>;</span><br><span class="line">    remainder section;</span><br><span class="line">&#125;<span class="keyword">while</span>(<span class="literal">TRUE</span>);</span><br></pre></td></tr></table></figure></li>
</ul>
<ol start="3">
<li>利用Swap指令实现进程互斥</li>
</ol>
<ul>
<li>Swap指令（或Exchange指令）<br>  交换两个字（字节）的内容</li>
</ul>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">  <span class="type">void</span> SWAP(<span class="type">int</span> *a, <span class="type">int</span> *b) </span><br><span class="line">   &#123;</span><br><span class="line">       <span class="type">int</span> <span class="keyword">temp</span>;</span><br><span class="line">       <span class="keyword">temp</span> = *a; </span><br><span class="line">       *a = *b;  </span><br><span class="line">       *b = <span class="keyword">temp</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>利用Swap实现进程互斥：每个临界资源设置一个公共布尔变量lock，初值为FALSE。每个进程设置一个私有局部布尔变量key</p>
<figure class="highlight sqf"><table><tr><td class="code"><pre><span class="line"><span class="keyword">do</span>&#123;</span><br><span class="line">    key = <span class="literal">TRUE</span>；</span><br><span class="line">    <span class="keyword">do</span>&#123;</span><br><span class="line">        swap(&amp;<span class="built_in">lock</span>,&amp;key);</span><br><span class="line">    &#125;<span class="keyword">while</span> （key !=<span class="literal">FALSE</span>）;</span><br><span class="line">    临界区操作；</span><br><span class="line">    <span class="built_in">lock</span> = <span class="literal">FALSE</span>；</span><br><span class="line">    ...</span><br><span class="line">&#125;<span class="keyword">while</span> (<span class="literal">TRUE</span>);</span><br></pre></td></tr></table></figure>

<h4 id="2-4-3-信号量机制"><a href="#2-4-3-信号量机制" class="headerlink" title="2.4.3 信号量机制"></a>2.4.3 信号量机制</h4><ol>
<li>整型信号量：</li>
</ol>
<ul>
<li><p>wait和signal操作可描述为：</p>
<p>  wait(int s)<br>   {</p>
<pre><code>  while(s&lt;=0);
  s--;   
</code></pre>
<p>   }</p>
<p>  signal(int s)<br>  {</p>
<pre><code>s++;
</code></pre>
<p>  }</p>
</li>
<li><p>为临界资源设置一个互斥信号量mutex(MUTual Exclusion)，其初值为1；</p>
</li>
<li><p>在每个进程中将临界区代码置于wait(mutex)和signal(mutex)原语之间<br>  必须成对使用wait和signal原语：遗漏wait原语则不能保证互斥访问，遗漏signal原语则不能在使用临界资源之后将其释放（给其他等待的进程）；</p>
</li>
<li><p>wait、signal原语不能次序错误、重复或遗漏:</p>
</li>
</ul>
<ol start="2">
<li>记录型信号量机制</li>
</ol>
<ul>
<li>每个信号量s除一个整数值外s.count，还有一个进程等待队列s.queue，其中是阻塞在该信号量的各个进程的标识</li>
<li>信号量只能通过初始化和两个标准的原语来访问－－作为OS核心代码执行，不受进程调度的打断。</li>
</ul>
<ol start="3">
<li>AND型信号量</li>
<li>信号量集</li>
</ol>
<h4 id="2-4-4-信号量的应用"><a href="#2-4-4-信号量的应用" class="headerlink" title="2.4.4 信号量的应用"></a>2.4.4 信号量的应用</h4><ol>
<li>利用信号量实现进程互斥：</li>
</ol>
<ul>
<li>利用整型信号量机制实现进程互斥时应注意，wait(mutex)和signal(mutex)必须成对出现</li>
<li>缺少wait(mutex)会导致系统混乱，不能保证对临界资源的互斥访问</li>
<li>缺少signal(mutex)将会使临界资源永远不被释放，从而使因等待该资源而阻塞的进程不再被唤醒</li>
</ul>
<ol start="2">
<li>利用信号量实现前趋关系：</li>
</ol>
<ul>
<li>设有两个并发进程P1和P2。P1中有语句S1，P2中有语句S2，希望在执行完S1后执行S2</li>
<li>为实现这种前趋关系，可让进程P1和P2共享一个公用信号量S，并赋初值为0，将signal(S)操作放在语句S1后面；而在S2语句前插入wait(S)操作</li>
<li>进程P1， S1;signal(S);</li>
<li>进程P2， wati(S); S2;</li>
<li>由于S被初始化为0，若P2先执行，必定阻塞，只有在进程P1执行完使S增为1后，P2才能执行S2操作</li>
</ul>
<h4 id="2-4-5-管程机制"><a href="#2-4-5-管程机制" class="headerlink" title="2.4.5 管程机制"></a>2.4.5 管程机制</h4><ol>
<li>管程的定义：代表共享资源的<strong>数据结构</strong>以及由对该共享数据结构实施<strong>操作</strong>的一组过程所组成的资源管理程序共同构成了一个操作系统的资源管理模块</li>
<li>一个管程定义了一个数据结构和能为并发进程所执行（在该数据结构上）的一组操作，这组操作能同步进程和改变管程中的数据</li>
<li>管程的组成部分：<br> （1）管程的名字<br> （2）局部于管程的共享数据结构说明<br> （3）对该数据结构进行操作的一组过程<br> （4）对局部于管程的共享数据设置初始值的语句</li>
<li>所有进程要访问临界资源时，都只能通过管程间接访问，而管程每次只准许一个进程进入管程，执行管程内的过程，从而实现了进程互斥</li>
<li>管程的特性：<br> （1）模块化<br> （2）抽象数据结构<br> （3）信息掩蔽</li>
<li>进程与管程的区别：<br> （1）进程定义私有数据结构PCB，管程定义的是公共数据结构如消息队列<br> （2）进程是由顺序程序执行有关操作，管程主要是进行同步操作和初始化操作<br> （3）设置进程的目的在于实现系统的并发性，管程的设置是解决共享资源的互斥使用问题<br> （4）进程通过调用管程中的过程对共享数据结构实行操作，因而管程被动，进程主动<br> （5）进程之间能并发执行，管程不能<br> （6）进程具有动态性，管程是操作系统中的一个资源管理模块，供进程使用</li>
<li>条件变量</li>
</ol>
<h3 id="2-5-经典进程的同步问题"><a href="#2-5-经典进程的同步问题" class="headerlink" title="2.5 经典进程的同步问题"></a>2.5 经典进程的同步问题</h3><h4 id="2-5-1-生产者-消费者问题"><a href="#2-5-1-生产者-消费者问题" class="headerlink" title="2.5.1 生产者-消费者问题"></a>2.5.1 生产者-消费者问题</h4><pre><code>int in= 0,out= 0;
item buffer[n];
semaphore mutex = 1,empty = n,full = 0;
void producer()&#123;
    do&#123;
        producer an item nextp;
        ...
        wait(empty);
        wait(mutex);
        buffer[in] = nextp;
        in = (in + 1) % n;
        signal(mutex);
        signal(full);
    &#125;while(TRUE);
 &#125;
 void consumer()&#123;
    do&#123;
    wait(full);
    wait(mutex);
    nextc = buffer[out];
    out = (out+1)%n;
    signal(mutex)
    signal(empty)
    consumer the item in nextc;
    ...
    &#125;while(TRUE);
 &#125;
 void main()&#123;
    cobegin
        producer();
        consumer();
    coend
&#125;
</code></pre>
<h4 id="2-5-2-哲学家进餐问题"><a href="#2-5-2-哲学家进餐问题" class="headerlink" title="2.5.2 哲学家进餐问题"></a>2.5.2 哲学家进餐问题</h4><p>略</p>
<h4 id="2-5-3-读者-写者问题"><a href="#2-5-3-读者-写者问题" class="headerlink" title="2.5.3 读者-写者问题"></a>2.5.3 读者-写者问题</h4><p>略</p>
<h3 id="2-6-进程通信"><a href="#2-6-进程通信" class="headerlink" title="2.6 进程通信"></a>2.6 进程通信</h3><ul>
<li>进程通信：进程间的信息交换</li>
<li>低级进程通信：进程的互斥和同步在进程间交换信息<br>  （1）效率低（2）通信对用户不透明</li>
<li>高级通信：进程间传送大量数据<br>  （1）使用方便（2）高效地传送大量数据</li>
</ul>
<h4 id="2-6-1-进程通信的类型"><a href="#2-6-1-进程通信的类型" class="headerlink" title="2.6.1 进程通信的类型"></a>2.6.1 进程通信的类型</h4><ul>
<li>高级通信机制分为：<strong>共享存储器系统，管道通信系统，消息传递系统，客户机-服务器系统</strong></li>
</ul>
<ol>
<li>共享存储器系统：<br> （1）基于共享数据结构的通信方式：仅适用于相对少量的数据，通信效率低，属于低级通信<br> （2）基于共享存储区的通信方式：在内存中划出一块共享存储区域，诸进程可通过对该区域的读或写交换信息，实现通信，数据的形式和位置甚至访问控制都是由进程负责，而不是OS，属于高级通信</li>
<li>管道通信系统</li>
</ol>
<ul>
<li>管道：指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又名pipe文件。</li>
<li>提供互斥，同步，确定对方是否存在三个方面的协调能力</li>
</ul>
<ol start="3">
<li>消息传递系统</li>
</ol>
<ul>
<li>以格式化的消息为单位，将通信的数据封装在消息中，并利用操作系统提供的一组通信命令（原语），在进程间传递消息，完成进程间的数据交换</li>
<li>（1）直接通信方式，如消息缓冲机制</li>
<li>（2）间接通信方式，如电子邮箱系统</li>
</ul>
<ol start="4">
<li>客户机-服务器系统</li>
</ol>
<ul>
<li>实现的三种方法：套接字，远程过程调用，远程方法</li>
<li>（1）套接字：是一个通信标识类型的数据结构，包含了通信目的地址，端口号，协议等，是进程通信和网络通信的基本构件</li>
<li>分类：①基于文件型②基于网络型</li>
<li>（2）远程过程调用和远程方法调用：远程过程调用PRC，是一个通信协议，用于通过网络连接的系统。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称做远程方法调用</li>
</ul>
<h4 id="2-6-2-消息传递通信的实现方式"><a href="#2-6-2-消息传递通信的实现方式" class="headerlink" title="2.6.2 消息传递通信的实现方式"></a>2.6.2 消息传递通信的实现方式</h4><ol>
<li>直接消息传递系统：<br> （1）对称寻址原语：不足：一旦改变进程的名字，则可能需要检查所有其他进程的定义<br> （2）非对称寻址方式<br> （3） 消息的格式<br> （4） 进程的同步方式<br> （5）通信链路：为使在发送进程和接受进程之间能进行通信，必须在两者之间建立一条通信链路</li>
</ol>
<ul>
<li>分为：单向通信链路，双向通信链路</li>
</ul>
<ol start="2">
<li>信箱通信：</li>
</ol>
<ul>
<li>信箱通信属于间接通信方式，即进程之间的通信，需要通过某种中间实体来完成。该实体建立在随机存储器的公用缓冲区上，用来暂存发送进程发送给目标进程的消息；接受进程可以从该实体中取出发送进程发送给自己的消息，通常把这种中间实体称为邮箱（或信箱），每个邮箱都有唯一的标识符。<br>  （1）信箱的结构：信箱头，信箱体<br>  （2）信箱通信原语<br>  （3）信箱的类型：①私用信箱②公用信箱③共享信箱</li>
</ul>
<h3 id="2-7-线程的基本概念"><a href="#2-7-线程的基本概念" class="headerlink" title="2.7 线程的基本概念"></a>2.7 线程的基本概念</h3><ul>
<li>线程：比进程更小的基本单位</li>
<li>线程目的：提高程序并发执行的程度</li>
</ul>
<h4 id="2-7-1-线程的引入"><a href="#2-7-1-线程的引入" class="headerlink" title="2.7.1 线程的引入"></a>2.7.1 线程的引入</h4><ul>
<li>引入进程的目的：为了多个程序能并发执行，以提高资源利用率和系统吞吐量</li>
<li>引入线程的目的：减少程序在并发执行时所付出的时空开销，使OS具有更好的并发性</li>
</ul>
<ol>
<li>进程的两个基本属性：<br> （1）进程是一个可拥有资源的独立单位<br> （2）进程同时又是一个可独立调度和分派的基本单位</li>
<li>程序并发执行所需付出的时空开销<br> （1）创建进程，分配所需资源，建立PCB<br> （2）撤销进程，执行回收操作，撤销PCB<br> （3）进程切换，需保留当前CPU环境，建立新的CPU环境</li>
<li>线程 ——作为调度和而分派的基本单位</li>
</ol>
<h4 id="2-7-2-线程与进程的比较"><a href="#2-7-2-线程与进程的比较" class="headerlink" title="2.7.2 线程与进程的比较"></a>2.7.2 线程与进程的比较</h4><ul>
<li>传统进程：重型进程，线程：轻型进程/进程元</li>
</ul>
<ol>
<li><strong>调度的基本单位</strong>：</li>
</ol>
<ul>
<li>线程间通信比进程更方便</li>
<li>同一进程的线程，计数器，堆栈资源不同</li>
<li>线程的切换，建立，撤销均快于进程</li>
<li>线程的切换不会引起进程的切换，但从一个进程中的线程切换到另一个进程的线程时，必然会引起进程的切换。</li>
</ul>
<ol start="2">
<li><strong>并发性</strong>：一个进程中的多个线程之间亦可以并发执行，甚至还允许在一个进程中所有线程都能并发执行</li>
<li><strong>拥有资源</strong>：仅有一点必不可少的，能保证独立运行的资源，如：TCB等</li>
<li><strong>独立性</strong>：同一进程中的不同线程之间的独立性要比不同进程之间的独立性低</li>
<li><strong>系统开销</strong>：线程低于进程</li>
<li>支持多处理机系统</li>
</ol>
<h4 id="2-7-3-线程的状态和线程控制块"><a href="#2-7-3-线程的状态和线程控制块" class="headerlink" title="2.7.3 线程的状态和线程控制块"></a>2.7.3 线程的状态和线程控制块</h4><ol>
<li>线程的三种状态：（1）执行（2）就绪（3）阻塞</li>
<li><strong>线程控制块TCB</strong>：将所有用于控制和管理线程的信息记录其中</li>
<li>多线程OS中的进程属性：<br> （1）进程是一个可拥有资源的基本单位<br> （2）多个线程可以并发执行<br> （3）进程已不是可执行的实体，<strong>在多线程OS中，是把线程作为独立运行的基本单位</strong></li>
</ol>
<h3 id="2-8-线程的实现"><a href="#2-8-线程的实现" class="headerlink" title="2.8 线程的实现"></a>2.8 线程的实现</h3><h4 id="2-8-1-线程的实现方式"><a href="#2-8-1-线程的实现方式" class="headerlink" title="2.8.1 线程的实现方式"></a>2.8.1 线程的实现方式</h4><ol>
<li>内核支持线程KST<br> 优点：<br> （1）在多处理器系统中，内核能够同时调度同一进程中的多个线程并行执行<br> （2）如果进程中的一个线程被阻塞，内核可以调度该进程中的其他线程占用处理器运行，也可以运行其他进程中的线程<br> （3）内核支持线程具有很小的数据结构和堆栈，线程切换快，开销小<br> （4）内核本身采用多线程技术，可以提高系统的执行速度和效率<br> 缺点：<br> 系统开销大</li>
<li>用户级线程ULT<br> 优点：<br> （1）线程切换不需要转换到内核空间<br> （2）调度算法可以是进程专用的<br> （3）用户级线程的实现与OS平台无关，因为对于线程管理的代码是属于用户程序的一部分<br> 缺点：<br> （1）系统调用的阻塞问题<br> （2）进程中只有一个线程能执行</li>
<li>组合方式</li>
</ol>
<h4 id="2-8-2-线程的实现"><a href="#2-8-2-线程的实现" class="headerlink" title="2.8.2 线程的实现"></a>2.8.2 线程的实现</h4><ol>
<li>内核支持线程的实现：</li>
<li>用户级线程的实现：（中间系统）<br> （1）运行时系统：实质上是用于管理和控制线程的函数的集合<br> （2）内核控制线程：<strong>轻型进程LWP</strong>，<u style="line-height: 160%; box-sizing: content-box;">可看作是ULT和KLT之间的映射，它把一个或多个ULT映射到一个KLT上。LWP还是核心独立调度的单位，它可以在多个处理器上并行执行</u></li>
</ol>
<ul>
<li>注意：核心向用户程序提供的界面是LWP，不提供核心线程和用户级线程，用户程序接触不到核心线程，只能看到LWP和用户态线程。</li>
<li>把这些LWP做成一个线程池，只有连接到LWP上的线程才能与内核通信</li>
<li>LWP实现理内核和用户级线程之间的隔离</li>
</ul>
<h4 id="2-8-3-线程的创建和终止"><a href="#2-8-3-线程的创建和终止" class="headerlink" title="2.8.3 线程的创建和终止"></a>2.8.3 线程的创建和终止</h4><ul>
<li>线程具有生命周期</li>
<li>创建完成后返回一个线程标识符</li>
<li>线程被终止后并不立即释放它所占有的资源，只有当进程中的其他线程执行分离函数后，被终止线程才与资源分离</li>
</ul>
<h2 id="第三章-处理机调度与死锁"><a href="#第三章-处理机调度与死锁" class="headerlink" title="第三章 处理机调度与死锁"></a>第三章 处理机调度与死锁</h2><h3 id="3-1-处理机调度的层次和调度算法的目标"><a href="#3-1-处理机调度的层次和调度算法的目标" class="headerlink" title="3.1 处理机调度的层次和调度算法的目标"></a>3.1 处理机调度的层次和调度算法的目标</h3><ul>
<li>调度的实质是一种资源分配，处理机调度是对处理机资源进行分配</li>
</ul>
<h4 id="3-1-1-处理机调度的层次"><a href="#3-1-1-处理机调度的层次" class="headerlink" title="3.1.1 处理机调度的层次"></a>3.1.1 处理机调度的层次</h4><ol>
<li>高级调度：又称长程调度或<strong>作业调度</strong>，调度对象是作业，高级调度主要用于多道批处理系统中，而在分时和实时系统中不设置</li>
<li>低级调度：又称<strong>进程调度</strong>或短程调度，调度对象是进程，最基本的调度</li>
<li>中级调度：又称<strong>内存调度</strong>，目的：提高内存利用率和系统吞吐量。将那些暂时不能运行的进程，调至外存等待，此时进程的状态称为挂起</li>
</ol>
<ul>
<li>其中进程调度的运行频率最高</li>
<li>作业调度周期最长</li>
<li>中级调度的运行频率介于两者之间</li>
</ul>
<h4 id="3-1-2-处理机调度算法的目标"><a href="#3-1-2-处理机调度算法的目标" class="headerlink" title="3.1.2 处理机调度算法的目标"></a>3.1.2 处理机调度算法的目标</h4><ol>
<li>处理机调度算法的共同目标<br> （1）资源利用率：<br> cpu的利用率=cpu有效工作时间/（cpu有效工作时间+cpu空闲等待时间）<br> （2）公平性<br> （3）平衡性<br> （4）策略强制转换</li>
<li>批处理系统的目标：<br> （1）平均周转时间短<br> （2）系统吞吐量高<br> （3）处理机利用率高</li>
<li>分时系统的目标<br> （1）响应时间快<br> （2）均衡性</li>
<li>实时系统的目标<br> （1）截至时间的保证<br> （2）可预测性</li>
</ol>
<h3 id="3-2-作业与作业调度"><a href="#3-2-作业与作业调度" class="headerlink" title="3.2 作业与作业调度"></a>3.2 作业与作业调度</h3><h4 id="3-2-1-批处理系统中的作业"><a href="#3-2-1-批处理系统中的作业" class="headerlink" title="3.2.1 批处理系统中的作业"></a>3.2.1 批处理系统中的作业</h4><ol>
<li>作业和作业步：<br> （1）作业：<ul>
<li>  作业是用户提交给系统的以向相对独立的工作</li>
<li>  在批处理系统中是以作业为基本单位从外存调入内存的</li>
</ul>
</li>
</ol>
<p>（2）作业步：  </p>
<ul>
<li>在作业运行期间，每个作业都必须经过若干个相对独立的，又相互关联的顺序加工步骤才能得到结果。我们把其中的每一加工步骤叫做一个作业步  </li>
<li>一个典型的作业可以分成：编译作业步，链接装配作业步，运行作业步<br>2. 作业运行的三个阶段和三种状态：</li>
</ul>
<p>（1）收容阶段：操作员把用户提交的作业通过某种输入方式或SPOOLing系统输入到硬盘上，在为该作业建立JCB，并把它们放到作业后备队列中。此时作业的状态也叫“后备状态”<br>（2）运行阶段：“运行状态”<br>（3）完成阶段：“完成状态”</p>
<h4 id="3-2-2-作业调度的主要任务"><a href="#3-2-2-作业调度的主要任务" class="headerlink" title="3.2.2 作业调度的主要任务"></a>3.2.2 作业调度的主要任务</h4><ul>
<li>主要任务：根据JCB中的信息，检查系统中的资源能否满足作业对资源的需求，以及按照一定算法，将作业调入内存，创建进程，分配资源，将新建立的进程排在就绪队列上等待调度，故作业调度也叫接纳调度。</li>
<li>接纳多少个作业</li>
<li>接纳那些作业</li>
</ul>
<h4 id="3-2-3-先来先服务（FCFS）和短作业有限（SJF）调度算法"><a href="#3-2-3-先来先服务（FCFS）和短作业有限（SJF）调度算法" class="headerlink" title="3.2.3 先来先服务（FCFS）和短作业有限（SJF）调度算法"></a>3.2.3 先来先服务（FCFS）和短作业有限（SJF）调度算法</h4><ol>
<li><strong>先来先服务调度算法（FCFS）</strong>：</li>
</ol>
<ul>
<li>按照作业的到达的先后次序来调度，即优先考虑等待时间最长的作业</li>
<li>缺点：对于短进程而言，带权周转时间可能非常的大</li>
<li>适用于作业调度和进程调度</li>
</ul>
<ol start="2">
<li><strong>短作业有限的调度算法（SJF）</strong>：</li>
</ol>
<ul>
<li>按照作业的长短来计算优先级，作业越短，其优先级越高</li>
<li>缺点：<br>  （1）必须预知作业的运行时间<br>  （2）对长作业非常不利<br>  （3）在采用SJF时，人机交互无法实现<br>  （4）该调度算法完全未考虑作业的紧迫程度，故不能保证紧迫作业能得到及时处理</li>
</ul>
<h4 id="3-2-4-优先级调度算法和高响应比调度算法"><a href="#3-2-4-优先级调度算法和高响应比调度算法" class="headerlink" title="3.2.4 优先级调度算法和高响应比调度算法"></a>3.2.4 优先级调度算法和高响应比调度算法</h4><ol>
<li><strong>优先级调度算法（PSA）</strong></li>
</ol>
<ul>
<li>根据作业的优先级进行调度</li>
</ul>
<ol start="2">
<li>高响应比优先调度算法：</li>
</ol>
<p>优先权=（等待时间+要求服务时间）/要求服务时间=响应时间/要求服务时间</p>
<ul>
<li>动态优先级</li>
<li>更公平但增加了系统开销</li>
</ul>
<h3 id="3-3-进程调度"><a href="#3-3-进程调度" class="headerlink" title="3.3 进程调度"></a>3.3 进程调度</h3><h4 id="3-3-1-进程调度的任务，机制和方式"><a href="#3-3-1-进程调度的任务，机制和方式" class="headerlink" title="3.3.1 进程调度的任务，机制和方式"></a>3.3.1 进程调度的任务，机制和方式</h4><ol>
<li>进程调度的任务：<br> （1）保存处理机的现场信息<br> （2）按某种算法选取进程<br> （3）把处理器分配给进程</li>
<li>进程调度机制<br> 三个部分<br> （1）排队器<br> （2）分派器<br> （3）上下文切换器</li>
<li>进程调度方式<br> （1）非抢占方式：</li>
</ol>
<blockquote>
<p>在采用非抢占调度方式时，可能引起进程调度的因素可归结为这样几个：① 正在执行的进程执行完毕， 或因发生某事件而不能再继续执行； ② 执行中的进程因提出I/O请求而暂停执行；③ 在进程通信或同步过程中执行了某种原语操作，如P操作(wait操作)、Block原语、Wakeup原语等。这种调度方式的优点是实现简单、系统开销小，适用于大多数的批处理系统环境。但它难以满足紧急任务的要求——立即执行。</p>
</blockquote>
<p>（2）抢占方式<br>主要原则：<br>（1）优先权原则。<br>（2）短作业(进程)优先原则。<br>（3）时间片原则。</p>
<h4 id="3-3-2-轮转调度算法（RR）"><a href="#3-3-2-轮转调度算法（RR）" class="headerlink" title="3.3.2 轮转调度算法（RR）"></a>3.3.2 轮转调度算法（RR）</h4><ul>
<li>基于时间片的轮转，非常公平</li>
<li>每个进程每次大约可获得1/n的处理机时间</li>
</ul>
<ol>
<li>轮转法的基本原理：系统根据FCFS策略，将所有的就绪进程排成一个就绪队列，并每隔一段时间产生一次中断，激活系统中的进程调度，将CPU分配给队首进程，令其执行</li>
<li>进程切换时机：<br> （1）若一个时间片尚未用完，正在运行的进程便已经完成，就立即激活调度程序，将它从就绪队列中删除，再调度就绪队列队首的进程运行，并启动新的时间片<br> （2）在一个时间片用完时，计时器中断处理程序被激活，如果进程尚未运行完，调度程序把它送入就绪队列末尾</li>
<li>时间片大小的确定</li>
</ol>
<ul>
<li>小：频繁地执行进程调度和进程上下文切换，增加系统开销</li>
<li>大：每个进程都能在一个时间片内完成，算法退化为FCFS</li>
</ul>
<h4 id="3-3-3-优先级调度算法"><a href="#3-3-3-优先级调度算法" class="headerlink" title="3.3.3 优先级调度算法"></a>3.3.3 优先级调度算法</h4><ol>
<li>优先级调度算法分类：<br> （1）非抢占式优先级调度算法：优先级低的正在运行时，优先级高的不能抢占CPU<br> （2）抢占式优先级调度算法</li>
<li>优先级的类型：<br> （1）静态优先级：<ul>
<li>  在创建进程时确定</li>
<li>  依据：进程类型，进程对资源的需求，用户需求</li>
<li>简单易行，系统开销小，但不够精确<br>  （2）动态优先级：</li>
</ul>
</li>
</ol>
<ul>
<li>其值随进程的推进或时间的增加而改变，以获得更好的性能</li>
</ul>
<h4 id="3-3-4-多队列调度算法"><a href="#3-3-4-多队列调度算法" class="headerlink" title="3.3.4 多队列调度算法"></a>3.3.4 多队列调度算法</h4><ul>
<li>该算法将系统中的进程就绪队列从一个拆分成若干个，将不同类型或性质的进程固定分配在不同的就绪队列，不同的就绪队列采用不同的调度算法，一个就绪队列中的进程可以设置不同的优先级，不同的就绪队列本身也可以设置不同优先级</li>
</ul>
<h4 id="3-3-5-多级反馈队列调度算法"><a href="#3-3-5-多级反馈队列调度算法" class="headerlink" title="3.3.5 多级反馈队列调度算法"></a>3.3.5 多级反馈队列调度算法</h4><ol>
<li>调度机制：<br> （1）设置多个就绪队列。第一个队列优先高，时间片最短，其后依此降低优先级，增大时间片<br> （2）每个队列内采用FCFS算法<br> （3）调度算法的性能：<ul>
<li>  能较好的满足用户的需要</li>
</ul>
</li>
</ol>
<h4 id="3-3-6-基于公平原则的调度算法"><a href="#3-3-6-基于公平原则的调度算法" class="headerlink" title="3.3.6 基于公平原则的调度算法"></a>3.3.6 基于公平原则的调度算法</h4><ol>
<li>保证调度算法：n个相同类型的进程，每个都获得相同的处理机时间1/n</li>
<li>公平分享调度算法：分配给每个进程相同的处理机时间，公平性是针对用户而言，要考虑每一个用户的进程数目</li>
</ol>
<h3 id="3-4-实时调度"><a href="#3-4-实时调度" class="headerlink" title="3.4 实时调度"></a>3.4 实时调度</h3><h4 id="3-4-1-实现实时调度的基本条件"><a href="#3-4-1-实现实时调度的基本条件" class="headerlink" title="3.4.1 实现实时调度的基本条件"></a>3.4.1 实现实时调度的基本条件</h4><ol>
<li>提供必要的信息：<br> （1）就绪时间<br> （2）开始截止时间和完成截止时间<br> （3）处理时间<br> （4）资源要求<br> （5）优先级</li>
<li>系统处理能力强<br> （1）单处理机，必须满足下面的限制条件：</li>
</ol>
<p>c是处理机时间，p是周期时间<br>（2）多处理机，限制条件改为：  </p>
<p>3.采用抢占式调度机制</p>
<ul>
<li>在含有HRT任务的实时系统中，广泛采用抢占式机制，满足对截止时间的要求</li>
</ul>
<ol start="4">
<li>具有快速切换机制<br> （1）对中断的快速响应<br> （2）快读的任务分派能力</li>
</ol>
<h4 id="3-4-2-实时调度算法的分类"><a href="#3-4-2-实时调度算法的分类" class="headerlink" title="3.4.2 实时调度算法的分类"></a>3.4.2 实时调度算法的分类</h4><ol>
<li>非抢占式调度算法<br> （1）非抢占式轮转调度算法<br> （2）非抢占式优先调度算法</li>
<li>抢占式调度算法<br> （1）基于时钟中断的抢占式优先级调度算法<br> （2）立即抢占的优先级调度算法</li>
</ol>
<h4 id="3-4-3-最早截止时间优先EDF算法"><a href="#3-4-3-最早截止时间优先EDF算法" class="headerlink" title="3.4.3 最早截止时间优先EDF算法"></a>3.4.3 最早截止时间优先EDF算法</h4><ul>
<li>任务的截止时间越早，其优先级越高，具有最早截止时间的任务排在队列的队首</li>
</ul>
<ol>
<li>非抢占式调度方式用于非周期实时任务</li>
<li>抢占式调度方式用于周期实时任务</li>
</ol>
<h4 id="3-4-4-最低松弛度优先LLF算法"><a href="#3-4-4-最低松弛度优先LLF算法" class="headerlink" title="3.4.4 最低松弛度优先LLF算法"></a>3.4.4 最低松弛度优先LLF算法</h4><ul>
<li>任务紧急程度越高，赋予该任务的优先级就越高，以使之优先执行</li>
<li>松弛度=必须完成时间-其本身的运行时间-当前时间</li>
</ul>
<h4 id="3-4-5-优先级倒置"><a href="#3-4-5-优先级倒置" class="headerlink" title="3.4.5 优先级倒置"></a>3.4.5 优先级倒置</h4><ul>
<li>高优先级进程被低优先级进程延迟或阻塞</li>
</ul>
<h3 id="3-5-死锁"><a href="#3-5-死锁" class="headerlink" title="3.5 死锁"></a>3.5 死锁</h3><h4 id="3-5-1-资源问题"><a href="#3-5-1-资源问题" class="headerlink" title="3.5.1 资源问题"></a>3.5.1 资源问题</h4><ol>
<li>可重用性资源和消耗性资源</li>
</ol>
<ul>
<li>（1）可重用性资源：用户可以重复使用多次的资源<ul>
<li>性质：（1）每一个可重用资源中的单位只能分配给一个进程使用<br>  （2）进程在使用时的顺序：①请求资源②使用资源③释放资源<br>  （3）系统中每一类可重用资源的单元数目都是固定的，进程在运行期间既不能创建也不能删除</li>
<li>  对资源的请求和释放都是利用系统调用来实现的</li>
</ul>
</li>
<li>（2）可消耗性资源：又称临时资源<ul>
<li>  性质：（1）每一个可消耗性资源的单元数目在进程运行期间是可以不断变化的</li>
</ul>
</li>
</ul>
<ol start="2">
<li>可抢占性资源和不可抢占性资源：<br> （1）可抢占性资源：这类资源不会引起死锁<br> （2）不可抢占性资源：例如磁带机，打印机</li>
</ol>
<h4 id="3-5-2-计算机系统中的死锁"><a href="#3-5-2-计算机系统中的死锁" class="headerlink" title="3.5.2 计算机系统中的死锁"></a>3.5.2 计算机系统中的死锁</h4><ul>
<li>死锁：多个进程对资源的争夺，不仅对不可抢占性资源争夺会引起死锁，对可消耗性资源的争夺也会引起死锁</li>
</ul>
<ol>
<li>竞争不可抢占性资源引起死锁</li>
<li>竞争可消耗资源引起死锁</li>
<li>进程推进顺序不当引起死锁</li>
</ol>
<h4 id="3-5-3-死锁的定义，必要条件和处理方法"><a href="#3-5-3-死锁的定义，必要条件和处理方法" class="headerlink" title="3.5.3 死锁的定义，必要条件和处理方法"></a>3.5.3 死锁的定义，必要条件和处理方法</h4><ol>
<li>死锁的定义：如果一组进程中的每一个进程都在等待仅由该组进程中的其他进程才能引发的事件，那么该组进程是死锁的</li>
<li><strong>产生死锁的必要条件</strong>：</li>
</ol>
<ul>
<li>（1）互斥条件</li>
<li>（2）请求和保持条件</li>
<li>（3）不可抢占条件</li>
<li>（4）循环等待条件</li>
</ul>
<ol start="3">
<li>处理死锁的方法：</li>
</ol>
<ul>
<li>（1）预防死锁：设置某些限制条件，破坏产生死锁的四个必要条件</li>
<li>（2）避免死锁：在资源的动态分配过程中采取某种方法，使之保持安全状态</li>
<li>（3）检测死锁</li>
<li>（4）解除死锁：撤销进程，回收资源</li>
</ul>
<h3 id="3-6-预防死锁"><a href="#3-6-预防死锁" class="headerlink" title="3.6 预防死锁"></a>3.6 预防死锁</h3><ul>
<li>互斥条件是非共享设备所必须的，不仅不能改变，还应加以保证，因此主要破坏产生死锁的后三个条件</li>
</ul>
<h4 id="3-6-1-破坏“请求和保持条件”"><a href="#3-6-1-破坏“请求和保持条件”" class="headerlink" title="3.6.1 破坏“请求和保持条件”"></a>3.6.1 破坏“请求和保持条件”</h4><ol>
<li>第一种协议：所有进程在开始运行钱，必须一次性申请所需全部资源<ul>
<li>  简单，易行且安全，但①资源被严重浪费，②进程经常发送饥饿现象</li>
</ul>
</li>
<li>第二种协议：<ul>
<li>  允许进程只获取运行初期所需的资源，便可开始运行，在逐步释放已用毕的全部资源，再请求新的资源</li>
<li>  更快，提高设备的利用率，减少饥饿机率</li>
</ul>
</li>
</ol>
<h4 id="3-6-2-破坏“不可抢占”条件"><a href="#3-6-2-破坏“不可抢占”条件" class="headerlink" title="3.6.2 破坏“不可抢占”条件"></a>3.6.2 破坏“不可抢占”条件</h4><ul>
<li>一个已经保持了某些不可抢占资源的进程，提出新的资源请求而不能得到满足时，必须释放已经保持的多有资源，待以后再申请</li>
<li>实现复杂，延长了进程的周转事件，增加系统开销，降低系统吞吐量</li>
</ul>
<h4 id="3-6-3-破坏“循环等待”-条件"><a href="#3-6-3-破坏“循环等待”-条件" class="headerlink" title="3.6.3 破坏“循环等待” 条件"></a>3.6.3 破坏“循环等待” 条件</h4><ul>
<li>对系统所有资源类型进行线性排序，并赋予不同的序号，必须按照序号递增的顺序请求资源</li>
<li>如果需要多个同类资源单元，则必须一起请求</li>
<li>假如进程已请求到一些序号较高的资源后，后来它又想请求序号低的资源，必须先释放所有具有相同和更高序号的资源后才能申请</li>
</ul>
<h3 id="避免死锁"><a href="#避免死锁" class="headerlink" title="避免死锁"></a>避免死锁</h3><ul>
<li>再资源的动态分配过程中，防止系统进入不安全状态，以避免发送死锁</li>
</ul>
<h4 id="3-7-1-系统安全状态"><a href="#3-7-1-系统安全状态" class="headerlink" title="3.7.1 系统安全状态"></a>3.7.1 系统安全状态</h4><ol>
<li>安全状态：是指系统能按某种顺序，来为每个进程分配其所需资源，直至最大需求，使每个进程都可顺利完成。</li>
<li>安全序列：<br> 一个进程序列{P1，…，Pn}是安全的，如果对于每一个进程Pi(1≤i≤n），它以后需要的资源量不超过系统当前剩余资源量与所有进程Pj (j &lt; i )当前占有资源量之和，系统处于安全状态。<br> (安全状态一定是没有死锁发生的)</li>
</ol>
<h4 id="3-7-2-利用银行家算法避免死锁"><a href="#3-7-2-利用银行家算法避免死锁" class="headerlink" title="3.7.2 利用银行家算法避免死锁"></a>3.7.2 利用银行家算法避免死锁</h4><blockquote>
<p>银行家算法（Banker’s Algorithm）</p>
</blockquote>
<ul>
<li>概念<br>  银行家算法是一个避免死锁产生的算法。以银行借贷分配策略为基础，判断并保证系统处于安全状态。<br>  客户在第一次申请贷款时，声明所需最大资金量，在满足所有贷款要求并完成项目时，及时归还<br>  在客户贷款数量不超过银行拥有的最大值时，银行家尽量满足客户需要</li>
</ul>
<h3 id="3-8-死锁的检测和解除"><a href="#3-8-死锁的检测和解除" class="headerlink" title="3.8 死锁的检测和解除"></a>3.8 死锁的检测和解除</h3><p>允许系统进入死锁状态<br>维护系统的资源分配图<br>定期调用死锁检测算法来搜索图中是否存在死锁<br>出现死锁时，用死锁恢复机制进行恢复</p>
<ul>
<li>解除死锁：<br>  （1）资源剥夺法：挂起某些死锁进程并抢夺它的资源，以便让其他进程继续推进<br>  （2）撤销进程法：强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源<br>  （3）进程回退法：让进程回退到足以回避死锁的地步</li>
<li>算法：<br>  (1)银行家算法为死锁避免算法；<br>  (2)死锁检查算法和资源分配图化简法为死锁检测；<br>  (3)资源有序分配算法为死锁预防策略；</li>
<li>所谓CPU繁忙型的作业，是指该类作业需要大量的CPU时间进行计算，而很少请求I/O操作。I/O繁忙型的作业是指CPU处理时，需频繁的请求I/O操作。<br>  (1)周转时间 = 作业完成时间 - 作业提交时间；<br>  (2)平均周转时间 = （作业1的周转时间 + … + 作业n的周转时间）/ n ；<br>  (3)带权周转时间 = 作业周转时间 / 作业实际运行时间；<br>  (4)平均带权周转时间 = （作业1的带权周转时间 + … + 作业n的带权周转时间）/ n；<br>  (5)响应比Rp = (等待时间 + 要求服务时间) /要求服务时间；</li>
</ul>
<h2 id="第四章-存储器管理"><a href="#第四章-存储器管理" class="headerlink" title="第四章 存储器管理"></a>第四章 存储器管理</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/202109080918412.png" alt="Image [5]"></p>
<h3 id="内存管理："><a href="#内存管理：" class="headerlink" title="内存管理："></a>内存管理：</h3><ul>
<li>引入目的：更好的支持多道程序并发执行，提升系统性能<br>  -‘程序的编译’：由编译程序将用户源代码编译成若干个目标模块；<br>  -‘程序的链接’：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块；<br>  （1）静态链接：在程序运行之前链接<br>  （2）装入时动态链接：在装入内存时，采用边装入边链接的链接方式<br>  （3）运行时动态链接：在程序执行中需要该目标模块时，才对它进行链接<br>  -‘程序的装入’：由装入程序将装入模块装入内存运行；<br>  （1）绝对装入：适合单道程序环境<br>  （2）静态重定位：适合装入之后不再移动的情况<br>  （3）动态重定位：适合装入之后还会移动的情况</li>
<li>‘地址空间’：<br>  （1）逻辑地址空间：是指一个源程序在编译或者链接装配后指令和数据所用的所有相对地址的空间；<br>  （2）物理地址空间：内存中物理单元的集合；</li>
<li>‘地址重定位’：通过地址转换将逻辑地址转换为物理地址。</li>
<li>‘内存保护’：<br>  （1）上、下限寄存器：分别与上、下限寄存器比较<br>  （2）基址、限长寄存器：与限长寄存器比较，与基址寄存器相加</li>
<li>管理方式：<br>  （1）连续分配：产生内部碎片；用户进程（或作业）在主存中都是连续存放的<ul>
<li>  单一连续分配：分配到内存固定区域，只适合单任务系统；</li>
<li>固定分区分配：分配到内存中不同的固定区域，分区可以相等也可以不等；<ul>
<li>  产生内部碎片</li>
</ul>
</li>
<li>动态分区分配：<ul>
<li>  产生外部碎片</li>
<li>  基本概念：按照程序的需要进行动态的划分</li>
<li>分配算法：<br>  （1）首次适应：空闲区按地址从小到大为序，分配第一个符合条件的分区；<br>  （2）最佳适应：空闲区按空间大小从小到大排序，分配第一个符合条件的分区；<br>  （3）最坏适应：空闲区按空间从大到小排序，分配第一个符合条件的分区；<br>  （4）邻近适应：空闲区按地址地址递增的次序排列，分配内存时从上次查找结束的位置开始继续查找；</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>（2） 非连续分配：允许一个程序分散地装入到不相邻的内存分区中，需要额外的空间去存储分散区域的索引</p>
<ul>
<li>基本分页：内存分为固定的块，按物理结构划分，会有内部碎片；<ul>
<li>  主存、进程都划分为大小固定的块，进程在执行时，以块为单位申请主存中的块空间；</li>
<li>  进程中的块为页，内存中的块为页框。系统为每个进程建立一张页表，页表记录页面在内存中对应的物理块号，实现从页号到物理块号的地址映射；</li>
<li>  页式管理中地址空间是一维的；</li>
</ul>
</li>
<li>基本分段：内存块的大小不固定，按逻辑结构划分，会有外部碎片；<ul>
<li>  段式管理方式按照用户进程中的自然段划分逻辑空间。段内要求连续，段间不要求连续。段号和段内偏移量必须由用户显示提供。</li>
<li>  方便编程、共享、保护、动态链接和增长。</li>
</ul>
</li>
<li>段页式：基本分段和基本分页的结合，会有内部碎片；<ul>
<li>  作业的逻辑地址分为：段号、页号和页内偏移量；采用分段方法来分配和管理用户地址空间，采用分页方法来管理物理存储空间；开销大。</li>
</ul>
</li>
<li>请求分页存储管理：采用虚拟技术，开始运行时不必将作业全部一次性装入内存；</li>
<li>多级页表：将页表的10页空间也进行地址映射，建立上一级页表，用于存储页表的映射关系；</li>
</ul>
<h3 id="多道程序下的内存扩充："><a href="#多道程序下的内存扩充：" class="headerlink" title="多道程序下的内存扩充："></a>多道程序下的内存扩充：</h3><ul>
<li>覆盖：预先设定覆盖段，覆盖掉暂时不用的内容，通常在同一个程序之中进行；</li>
<li>交换：把处于等待的程序暂时移到外存，通常在不同程序之间进行；</li>
<li>虚拟内存：只能基于非连续分配技术。<ul>
<li>  引入原因：在逻辑上扩充内存</li>
<li>  时间局部性：程序中存在着大量的循环操作；</li>
<li>  空间局部性：程序在一段时间内所访问的地址，可能集中在一定的范围内；</li>
<li>组成部分：<br>  （1）页表机制：通过查表获取相关信息；<br>  （2）中断机制：要访问页不在内存时产生缺页中断<br>  （3）地址变换机构：把逻辑地址变换成物理地址<br>  （4）内存和外存：需要一定容量的内存和外存支持</li>
<li>置换算法：<br>  （1）最佳置换算法（OPT）：选择以后不用的页面<br>  （2）先进先出（FIFO）：选择最先装入的页面<br>  （3）最近最久未使用（LRU）：选择最近最近未使用的页面<br>  （4）时钟置换算法（最近未用算法）：选择最近未用的页面<br>  （5）改进型CLOCK：考虑页面修改问题</li>
<li>  地址翻译：TLB-&gt;页表（TLB不命中）-&gt;Cache-&gt;主存-&gt;外存</li>
</ul>
</li>
</ul>
<h3 id="页面分配策略："><a href="#页面分配策略：" class="headerlink" title="页面分配策略："></a>页面分配策略：</h3><ul>
<li>固定分配局置换：每个进程分配一定数目的物理块，在整个运行期间不变，缺页时只在该进程在内存中的页面中进行置换；</li>
<li>可变分配全局置换：为每个进程分配一定数目的物理块，操作系统自身也保持一个空闲物理块队列；</li>
<li>可变分配局部置换：若进程在运行中频繁地缺页，系统再为该进程分配若干物理块；</li>
<li>抖动（颠簸）：刚换出的页面马上又要换入内存；刚换入的页面马上就要换出内存；</li>
<li>工作集（驻留级）：<ul>
<li>  指在某段时间间隔内，进程要访问的页面集合。</li>
</ul>
</li>
<li>虚拟内存空间大小：<ul>
<li>  &lt;=内存容量和外存容量之和&lt;</li>
<li>  &lt;=计算机的地址位数能容纳的最大容量</li>
</ul>
</li>
<li>虚拟存储的页表项：<ul>
<li>  页号</li>
<li>  物理块号</li>
<li>  状态位P：用于指示该页是否已调入内存，供程序访问参考；</li>
<li>  访问字段A：用于记录本页在一段时间内被访问的次数，或记录本页最近已有多长时间未被访问，供置换算法换出页面时参考；</li>
<li>  修改位M：标识该页在调入内存后是否被修改过；</li>
<li>  外存地址</li>
</ul>
</li>
<li>Belady现象：进程的缺页次数随着分配给进程的页框个数的增加而增加，只有FIFO队列式页面置换算法才有。</li>
<li>快表（联想寄存器TLB）：用来存放当前访问的若干页表项，以加速地址变换的过程，若所需访问页号在快表中则可减少一次内存访问。</li>
</ul>
<h2 id="第五章-虚拟存储器"><a href="#第五章-虚拟存储器" class="headerlink" title="第五章 虚拟存储器"></a>第五章 虚拟存储器</h2><p>略</p>
<h2 id="第六章-输入输出系统"><a href="#第六章-输入输出系统" class="headerlink" title="第六章 输入输出系统"></a>第六章 输入输出系统</h2><ul>
<li>I/O管理概述：状态跟踪、设备存取、设备分配、设备控制</li>
<li>设备分类：按传输速率分：<br>  低速：如磁盘、鼠标中速：如行式打印机、激光打印机高速：如磁带机、磁盘机、光盘机按信息交换单位分：<br>  块设备：如磁盘字符设备：如键盘、打印机</li>
<li>控制方式：程序直接控制：程序直接对设备特环测试中断驱动：引入中断机制，当设备准备完成时发生中断DMA：在I/O设备与主存之间开辟直接数据通路，彻底“解放”CPU。<br>  基本数据单位是块；传送的数据从设备直接送入内存（或相反）仅在传送一个或多个数据块的开始和结束时，才需要CPU干预，整块数据的传送是在DMA控制器的控制下完成的；包含的四类控制器：<br>  命令/状态寄存器（CR）内存地址寄存器（MAR）数据寄存器（DR）数据计数器（DC）</li>
<li>通道控制：引入专门的I/O处理机进行管理</li>
<li>I/O子系统层次：用户层I/O软件：实现与用户交互的接口设备独立性软件：实现用户程序与设备驱动器的统一接口、设备命令、设备保护以及设备分配与释放设备驱动程序：与硬件直接相关，负责具体实现系统对设备发出的操作指令中断处理程序：用于处理中断相关事项硬件设备：包括一个机械部件（设备本身）和一个电子邮件（控制器）</li>
<li>I/O核心子系统：<br>  I/O调度：确定一个好的顺序来执行这些I/O请求<br>  磁盘高速缓存：指利用内存中的存储空间来暂存从磁盘上读出的一系列盘块中的信息；逻辑上属于磁盘，物理上属于内存；1：在内存中开辟一个单独的存储空间作为磁盘高速缓存，大小固定2：把未利用的内存空间作为一个缓冲池，供请求分页系统和磁盘时I/O共享<br>  缓冲区：位于内存区域<br>  特点：当缓冲区的数据非空的时候，不能往缓冲区冲入数据，只能从缓冲区把数据传出；为空时，可以冲入数据，但必须充满遗憾才能再传出。<br>  引入缓冲区的目的：缓和CPU与I/O设备间速度不匹配的矛盾减少对CPU的中断频率，放宽对CUP中断响应时间的限制解决基本数据单元大小不匹配的问题提高CPU和I/O设备之间的并行性<br>  单缓冲<br>  双缓冲<br>  循环缓冲<br>  缓冲池</li>
</ul>
<table>
<thead>
<tr>
<th>比较</th>
<th>高度缓存</th>
<th>缓冲区</th>
</tr>
</thead>
<tbody><tr>
<td>存放数据</td>
<td>存放的是低速设备上的某些数据的复制数据</td>
<td>存放的是低速设备传递给高速设备的数据（或相反）</td>
</tr>
<tr>
<td>目的</td>
<td>高速缓存存放的是高速设备经常要访问的数据</td>
<td>高速设备和低速设备的通信都要经过缓冲区，高速设备永远不会直接去访问低速设备</td>
</tr>
<tr>
<td>相同点</td>
<td>都是介于高速设备和低速设备之间</td>
<td>都是介于高速设备和低速设备之间</td>
</tr>
</tbody></table>
<ul>
<li>设备的分配与回收：<ul>
<li>分类：<br>  （1）独点式使用设备：设备被使用时不再允许其他进程使用设备<br>  （2）分时共享式使用设备：设备没有独占使用的要求时，可以通过分时共享使用<br>  （3）SPOOLing技术：将独占设备改造成共享设备,实现了虚拟设备的功能；以空间换时间，必须先有独占设备</li>
<li>设备分配的数据结构：<br>  （1）设备控制表（DCT）：每个设备配置一张DCT，以记录本设备的情况；<br>  （2）控制器控制表（COCT）：每个控制器有一张COCT；<br>  （3）通道控制表（CHCT）：每个通道配置一张CHCT；<br>  （4）系统设备表（SDT）整个系统只有一张SDT，记录已连接到系统中的所有物理设备的情况<br>  （5）SDT中有一个DCT指针，DCT中有一个COCT指针，COCT中有一个CHCT指针，CHCT中有一个COCT指针。</li>
<li>  分配原则：即要求充分发挥设备的使用效率，又要避免造成进程死锁，还要将用户程序和具体设备隔离开</li>
<li>分配方式：<br>  （1）静态分配：在用户作业开始执行前，由系统一次性分配该作业所要求的全部设备<br>  （2）动态分配：在进程执行过程中根据执行需要进行分配</li>
<li>设备分配的安全性：<br>  （1）安全分配方式：每当进程发出I/O请求后便进入阻塞状态，直到其I/O操作完成时才被唤醒。<br>  （2）不安全分配方式：进程发出多个I/O请求并继续运行，仅当进程所请求的设备已被另一进程占用时，才进入阻塞状态。</li>
<li>  设备独立性是指应用程序独立于具体使用的物理设备</li>
<li>  SPOOLing技术：主要包括输入井、输出井、输入缓冲区和输出缓冲区以及输入进程和输出进程。</li>
<li>输入井和输出井是在磁盘上开辟的两大存储空间；<br>  （1）输入井是模拟脱机输入时的磁盘设备，用于暂存I/O设备输入的数据<br>  （2）输出井是模拟脱机输出时的磁盘，用于暂存用户程序的输出数据</li>
</ul>
</li>
</ul>
<h2 id="第七章-文件管理"><a href="#第七章-文件管理" class="headerlink" title="第七章 文件管理"></a>第七章 文件管理</h2><ul>
<li>文件控制块（FCB），类似进程管理的PCB，存放控制文件需要的各种信息的数据结构。<ul>
<li>  基本信息：包括文件物理位置</li>
<li>  存取控制信息</li>
<li>  使用信息</li>
<li>  索引结点一个</li>
</ul>
</li>
<li>文件对应一个FCB，而一个文件目录项就是一个FCB。</li>
<li>打开文件操作是讲该文件的FCB存入内存的活跃文件目录表，而不是将文件内容负责到主存，找到指定文件目录是打开文件之前的操作。</li>
</ul>
<h3 id="文件系统基础："><a href="#文件系统基础：" class="headerlink" title="文件系统基础："></a>文件系统基础：</h3><ul>
<li>逻辑结构：<ul>
<li>  无结构文件（流式文件）：将数据按顺序组织成记录并积累保存，（流式文件）则被看成是一个字符流，以字节（Byte）为单位；</li>
<li>有结构文件：<br>  （1）顺序文件：<ul>
<li>  串结构：记录之间的顺序与关键字无关</li>
<li>顺序结构：记录之间的顺序与关键字有关<br>  （2）索引文件：为变长文件建立索引表，提高查找速度<br>  （3）索引顺序文件：顺序文件和索引文件的结合，将顺序文件中的所有记录分为若干组，为顺序文件建立一张索引表，在索引中为每组的第一个记录建立一个索引项，其中含有该记录的关键字值和指向该记录的指针<br>  （4）直接文件（查找文件）Hash File：通过哈希函数直接决定记录地址</li>
</ul>
</li>
</ul>
</li>
<li>目录结构：<ul>
<li>  单级：全部文件都放在一个目录下</li>
<li>  两级：在目录下分出用户目录</li>
<li>  多级：将两级结构加以推广，采用树形结构</li>
<li>  无环图：在树形结构上加入一些有向边，便于共享</li>
</ul>
</li>
</ul>
<h3 id="文件共享："><a href="#文件共享：" class="headerlink" title="文件共享："></a>文件共享：</h3><ul>
<li>基于索引结点（硬链接）：共享文件指向同一个索引节点；链接计数count；</li>
<li>基于符号链（软链接）：有文件拥有者才拥有指向其索引结点的指针，共享该文件的其他用户则只有该文件的路径；</li>
</ul>
<h3 id="文件保护："><a href="#文件保护：" class="headerlink" title="文件保护："></a>文件保护：</h3><ul>
<li>口令保护：通过口令访问文件</li>
<li>加密保护：对文件进行加密处理</li>
<li>访问控制：根据访问者的身份进行限制</li>
</ul>
<h3 id="文件系统实现："><a href="#文件系统实现：" class="headerlink" title="文件系统实现："></a>文件系统实现：</h3><ul>
<li>目录实现：线性列表：<ul>
<li>  无序：查找文件较慢，新建文件较快</li>
<li>  有序：查找文件较快，新建文件较慢</li>
<li>  哈希表：查找、新建文件都较快，要处理冲突</li>
</ul>
</li>
<li>文件实现：<ul>
<li>  连续分配：在磁盘上连续存放文件</li>
<li>  链接分配：隐式：采用类似链表的结构，显式：把隐式文件中的指针单独抽离出来</li>
<li>  索引分配：每个文件所有的盘块号都集中存放，建立索引表</li>
</ul>
</li>
</ul>
<h3 id="存储空间管理："><a href="#存储空间管理：" class="headerlink" title="存储空间管理："></a>存储空间管理：</h3><ul>
<li>空闲表：把所有空闲块组织成表</li>
<li>空闲链表法：把所有空闲块组织成链表</li>
<li>位示图：利用二进制的每位记录空闲块</li>
<li>成组链接：空闲表和空闲链表的结合，适合大的文件系统</li>
</ul>
<h2 id="第八章-磁盘存储器的管理"><a href="#第八章-磁盘存储器的管理" class="headerlink" title="第八章 磁盘存储器的管理"></a>第八章 磁盘存储器的管理</h2><h3 id="磁盘管理"><a href="#磁盘管理" class="headerlink" title="磁盘管理"></a>磁盘管理</h3><ul>
<li>磁盘地址结构：柱面号、盘面号、扇区号</li>
<li>读写时间：<br>  （1）寻道时间：将磁头移动到指定磁道所需要的时间<br>  （2）延迟时间：磁头定位到某一磁道的扇区所需要的时间<br>  （3）传输时间：从磁盘读出或向磁盘写入数据所经历的时间<br>  （4）启动时间（一般忽略）：控制器的启动时间</li>
<li>调度算法：<br>  （1）先来先服务（FCFS）：根据进程请求访问磁盘的先后顺序进行调度<br>  （2）最短寻找时间优先（SSTF）：选择当前磁头所在的磁道距离最近的磁道<br>  （3）扫描（SCAN）算法（电梯算法）：在磁头当前移动方向上选择与当前磁头所在磁道距离最近的请求<br>  （4）循环扫描（C-SCAN）：在扫描算法的基础上规定磁头单向移动来提供服务</li>
<li>磁盘管理：<ul>
<li>  初始化：对磁盘进行低级格式化和逻辑化</li>
<li>  引导块：存放自举程序</li>
<li>  坏块：对于损坏扇区的处理</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>大学课程</tag>
        <tag>计算机操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>大学课程 | 计算机系统结构</title>
    <url>/posts/50754.html</url>
    <content><![CDATA[<p>大三计算机系统结构知识点总结笔记</p>
<span id="more"></span>

<h1 id="计算机系统结构"><a href="#计算机系统结构" class="headerlink" title="计算机系统结构"></a>计算机系统结构</h1><h2 id="第一章-计算机系统结构基础及并行性的开发"><a href="#第一章-计算机系统结构基础及并行性的开发" class="headerlink" title="第一章 计算机系统结构基础及并行性的开发"></a>第一章 计算机系统结构基础及并行性的开发</h2><ul>
<li>计算机性能的高速增长受益于<ul>
<li>电路技术的发展</li>
<li>体系结构技术的发展</li>
<li>其他因素(OS, Compiler 的发展)</li>
</ul>
</li>
<li>80年代后，RISC技术和微处理器技术使得体系结构技术对计算机性能发展的影响越来越大</li>
</ul>
<blockquote>
<p>CISC(复杂指令集)结构出现得较早。在这种结构中，新功能的增加主要靠增加新的指令，但为了保持向下兼容，就必须保持原有的指令；每条指令都有不同的操作指令码，对应不同的数据类型和位置，这样就造成了系统具有较大的指令系统和复杂的寻址技术，指令格式也很不规范。而RISC(精简指令集)结构则采用定长指令，使用流水线的方式执行指令。这种结构大量利用寄存器间的操作，大大简化了处理器的结构，优化了VLSI器件的使用效率，同时功耗较低。与CISC处理器相比，RISC处理器的突出特点是只用硬件实现最常用的指令，其他指令通过微代码软件来模拟实现，通过简短的定长指令提高并行度。这样虽然硬件设计较简单，但处理器指令的逻辑设计反而复杂了。RISC诞生之时恰逢386处理器取得了巨大的成功。在当时条件下，同样工艺水平的芯片，采用RISC架构的产品，其速度比CISC快3倍左右，这在Intel内部产生了很大的震动。最终诞生的 486处理器是第一个真正引入RISC技术的X86处理器。</p>
</blockquote>
<h3 id="1-1-计算机系统的层次结构"><a href="#1-1-计算机系统的层次结构" class="headerlink" title="1.1 计算机系统的层次结构"></a>1.1 计算机系统的层次结构</h3><ul>
<li>如何从整体上认识计算机系统？<ul>
<li>一种新的认识方法：从计算机语言的角度，将计算机系统看成按<strong>功能</strong>划分的<strong>多级层次结构</strong></li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GmXU9f.jpg" alt="GmXU9f.jpg"></p>
<ul>
<li>M0用硬件实现，M1用微程序（固件）实现，M2到M5大多用软件实现</li>
<li>固件：是一种具有软件功能的硬件</li>
<li>虚拟机：由软件实现的机器。虚拟机的功能不一定全由软件实现，也可以是固件或硬件</li>
<li><strong>选择什么样的软硬件比例</strong>，是系统结构研究的核心内容之一</li>
<li>多层系统结构的意义和作用<ul>
<li>推动了计算机系统结构的发展<ul>
<li>有利于正确理解软件、硬件和固件在系统结构中的地位和作用</li>
</ul>
</li>
<li>发展了多处理机系统、分布处理系统、计算机网络系统等系统结构<ul>
<li>每级有各自的用户、实现方法和指令集，摆脱各级功能在一台机器实现</li>
</ul>
</li>
<li>推动自虚拟机、多种操作系统共行等技术</li>
</ul>
</li>
<li>对于使用某一级语言编程的程序员来说，只需要熟悉和遵守该级语言的使用规定。</li>
<li>各机器级的实现采用翻译技术或解释技术，或者两者结合</li>
<li><strong>翻译</strong>： 先用转换程序将高一级机器级上的程序<strong>整个</strong>地变换成低一级机器级上等效的程序，然后再在低一级机器级上实现的技术</li>
<li><strong>解释</strong>： 在低级机器级上用它的一串语句或指令来仿真高级机器级上的一条语句或指令的功能，是通过对高级的机器级语言程序中的每条语句或指令<strong>逐条</strong>解释来实现的技术</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/Gn93xx.jpg" alt="Gn93xx.jpg"></p>
<h3 id="1-2-计算机系统结构，计算机组成和计算机实现"><a href="#1-2-计算机系统结构，计算机组成和计算机实现" class="headerlink" title="1.2 计算机系统结构，计算机组成和计算机实现"></a>1.2 计算机系统结构，计算机组成和计算机实现</h3><h4 id="1-2-1-计算机系统结构的定义和内涵"><a href="#1-2-1-计算机系统结构的定义和内涵" class="headerlink" title="1.2.1 计算机系统结构的定义和内涵"></a>1.2.1 计算机系统结构的定义和内涵</h4><p>从计算机系统的层次结构角度来看，系统结构是对计算机系统中各级界面的定义及其上下的功能分配。计算机系统的每一级都有自己的系统结构。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GKobNV.png" alt="GKobNV.png"></p>
<ul>
<li>从不同级看到的计算机属性是不同的</li>
<li>计算机系统的层次结构具有的特征：<strong>透明性</strong></li>
<li>透明：客观存在的事物或属性从某个角度<strong>看不到</strong><ul>
<li>优点：可以不用管理它，简化设计</li>
<li>缺点：看不到而无法加以控制，会带来不利</li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GKT6KJ.png" alt="GKT6KJ.png"></p>
<p>计算机系统结构也称为计算机系统的体系结构，它只是系统结构中的一部分，指的是传统机器级的系统结构。</p>
<ul>
<li>结论：计算机系统结构研究的是软，硬件之间的功能分配以及对传统机器级界面的确定</li>
<li>计算机系统结构是程序员所看到的计算机的属性，即概念性结构与功能特性</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GnAISJ.jpg" alt="GnAISJ.jpg"></p>
<blockquote>
<p>堆栈型机器、累加器型机器和通用寄存器型机器各自有什么优缺点<br>1.堆栈型机器——CPU 中存储操作数的单元是堆栈的机器。<br>2.累加型机器——CPU 中存储操作数的单元是累加器的机器。<br>3.通用寄存器型机器——CPU 中存储操作数的单元是通用寄存器的机器。<br>CPU状态分为管态和目态，CPU的状态属于程序状态字PSW的一位，管态又称特权状态、系统态或核心态。通常，操作系统在管态下运行，CPU在管态下可以执行指令系统的全集。<br>目态又称常态或用户态，机器处于目态时，程序只能执行非特权指令。用户程序只能在目态下运行。</p>
</blockquote>
<h4 id="1-2-2-计算机组成和计算机实现的定义及内涵"><a href="#1-2-2-计算机组成和计算机实现的定义及内涵" class="headerlink" title="1.2.2 计算机组成和计算机实现的定义及内涵"></a>1.2.2 计算机组成和计算机实现的定义及内涵</h4><p>1.<strong>计算机组成</strong>：是指<strong>计算机系统结构的逻辑实现</strong>，包括机器级内部的数据流和控制流的组成以及逻辑设计等等<br>（1）着眼点：机器内部各事件的排序方式与控制机构，各部件的功能及各部件间的联系。<br>（2）预解决：在合理或满足要求的性能和价格的条件下，怎么最佳、最合理地把各种设备和部件组织成计算机，以实现所确定的计算机。</p>
<ul>
<li>计算机组成设计要确定的方面包括：<ul>
<li>数据通路宽度（数据总线上一次并行传送的信息位数）</li>
<li>各种操作对功能部件的共享程度</li>
<li>专用功能部件的设置</li>
<li>功能部件的并行性</li>
<li>缓冲和排队技术</li>
<li>预测技术</li>
<li>可靠性技术</li>
<li>控制机构的组成，等等</li>
</ul>
</li>
</ul>
<p>2.<strong>计算机实现</strong>：是计算机组成的<strong>物理实现</strong><br>（1）着眼点：器件技术（主导作用），微组装技术</p>
<ul>
<li>计算机实现:(是数字电路等课程主要研究的内容)<ul>
<li>处理器、主存的物理结构</li>
<li>器件的集成度和速度</li>
<li>信号传输</li>
<li>器件、模块、插件、底板的划分与连接</li>
<li>涉及的专用器件</li>
<li>电源、冷却、微组装技术、整机装配技术，等等</li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQGiSH.jpg" alt="GQGiSH.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQGwp4.png" alt="GQGwp4.png"></p>
<ul>
<li>系列机：CPU的机器指令和汇编指令系统相同（或绝大部分相同）</li>
<li><strong>狭义的系统结构</strong>是<strong>组成</strong>的抽象</li>
<li><strong>组成</strong>是<strong>实现</strong>的抽象</li>
<li>一种体系结构可以有多种组成，一种组成可以有多种物理实现</li>
<li><strong>计算机系统结构</strong>研究的范畴：机器/汇编指令系统，数据表示，是否采用通道方式输入/输出的确定</li>
<li><strong>计算机组成研究</strong>的范畴：指令采用顺序，重叠，流水还是其他方式解释，数据通路宽度的确定，通道采用结合型还是独立型</li>
<li><strong>广义</strong>的计算机体系结构定义：包括<strong>狭义的系统结构，计算机组成</strong><ul>
<li>任务：<ul>
<li>从程序设计者角度：软硬件的功能分配以及确定软硬件界面</li>
<li>从计算机设计者角度：更合理地实现分配给硬件的功能</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="1-2-3-计算机系统结构，组成和实现的相互影响"><a href="#1-2-3-计算机系统结构，组成和实现的相互影响" class="headerlink" title="1.2.3 计算机系统结构，组成和实现的相互影响"></a>1.2.3 计算机系统结构，组成和实现的相互影响</h4><ul>
<li>计算机系统结构，组成，实现三者互不相同，但又互相影响</li>
<li>不同的系统结构会影响到组成技术</li>
<li>组成技术也会影响系统结构，是一种推动作用<ul>
<li>专用部件的设置</li>
</ul>
</li>
<li><strong>实现</strong>永远是结构和组成的最坚实基础</li>
</ul>
<h3 id="1-3-计算机系统的软硬件取舍，性能评测及定量设计原理"><a href="#1-3-计算机系统的软硬件取舍，性能评测及定量设计原理" class="headerlink" title="1.3 计算机系统的软硬件取舍，性能评测及定量设计原理"></a>1.3 计算机系统的软硬件取舍，性能评测及定量设计原理</h3><h4 id="1-3-1-软，硬件取舍的基本原则"><a href="#1-3-1-软，硬件取舍的基本原则" class="headerlink" title="1.3.1 软，硬件取舍的基本原则"></a>1.3.1 软，硬件取舍的基本原则</h4><ul>
<li>计算机系统结构的任务：<ul>
<li>软、硬功能分配，确定软硬界面</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>提高硬件功能比例</th>
<th>提高软件功能比例</th>
</tr>
</thead>
<tbody><tr>
<td>提高解题速度</td>
<td>降低解题速度</td>
</tr>
<tr>
<td>减少程序所需存储空间</td>
<td>增加程序所需存储空间</td>
</tr>
<tr>
<td>增加硬件成本</td>
<td>减少硬件成本</td>
</tr>
<tr>
<td>降低软件费用</td>
<td>增加软件费用</td>
</tr>
<tr>
<td>降低硬件利用率</td>
<td>增加系统灵活性</td>
</tr>
<tr>
<td>降低系统灵活性</td>
<td></td>
</tr>
</tbody></table>
<ul>
<li><p>软硬件取舍的<strong>三原则</strong>：</p>
<ul>
<li>在现有的硬件和器件条件下，系统要有<strong>高的性能价格比</strong>；</li>
<li>在软硬功能分配时，要考虑到准备采用的组成和实现技术，<strong>使其不过多的限制或不合理限制各种组成、实现技术</strong>；</li>
<li>在软硬功能分配时，除了从“硬件”角度考虑，还要从“软”的角度考虑，把为<strong>编译、OS以及高级语言的设计与实现提供更多、更好的硬件支持放在首位</strong>。</li>
</ul>
</li>
<li><p>语义差距的大小实质上取决于软硬件功能的分配</p>
</li>
</ul>
<h4 id="1-3-2-计算机系统的性能评测与定量设计原理"><a href="#1-3-2-计算机系统的性能评测与定量设计原理" class="headerlink" title="1.3.2 计算机系统的性能评测与定量设计原理"></a>1.3.2 计算机系统的性能评测与定量设计原理</h4><p>1.计算机系统的性能评测</p>
<ul>
<li>时钟频率：CPU的主频表示在CPU内数字脉冲信号震荡的速度，与CPU实际的运算能力并没有直接关系</li>
<li>计算机系统的性能指标体现于<strong>时间</strong>和<strong>空间</strong>两个方面，在系统上程序实际运行的<strong>时间</strong>应该是衡量机器时间（速度）性能最可靠的标准</li>
<li>机器的性能是通过采用好的硬件，系统结构以及高效的资源管理等技术来提高的</li>
<li>计算机性能指：数据处理（数据运算（速度），数据传输（速度）），数据容量，数据质量的综合性能</li>
<li>系统性能的测量依赖于人（计算机用户/系统管理者）的观点</li>
<li>计算机的性能以及对系统评价的目标都指<strong>系统速度的性能</strong>，通常是用<strong>响应时间</strong>来衡量</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQT9Nq.png" alt="GQT9Nq.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQTuU1.png" alt="GQTuU1.png"></p>
<ul>
<li><p>减少CPI是RISC思想的精华 </p>
</li>
<li><p>反应程序的运行速度通常引入下面一些指标</p>
<ul>
<li>MIPS：计算机单位时间执行的指令条数<ul>
<li>主频越高f，平均每条指令的时钟周期数CPI越少，其MIPS越高，在一定程度反映了机器的性能</li>
<li>MIPS很大程度的依赖指令集，它很难衡量指令系统不同机器之间的性能</li>
<li>用于比较相同指令系统系统</li>
<li>即使在同一台机器上，程序负荷不同，CPI也不同，MIPS也就受到影响——浮点运算、定点运算</li>
<li>MIPS还与机器的硬件实现有关<ul>
<li>浮点运算在硬件上实现，MIPS低，性能高</li>
<li>浮点运算用软件实现，MIPS高，性能低</li>
</ul>
</li>
</ul>
</li>
<li>MFLOPS：每秒百万次浮点运算<ul>
<li>Tflops:每秒一万亿次浮点运算</li>
<li>1T=1024G ， 1G=1024M  </li>
</ul>
</li>
</ul>
</li>
<li><p>计算机的性能通常用<strong>峰值性能</strong>和<strong>持续性能</strong>来评价</p>
<ul>
<li>峰值性能：理想情况下计算机系统可以获得的最高理论性能值</li>
<li>持续性能：也称<strong>实际性能</strong>，其表示有<strong>算术性能平均值</strong>，<strong>调和性能平均值</strong>，<strong>几何性能平均值</strong></li>
</ul>
</li>
<li><p>算术性能平均值</p>
<ul>
<li>设算术性能平均值Am是n道程序运算速度或运算时间的算术平均值</li>
<li>以速率评价<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQHup6.png" alt="GQHup6.png"></li>
<li>Ti是第i个程序的执行时间，Ri是第i个程序的执行速率</li>
<li>以执行时间评价<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQHTE9.png" alt="GQHTE9.png"></li>
</ul>
</li>
<li><p>调和性能平均值</p>
<ul>
<li>调和平均数又称倒数平均数，<strong>给定数据的倒数之算术平均数的倒数</strong></li>
<li><strong>Hm的值与运行全部程序所需的时间成反比—比较准确</strong></li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQbfPI.jpg" alt="GQbfPI.jpg"></li>
</ul>
</li>
<li><p>几何性能平均值</p>
<ul>
<li>几何平均数是n个变量值连乘积的n次方根</li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQqlod.png" alt="GQqlod.png"></li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/G1iX6g.png" alt="G1iX6g.png"></li>
<li>几何平均值无法给出系统性能的真实期望.</li>
<li>几何平均值常常使用测试机和参考机之间归一化的比值</li>
</ul>
</li>
<li><p><strong>调和平均数、几何平均数和算术平均数三者间，存在如下数量关系：  H≤G≤A</strong></p>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQOgZF.png" alt="GQOgZF.png"></p>
<p>2.计算机系统的定量设计原理<br>（1）哈夫曼压缩原理</p>
<ul>
<li>也称关注经常性事件原则</li>
<li>抓主要矛盾</li>
<li>性能——功耗的折中<ul>
<li>处理器执行两个数的加法运算，溢出不溢出情况</li>
<li>Pentium M处理器为了降低系统功耗且同时提高计算机性能，在其译码单元引入“micro-op Fusion”概念，把原有的两个micro-op（microinstructions）合成为一个进行操作</li>
</ul>
</li>
</ul>
<p>（2）Amdahl定律</p>
<ul>
<li>该定律将“关注经常性事件原则”进行了量化</li>
<li>用于确定对系统中<strong>性能瓶颈部件采取措施提高速度后</strong>能得到系统性能改进的程度，即系统加速比Sp</li>
<li><strong>Sp定义为系统改进后的性能与未改进时的性能的比值，或者定义为系统未改进时的程序执行时间Told与改进后程序执行时间Tnew的比值</strong></li>
<li>Sp与两个因素有关，即性能可改进比fnew和部件加速比rnew</li>
<li>性能可改进比fnew是系统性能可改进部件占用的时间与未改进时系统总执行时间的比值<ul>
<li>0≤fnew≤1</li>
</ul>
</li>
<li>部件加速比rnew是系统性能可改进部分在改进后性能提高的比值<ul>
<li>Rnew&gt;1</li>
<li>Rnew=TRold/TRnew</li>
</ul>
</li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/G1kiVA.png" alt="G1kiVA.png"></li>
<li>当fnew为0时，Sp=1；当Rnew趋于无穷大时，Sp=1/(1-fnew);</li>
<li>通过使用某种较快的执行方式所获得的性能提高，受限于该部件占用系统执行时间的百分比,它是一个悲观定律</li>
<li>通用多核系统在扩展到8个核以上时，往往会达到一个性能降低的拐点</li>
<li>应用本身受到串行处理模式和技术的限制。无论拥有多少个核心，它们中的许多都因等待数据进行串行处理而被闲置起来</li>
<li>阿姆达尔定律描述的一个关键事实是它<strong>只适用于计算的一种场合</strong>，即施行并行化后计算中的顺序部分将占据执行时间的主要部分</li>
<li>阿姆达尔定律是在<strong>固定应用规模的前提下</strong>考虑并行性增长的影响。但大多数并行计算则是<strong>固定并行性而扩展应用的规模</strong></li>
</ul>
<p>（3）程序访问的局部性规律</p>
<ul>
<li>时间局部性: 一个存储项被访问,可能很快再访问</li>
<li>空间局部性: 存储项被访问,它的邻近项可能很快被访问</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQX3FJ.png" alt="GQX3FJ.png"></p>
<p><strong>某一计算机用于商业外贸的事务处理，有大量的字符串操作。由于这种事务处理很普遍，有较大的市场，故而设计人员决定在下一代此类计算机的CPU中加入字符串操作的功能。经测试应用软件调查发现，字符串操作的使用占整个程序运行时间的50%，而增加此功能如用软件（如微程序）实现，则快5倍，增加CPU成本1/5倍；如果用硬件实现，则快100倍，CPU成本增加到5倍。问设计人员提出增加此功能是否恰当？是否用软件还是硬件？（设CPU成本占整机成本的1/3）</strong><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQX0Te.png" alt="GQX0Te.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQXclt.png" alt="GQXclt.png"></p>
<h4 id="1-3-3-计算机系统设计的主要任务和方法"><a href="#1-3-3-计算机系统设计的主要任务和方法" class="headerlink" title="1.3.3 计算机系统设计的主要任务和方法"></a>1.3.3 计算机系统设计的主要任务和方法</h4><p>1.计算机系统设计的主要任务</p>
<ul>
<li>包括系统结构，计算机组成和计算机实现的设计</li>
</ul>
<p>2.计算机系统的设计方法</p>
<ul>
<li>由上往下<ul>
<li>先考虑如何满足用户要求，定好面对使用者的虚拟机的基本功能和环境，如指令系统、语言结构、数据类型等，然后逐级向下设计，每一级都严格考虑优化上一级来实现</li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQj7Ue.png" alt="GQj7Ue.png"></li>
</ul>
</li>
<li>由下往上<ul>
<li>不考虑用户的具体需求，只根据当时拿到的器件，参照或吸收已有各种机器的特点，把微程序机器级和传统机器级分别研制出来，然后再配上适合不同应用环境的各种操作系统和各种编译程序，以满足不同方面的应用要求。</li>
<li>优点:<ul>
<li>有利于缩短研制周期</li>
<li>有利于软硬件人员之间的交流</li>
<li>软硬分配更加合理</li>
<li>系统的性能价格比更高</li>
</ul>
</li>
</ul>
</li>
<li>从中间往两头</li>
</ul>
<h3 id="1-4-软件，应用，器件的发展对系统结构的影响"><a href="#1-4-软件，应用，器件的发展对系统结构的影响" class="headerlink" title="1.4 软件，应用，器件的发展对系统结构的影响"></a>1.4 软件，应用，器件的发展对系统结构的影响</h3><h4 id="1-4-1-软件的发展对系统结构的影响"><a href="#1-4-1-软件的发展对系统结构的影响" class="headerlink" title="1.4.1 软件的发展对系统结构的影响"></a>1.4.1 软件的发展对系统结构的影响</h4><ul>
<li>软件的可移植：软件不用修改或只需经少量加工就能由一台机器投到另一台机器上运行，即同一软件可以应用于不同的环境</li>
<li>软件移植的三种技术<ul>
<li>统一高级语言：面向题目和算法，和具体结构关系不大<ul>
<li>指一种完全通用的高级语言，为所有程序员所使用，并能在完全不同的机器之间实现程序的软件移植。</li>
</ul>
</li>
<li>系列机、兼容机：具有相同结构的各种机器之间<ul>
<li>兼容机：不同厂家生产的具有相同指令集结构的计算机</li>
<li>系列机：CPU的机器指令和汇编指令系统相同（或绝大部分相同）</li>
<li>软件兼容：即同一个软件可以不加修改地运行于体系结构相同的各档机器，而且它们    所获得的结果一样，差别只在于有不同的运行时间。</li>
<li>向上(下)兼容指的是按某档机器编制的程序，不加修改的就能运行于比它高(低)档的机器。</li>
<li>向前(后）兼容指的是按某个时期投入市场的某种型号机器编制的程序，不加修改地就能运行于在它之后(前)投入市场的机器。</li>
<li>系列机软件兼容性必须保证做到向后兼容，力争向上兼容</li>
</ul>
</li>
<li>模拟与仿真：软件在不同体系结构之间的移植<ul>
<li>模拟<ul>
<li>用A机的机器语言程序解释B机器语言程序，从而实现软件移植方法 宿主机 A机  虚拟机 B机</li>
<li>为实现模拟编制的各种解释程序</li>
</ul>
</li>
<li>仿真<ul>
<li>用A机的微程序解释B机的机器语言程序，从而实现软件移植方法 宿主机 A机  目标机 B机</li>
<li>为实现仿真编制的各种解释微程序</li>
</ul>
</li>
<li><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GQzTET.png" alt="GQzTET.png"></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/GlSiPe.png" alt="GlSiPe.png"></p>
<h4 id="1-4-2-应用对系统结构的影响"><a href="#1-4-2-应用对系统结构的影响" class="headerlink" title="1.4.2 应用对系统结构的影响"></a>1.4.2 应用对系统结构的影响</h4><ul>
<li>应用需求是促使计算机系统结构发展的最根本的动力</li>
<li>不同的应用对计算机系统结构的设计提出了不同的要求</li>
<li>计算机应用可归纳为：数据处理，信息处理，知识处理，智能处理</li>
</ul>
<h4 id="1-4-3-器件的发展对系统结构的影响"><a href="#1-4-3-器件的发展对系统结构的影响" class="headerlink" title="1.4.3 器件的发展对系统结构的影响"></a>1.4.3 器件的发展对系统结构的影响</h4><ul>
<li><p>芯片制造的发展</p>
</li>
<li><p>器件的发展对系统的影响</p>
<ul>
<li>功能和使用方法—非用户片、现场片及用户片</li>
<li>改变了逻辑设计的传统方法—速度、规整</li>
<li>推动了系统结构技术的发展</li>
<li>体系结构”下移”速度加快—并行计算</li>
<li>促进了算法、语言和软件的发展</li>
</ul>
</li>
<li><p>软件是促使计算机系统结构发展的最重要的因素</p>
</li>
<li><p>应用需求是促使计算机系统结构发展的最根本的动力</p>
</li>
<li><p>器件是促使计算机系统结构发展最活跃的因素</p>
</li>
<li><p>非用户片：也称通用片，其功能是由器件厂家生产时已确定的，器件的用户（即机器设计者）只能使用，不能改变器件内部功能</p>
</li>
<li><p>现场片：是用户根据需要可改变器件内部功能的芯片（FPGA）</p>
</li>
<li><p>用户片：是专门按用户要求生产的高集成度VLSI器件（ASIC）</p>
<ul>
<li>全用户片：是完全按用户要求设计的用户片</li>
<li>半用户片：是基本按通用片进行生产，最后按用户要求再制作的用户片，如门阵列、门-触发器阵列等</li>
</ul>
</li>
</ul>
<h3 id="1-5-系统结构钟的并发性开发及计算机系统的分类"><a href="#1-5-系统结构钟的并发性开发及计算机系统的分类" class="headerlink" title="1.5 系统结构钟的并发性开发及计算机系统的分类"></a>1.5 系统结构钟的并发性开发及计算机系统的分类</h3><h4 id="1-5-1-并行性的概念和开发"><a href="#1-5-1-并行性的概念和开发" class="headerlink" title="1.5.1 并行性的概念和开发"></a>1.5.1 并行性的概念和开发</h4><p>1.并行性的含义和级别</p>
<ul>
<li><p><strong>并行性</strong>：解题中具有可以同时进行运算或操作的特性</p>
</li>
<li><p>并行性包含了同时性和并发性二重含义</p>
<ul>
<li><strong>同时性</strong>（Simultaneity）：两个或多个事件在<strong>同一时刻</strong>发生</li>
<li><strong>并发性</strong>（Concurrency）：两个或多个事件在<strong>同一时间间隔内</strong>发生</li>
</ul>
</li>
<li><p><strong>只要时间上有重叠就存在并行性！</strong></p>
</li>
<li><p>并行性的等级：</p>
<ul>
<li>从计算机系统中执行程序的角度（由低到高）<ul>
<li>指令内部—一条指令内部各个微操作之间的并行</li>
<li>指令之间—多条指令的并行执行</li>
<li>任务或进程之间—多个任务或程序段的并行执行</li>
<li>作业或程序之间—多个作业或多道程序的并行。</li>
</ul>
</li>
<li>从处理数据的角度（由低到高）<ul>
<li>位串字串——顺序</li>
<li>位并字串——同时对一个字的全部位</li>
<li>位片串字并——同时对许多字的同一位</li>
<li>全并行——同时对许多字的全部或部分</li>
</ul>
</li>
<li>从计算机信息加工的各个步骤和阶段<ul>
<li>存储器操作并行</li>
<li>处理器操作步骤并行</li>
<li>处理器操作并行</li>
<li>指令、任务、作业并行</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>2.并行性开发的途径</p>
<ul>
<li><p><strong>时间重叠</strong></p>
<ul>
<li>是在并行性概念中引入时间因素，让多个处理过程在时间上相互错开，轮流重叠地使用同一套硬件设备的各个部分，以加快硬件周转而赢得速度。<ul>
<li>举例：流水线</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>资源重叠</strong></p>
<ul>
<li>是在并行性概念中引入空间因素，通过重复设置硬件资源来提高可靠性或性能<ul>
<li>例如：双工系统</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>资源共享</strong></p>
<ul>
<li>是利用<strong>软件的方法</strong>让多个用户按一定时间顺序轮流地使用同一套资源，以提高其利用率，这样也可以提高整个系统的性能<ul>
<li>例如：网络打印机</li>
<li>多道程序、分时OS →真正的处理机代替虚拟机→分布处理系统</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>3.计算机系统的并行性发展</p>
<ul>
<li>不同时间阶段，并行性发展的主要表现不同</li>
</ul>
<p>4.多机系统的耦合度</p>
<ul>
<li>多机系统：包含多处理机系统和多计算机系统<ul>
<li>多处理机系统<ul>
<li>是由多台处理机组成的单一计算机系统，各处理机都可有自己的控制部件，可带自己的局部存储器，能执行各自的程序</li>
<li><strong>在逻辑上受统一的操作系统控制</strong>，体系结构可以是共享存储器，也可以是分布式存储器</li>
</ul>
</li>
<li>多计算机系统<ul>
<li>是由多台独立的计算机组成的系统，<strong>各计算机分别在逻辑上独立的操作系统控制下运行</strong>，机间可以互不通信，即使通信也只是经通道或通信线路以文件或数据集形式进行，实现多个作业的并行</li>
<li>一般指分布式存储结构</li>
<li>集群系统和大规模并行处理机MPP都是多计算机系统</li>
</ul>
</li>
</ul>
</li>
<li><strong>耦合度</strong>：一般用耦合度反映多机系统中各机器之间物理连接的紧密程度和交叉作用能力的强弱<ul>
<li><strong>最低耦合系统</strong>（Least Coupled System）：各种脱机系统 </li>
<li><strong>松散耦和系统</strong>（Loosely Coupled System）：如果多台计算机通过通道或通信线路实现互连，共享某些磁带、磁盘等外围设备，以较低频带在文件或数据集一级相互作用。又称间接耦合系统</li>
<li><strong>紧密耦合系统</strong>（Tightly Coupled System）：如果多台机器之间通过总线或高速开关互连，<strong>共享主存</strong>，并有较高的信息传输速度，可以实现数据集一级、任务级、作业级的并行。又称直接耦合系统 </li>
</ul>
</li>
</ul>
<h4 id="1-5-2-计算机系统的分类"><a href="#1-5-2-计算机系统的分类" class="headerlink" title="1.5.2 计算机系统的分类"></a>1.5.2 计算机系统的分类</h4><p>1.弗林分类</p>
<ul>
<li>弗林分类法（Michael J,Flynn分类）：弗林提出按<strong>指令流</strong>和<strong>数据流</strong>的多倍性对计算机系统进行分类<ul>
<li><strong>指令流</strong>：是指机器执行的<strong>指令序列</strong></li>
<li><strong>数据流</strong>：是指指令流调用的<strong>数据序列</strong>，包括输入数据和中间结果</li>
<li><strong>多倍性</strong>：是指在系统性能瓶颈部件上处于<strong>同一执行阶段</strong>的指令或数据的最大可能个数</li>
</ul>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/G1KCqK.png" alt="G1KCqK.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/G1KQZ8.png" alt="G1KQZ8.png"></p>
<ul>
<li>主要缺点：  <ul>
<li>(1)分类太粗：例如，在SIMD中包括有多种处理机，对流水线处理机的划分不明确，标量流水线为SISD，向量流水线为SIMD </li>
<li>(2)根本问题是把两个不同等级的功能并列对待；通常，数据流受指令流控制，从而造成MISD不存在  </li>
<li>(3)非冯计算机的分类；其他新型计算机的分类  </li>
</ul>
</li>
</ul>
<p>2.库克分类</p>
<ul>
<li>用<strong>指令流</strong>和<strong>执行流</strong>（Execution Stream）及其多倍性来描述计算机系统总控制器的结构特征<ul>
<li>SISE：单处理机系统 </li>
<li>SIME：多操作部件的处理机</li>
<li>MISE：带指令级多道程序的单处理机</li>
<li>MIME：多处理机 </li>
</ul>
</li>
<li>缺点 <ul>
<li>有些系统，如分布处理机等，没有总控制器  </li>
<li>分类太粗，如SIME中包含了多种类型的处理机  </li>
</ul>
</li>
</ul>
<p>3.冯泽云分类</p>
<ul>
<li>提出用数据处理的并行度来定量地描述各种计算机系统特性<ul>
<li>WSBS（字串位串） </li>
<li>WSBP（字串位并）</li>
<li>WPBS（字并位串）</li>
<li>WPBP（字并位并）</li>
</ul>
</li>
<li>缺点<ul>
<li>仅考虑了数据的并行性，没有考虑指令、任务、作业的并行<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/G1MekF.png" alt="G1MekF.png"></li>
</ul>
</li>
</ul>
<h3 id="1-6-本章小结"><a href="#1-6-本章小结" class="headerlink" title="1.6 本章小结"></a>1.6 本章小结</h3><ol>
<li>重点：（1）计算机系统结构，计算机组成，计算机实现三者的定义以及包含的内容（2）有关透明性问题的判断（3）软件和硬件的功能分配原则（4）软件可移植性的途径，方法，适用场合，存在问题和对策（5）并行性的概念（6）系统结构中开发并行性的途径</li>
<li>难点：透明性的判断与分析</li>
</ol>
<blockquote>
<p>下列哪些对<strong>系统程序员</strong>是透明的?<br><strong>A、超大规模集成电路</strong><br>B、虚拟存储器<br><strong>C、Cache存储器</strong><br>D、程序状态字<br>E、“启动I/O”指令<br>F、“执行”指令<br><strong>G、指令缓冲寄存器</strong></p>
</blockquote>
<p>正确答案： ACG </p>
<blockquote>
<p>下列哪些对<strong>应用程序员</strong>是透明的?<br><strong>A、虚拟存储器</strong><br><strong>B、Cache存储器</strong><br><strong>C、程序状态字</strong><br><strong>D、“启动I/O”指令</strong><br>E、“执行”指令<br><strong>F、指令缓冲寄存器</strong></p>
</blockquote>
<p>正确答案： ABCDF </p>
<blockquote>
<p>1.系列机可将单总线改成双总线来减少公用总线的使用冲突。 【答案：√】<br>2.系列机增加新机种时,为增加寻址灵活性和缩短平均指令字长,由原等长操作码改为多种码长的扩展操作码。【答案：×】<br>3.系列机应用软件应做到向前兼容,力争向下兼容。【答案：×】<br>4.可以说向后兼容是系列机的根本特征。 【答案：√】<br>5.系列机不再是方向,因为它约束了计算机系统结构的发展。 【答案：×】<br>6.由同一厂家生产的,系统结构相同的,但组成和实现不同的所有计算机,称为兼容机。 【答案：×】 </p>
</blockquote>
<h2 id="第二章-数据表示，寻址方式与指令系统"><a href="#第二章-数据表示，寻址方式与指令系统" class="headerlink" title="第二章 数据表示，寻址方式与指令系统"></a>第二章 数据表示，寻址方式与指令系统</h2><h3 id="2-1-数据表示"><a href="#2-1-数据表示" class="headerlink" title="2.1 数据表示"></a>2.1 数据表示</h3><h4 id="2-1-1-数据表示与数据结构"><a href="#2-1-1-数据表示与数据结构" class="headerlink" title="2.1.1 数据表示与数据结构"></a>2.1.1 数据表示与数据结构</h4><ul>
<li>数据表示：能由机器硬件识别和引用的<strong>数据类型</strong>，表现在它有对这种类型的数据进行操作的指令和运算部件。</li>
<li>数据类型：<strong>不同于数据，数据类型除了指一组值的集合外，还定义了可作用于这个集合上的操作集</strong> <ul>
<li><strong>基本数据</strong>类型</li>
<li><strong>结构数据</strong>类型<ul>
<li>一组由相互有关的数据元素复合而成的数据类型，这些数据元素可以是基本数据类型中的元素，也可以是结构数据类型本身中的元素。也就是说这些数据是有结构的，<strong>包括向量和数组、字符串、堆栈、队列、记录</strong>等，结构数据类型中的元素不一定都具有相同类型</li>
</ul>
</li>
<li>访问指针</li>
<li>抽象数据等类型</li>
</ul>
</li>
<li>数据结构：通过软件映像，变换成机器中所具有的数据表示来实现的。<ul>
<li>是应用中相互之间存在一种或多种特定关系的数据元素的集合。如：线性表、栈、队列、串、数组、阵列、链表、树和图等。</li>
<li>是结构数据类型的组织方式，它反映了结构数据类型中各种数据元素或信息单元之间的结构关系 </li>
<li>不同数据表示可以为数据结构的实现提供不同的支持。<strong>数据表示是数据结构的子集</strong></li>
<li>数据结构和数据表示是软硬件的交界面。</li>
</ul>
</li>
</ul>
<p>图为变址操作对向量，阵列数据结构的支持：<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/1.png"></p>
<h4 id="2-1-2-高级数据表示"><a href="#2-1-2-高级数据表示" class="headerlink" title="2.1.2 高级数据表示"></a>2.1.2 高级数据表示</h4><p>1.自定义数据表示<br>（1）标志符数据表示</p>
<ul>
<li>为缩短高级语言与机器语言的语义差距，让机器中每个数据都带类型标志位</li>
<li>| 类型标志 | 数据值 |</li>
<li>标志符数据表示的主要优点<ul>
<li>简化了指令系统和程序设计<ul>
<li>减少指令种类</li>
</ul>
</li>
<li>简化了编译程序<ul>
<li>不用做复杂的映射</li>
</ul>
</li>
<li>便于实现一致性校验</li>
<li>能由硬件自动变换数据类型</li>
<li>为软件调试和应用软件开发提供了支持</li>
</ul>
</li>
<li>使用标志符数据表示可能带来如下问题<ul>
<li>每个数据字因增设标志符，会增加程序所占的主存空间</li>
<li>采用标志符会降低指令的执行速度<ul>
<li>增加按标志符确定数据属性及判断操作数之间是否相容等操作，单条指令的执行速度会下降。</li>
<li>程序的编制和调试时间的缩短，是解题总时间缩短</li>
<li>所以，引入标志符数据表示对微观性能（机器的运算速度）不利，但对宏观性能（解题总时间）是有利的。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>（2）数据描述符</p>
<ul>
<li><p>为了进一步减少标志符所占存储空间，对向量、数组、记录等数据，由于元素属性相同，因此就发展出数据描述符</p>
</li>
<li><p>描述符和数据分开，表示访问的数据是整块还是单个，地址信息等其他信息<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200415122950.png"></p>
</li>
<li><p>描述符方法优点：</p>
<ul>
<li>描述符方法实现阵列数据的索引要比用变址方法实现更方便</li>
<li>且便于检查出程序中的阵列越界错误</li>
<li>数据描述符方法为向量、数组数据结构的实现提供了一定的支持，有利于并简化编译中的代码生成，可以比变址法更快地形成元素地址</li>
</ul>
</li>
</ul>
<p>2.向量数组数据表示</p>
<ul>
<li>为向量、数组数据结构的<strong>实现和快速运算提供更好的硬件支持的方法是增设向量、数组数据表示</strong></li>
<li>向量在内存中是连续存放在一段空间里的，换句话说，这些向量元素的地址是连续的 </li>
<li>在标量计算机上运行时，由于没有专门的向量数据表示，因此在计算一个向量(相当于一维数组的计算)时，每取用一个数据元素，都要用到计算该元素的地址。</li>
<li>而在向量机中，由于有了向量数据表示，就<strong>可以把一个向量用一个位串来表示出来</strong>。向量指令就是能够用一条指令对向量的全部元素进行运算的指令。 </li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200415134043.png"></p>
<ul>
<li>引入向量、数组数据表示优点<ul>
<li>不只是能加快形成元素地址；</li>
<li>便于实现把向量各元素成块预取到中央处理器；</li>
<li>能对阵列中的每个元素又是一个子阵列的相关交叉型阵列进行处理；</li>
<li>对稀疏矩阵能实现压缩存储、还原、运算等多种功能操作，不但节省了空间，也由于不必处理零元素而节省了时间。</li>
</ul>
</li>
</ul>
<p>3.堆栈数据表示</p>
<ul>
<li><p>堆栈数据结构在编译和子程序调用中很有用</p>
</li>
<li><p>通用寄存器型机器对堆栈数据结构支持<strong>较差</strong></p>
<ul>
<li>堆栈操作用的机器指令数少，功能单一，没有专门的堆栈指令</li>
</ul>
</li>
<li><p>寄存器型机器的内存分配，有堆栈(Stack)空间</p>
<ul>
<li>堆栈置于存储器内，访问堆栈的速度低</li>
<li>通常只用于保存子程序调用时的<strong>返回地址</strong></li>
<li>少量用堆栈来实现程序之前的<strong>参数传递</strong></li>
</ul>
</li>
<li><p>堆栈机器</p>
<ul>
<li>有堆栈数据表示的机器称为堆栈机器</li>
<li>堆栈寻址方式的地址是隐含的，在指令中不必给出操作数的地址，<strong>零地址指令</strong></li>
<li>从60年代开始，出现了一批以堆栈寻址方式为主的堆栈计算机</li>
<li>堆栈对以下这些方面处理非常方便<ul>
<li>表达式求值</li>
<li>子程序调用，递归，中断嵌套</li>
<li>块结构语言中的变量访问</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>堆栈计算机具有如下特点：<br>（1）有高速寄存器组成的硬件堆栈，并附加控制电路，让它与主存中的堆栈区在逻辑上构成整体，使堆栈的访问速度是寄存器级，容量是主存级。<br>（2）有丰富的堆栈指令且功能很强。<br>（3）支持高级语言，有利于编译程序。因为一般的算术表达式可以很容易地转化成逆波兰表达式，而逆波兰表达式能够直接形成由堆栈指令组成的程序，这样就简化了编译程序。</p>
<ul>
<li><strong>以主存寻址方式为主的计算机系统</strong>，在编译一个算术表达式时，要<strong>为每一个变量分配主存单元</strong>，另外，还会人为地产生一些中间变量。<strong>如何减少中间变量的个数</strong>，合理地为变量分配存储单元，是编译器的一项许多相当困难的工作。</li>
<li><strong>以寄存器寻址方式为主的计算机系统</strong>，编译器需要决定哪些变量放在通用寄存器中，哪些变量放在主存中，<strong>以减少访问主存储器的次数</strong>。另外，也同样存在<strong>如何减少了中间变量</strong>，节省了存储空间的问题</li>
</ul>
<p>（4）支持程序的嵌套和递归调用，支持中断处理</p>
<h4 id="2-1-3-引入数据表示的原则"><a href="#2-1-3-引入数据表示的原则" class="headerlink" title="2.1.3 引入数据表示的原则"></a>2.1.3 引入数据表示的原则</h4><p><strong>从根本上讲，存储器一维线性的存储结构与要求经常使用的多维离散数据结构有着很大的差距，不利于数据结构的实现。</strong></p>
<p>一是基本数据表示不可少；<br>二是看系统的效率是否显著提高；<br>三是看引入这种数据表示后，其通用性和利用率是否提高。<br>四是也需要挖掘基本数据表示的细节问题。</p>
<h4 id="2-1-4-浮点数尾数基值大小和下溢处理方法的选择"><a href="#2-1-4-浮点数尾数基值大小和下溢处理方法的选择" class="headerlink" title="2.1.4 浮点数尾数基值大小和下溢处理方法的选择"></a>2.1.4 浮点数尾数基值大小和下溢处理方法的选择</h4><p>1.浮点数尾数基值的选择<br>如果小数点的位置事先已有约定，不再改变，此类数称为“定点数”。<br>如果小数点的位置可变，则称为“浮点数”。<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200826171758.png"></p>
<p>rm ：尾数的基<br>re ：阶码的基（re =2）<br>m： 尾数长度 (注意其含义)<br>p： 阶码长度<br>【p表示数的范围大小；尾数的位数m主要影响表示值的精度】<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200415135441.png"></p>
<ul>
<li>浮点数表数误差产生的原因：<ul>
<li>运算的结果</li>
<li>十进制转化为二进制、四进制、八进制、十六进制</li>
</ul>
</li>
<li>浮点数尾数基值的选择<ul>
<li>可表示数的范围<ul>
<li>随着rm增大，可表示的范围增大</li>
<li>随着rm增大，可表示数的最小值rm^-1将减少</li>
</ul>
</li>
<li>可表示数的个数<ul>
<li>(2^p)×(rm^m’)×(1-(rm^(-1)) ，其中rm的增大将因<code>(1-(rm^-1))</code>增大而使可表示数的个数增多</li>
</ul>
</li>
<li>可表示的精度<ul>
<li>rm越大，数在数轴上的分布越稀，数的表示精度自然就下降</li>
</ul>
</li>
<li>运算中的精度损失<ul>
<li>尾数右移出机器字长，使有效数字丢失，但其不同于可表示数的精度，由于尾数基值rm取大后，对阶移位的机会和次数减少，又由于数的表示范围扩大，使尾数溢出需右规的机会也减少。因此，rm越大，尾数右移的机会越小，精度的损失就越小</li>
</ul>
</li>
<li>运算速度<ul>
<li>Rm增大时，由于对阶或尾数溢出需右移及规格化需左移的次数减少，运算速度可以提高</li>
</ul>
</li>
</ul>
</li>
<li>综上所述，尾数基值取大，会扩大浮点数的表示范围、增加可表示数的个数、减少移位次数、降低右移造成的精度损失和提高运算速度，但是会，降低数据的表示精度，数值的分布变稀</li>
<li>规格化正尾数：<strong>正尾数小数点后第一个rm进制数位不是0的数</strong></li>
</ul>
<table>
<thead>
<tr>
<th align="center">条件：非负阶，规格化，正尾数</th>
<th align="center">阶值：二进制p位，尾数：rm进制m’位</th>
<th align="center">若p=2，m=4，当rm=2（即m’=4）时</th>
<th align="center">若p=2，m=4，当rm=16（即m’=1）时</th>
</tr>
</thead>
<tbody><tr>
<td align="center">可表示最小尾数值</td>
<td align="center">rm^(-1)</td>
<td align="center">1/2</td>
<td align="center">1/16</td>
</tr>
<tr>
<td align="center">可表示最大尾数值</td>
<td align="center">1-1×rm^(-m’)</td>
<td align="center">15/16</td>
<td align="center">15/16</td>
</tr>
<tr>
<td align="center">最大阶值</td>
<td align="center">2^p-1</td>
<td align="center">3</td>
<td align="center">3</td>
</tr>
<tr>
<td align="center">可表示最小值</td>
<td align="center">rm^(-1)</td>
<td align="center">1/2</td>
<td align="center">1/16</td>
</tr>
<tr>
<td align="center">可表示最大值</td>
<td align="center">rm^(2^p-1)×(1-rm^(-m’))</td>
<td align="center">7.5</td>
<td align="center">3840</td>
</tr>
<tr>
<td align="center">可表示的尾数个数</td>
<td align="center">rm^(m’)×(rm-1)/rm</td>
<td align="center">8</td>
<td align="center">15</td>
</tr>
<tr>
<td align="center">可表示阶的个数</td>
<td align="center">2^p</td>
<td align="center">4</td>
<td align="center">4</td>
</tr>
<tr>
<td align="center">可表示数的个数</td>
<td align="center">2^p×rm^(m’)×(rm-1)/rm</td>
<td align="center">32</td>
<td align="center">60</td>
</tr>
</tbody></table>
<p>2.浮点数位数的下溢处理方法<br>减少运算中的精度损失关键是要处理好运算中尾数超出字长的部分，使精度损失最小<br>（1）<strong>截断法</strong><br>方法：<strong>将尾数超出机器字长的部分去掉</strong></p>
<ul>
<li><p>以rm=2，m=2为例讨论最大误差</p>
<ul>
<li>在整数时接近于1(“11:111…1”截断成“11:”)</li>
<li>在分数时接近于2^(-m) (“.01:111…1”截断成“.01:”)<br>总是产生负误差<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200415140626.png"></li>
</ul>
</li>
<li><p>优点</p>
<ul>
<li>实现简单，不增加硬件，不需要处理时间</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>最大误差较大，且平均误差大且无法调节，因而已很少使用</li>
</ul>
</li>
</ul>
<p>（2）<strong>舍入法</strong><br>在机器运算的规定字长之外增设一位附加位，存放溢出部分的最高位，每当进行尾数下溢处理时，将附加位加1,(整数加0.5，分数加2-(m+1))</p>
<ul>
<li><p>例如：</p>
<ul>
<li>整数：“10:10…0”舍入成“11:” 正误差</li>
<li>分数：“.10:01…0”舍入成“.10:” 负误差</li>
</ul>
</li>
<li><p>优点</p>
<ul>
<li>实现简单，增加的硬件开销少，最大误差小，平均误差接近于零</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>处理速度慢，需要花费在数的附加位加1以及因此产生进位的时间，最坏情况下，需要从尾数最低位进制<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/Y5E%7B1ZHXC%25%5B77%7BW_5Z2%5BY%5DO.png"><br>（3）<strong>恒置“1”法</strong></li>
</ul>
</li>
<li><p>将机器运算的规定字长之最低位恒置“1”</p>
</li>
<li><p>最大误差</p>
<ul>
<li>整数为1（如“10:00…0”处理成“11:”）</li>
<li>分数为2-m（如“.00:00…0”处理成“.01:”）</li>
</ul>
</li>
<li><p>误差有正负</p>
<ul>
<li>负误差（如“.11:10…1”处理成“.11:”）</li>
<li>正误差（如“.00:00…0”处理成“.01:”)<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/%25%7DMG%25YPJF2L0QNXJ%7DK8FC%402.png"></li>
</ul>
</li>
<li><p>优点</p>
<ul>
<li>实现简单，不需要增加硬件和处里时间，平均误差趋于0</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>最大误差最大，比截断法还大（接近于1）<br>多用于中、高速机器中，由于尾数位数比微、小型机器长</li>
</ul>
</li>
</ul>
<p>（4）查表舍入法<br>取尾数p位的最后k-1位和准备舍弃的最高1位，共k位。通过ROM或PLA查表得到k-1位，作为新的尾数p位的最后k-1位<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/%29%7DUAT%7DO7%7D%7B%25%28WNSFI%40I%25MOP.png"></p>
<ul>
<li><p>下溢处理表的内容</p>
<ul>
<li>当尾数最低k-1位为全”1“时以截断法设置处理结果</li>
<li>其余情况采用舍入法<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200415142649.png"></li>
</ul>
</li>
<li><p>优点</p>
<ul>
<li>ROM法速度较快，平均误差可调到0</li>
<li>避免再次右规操作</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>需要硬件配合</li>
</ul>
</li>
<li><p>上述4种处理方法中，</p>
<ul>
<li><strong>最大误差最大</strong>的是恒置“1”法，</li>
<li><strong>最大误差最小</strong>的是舍人法；</li>
<li><strong>平均误差最大</strong>的是截断法；</li>
<li><strong>平均误差可人为调节</strong>的是查表舍入法；</li>
<li><strong>下溢处理不需要附加时间开销，即速度最快</strong>的是截断法和恒置“1”法，</li>
<li><strong>处理速度最慢</strong>的是舍人法；</li>
<li><strong>实现上最花费硬件</strong>的是查表舍入法，</li>
<li><strong>最省硬件</strong>的是截断法和恒置“1”法。 </li>
</ul>
</li>
</ul>
<h3 id="2-2-寻址方式"><a href="#2-2-寻址方式" class="headerlink" title="2.2 寻址方式"></a>2.2 寻址方式</h3><p>寻址方式指的是按什么方式寻找（或访问）到所需的操作数或信息的。</p>
<h4 id="2-2-1-寻址方式的三种面向"><a href="#2-2-1-寻址方式的三种面向" class="headerlink" title="2.2.1 寻址方式的三种面向"></a>2.2.1 寻址方式的三种面向</h4><p><strong>面向主存</strong>，寻址主要访问主存，少量访问寄存器；<br><strong>面向寄存器</strong>，主要访问寄存器，少量访问主存和堆栈；<br><strong>面向堆栈</strong>，主要访问堆栈，少量访问主存或寄存器。</p>
<h4 id="2-2-2-寻址方式在指令中的指明"><a href="#2-2-2-寻址方式在指令中的指明" class="headerlink" title="2.2.2 寻址方式在指令中的指明"></a>2.2.2 寻址方式在指令中的指明</h4><ul>
<li>具体的寻址方式，组成原理已经讲过</li>
<li>基本的指令格式：操作码 + 地址码</li>
<li>寻址方式指明方法：<ul>
<li>占用操作码的某些位指明</li>
<li>不占操作码，在地址码设置寻址方式字段</li>
</ul>
</li>
</ul>
<h4 id="2-2-3-程序在主存中的定位技术"><a href="#2-2-3-程序在主存中的定位技术" class="headerlink" title="2.2.3 程序在主存中的定位技术"></a>2.2.3 程序在主存中的定位技术</h4><ul>
<li>逻辑地址与主存物理地址 <ul>
<li>逻辑地址：程序员编写程序时使用的地址；</li>
<li>物理地址：程序在主存中的实际地址；</li>
</ul>
</li>
<li>早期——单道程序<ul>
<li>逻辑地址和物理地址是一致的，程序和数据存放在主存中的位置是由程序员编写程序时指明的；</li>
</ul>
</li>
<li>现在——多道程序<ul>
<li>程序员已不用主存的实际地址编程，改用符号、标号名编址；</li>
<li>由源程序中的符号名空间→目标程序的逻辑地址空间→主存中的物理地址空间 </li>
<li>程序员事先无法知道程序装在主存中什么位置；</li>
<li>各道程序的逻辑地址都是从0开始编制，主存物理空间地址是从0开始编址的一堆线性空间；</li>
</ul>
</li>
</ul>
<ol>
<li>静态再定位<br>（1）在目标程序装入内存时，由装入程序对目标程序中的指令和数据的地址进行修改，即把程序的逻辑地址都改成实际的内存地址。重定位在程序装入时一次完成<br>（2）存在问题<br>①一道程序地址改错而导致其他程序出错；<br>②指令修改妨碍了程序的可重入。<br>③指令修改了，不利于程序定位和调试。</li>
<li>动态再定位<br>是在程序执行期间完成的，即程序的逻辑地址在装入内存时不作任何修改，程序执行中，每取出一条指令，CPU对其译码时，如果有逻辑地址，就借助于重定位机构将其转换成绝对地址，然后执行该指令。</li>
<li>基址寻址<br>（1）指令中给出一个形式地址（作为修改量），并给出基址寄存器号，基址寄存器内容（作为基准量）与形式地址相加得到操作数有效地址<br>（2）主要解决<br>①程序重定位；<br>②扩展有限字长指令的寻址空间<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/8K2W9S17_VYSURM8WL~%25YOQ.png"></li>
<li>虚实地址映象表<br>地址加界法要求程序员所用编址空间不能超出实际主存空间容量。</li>
</ol>
<h4 id="2-2-4-物理主存中信息的存储分布"><a href="#2-2-4-物理主存中信息的存储分布" class="headerlink" title="2.2.4 物理主存中信息的存储分布"></a>2.2.4 物理主存中信息的存储分布</h4><p>目前使用最普遍的编址单位是字节编址，这是为了适应非数值计算的需要</p>
<h3 id="2-3-指令系统的设计和优化"><a href="#2-3-指令系统的设计和优化" class="headerlink" title="2.3 指令系统的设计和优化"></a>2.3 指令系统的设计和优化</h3><h4 id="2-3-1-指令系统设计的基本原则"><a href="#2-3-1-指令系统设计的基本原则" class="headerlink" title="2.3.1 指令系统设计的基本原则"></a>2.3.1 指令系统设计的基本原则</h4><ul>
<li>指令系统是软、硬件的主要界面</li>
<li>指令系统的设计主要包括<strong>指令的功能</strong>（操作类型、具体操作内容）和<strong>指令格式</strong>的设计.</li>
<li>指令设计的步骤：<ul>
<li><strong>根据应用</strong>，初拟出指令的分类和具体的指令；</li>
<li>试编出用该指令系统设计的各种<strong>高级语言的编译程序</strong>；</li>
<li><strong>大量测试</strong>程序进行<strong>模拟测试</strong>，看指令系统的操作码和寻址方式效能是否都比较高；</li>
<li><strong>将程序中高频出现的指令串复合改成一条强功能新指令</strong>，即改用硬件方式实现；而将频度很低的指令的操作改成基本的指令组成的指令串来完成，即用软件方式实现；</li>
</ul>
</li>
<li>系统设计人员希望：指令码密度适中，兼容性，适应性</li>
<li>指令的组成：<ul>
<li>一般的指令主要由两部分组成：<strong>操作码</strong>和<strong>地址码</strong></li>
<li>操作码主要包括两部分内容：<ul>
<li>操作种类：加、减、乘、除、数据传送、移位、转移、输入输出</li>
<li>操作数描述<ul>
<li>数据的类型：定点数、浮点数、复数、字符、字符串、逻辑数、向量</li>
<li>进位制：2进制、10进制、16进制</li>
<li>数据字长：字、半字、双字、字节</li>
</ul>
</li>
</ul>
</li>
<li>地址码通常包括三部分内容：<ul>
<li>地址：直接地址、间接地址、立即数、寄存器编号、变址寄存器编号</li>
<li>地址的附加信息：偏移量、块长度、跳距</li>
<li>寻址方式：直接寻址、间接寻址、立即数寻址、变址寻址、相对寻址、寄存器寻址(可能)</li>
</ul>
</li>
</ul>
</li>
<li>指令格式的优化<ul>
<li>指令=操作码+地址码</li>
<li>指令格式的优化：如何用最短的位数来表示指令的操作信息和地址信息，使程序中指令的平均字长最短。</li>
<li>主要目标：<ul>
<li>节省程序的存储空间</li>
<li>指令格式尽量规整，便于译码</li>
</ul>
</li>
</ul>
</li>
<li>操作码的优化表示：<ul>
<li>操作码的三种编码方法：<ul>
<li>固定长度：规整性好，解码简单，空间大</li>
<li>Huffman编码：空间小，规整性不好，解码复杂。</li>
<li>扩展编码：折衷方案，由固定长操作码与Huffman编码法相结合形成</li>
</ul>
</li>
<li>改进操作码编码方式能够节省程序存储空间</li>
</ul>
</li>
<li>指令字格式的优化：<ul>
<li>只有操作码的优化，没有在地址码和寻址方式上采取措施，程序的总位数还是难以减少。</li>
<li>如果主存按位编址，则部分指令的读取需要两个周期，是机器速度明显下降。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>大学课程</tag>
        <tag>计算机系统结构</tag>
      </tags>
  </entry>
  <entry>
    <title>大学课程 | 计算机系统结构精简知识点</title>
    <url>/posts/651e6a0b.html</url>
    <content><![CDATA[<p><a href="/posts/50754.html">计算机系统结构笔记传送门</a></p>
<h1 id="计算机系统结构知识点"><a href="#计算机系统结构知识点" class="headerlink" title="计算机系统结构知识点"></a>计算机系统结构知识点</h1><ol>
<li>多级层次结构：<br>（1）按功能划分成多层机器级组成的层次结构，从上到下依次为，应用语言机器级，高级语言机器级，汇编语言机器级，操作系统机器级，传统机器语言机器级，微程序机器级。<br>（2）机器，被定义为能存储和执行相应语言程序的算法和数据结构的集合体<br>（3）微程序机器级用硬件实现，传统机器语言机器级用固件实现<br>（4）固件：具有软件功能的硬件<br>（5）以软件为主实现的机器称为虚拟机器，由硬件或固件实现的称为实际机器</li>
<li>透明性：<br>（1）客观存在的事物或属性从某个角度看不见</li>
<li>翻译与解释<br>（1）翻译：先用转换程序将高一级机器级上的程序<code>整个</code>变换成低一级机器级上等效的程序，然后再在低一级机器级上实现的技术<br>（2）解释：在低级机器级上用它的一串语句或指令来仿真高级机器级上的一条语句或指令的功能，是通过对高级的机器级语言程序中的每条语句或指令<code>逐条</code>解释来实现的技术</li>
<li>软硬件逻辑功能等效<br>（1）概念：软硬件逻辑功能等效是指计算机系统的某功能可以由硬件实现也可以由软件实现，在逻辑功能上是等价的。由硬件实现功能的特点是速度快、增加硬件成本，灵活性低。由软件实现功能的特点是灵活性好、但速度较慢，增加软件设计费用等</li>
<li>计算机系统结构、组成与实现的定义及三者之间的关系，以乘法指令为例说明上述三者各自的研究内容<br>（1）计算机系统结构的定义：对计算机系统中各级界面的定义及其上下的功能分配<br>（2）计算机组成的定义：计算机系统结构的逻辑实现，包括机器级内部的数据流和控制流的组成以及逻辑设计等<br>（3）计算机实现：是指计算机组成的物理实现（具体电路，器件的设计，装配技术等等）<br>（4）三者的关系：三者互不相同，但又相互影响。组成向上决定于结构，向下受限于实现技术。<br>（5）对于乘法指令，计算机系统结构主要考虑是否要设置乘法指令；而计算机组成主要考虑乘法指令是用专门的高速乘法器还是用加法器和移位器实现；计算机实现主要考虑乘法器，加法器的物理显示，如器件的类型，继承父，数量的确定和选择</li>
<li>计算机系统结构的设计思路<br>（1）<code>“由上往下”设计</code>，由顶向底。先考虑应用要求，再逐级向下，下一级是对上一级的优化。是一种穿行设计方法，设计周期较长<br>（2）<code>“由下往上”设计</code>，由底向顶。先设计底层，再加配操作系统和编译系统，以及设施的系统软件和算法等等。软硬件容易脱节，串行设计，周期长，很少采用<br>（3）<code>“从中间开始”向两边设计</code>。一般方法。软硬件并行设计，较好的设计方法</li>
<li>软件移植及三种移植技术<br>（1）软件的可移植性：软件不修改或只经少量修改就可以由一台机器移到另一台机器上允许，同一软件可应用于不同的环境<br>（2）移植技术：<code>统一高级语言</code>；<code>采用系列机</code>；<code>模拟和仿真</code></li>
<li>软件兼容及分类<br>（1）软件兼容：机器语言程序以及编译程序能不加修改地通用于各档机器<br>（2）分类：<br>a. 向上兼容/向下兼容：向上（下）兼容是指，按某党机器编制的软件，不加修改就能运行于比他高（低）档的机器上。<br>b. 向前兼容/向后兼容：向前（后）兼容是指，按某个时期投入市场的该型号机器上编制的软件，不加修改就能运行于在它之前（后）的投入市场的机器上。<br>（3）系列机软件必须保证向后兼容，力争向上兼容</li>
<li>系列机与兼容机，模拟与仿真<br>（1）系列机：是具有相同体系结构，但组成和实现不同的一系列不同型号的计算机系统。<br>兼容机：不同厂家生产的具有相同体系结构的计算机。<br>（2）模拟：用机器语言程序（在主存）解释实现软件移植的方法；运行速度低，实时性差，模拟程序复杂<br>仿真：用微程序（在控制寄存器）直接解释另一种机器指令系统的方法；两种系统结构差别较大时，难以仿真<br>两者的主要区别在于解释用的语言，其次有解释程序的所存位置不同</li>
<li>应用与器件对系统结构的影响<br>（1）应用的发展对结构设计提出范围广泛的要求<br>（2）器件的发展改变了逻辑设计的传统方法；推动结构和组成前进的关键因素；加速了结构“下移”；促进了算法，语言和软件的发展</li>
<li>并行性概念及发展并行性的三种技术途径<br>（1）并行性：把解题中具有可以同时进行运算或操作的特性称为并行性，并行性包括同时性和并发性<br>（2）并行性等级：<br>①按计算机系统执行程序的角度，从低到高：指令内部，指令之间，任务或进程之间，作业或程序之间<br>②从计算机系统中处理数据的角度来看，从低到高：位串字串，位并字串，位片串字并，全并行<br>（3）三种技术途径：时间重叠，资源重叠，资源共享<br>时间重叠：多个处理过程在时间上错开<br>资源重叠：重复设置硬件资源来提高可靠性和性能<br>资源共享：多个用户按时间顺序轮流使用同一套资源</li>
<li>耦合度概念<br>（1）耦合度概念：反映多机系统中各机器之间物理连接的紧密度和交叉作用能力<br>（2）分类：<br>最低耦合：除存储介质，无物理连接，脱机<br>松散耦合：通过通道或通信线路互连，磁带，磁盘…<br>紧密耦合：通过总线或高速开关互连，主存…</li>
<li>弗林分类法<br>（1）单指令流单数据流（SISD），传统单处理器计算机<br>（2）单指令流多数据流（SIMD），阵列处理机和相联处理机<br>（3）多指令流单数据流（MISD），很少见<br>（4）多指令流多数据流（MIMD），多级系统</li>
<li>数据表示与数据结构<br>（1）数据表示：能由机器硬件识别和引用的数据类型（数据类型指一类值的集合和可作用于其上的操作集）<br>（2）数据结构：结构数据类型的组织方式，反映了应用中要用到的各种数据元素或信息单元之间的结构关系<br>（3）数据结构和数据表示是软硬件的交界面，数据结构是软，数据表示是硬</li>
<li>高级数据表示<br>（1）自定义数据表示：<br>a). 标识符数据表示<br>①每个数据带了类型标志位，标识符主要用于指明数据类型，但也可以用域指明所用信息类型。标识符由编译程序建立，对高级语言程序透明。<br>②优点：简化了指令系统和程序设计；简化了编译程序；便于一致性校验；能由硬件自动变换数据类型；支持数据库系统的实现与数据类型无关的要求；为软件调试和应用软件开发提供了支持，便于程序的跟踪和调试<br>③缺点：增加程序所占的主存空间；降低指令的执行速度<br>b). 数据描述符<br>①描述符和数据分开存放，用于描述所访问的数据是整块的还是单个的，访问该数据块或数据元素所要的地址以及其它信息<br>②优点：进一步减少标识符所占存储空间<br>（2）向量，数组数据表示<br>①有向量数据表示的处理机是向量处理机<br>②优点：加快形成元素地址，便于实现把向量各元素成块预取到中央处理机，用一条向量，数组指令流水或同事对整个向量，数组进行高速处理<br>（3）堆栈数据表示<br>①有堆栈数据表示的处理机是堆栈机器<br>②通常用于保存子程序调用时的返回地址<br>③堆栈机器特点：有丰富的堆栈操作指令且功能强大；有力地支持了高级语言程序的编译；有力的支持了子程序的嵌套和递归调用</li>
<li>引入数据表示的原则<br>（1）原则1：看系统的效率是否显著提高，包括实现时间和存储空间是否显著减少。实现时间是否减少又主要看主存和处理机之间传送的信息量是否减少<br>（2）原则2：看引入这种数据表示后，其通用性和利用率是否提高<br>（3）原则3：基本的数据表示，也有可挖掘的细节问题<br>（4）原则4：基本的数据类型必须设</li>
<li>浮点数尾数基值的选择与下溢处理方法<br>（1）浮点数尾数基值的选择<br>如果小数点的位置事先已有约定，不再改变，此类数称为“定点数”。<br>如果小数点的位置可变，则称为“浮点数”。<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200826171758.png"><br>rm ：尾数的基<br>re ：阶码的基（re =2）<br>m： 尾数长度 (注意其含义)<br>p： 阶码长度<br>【p表示数的范围大小；尾数的位数m主要影响表示值的精度】<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200415135441.png"></li>
</ol>
<table>
<thead>
<tr>
<th align="center">条件：非负阶，规格化，正尾数</th>
<th align="center">阶值：二进制p位，尾数：rm进制m’位</th>
<th align="center">若p=2，m=4，当rm=2（即m’=4）时</th>
<th align="center">若p=2，m=4，当rm=16（即m’=1）时</th>
</tr>
</thead>
<tbody><tr>
<td align="center">可表示最小尾数值</td>
<td align="center">rm^(-1)</td>
<td align="center">1/2</td>
<td align="center">1/16</td>
</tr>
<tr>
<td align="center">可表示最大尾数值</td>
<td align="center">1-1×rm^(-m’)</td>
<td align="center">15/16</td>
<td align="center">15/16</td>
</tr>
<tr>
<td align="center">最大阶值</td>
<td align="center">2^p-1</td>
<td align="center">3</td>
<td align="center">3</td>
</tr>
<tr>
<td align="center">可表示最小值</td>
<td align="center">rm^(-1)</td>
<td align="center">1/2</td>
<td align="center">1/16</td>
</tr>
<tr>
<td align="center">可表示最大值</td>
<td align="center">rm^(2^p-1)×(1-rm^(-m’))</td>
<td align="center">7.5</td>
<td align="center">3840</td>
</tr>
<tr>
<td align="center">可表示的尾数个数</td>
<td align="center">rm^(m’)×(rm-1)/rm</td>
<td align="center">8</td>
<td align="center">15</td>
</tr>
<tr>
<td align="center">可表示阶的个数</td>
<td align="center">2^p</td>
<td align="center">4</td>
<td align="center">4</td>
</tr>
<tr>
<td align="center">可表示数的个数</td>
<td align="center">2^p×rm^(m’)×(rm-1)/rm</td>
<td align="center">32</td>
<td align="center">60</td>
</tr>
</tbody></table>
<p>（2）下溢处理方法（对应用程序员，系统程序员透明）<br>减少运算中的精度损失关键是要处理好运算中尾数超出字长的部分，使精度损失最小<br>a) <strong>截断法</strong><br>①方法：<strong>将尾数超出机器字长的部分去掉</strong><br>②以rm=2，m=2为例讨论最大误差：在整数时接近于1(“11:111…1”截断成“11:”)；在分数时接近于2^(-m) (“.01:111…1”截断成“.01:”)<br>③对于正数，如有误差总是负误差<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200415140626.png"><br>④优点：实现简单，不增加硬件，不需要处理时间<br>缺点：最大误差较大，且平均误差为负且较大，无法调节，因而已很少使用<br>b) <strong>舍入法</strong><br>①方法：在机器运算的规定字长之外增设一位附加位，存放溢出部分的最高位，每当进行尾数下溢处理时，将附加位加1，[整数加0.5，分数加2^(-(m+1))]<br>②例如：整数：“10:10…0”舍入成“11:” 正误差；分数：“.10:01…0”舍入成“.10:” 负误差<br>③优点：实现简单，增加的硬件开销少，最大误差小，平均误差接近于零，略偏正<br>缺点：处理速度慢，需要花费在数的附加位加1以及因此产生进位的时间，最坏情况下，需要从尾数最低位进制<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/Y5E%7B1ZHXC%25%5B77%7BW_5Z2%5BY%5DO.png"><br>c) <strong>恒置“1”法</strong><br>①方法：将机器运算的规定字长之最低位恒置“1”<br>②最大误差：整数为1（如“10:00…0”处理成“11:”）；分数为2-m（如“.00:00…0”处理成“.01:”）<br>③误差有正负：负误差（如“.11:10…1”处理成“.11:”）；正误差（如“.00:00…0”处理成“.01:”)<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/%25%7DMG%25YPJF2L0QNXJ%7DK8FC%402.png"><br>④优点：实现简单，不需要增加硬件和处里时间，平均误差趋于0<br>缺点：最大误差最大，比截断法还大（接近于1）<br>⑤多用于中、高速机器中，由于尾数位数比微、小型机器长<br>d) <strong>查表舍入法</strong><br>①方法：取尾数p位的最后k-1位和准备舍弃的最高1位，共k位。通过ROM或PLA查表得到k-1位，作为新的尾数p位的最后k-1位<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/%29%7DUAT%7DO7%7D%7B%25%28WNSFI%40I%25MOP.png"><br>②下溢处理表的内容：当尾数最低k-1位为全”1“时以<code>截断法</code>设置处理结果；其余情况采用<code>舍入法</code><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200415142649.png"><br>③优点：ROM法速度较快，平均误差可调到0；避免再次右规操作<br>缺点：需要硬件配合，硬件量大<br>（3）上述4种处理方法中：<br><strong>最大误差最大</strong>的是恒置“1”法，<br><strong>最大误差最小</strong>的是舍入法；<br><strong>平均误差最大</strong>的是截断法；<br><strong>平均误差可人为调节</strong>的是查表舍入法；<br><strong>下溢处理不需要附加时间开销，即速度最快</strong>的是截断法和恒置“1”法，<br><strong>处理速度最慢</strong>的是舍入法；<br><strong>实现上最花费硬件</strong>的是查表舍入法，<br><strong>最省硬件</strong>的是截断法和恒置“1”法。 </p>
<ol start="18">
<li>程序在主存中的定位技术<br>（1）静态再定位：再目的程序装入主存时，由装入程序用软件方法把目的程序的逻辑地址变换成物理地址，程序执行时，物理地址不再改变<br>（2）动态再定位：在执行每条指令时才形成访存物理地址的方法<br>①基址寻址：设置基址寄存器和地址加法器硬件，实现逻辑地址到物理地址空间变换的支持<br>②优越性：地址加法器形成物理地址的速度快于装入程序形成的物理地址速度；具有越界保护措施，如设置上、下界寄存器，判断是否出现地址越界错误<br>（3）虚实地址映像表：用虚拟存储器增加映像表硬件后，程序空间可以超过实际主存空间，采用基地址寄存器加位移量的方法</li>
<li>基址寻址与变址寻址的区别<br>（1）基址寻址：基址寄存器里的值加上指令格式内的逻辑地址形成物理地址；对逻辑地址空间到物理地址空间变换的支持；通常基址寄存器的内容不变，逻辑地址可变；<br>（2）变址寻址：变址寄存器的值和指令地址码部分给出的地址之和作为操作数地址；对诸如向量，数组等数据块运算的支持；通常逻辑地址不变，变址寄存器里面的值由用户定义</li>
<li>信息按整数边界存储<br>（1）为了使任何时候所需的信息都只用一个存储周期访问到，要求信息在主存中存放的地址必须是该信息宽度（字节数）的整数倍，防止信息跨主存边界存放<br>（2）优点：访问周期短；缺点：存储空间浪费</li>
<li>哈夫曼压缩思想与指令格式的优化<br>（1）指令包含操作码和地址码两部分，为了优化指令格式，要使指令的平均字长最短，减少程序总位数以及增加指令字能表示的操作信息和地址信息<br>（2）哈夫曼压缩思想：当各种时间发生的概率不均等时，对发生概率最高的事件用最短的位数（时间）来表示（处理），而对出现概率较低的事件允许用较长的位数（时间）来表示（处理），就会使表示（处理）的平均位数（时间）缩短<br>（3）扩展操作码编码</li>
<li>CISC与RISC的常用技术<br>（1）CISC（复杂指令系统计算机）：进一步增强原有指令的功能以及设置更为复杂的新指令，取代原先由软件子程序完成的功能，实现软件功能的硬化；<br>a)面向目标程序的优化实现改进<br>①途径1：对大量已有机器的机器语言程序及其执行情况进行统计各种指令和指令串的使用频度来加以分析和改进。<br>使用频度分为<code>静态使用频度</code>（程序中统计出的指令及指令串的使用频度称为静态使用频度。着眼于减少目标程序所占用的存储空间）和<code>动态使用频度</code>（目标程序执行过程中对指令和指令串统计出的频度称为动态使用频度。着眼于减少目标程序的执行时间）<br>②途径2：增设强功能复合指令来取代原先由常用宏指令或子程序实现的功能，由微程序解释实现，不仅大大提高了运算速度，减少了程序调用的额外开销，也减少了子程序所占的主存空间。<br>b)面向高级语言的优化实现改进<br>①目的：缩短高级语言和机器语言的语义差距，支持高级语言编译，缩短编译程序长度和时间<br>②途径1：通过对源程序中各种高级语言语句的使用频度进行统计来分析改进<br>③途径2：如何面向编译，优化代码生成来改进<br>④途径3：改进指令系统，使它与各种语言间的语义差距都有同等的缩小<br>⑤途径4：让机器具有分别面向各种高级语言的多种指令系统，多种系统结构的面向问题动态自寻优的计算机系统<br>⑥途径5：发展高级语言计算机（或称高级语言机器）<br>c)面向操作系统的优化实现改进<br>①目的：通过缩短操作系统与计算机系统结构之间的语义差距，来进一步减少运行操作系统的时间和节省操作系统软件所占用的存储空间<br>②途径1：通过对操作系统中常用指令和指令串的使用频度进行统计分析来改进<br>③途径2：考虑如何增设专用于操作系统的新指令<br>④途径3：把操作系统中频繁使用的，对速度影响大的机构型软件子程序硬化或固化，直接用硬件或微程序解释实现<br>⑤途径4：发展让操作系统由专门的处理机来执行的功能分布处理系统结构<br>d) CISC的问题：指令系统庞大；许多质量操作繁杂，执行速度很低；编译程序太长，太复杂；部分指令利用率很低<br>（2）RISC（精简指令系统计算机）：通过减少指令种数和简化指令功能来降低硬件设计的复杂度，提高指令的执行速度<br>a) RISC的基本技术<br>①按照设计RISC一般原则来设计<br>②逻辑实现采用硬联和微程序相结合<br>③在CPU中设置大量工作寄存器并采用重叠寄存器窗口<br>④指令用流水和延迟转移<br>⑤采用高速缓冲寄存器cache，设置指令cache和数据cache分别存放指令和数据<br>⑥优化设计编译系统<br>b) RISC的问题<br>①指令少，加重汇编语言程序设计的负担，增加了机器语言程序的长度，占用存储空间多，加大了指令的信息流量<br>②对浮点运算和虚拟存储器支持不足<br>③RISC机器的编译程序比CISC的难写</li>
<li>总线的分类<br>（1）按在系统中的位置分为<code>芯片级</code>，<code>板级</code>，<code>系统级</code><br>（2）按允许信息传送方向分为<code>单向传输</code>，<code>双向传输（半双向和全双向）</code><br>（3）按用法分为<code>专用</code>和<code>非专用</code></li>
<li>总线的控制技术及通讯技术<br>（1）控制技术<br>a） 集中式控制<br>①优先次序的确定方法：串行链接，定时查询，独立请求<br>②串行链接获得使用总线权优先次序由“总线可用”线所接不见的物理位置决定，离总线控制器越近，优先级越高；三根总线，总线忙，总线可用，总线请求<br>③定时查询：查询线上计数值与发出请求的部件号是否一致；总线忙+总线请求+「logn「个定时查询计数线=2+「logn「<br>④独立请求：1根总线已被分配线+每个部件各有一对总线请求和总线准许线=2×N+1<br>b） 分布式控制<br>（2）通讯技术<br>a) 同步通信：定宽，定距的系统时标同步<br>b) 异步通信：<br>分为单向控制（分为单向源控和单向目控）和请求/回答双向控制（分为源控式（互锁和非互锁）和目控）</li>
<li>中断响应优先级与中断处理程序优先级及分析过程<br>（1）基本概念:<br>中断：CPU中止正在执行的程序，转去处理随机提出的请求，待处理完后，再回到预先被打断的程序继续恢复执行的过程<br>中断系统：相应和处理各种中断的软硬件总体称为中断系统<br>中断分为内部中断（CPU内的异常引起），外部中断（由中断信号引起）和软件中断（由自陷指令引起）；外部中断又分为可屏蔽中断和不可屏蔽中断<br>中断源：引起中断的各种事件<br>中断请求：中断源向中断系统发出请求中断的申请<br>中断响应：允许中断CPU现行程序的运行，转去对该请求进行预处理，包括保存好断电及其现场，调出有关处理该中断的中断服务程序，准备运行（交换新旧程序状态字PSW）<br>中断现行程序细分为中断（可屏蔽）和异常（不可屏蔽，如自陷，故障，失败）<br>（2）中断分级<br>机器校验（第1级），程序性中断和管理程序调用（第2级），外部中断（第3级），输入/输出（第4级），重新启动（最低级）<br>（3）中断的响应次序与处理次序<br>中断级屏蔽位寄存器<br>本级对本级屏蔽<br>中断响应次序，中断处理完成次序，中断处理次序<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909153438.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909154306.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909160431.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909160611.png"><br>（4）通道程序结束引起的中断属于I/O中断；<br>访管中断属于第2级；</li>
<li>通道的工作原理及三类通道的流量计算<br>（1）通道的工作原理：用户只能再目态程序中安排要求输入输出的广义指令，然后进入相应管理程序执行这些输入输出管态指令<br>a) 目态和管态：<br>管态又叫特权态，系统态或核心态。CPU在管态下可以执行指令系统的全集。通常，操作系统在管态下运行。<br>目态又叫常态或用户态。机器处于目态时，程序只能执行非特权指令。<br>从目态转换为管态的唯一途径是中断。<br>从管态到目态可以通过修改程序状态字来实现，这将伴随这由操作系统程序到用户程序的转换。<br>启动I/O指令属于管态指令<br>（2）三类通道：<code>字节多路</code>，<code>数组多路</code>和<code>选择通道</code><br>通道流量和通道工作方式，数据传送期内选择一次设备的时间Ts，传送一个字节的时间Td有关<br>通道的极限流量：<br>fmaxbyte=1/(Ts+Td)<br>fmaxblock=K/(Ts+K×Td)<br>fmaxselect=N/(Ts+N×Td)<br>设备要求通道的实际最大流量只有小于等于通道所能达到的极限<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909165849.png"><br>工作周期小的不能挂载<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909171038.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909171326.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909171903.png"></li>
<li>存储器的性能指标<br>（1）容量Sm：存储器的位数或总字节数<br>Sm=W×L×m （W:存储体的字长，L每个存储体的字数，m并行工作存储体的个数）<br>（2）速度<br>访问时间Tn，存储周期Tm，频宽Bm<br>（3）价格<br>总价格C，每位价格c<br>同等容量下，存储器的访问速度由高到低：双极型→MOS→电荷耦合型→磁泡→定位磁盘→动头磁盘→磁带</li>
<li>单体多字、多体单字与多体多字<br>（1）并行主存系统的三种模式：单体多字，多体单字，多体多字</li>
<li>存储器系统、并行存储体系与存储层次<br>（1）存储系统：存储系统是指计算机中由存放程序和数据的各种存储设备、控制部件及管理信息调度的设备（硬件）和算法（软件）所组成的系统。<br>（2）存储体系（存储层次）：构成存储系统的几种不同的存储器之间，配上辅助软硬件或辅助硬件，使之从应用程序员来看，在逻辑上是一个整体<br>基本的二级存储体系：虚拟存储器和Cache存储器（主存-辅存存储层次）<br>Cache存储器对于应用程序员和系统程序员都是透明的<br>（3）并行主存系统：可以并行读出多个CPU字的单体多字，多体单字，，多体多字的交叉存储主存系统</li>
<li>虚拟存储器与高速缓冲存储器<br>（1）在具有层次结构存储器的计算机系统中，增设地址映像表机构来实现程序在主存中的定位，自动实现部分装入和部分替换功能，能从逻辑上为用户提供一个比物理贮存容量大得多，可寻址的“主存储器”。虚拟存储区的容量与物理主存大小无关，而受限于计算机的地址结构和可用磁盘容量。<br>（2）存储管理方式：段式，页式，段页式</li>
<li>段式存储管理与页式存储管理技术<br>（1）段式管理：将主存按段分配的存储管理方式<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909201223.png"><br>首先分配算法<br>最佳分配算法<br>（2）页式管理：将主存空间和程序空间都机械等分成固定大小的页<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909201854.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909202427.png"><br>（3）段页式管理：将主存机械等分成固定大小的页，程序按模块分段，每个段又分为和主存页面大小相同的页</li>
<li>地址的映像与变换<br>（1）地址的映像：将每个虚存单元按什么规则（算法）装入（定位于）主存，建立起多用户虚地址N和贮存地址n之间的对应关系<br>（2）地址变换：是指程序按照映像关系装入实存后，在执行中，如何将多用户虚地址N变换成对应的实地址</li>
<li>全相联映像、直接相联映像与组相联映像<br>（1）Cache的全相联映像：主存中任意一块都可映像装入到Cache中任意一块位置<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909212811.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909212838.png"><br>（2）Cache的直接相联映像：把主存空间按Cache大小等分成区，每区内的各块只能映像到Cache中唯一一个特定块位置<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909212844.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909212845.png"><br>（3）Cache的组相联映像：将Cache和贮存空间先分成若干个组，共有2^n个组。Cache中多有的组构成Cache的唯一一个区。而主存则分成与Cache同样大小的2^(nd)个区<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909212846.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909212847.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200910083257.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200910212801.png"></li>
<li>常用替换算法<br>（1）随机算法：RAND，随机产生页号，命中率低，不采用<br>（2）先进先出算法：FIFO，选择最早装如主存的页作为被替换的页<br>（3）近期最少使用算法：LRU，选择近期最少访问的页作为被替换的页<br>（4）优化替换算法：OPT，将未来的近期内不用的页替换出去的算法，有较高的主存命中率，但是不太现实<br>（5）页面失效频率法（动态算法）：PFF，根据各道程序运行中的主存页面失效率的高低，由操作系统来动态操控</li>
<li>堆栈型替换算法<br>（1）堆栈型替换算法：任何时刻t，在n个实页中的虚页集合总是被包含在给其增加一个实页，即n+1个实页时，在实存中的虚页集合之内的<br>（2）堆栈型替换算法，命中率H随着主存页数n的增减单调上升，至少不下降。<br>LRU替换算法属于堆栈型替换算法，操作：将刚访问过的页号置于栈顶，最久未被访问过的页号置于栈底<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200909212445.png"></li>
<li>重叠与流水的区别<br>（1）重叠解释方式：在解释第K条指令的操作完成之前，就开始解释第K+1条指令<br>（2）重叠和流水的区别：依次重叠时把一条指令的解释分为两个子程序，而流水是分为更多个子过程</li>
<li>流水线中的各种相关及解决方案<br>（1）局部性相关：指的是在机器同时解释的多条指令之间出现了对同一主存单元或寄存器要求“先写后读”；包括<code>指令相关</code>，<code>访存操作数相关</code>和<code>通用寄存器组相关</code>等;<br>a）指令相关：包含寄存器相关（包括数据相关和名字相关）和控制相关<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200910101227.png"><br>b）主存空间数相关：相邻两条指令之间出现要求对同一主存单元先写入而后再读出的关联<br>解决方法：推后读<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200910101451.png"><br>（2）全局性相关：已进入流水线的转移指令（尤其时条件转移指令）和后续指令之间的相关</li>
<li>流水线的分类及三个性能指标的计算方法<br>（1）流水线分类：<br>按处理级别：部件级，处理机级，系统级<br>按具有的功能多少：单功能流水线，多功能流水线<br>按多功能流水线的各段能否允许同时用于多种不同功能连接流水：静态流水线，动态流水线<br>按机器所具有的数据表示：标量流水机和向量流水机<br>按各功能段间是否有反馈电路分为：线性流水和非线性流水<br>按信息流动控制方式：顺序流动流水线，异步流动流水线<br>（2）三个性能指标<br>a) 吞吐率Tp ：流水线单位时间里能流出的任务数或结果数<br>Tpmax = 1/max{各个子过程的时间}<br>Tp = n/(m×▲t+(n-1)×▲t) ：m段流水线，各段时间为▲t，完成n个任务的解释共需要时间m×▲t+(n-1)×▲t<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200910102823.png"><br>b) 加速比Sp ：流水线方式相对于非流水线顺序方式速度提高的比值<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200910103021.png"><br>c) 效率η：流水线设备的时间利用率，设备实际使用时间占整个设备运行时间的比值<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200910103134.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200910103907.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200910103939.png"><br>（3）消除瓶颈：<br>①瓶颈子过程再细分<br>②重复设置多套瓶颈段并联</li>
<li>单功能非线性流水线的调度技术<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200910105055.png"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20200910104959.png"></li>
</ol>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>大学课程</tag>
        <tag>计算机系统结构</tag>
      </tags>
  </entry>
  <entry>
    <title>大学课程 | 计算机组成原理</title>
    <url>/posts/51917.html</url>
    <content><![CDATA[<p>计算机组成原理笔记整理</p>
<span id="more"></span>

<h1 id="计算机组成原理"><a href="#计算机组成原理" class="headerlink" title="计算机组成原理"></a>计算机组成原理</h1><h2 id="第一章-计算机系统概述"><a href="#第一章-计算机系统概述" class="headerlink" title="第一章 计算机系统概述"></a>第一章 计算机系统概述</h2><h3 id="1-1-计算机的基本概念"><a href="#1-1-计算机的基本概念" class="headerlink" title="1.1 计算机的基本概念"></a>1.1 计算机的基本概念</h3><p><strong>电子计算机</strong>是一种可以<strong>存储程序</strong>，并且通过<strong>执行程序指令</strong>，可以自动，高速，精确地对数字信息进行各种<strong>复杂处理</strong>，然后<strong>输出运算结果</strong>的高科技<strong>智能</strong>电子设备。</p>
<p>5个逻辑模块：<br>输入设备 存储器 输出设备 运算器 控制器<br><img src="https://s2.ax1x.com/2020/01/02/lt99DP.png" alt="lt99DP.png"><br>（如今运算器和控制器已集成在CPU中）</p>
<h4 id="1-1-1-信息的数字化表示"><a href="#1-1-1-信息的数字化表示" class="headerlink" title="1.1.1 信息的数字化表示"></a>1.1.1 信息的数字化表示</h4><ol>
<li>在计算机中用数字代码（二进制代码）表示各种信息</li>
<li>在物理机制上用数字信号（数字型电信号）表示数字代码</li>
<li>信息数字化表示的优点：（1）物理上易实现信息的表示与存储（2）抗干扰能力强，可靠性高（3）数值表示范围大，精度高（4）可表示的信息类型广泛（5）能用数字逻辑技术进行处理</li>
</ol>
<h4 id="1-1-2-存储程序工作方式"><a href="#1-1-2-存储程序工作方式" class="headerlink" title="1.1.2 存储程序工作方式"></a>1.1.2 存储程序工作方式</h4><ol>
<li>编制程序</li>
<li>存储程序</li>
<li>自动，连续执行程序</li>
<li>输出结果</li>
</ol>
<p>计算机的工作流程：<br>编写程序→输入程序→存储程序→转换为指令序列→执行指令→输出结果</p>
<h4 id="1-1-3-计算机的分类"><a href="#1-1-3-计算机的分类" class="headerlink" title="1.1.3 计算机的分类"></a>1.1.3 计算机的分类</h4><p>计算机从总体上来说分为两大类：<strong>模拟计算机</strong>和<strong>数字计算机</strong></p>
<p>特点：<br>模拟计算机：由模拟运算器件构成，处理在实践和数值上连续的模拟量（如：电压，电流等）<br>数字计算机：由数字逻辑器件构成，处理离散的数字量</p>
<p>其中数字计算机又可分为<strong>专用计算机</strong>和<strong>通用计算机</strong></p>
<p>按照系统规模和计算能力，也可以分为：巨型机（超算），大型机，小型机，微型机等，随着超大规模集成电路技术的不断发展，类型的划分会动态变化。</p>
<h3 id="1-2-计算机的诞生和发展"><a href="#1-2-计算机的诞生和发展" class="headerlink" title="1.2 计算机的诞生和发展"></a>1.2 计算机的诞生和发展</h3><p>计算机之父–冯·诺依曼<br>EDVAC（冯·诺依曼思想）<br>第一台严格意义上的电子计算机（ENIAC，宾夕法尼亚大学，1946.2）</p>
<h4 id="1-2-1-冯·诺依曼体系"><a href="#1-2-1-冯·诺依曼体系" class="headerlink" title="1.2.1 冯·诺依曼体系"></a>1.2.1 冯·诺依曼体系</h4><p>（1）用二进制代码表示程序和数据；<br>任何复杂运算和操作都转换成二进制代码表示的指令，数据也用二进制代码来表示<br>（2）采用存储程序的工作方式；<br>将程序和数据存储起来（存储程序），让计算机自动地执行指令，完成各种复杂的运算操作（核心思想）。<br>（3）新型的现代计算机硬件组成；<br>存储器，运算器，控制器，输入设备和输出设备</p>
<p>奠定了现代电子计算机的理论基础</p>
<h4 id="1-2-2-计算机的发展历程"><a href="#1-2-2-计算机的发展历程" class="headerlink" title="1.2.2 计算机的发展历程"></a>1.2.2 计算机的发展历程</h4><p><img src="https://s2.ax1x.com/2020/01/02/ltA8PK.png" alt="ltA8PK.png"></p>
<h4 id="1-2-3-未来的发展趋势"><a href="#1-2-3-未来的发展趋势" class="headerlink" title="1.2.3 未来的发展趋势"></a>1.2.3 未来的发展趋势</h4><ol>
<li>向巨型化方向</li>
<li>向微型化方向</li>
<li>向多媒体化方向</li>
<li>向网络化方向</li>
<li>向智能化方向</li>
</ol>
<h3 id="1-3-计算机系统的层次结构"><a href="#1-3-计算机系统的层次结构" class="headerlink" title="1.3 计算机系统的层次结构"></a>1.3 计算机系统的层次结构</h3><p>硬件：是指构成计算机系统的实体和装置之类的有形设备，是组成计算机系统的物质基础。</p>
<p>软件：是指硬件所表达的各种内在信息，包括数据与控制程序。因为它们是无形的东西，所以称为软件或软设备。</p>
<h4 id="1-3-1-计算机的硬件系统组成"><a href="#1-3-1-计算机的硬件系统组成" class="headerlink" title="1.3.1 计算机的硬件系统组成"></a>1.3.1 计算机的硬件系统组成</h4><p>1.硬件系统的基本组成模型</p>
<p><img src="https://s2.ax1x.com/2020/01/03/laAwtI.png" alt="laAwtI.png"></p>
<p>主要功能部件：<br>（1）CPU，主要由运算器，控制器等部件组成</p>
<ul>
<li>运算器<ul>
<li>功能：完成两类（算术和逻辑）运算</li>
<li>组成特点：<ul>
<li>主要有ALU(算术逻辑单元)构成，执行算术，逻辑运算以及移位循环等操作，是CPU功能的主要执行部件</li>
<li>ALU以全加器为核心，具有多种运算功能</li>
<li>运算的位数越多，计算精度就越高，但期间也更复杂</li>
<li>运算器的数据宽度一般是：8/16/32/64位</li>
</ul>
</li>
</ul>
</li>
<li>控制器<ul>
<li>功能：产生控制命令（微命令），控制全机操作</li>
<li>基本组成：<img src="https://s2.ax1x.com/2020/01/03/laEWrD.png" alt="laEWrD.png"><br>（2）存储器，存储数据和数字化后的程序</li>
</ul>
</li>
<li>存储单元</li>
<li>地址</li>
<li>存储容量</li>
<li>内存储器（主存）</li>
<li>外存储器（辅存）<br>（3）输入输出设备<br>（4）总线：能为多个部件分时共享的一组信息传送通路</li>
<li>数据总线</li>
<li>地址总线</li>
<li>控制总线<br>（5）接口，具有缓冲，转换，连接的功能的部件</li>
</ul>
<p>2.计算机硬件的典型架构<br>（1）微型计算机：南-北桥架构<br><img src="https://s2.ax1x.com/2020/02/18/3ixYod.png" alt="3ixYod.png"><br>（2）小型计算机：多处理器架构<br><img src="https://s2.ax1x.com/2020/02/18/3ixDOS.png" alt="3ixDOS.png"><br>（3）超级计算机（超算）：集群式架构<br><a href="https://imgchr.com/i/3izitA"><img src="https://s2.ax1x.com/2020/02/18/3izitA.png" alt="3izitA.png"></a><br>（4）多处理机系统结构：用多处理器CPU构成<br>根据处理器之间连接的紧密程度，又分为：①紧密耦合型多机系统②松散耦合型多机系统</p>
<h4 id="1-3-2-软件系统"><a href="#1-3-2-软件系统" class="headerlink" title="1.3.2 软件系统"></a>1.3.2 软件系统</h4><ol>
<li>软件类别：<strong>系统程序</strong>和<strong>应用程序</strong><br>（1）系统程序：负责系统调度管理，提供运行和开发环境，各种服务，确保系统运行良好<br>（2）应用程序：利用计算机来解决应用问题所编制的程序，如工程设计程序，数据处理程序，自动控制程序，企业管理程序，情报检索程序，科学计算程序等等</li>
</ol>
<h4 id="1-3-3-硬，软件系统层次结构"><a href="#1-3-3-硬，软件系统层次结构" class="headerlink" title="1.3.3 硬，软件系统层次结构"></a>1.3.3 硬，软件系统层次结构</h4><p>计算机系统是一个由多层次的软件和硬件组成的系统，基本结构如下图所示：<br><img src="https://s2.ax1x.com/2020/02/18/3FIup4.png" alt="3FIup4.png"></p>
<h4 id="1-3-4-软件和硬件的逻辑等价性"><a href="#1-3-4-软件和硬件的逻辑等价性" class="headerlink" title="1.3.4 软件和硬件的逻辑等价性"></a>1.3.4 软件和硬件的逻辑等价性</h4><ol>
<li><p>软件的特点：易于实现各种逻辑与运算功能，但是常受到速度指标和软件容量的制约</p>
</li>
<li><p>硬件的特点：可以高速实现逻辑和运算的功能，但是难以实现复杂功能或计算，受到控制复杂性指标的制约</p>
</li>
</ol>
<p><strong>计算机中的软件，理论上都可以“固化”或“硬化”成硬件，以提高执行速度</strong></p>
<h3 id="1-4-计算机系统的性能指标"><a href="#1-4-计算机系统的性能指标" class="headerlink" title="1.4 计算机系统的性能指标"></a>1.4 计算机系统的性能指标</h3><p>1.基本字长<br>（1）指一次数据操作的基本位数<br>（2）会影响计算的精度，指令的功能<br>2.外频<br>外频：外部频率或基频，也叫系统时钟频率<br><a href="https://imgchr.com/i/3Fz9aQ"><img src="https://s2.ax1x.com/2020/02/18/3Fz9aQ.png" alt="3Fz9aQ.png"></a><br>3.常用的CPU性能指标<br>（1）CPU的主频=外频✖倍频系数<br>（2）IPS，每秒执行指令数<br>（3）CPI，每一个指令执行过程中所需的时钟周期数量；<br>（4）FLOPS，每秒执行浮点运算的次数<br>（5）CPU的功耗<br><img src="https://s2.ax1x.com/2020/02/18/3kSmlt.png" alt="3kSmlt.png"><br>静态功耗是由于半导体电路自身的损耗造成的功耗</p>
<p>4.数据传输率<br>带宽=（位宽✖工作频率）/8（B/S）<br>物理含义：单位时间内数据的传输量。<br>注意：计算PCI-E总线的带宽时，一般还要考虑编码方式，单双工模式和通道路数等。<br><img src="https://s2.ax1x.com/2020/02/18/3kpqPJ.png" alt="3kpqPJ.png"></p>
<p>5.存储器的容量<br><img src="https://s2.ax1x.com/2020/02/18/3k99aD.png" alt="3k99aD.png"></p>
<h2 id="第二章-数据的表示，运算与校验"><a href="#第二章-数据的表示，运算与校验" class="headerlink" title="第二章 数据的表示，运算与校验"></a>第二章 数据的表示，运算与校验</h2><h3 id="2-1-数值及其相互转换"><a href="#2-1-数值及其相互转换" class="headerlink" title="2.1 数值及其相互转换"></a>2.1 数值及其相互转换</h3><h4 id="2-1-1-进位计数制"><a href="#2-1-1-进位计数制" class="headerlink" title="2.1.1 进位计数制"></a>2.1.1 进位计数制</h4><p>1.数值的基与权<br>在任一数制中，每一数位上允许使用的计数符号的个数被称为该数制的<strong>基数</strong>。<br>每1位都对应1个表示该位在数码中的位置的值，这个值就称为数位的<strong>权值</strong>w。<br><img src="https://s2.ax1x.com/2020/02/18/3kCGfH.png" alt="3kCGfH.png"><br>2.常用进位制：2进制，8进制，16进制<br>3.进制之间的转换</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>大学课程</tag>
        <tag>软件工程</tag>
      </tags>
  </entry>
  <entry>
    <title>Jupyter Lab | 安装、配置、插件推荐、多用户使用教程</title>
    <url>/posts/e05a9ab6.html</url>
    <content><![CDATA[<p>首先相信很多使用过python的人都或多或少地了解过<code>Jupyter Notebook</code>这个应用。<code>Jupyter Notebook</code>是一个开源Web应用程序，可让用户创建和共享包含实时代码、公式、可视化和叙述文本的文档。 用途包括：数据清理和转换、数值模拟、统计建模、数据可视化、机器学习等等。</p>
<p>而<code>Jupyter Lab</code>则是Jupyter的下一代笔记本界面。<code>Jupyter Lab</code> 是一个基于Web的交互式开发环境，用于Jupyter notebook、代码和数据。 <code>Jupyter Lab</code> 非常灵活，可支持数据科学、科学计算和机器学习领域的广泛工作。 <code>Jupyter Lab</code> 是可扩展和模块化的,其可编写插件来添加新组件并与现有组件相集成。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211125180351537.png" alt="image-20211125180351537"></p>
<h1 id="Jupyter-Lab安装和配置"><a href="#Jupyter-Lab安装和配置" class="headerlink" title="Jupyter Lab安装和配置"></a>Jupyter Lab安装和配置</h1><h2 id="1-Jupyter-Lab安装"><a href="#1-Jupyter-Lab安装" class="headerlink" title="1.Jupyter Lab安装"></a>1.Jupyter Lab安装</h2><p>首先进入自己的<code>Python</code>环境或者其他<code>Conda</code>虚拟环境：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source activate XXXXXXX</span><br></pre></td></tr></table></figure>

<p>然后在<code>terminal</code>或者<code>cmd</code>输入安装命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install jupyterlab</span><br><span class="line">//或者</span><br><span class="line">conda install -c conda-forge jupyterlab</span><br></pre></td></tr></table></figure>

<p>等待安装完成！</p>
<h2 id="2-Jupyter-Lab配置"><a href="#2-Jupyter-Lab配置" class="headerlink" title="2.Jupyter Lab配置"></a>2.Jupyter Lab配置</h2><p>使用命令创建配置文件，其会生成<code>C:\Users\用户名\.jupyter\jupyter_notebook_config.py</code>或者<code>/home/用户名/.jupyter/jupyter_notebook_config.py</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jupyter lab --generate-config</span><br></pre></td></tr></table></figure>

<p>使用编辑器打开配置文件，在文件上方添加：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">c.ServerApp.ip = <span class="string">&#x27;*&#x27;</span></span><br><span class="line">c.ServerApp.port = <span class="number">8000</span></span><br><span class="line">c.ServerApp.open_browser = <span class="literal">False</span></span><br><span class="line">c.ServerApp.root_dir = <span class="string">&#x27;/xxxx/xxxx/xxx&#x27;</span> </span><br><span class="line">c.ServerApp.password_required = <span class="literal">True</span></span><br><span class="line">c.ServerApp.password = <span class="string">&#x27;xxxxxxx&#x27;</span></span><br></pre></td></tr></table></figure>

<p>其中<code>ip</code>代表允许访问的ip，<code>*</code>代表全部，<code>port</code>用于设置端口，<code>open_browser</code>用于设置启动lab时是否打开浏览器，<code>root_dir</code>用于设置lab启动文件夹根路径，<code>password_required</code>用于设置是否需要密码，<code>password</code>用于设置（加密）密码，这个加密密码的获取方式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#打开python或者ipython环境</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</span><br><span class="line">passwd()</span><br><span class="line"><span class="comment">#Enter password: </span></span><br><span class="line"><span class="comment">#Verify password: </span></span><br><span class="line"><span class="comment">#Out[2]: &#x27;argon2:f704bjkasjdfkjasdjfkasjdkjfklmasjdfkalflakdkf&#x27;</span></span><br></pre></td></tr></table></figure>

<p>复制上方输出的加密密码即可。</p>
<p>当然也可以在<code>Terminal</code>强制设置/修改密码：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jupyter lab password</span><br></pre></td></tr></table></figure>

<p>更多配置可以查看默认配置文件下方的注释！</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120214858878.png" alt="image-20211120214858878"></p>
<h2 id="3-Jupyter-Lab启动"><a href="#3-Jupyter-Lab启动" class="headerlink" title="3. Jupyter Lab启动"></a>3. Jupyter Lab启动</h2><p>在<code>Terminal</code>输入:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jupyter lab -p 9090 --no-browser</span><br></pre></td></tr></table></figure>

<p>更多启动命名可通过<code>jupyter lab --help</code>查看，启动之后即可在浏览器输入：ip+端口 ，进行访问，如：<code>127.0.0.0:9090</code>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120215159090.png" alt="image-20211120215159090"></p>
<h2 id="4-Jupyter-Lab插件推荐"><a href="#4-Jupyter-Lab插件推荐" class="headerlink" title="4. Jupyter Lab插件推荐"></a>4. Jupyter Lab插件推荐</h2><p>首先启动Jupyter Lab，在Lab中打开菜单栏的<code>Setting</code>里的<code>Advanced Setting Editor</code>，接着找到<code>Extension Manager</code>，并在右边填入<code>&#123;&#39;enabled&#39;:true&#125;</code></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120215625334.png" alt="image-20211120215625334"></p>
<p>然后即可在左边菜单栏找到插件安装符号，在里面就可以搜索插件，推荐如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/image-20211120215754890.png" alt="image-20211120215754890"></p>
<ul>
<li>theme-darcula：一个好看的主题配色</li>
<li>jupyterlab_go_to_definition：跳转到定义</li>
<li>jupyterlab_lsp：代码跳转+代码补全</li>
<li>还有很多如：latex，git，html，plotly，bokeh，matplotlib，drawio等等</li>
</ul>
<h2 id="5-Jupyter-Lab多用户使用"><a href="#5-Jupyter-Lab多用户使用" class="headerlink" title="5. Jupyter Lab多用户使用"></a>5. Jupyter Lab多用户使用</h2><p>复制配置文件到指定位置，例如:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp /home/admin555/.jupyter/jupyter_notebook_config.py /指定位置/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure>

<p>之后启动时，使用命令：</p>
 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jupyter lab --config /指定位置/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure>

<p> 我的博客即将同步至腾讯云+社区，邀请大家一同入驻：<a href="https://cloud.tencent.com/developer/support-plan?invite_code=1izx0kxkb2lzz">https://cloud.tencent.com/developer/support-plan?invite_code=1izx0kxkb2lzz</a></p>
]]></content>
      <categories>
        <category>折腾记录</category>
      </categories>
      <tags>
        <tag>Jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title>大学课程 | 软件工程知识点</title>
    <url>/posts/38368.html</url>
    <content><![CDATA[<p>大二软件工程课程笔记</p>
<span id="more"></span>
<h2 id="软件工程要点"><a href="#软件工程要点" class="headerlink" title="软件工程要点"></a>软件工程要点</h2><ol>
<li><p>   软件是指令的集合，数据结构和软件描述信息的集合</p>
</li>
<li><p>   软件与硬件的区别：软件不会磨损，但会退化，退化的根本原因是不断变更</p>
</li>
<li><p>   软件工程是（1）将系统化的，规范的，可量化的方法应用于软件的开发，运行和维护.（2）对（1）中方法的研究</p>
</li>
<li><p>   工程化：系统化的，规范的，可量化的</p>
</li>
<li><p>   软件工程是一种层次化的技术，包含工具，方法，过程，质量关注点。</p>
</li>
<li><p>   软件工程的三要素：工具，方法，过程</p>
</li>
<li><p>   软件过程是工作产品构建是所执行的一系列活动，动作和任务的集合</p>
</li>
<li><p>   五种通用过程框架活动：沟通，策划，建模，构建，部署</p>
</li>
<li><p>   软件工程整体实践的原则：存在价值；保持简洁；保持愿景；关注使用者；面向未来；提前计划复用；认真思考</p>
</li>
<li><p>   四种过程流：线性过程流；迭代过程流；演化过程流；并行过程流；</p>
</li>
<li><p>   惯用过程模型：瀑布模型；V模型；增量过程模型；原型模型，螺旋模型；并发模型</p>
</li>
<li><p>   专用过程模型：基于构件；形式化方法模型；面向方面</p>
</li>
<li><p>   统一建模语言UML</p>
</li>
<li><p>   UP统一过程的五个阶段：起始阶段；细化阶段；构建阶段；转换阶段；生产阶段</p>
</li>
<li><p>   UP的五个阶段不是顺序进行，而是阶段性的并发进行</p>
</li>
<li><p>   敏捷原则（12条）</p>
</li>
<li><p>   普遍存在的变更是敏捷的基本动力</p>
</li>
<li><p>   需求工程是一个软件工程的动作，开始于沟通并持续到建模活动</p>
</li>
<li><p>   需求工程的7项任务：起始，获取，细化，协商，规格说明，确认，管理</p>
</li>
<li><p>   分析模型的作用：为基于计算机的系统提供必要的信息，功能和行为域的说明</p>
</li>
<li><p>   分析模型的元素：基于场景的元素；基于类的元素；行为元素数据流元素；</p>
</li>
<li><p>   需求建模动作结果：场景模型；面向类的模型；基于行为和模式的模型；数据模型；面向流的模型</p>
</li>
<li><p>   域分析：识别，分析和详细说明某个特定应用领域的共同需求以便确定可以在整个邻域内复用的对象</p>
</li>
<li><p>   需求建模的方法：结构化分析；面向对象分析（UML和UP）</p>
</li>
<li><p>   用例间的关系：包含关系（一个用例总是使用另一个用例的功能）；扩展关系；泛化关系（子类与夫类的关系）</p>
</li>
<li><p>   UML活动图：两端为半圆的矩形—特定的系统功能；箭头—通过系统的流；菱形—分支；实水平线—并行发生的活动</p>
</li>
<li><p>   泳道图：参与者职责由纵向分割图中的并行条表示</p>
</li>
<li><p>   类的分类：实体类；边界类；控制类</p>
</li>
<li><p>   类间关系：关联；继承；依赖</p>
</li>
<li><p>   面向对象的目的是封装，但仍保持对的数据以及对数据的操作</p>
</li>
<li><p>   潜在类的特征：保留信息；所需服务；多个属性；公共属性；公共操作；必要需求</p>
</li>
<li><p>   CRC模型：是表示类的标准索引卡片的集合</p>
</li>
<li><p>   CRC评审模型</p>
</li>
<li><p>   UML状态图：箭头—状态转移</p>
</li>
<li><p>   时序图（顺序图）</p>
</li>
<li><p>   四种设计模型：构件级设计；接口设计；体系结构设计；数据/类设计；</p>
</li>
<li><p>   设计概念包括：抽象，体系结构，模式，关注点分离，模块化，信息隐蔽，功能独立。求精，方面，重构，面向对象，设计类（完整性与充分性，原始性，高内聚性，低耦合性），依赖倒置，测试设计</p>
</li>
<li><p>   软件体系结构：程序或计算系统的软件结构是指系统的一个或多个结构，它包括软件构建，构建的外部可见属性以及他们之间的相互关系</p>
</li>
<li><p>   设计是体系结构的一个实例</p>
</li>
<li><p>   体系结构的风格包括：（1）完成系统需要的某种功能的一组构件；（2）能使构件间实现“通信，合作和协调”的一组连接件（3）定义构件如何集成为系统的约束（4）语义模型，能使设计者通过分析系统组成成分的已知属性来理解西戎的整体性质</p>
</li>
<li><p>   体系结构风格的分类：以数据为中心的体系结构；数据流体系结构；调用和返回体系结构；面向对象体系结构；层次体系结构</p>
</li>
<li><p>   构件：系统中模块化的，可部署的和可替换的部件，该部件封装了实现对外提供一组接口</p>
</li>
<li><p>   基本设计原则：开闭原则；Liskov替换原则；依赖倒置原则；接口分离原则；发布复用等价性原则；共同封装原则，共同复用原则</p>
</li>
<li><p>   内聚性：功能内聚；分层内聚；通信内聚</p>
</li>
<li><p>   耦合性：内容耦合；公共耦合；外部耦合；控制耦合（由强到弱）</p>
</li>
<li><p>   构件3C模型：概念，内容，环境</p>
</li>
<li><p>   用户界面黄金原则：（1）把控制权交给用户（2）减轻用户的记忆负担（3）保持界面一致</p>
</li>
<li><p>   软件测试策略：单元测试集成测试确认测试系统测试</p>
</li>
<li><p>   集成测试包括：自顶向下集成；自底向上集成；回归测试；冒烟测试</p>
</li>
<li><p>   面向对象的集成测试：基于线程的测试；基于使用的测试；簇测试</p>
</li>
<li><p>   α测试和β测试的区别：α测试是由有代表性的最终用户在开发者的场所进行。即α测试是在受控环境下进行。而β测试在一个或多个最终用户场所进行。与α测试不同，开发者通常不在场</p>
</li>
<li><p>   系统测试包括：恢复测试；安全测试；压力测试；性能测试；部署测试</p>
</li>
<li><p>   调试方法：蛮干法；回溯法；原因排除法</p>
</li>
<li><p>   白盒测试：（结构化测试）<br>（1） 逻辑覆盖<br>（2） 路径覆盖：①流图：箭头—边/连接/控制流；边和结点限制的区域—域；包含条件的结点—判定结点② 环复杂性：（1）V(G)=边数-节点数+2（2）V(G)=判定结点数+1（3）V(G)=域数③ 生成基本测试用例：（1）以设计或源代为基础画出相应的流图（2）确定所得流图的环复杂性（3）确定线性独立路径的基本集合（4）准备测试用例，强制执行基本集合中的每一条路径</p>
</li>
<li><p>   黑盒测试：（行为测试/功能测试）白盒测试在测试早期执行，黑盒测试倾向于在测试后期<br>（1）等价类法<br>（2）边界值法<br>（3）错误猜测法</p>
</li>
<li><p>   软件配置：在软件过程中产生的所有信息项</p>
</li>
<li><p>   软件配置管理：一组用于在计算机软件的整个生命周期内管理变更的活动</p>
</li>
<li><p>   软件过程输出信息可以分为：计算机程序；文档；数据或内容</p>
</li>
<li><p>   系统工程第一定律：不管你处在系统生命周期的什么阶段，系统都可能发生变更，并且在整个生命周期中将会持续不断的提出变更的要求</p>
</li>
<li><p>   配置管理系统的元素：构件元素；过程元素；构建元素；人员元素；</p>
</li>
<li><p>   基线：已经通过正式评审和批准的规格说明或产品，它可以作为进一步开发的基础，并且只有通过正式的变更控制规程才能修改它</p>
</li>
<li><p>   SCM中心存储库：是一组机制和数据结构，它使软件团队可以有效地管理变更</p>
</li>
<li><p>   SCM特征：版本控制；依赖性跟踪和变更管理；需求跟踪；配置管理；审核跟踪</p>
</li>
<li><p>   软件项目管理的4P：人员，产品，过程，项目</p>
</li>
<li><p>   W5HH原则</p>
</li>
<li><p>   软件度量：过程度量，项目度量，产品度量</p>
</li>
<li><p>   软件测试：<br>（1） 面向规模度量：LOC（代码行）<br>（2） 面向功能度量：FP（功能点）<br>（3） 面向对象度量<br>（4） 面向用例度量</p>
</li>
<li><p>   软件质量：测试指标：正确性；可维护性；完整性；可用性；<br>（1） 正确性：每千行代码的缺陷数<br>（2） 可维护性：平均变更时间MTTC<br>（3） 完整性：=∑(1-(危险性×(1-安全性)))</p>
</li>
<li><p>   缺陷排除效率：<br>（1） DRE=E/(E+D)<br>（2） E是软件交付给最终用户之前发现的错误数<br>（3） D是软件交付之后发现的错误数</p>
</li>
<li><p>   三类主要软件工程资源：人员，可复用的软件构件，开发环境（硬件和软件工具）<br>（1） 对每类资源都要说明四个特征：资源描述，可用性说明，何时需要资源，使用资源的持续时间</p>
</li>
<li><p>   基于问题估算：<br>（1） S=（Sopt+4Sm+Spess）/6<br>（2） Sopt乐观值，Sm可能值，Spess悲观值</p>
</li>
<li><p>   基于LOC的估算：<br>（3） LOC/pm–人月</p>
</li>
<li><p>   基于FP的估算：<br>（4） FPestimated=总计×（0.65+0.01×∑Fi）</p>
</li>
</ol>
<h2 id="软件工程简答题及答案"><a href="#软件工程简答题及答案" class="headerlink" title="软件工程简答题及答案"></a>软件工程简答题及答案</h2><h3 id="1-简述软件的定义及特征"><a href="#1-简述软件的定义及特征" class="headerlink" title="1.简述软件的定义及特征"></a>1.简述软件的定义及特征</h3><p>软件是：计算机系统中与硬件相互依存的另一部分，它包括程序，数据及其相关文档的完整集合。<br>（1）指令的集合（计算机程序），通过执行这些指令可以满足预期的特性、功能和性能需求；<br>（2）数据结构，使得程序可以合理利用信息；<br>（3）软件描述信息，用来描述程序的操作和使用。 </p>
<ul>
<li>软件的特征是：<ul>
<li>软件不会“磨损”，但会退化，退化的根本原因是不断变更；</li>
<li>软件是开发、设计出来的，不是生产出来的；</li>
<li>大多数软件是按照实际客户要求定制的。<h3 id="2-简述软件工程的定义及软件过程的5种框架活动"><a href="#2-简述软件工程的定义及软件过程的5种框架活动" class="headerlink" title="2.简述软件工程的定义及软件过程的5种框架活动"></a>2.简述软件工程的定义及软件过程的5种框架活动</h3></li>
</ul>
</li>
<li>软件工程是：<br>（1）将系统化的、规范的、可量化的方法应用于软件的开发、运行和维护，即将工程化方法应用于软件；<br>（2）对（1）中所述方法的研究。</li>
<li>软件工程过程框架通常包含以下5个活动：<ul>
<li>沟通、策划、建模、构建、部署。<h3 id="3-画图说明软件过程流的各种类型"><a href="#3-画图说明软件过程流的各种类型" class="headerlink" title="3.画图说明软件过程流的各种类型"></a>3.画图说明软件过程流的各种类型</h3>略<h3 id="4-画图说明软件过程的增量模型及适用情形和特点"><a href="#4-画图说明软件过程的增量模型及适用情形和特点" class="headerlink" title="4.画图说明软件过程的增量模型及适用情形和特点"></a>4.画图说明软件过程的增量模型及适用情形和特点</h3>略</li>
</ul>
</li>
<li>适用情形：初始的软件需求有明确的定义，但是整个开发过程却不宜单纯运用线性模型。迫切需要为用户迅速提供一套功能有限的软件产品，然后在后续版本中再进行细化和扩展功能。</li>
<li>特点：增量模型综合了线性过程流和并行过程流的特征。每个线性序列生产出软件的可交付增量且第一个增量往往是核心产品，满足了基本的需求。客户使用后进行评估，根据评估结果制定下一个增量计划。每一个增量的交付都会重复这一过程，直到最终产品产生。<h3 id="5-画图说明软件过程的原型模型及适用情形和特点"><a href="#5-画图说明软件过程的原型模型及适用情形和特点" class="headerlink" title="5.画图说明软件过程的原型模型及适用情形和特点"></a>5.画图说明软件过程的原型模型及适用情形和特点</h3>略</li>
<li>适用情形：客户定义了软件的一些基本任务，但是没有详细定义功能和特性需求。开发人员可能对算法的效率、操作系统的适用性和人机交互的形式等情况并没有把握。</li>
<li>特点：在大多数项目中，构建的第一个系统很少是好用的，可能太慢了、太大了、太难用了，或者同时具备上述三点。一般作为被丢弃的系统。开发者没有考虑整体软件质量和长期的可维护性。软件工程师经常会使用不合适的操作系统或程序设计语言或低效的算法。但是原型开发对于软件工程来说仍是有效的范型。<h3 id="6-画图说明统一过程的各个阶段"><a href="#6-画图说明统一过程的各个阶段" class="headerlink" title="6.画图说明统一过程的各个阶段"></a>6.画图说明统一过程的各个阶段</h3>略<br>UP：</li>
<li>   起始阶段，细化阶段，构建阶段，转换阶段，生产阶段</li>
<li> 五个UP阶段不是顺序进行，而是阶段性地并发进行。（可能在构建转换生产同时，下一个软件增量的工作已经开始）<h3 id="7-简述敏捷原则"><a href="#7-简述敏捷原则" class="headerlink" title="7.简述敏捷原则"></a>7.简述敏捷原则</h3>（1） 我们最优先要做的是通过尽早、持续交付有价值的软件来使客户满意。<br>（2） 即使在开发的后期，也欢迎需求变更。敏捷过程利用变更为客户创造竞争优势。<br>（3） 经常交付可运行软件，交付的间隔可以从几个星期到几个月，交付的时间间隔越短越好。<br>（4） 在整个项目开发期间，业务人员和开发人员必须天天都在一起工作。<br>（5） 围绕有积极性的个人构建项目。给他们提供所需的环境和支持，并且信任他们能够完成工作。<br>（6） 在团队内部，最富有效果和效率的信息传递方法是面对面交谈。<br>（7） 可运行软件是进度的首要度量标准。<br>（8） 敏捷过程提倡可持续的开发速度。责任人、开发者和用户应该能够长期保持稳定的开发速度。<br>（9） 不断地关注优秀的技能和好的设计会增强敏捷能力。<br>（10） 简单——使不必做的工作最大化的艺术——是必要的。<br>（11） 最好的架构、需求和设计出自于自组织团队。<br>（12） 每隔一定时间，团队会反省如何才能更有效地工作，并相应调整自己的行为。<h3 id="8-简述需求建模的模型"><a href="#8-简述需求建模的模型" class="headerlink" title="8.简述需求建模的模型"></a>8.简述需求建模的模型</h3>（1）场景模型：出自各种系统“参与者”观点的需求。<br>（2）面向类的模型：表示面向对象类（属性和操作）的模型，其方式为通过类的协作获得系统需求。<br>（3）基于行为和模式的模型：描述如何将软件行为看作外部“事件”后续的模型。<br>（4）数据模型：描述问题信息域的模型。<br>（5）面向流的模型：表示系统的功能元素并且描述当功能元素在系统中运行时怎样进行数据变换。<h3 id="9-简述CRC模型的评审步骤"><a href="#9-简述CRC模型的评审步骤" class="headerlink" title="9.简述CRC模型的评审步骤"></a>9.简述CRC模型的评审步骤</h3>①所有参加评审的人员拿到一部分CRC模型索引卡。拆分协作卡片。<br>②分类管理所有的用例场景。<br>③评审组长细致地阅读用例。当评审组长看到一个已命名的对象时，给拥有相应类索引卡的人员一个令牌。<br>④当令牌传递时，该类卡的拥有者需要描述卡上记录的职责。评审组确定职责是否满足用例需求。<br>⑤如果记录在索引卡上的职责和协作不能满足用例，就需要修改卡片，包括定义新类。<h3 id="10-简述行为建模的步骤"><a href="#10-简述行为建模的步骤" class="headerlink" title="10.简述行为建模的步骤"></a>10.简述行为建模的步骤</h3>（1）评估所有的用例，以保证完全理解系统内的交互顺序；<br>（2）识别驱动交互顺序的事件，并理解这些事件如何与特定的对象相互关联；<br>（3）为每个用例生成序列；<br>（4）创建系统状态图；<br>（5）评审行为模型以验证准确性和一致性。<h3 id="11-画图说明从需求模型到设计模型的转换"><a href="#11-画图说明从需求模型到设计模型的转换" class="headerlink" title="11.画图说明从需求模型到设计模型的转换"></a>11.画图说明从需求模型到设计模型的转换</h3>略<h3 id="12-简述模块的功能独立及评估标准"><a href="#12-简述模块的功能独立及评估标准" class="headerlink" title="12.简述模块的功能独立及评估标准"></a>12.简述模块的功能独立及评估标准</h3>  通过开发具有“专一”功能和“避免”与其他模块过多交互的模块，可以实现功能独立。<br>  独立性可以通过两条定性的标准进行评估：内聚性和耦合性。内聚性显示了某个模块相关功能的强度；耦合性显示了模块间的相互依赖性。<h3 id="13-简述重构的定义及重构时的检查要点"><a href="#13-简述重构的定义及重构时的检查要点" class="headerlink" title="13.简述重构的定义及重构时的检查要点"></a>13.简述重构的定义及重构时的检查要点</h3>  重构是使用这样一种方式改变软件系统的过程：不改变代码的外部行为而是改进其内部结构。<br>  在重构软件时，检查现有设计的冗余性、没有使用的设计元素、低效的或不必要的算法、拙劣的或不恰当的数据结构以及其他设计不足。<h3 id="14-简述体系结构风格描述的4个要素及其分类"><a href="#14-简述体系结构风格描述的4个要素及其分类" class="headerlink" title="14.简述体系结构风格描述的4个要素及其分类"></a>14.简述体系结构风格描述的4个要素及其分类</h3>四个要素：<br>（1）完成系统需要的某种功能的一组构件；<br>（2）能使构件间实现“通信、合作和协调”的一组连接件；<br>（3）定义构件如何集成为系统的约束；<br>（4）语义模型，能使设计者通过分析系统组成成分的已知属性来理解系统的整体性质。<br>分类：以数据为中心的体系结构、数据流体系结构、调用和返回体系结构、面向对象体系结构、层次体系结构。<h3 id="15-简述构件级设计的7个基本原则"><a href="#15-简述构件级设计的7个基本原则" class="headerlink" title="15.简述构件级设计的7个基本原则"></a>15.简述构件级设计的7个基本原则</h3>①开闭原则。模块（构件）应该对外延具有开放性，对修改具有封闭性。<br>②Liskov替换原则。子类可以替换它们的基类。<br>③依赖倒置原则。依赖于抽象，而非具体实现。<br>④接口分离原则。多个客户专用接口比一个通用接口要好。<br>⑤发布复用等价性原则。复用的粒度就是发布的粒度。<br>⑥共同封装原则。一同变更的类应该合在一起。<br>⑦共同复用原则。不能一起复用的类不能被分到一组。<h3 id="16-简述黄金规则中把控制权交给用户的规则"><a href="#16-简述黄金规则中把控制权交给用户的规则" class="headerlink" title="16.简述黄金规则中把控制权交给用户的规则"></a>16.简述黄金规则中把控制权交给用户的规则</h3>①以不强迫用户进入不必要的或不希望的动作的方式来定义交互模式。<br>②提供灵活的交互。<br>③允许用户交互被中断和撤销。<br>④当技能水平高时可以使交互流线化并允许定制交互。<br>⑤使用户与内部技术细节隔离开来。<br>⑥设计应允许用户与出现在屏幕上的对象直接交互。<h3 id="17-简述黄金规则中减轻用户记忆负担的原则"><a href="#17-简述黄金规则中减轻用户记忆负担的原则" class="headerlink" title="17.简述黄金规则中减轻用户记忆负担的原则"></a>17.简述黄金规则中减轻用户记忆负担的原则</h3>①减少对短期记忆的要求。<br>②建立有意义的默认设置。<br>③定义直观的快捷方式。<br>④界面的视觉布局应该基于真实世界的象征。<br>⑤以一种渐进的方式揭示信息。<h3 id="18-简述黄金规则中保持界面一致的原则"><a href="#18-简述黄金规则中保持界面一致的原则" class="headerlink" title="18.简述黄金规则中保持界面一致的原则"></a>18.简述黄金规则中保持界面一致的原则</h3>①允许用户将当前任务放入有意义的环境中。<br>②在完整的产品线内保持一致性。<br>③如果过去的交互模型已经建立起了用户期望，除非有不得已的理由，否则不要改变它。<h3 id="19-简述面向对象软件测试中集成测试的3种策略"><a href="#19-简述面向对象软件测试中集成测试的3种策略" class="headerlink" title="19.简述面向对象软件测试中集成测试的3种策略"></a>19.简述面向对象软件测试中集成测试的3种策略</h3>①基于线程的测试，对响应系统的一个输入或事件所需的一组类进行集成。<br>②基于使用的测试，通过测试很少使用服务类的那些类开始系统的构建。<br>③簇测试，借助试图发现协作错误的测试用例来测试协作的类簇。<h3 id="20-简述压力测试并举例说明"><a href="#20-简述压力测试并举例说明" class="headerlink" title="20.简述压力测试并举例说明"></a>20.简述压力测试并举例说明</h3>  压力测试的目的是使软件面对非正常的情形。压力测试要求以一种非正常的数量、频率或容量的方式执行系统。<br>  例如：（1）在平均每秒出现1~2次中断的情形下，可以设计每秒产生10次中转的测试用例；（2）将输入数据的量提高一个数量级以确定输入功能将如何反应；（3）执行需要最大内存或其他资源的测试用例；（4）设计可能在实际的运行系统中产生惨败的测试用例；（5）创建可能会过多查找磁盘驻留数据的测试用例。<h3 id="21-简述单元测试中桩模块和驱动模块的作用？"><a href="#21-简述单元测试中桩模块和驱动模块的作用？" class="headerlink" title="21.简述单元测试中桩模块和驱动模块的作用？"></a>21.简述单元测试中桩模块和驱动模块的作用？</h3>  驱动程序只是一个“主程序”，它接受测试用例数据，将这些数据传递给构件，并打印相关结果。<br>  桩程序的作用是替换那些从属于被测构件的模块。桩程序或“伪程序”使用从属模块的接口，可能做少量的数据操作，提供入口的验证，并将控制返回到被测模块。<h3 id="22-简述测试中症状与原因之间的关系"><a href="#22-简述测试中症状与原因之间的关系" class="headerlink" title="22.简述测试中症状与原因之间的关系"></a>22.简述测试中症状与原因之间的关系</h3>  症状与原因出现的地方可能相隔很远。也就是说，症状可能在程序的一个地方出现，而原因实际上可能在很远的另一个地方。高度耦合的构建加剧了这种情况的发生。<h3 id="23-简述软件的基线及SCI和项目数据库之间的关系"><a href="#23-简述软件的基线及SCI和项目数据库之间的关系" class="headerlink" title="23.简述软件的基线及SCI和项目数据库之间的关系"></a>23.简述软件的基线及SCI和项目数据库之间的关系</h3>基线的定义是：已经通过正式评审和批准的规格说明或产品，它可以作为进一步开发的基础，并且只有通过正式的变更控制规程才能修改它。<br>基线是软件开发中的里程碑，其标志是在正式技术评审中已经获得批准的一个或多个软件配置项的交付。<br>软件配置项是在软件工程过程中创建的信息。在现实中，是将SCI组织成配置对象，这些配置对象具有自己的名字，并且按类别存储在项目数据库中。配置对象具有一个名称和多个属性，并通过关系来表示与其他配置对象的“关联”。</li>
</ul>
<h3 id="24-简述选择软件团队结构时应考虑的7个因素"><a href="#24-简述选择软件团队结构时应考虑的7个因素" class="headerlink" title="24.简述选择软件团队结构时应考虑的7个因素"></a>24.简述选择软件团队结构时应考虑的7个因素</h3><p>①待解决问题的难度；<br>②开发程序的规模，以代码行或者功能点来度量；<br>③团队成员需要共同工作的时间 (团队生存期)；<br>④能够对问题做模块化划分的程度；<br>⑤待开发系统的质量要求和可靠性要求；<br>⑥交付日期的严格程度；<br>⑦项目所需要的友好交流的程度。</p>
<h3 id="25-简述软件团队的组织范型"><a href="#25-简述软件团队的组织范型" class="headerlink" title="25.简述软件团队的组织范型"></a>25.简述软件团队的组织范型</h3><p>①封闭式范型。按照传统的权利层次来组织团队。<br>②随机式范型。松散地组织团队，团队工作依赖于团队成员个人的主动性。<br>③开放式范型。试图以一种既具有封闭式范型的控制性，又包含随机式范型的创新性的方式来组织团队。<br>④同步式范型。依赖于问题的自然划分，组织团队成员各自解决问题的一部分，他们之间没有什么主动的交流。</p>
<h3 id="26-简述如何避免“团队毒性”"><a href="#26-简述如何避免“团队毒性”" class="headerlink" title="26.简述如何避免“团队毒性”"></a>26.简述如何避免“团队毒性”</h3><p>为了避免狂乱的工作环境，项目经理应该确保团队可以获取完成工作所需的所有信息；而且，主要目标一旦确定下来，除非绝对必要，否则不应该修改。给予软件团队尽可能更多的决策权，这样能使团队避免挫败。通过理解将要开发的产品和完成工作的人员，以及允许团队选择过程模型，可以避免选择不适当的软件过程，团队本身应该建立自己的责任机制。团队本身应该建立自己的责任机制，并规定一系列当团队成员未能完成任务时的纠正方法。最后，避免失败的关键是建立基于团队的信息反馈方法和解决问题的技术。</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>大学课程</tag>
        <tag>软件工程</tag>
      </tags>
  </entry>
  <entry>
    <title>随笔记录 | Loading竟然这样有趣</title>
    <url>/posts/e24ee5c3.html</url>
    <content><![CDATA[<p>如今无论是在手机端还是PC端，浏览的页面的内容都会做的十分丰富，于是乎需要加载的东西就会很多。但是用户或许会网速慢或硬件卡，可能会遇到需要加载的情况，而没有耐心的人，就会因为不断的加载而放弃浏览直接关闭。</p>
<p>于是添加一个有趣的Loading的画面，就可以大大地缓解等待过程的无趣感，让用户知道目前的加载状态，以及让用户多多关注在Loading画面的本身上，让他们把等待看成一件美好的事，那么我们来探寻一些有趣的Loading画面吧。</p>
<div class="fj-gallery"><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/ambulanceloading.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/ballloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/ballloading2.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/ballonloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/bigheadloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/bikeloading2.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/birdloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/blockloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/capsuleloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/carloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/catloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/catloading2.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/catloading3.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/changeloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/changeloading3.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/changeloading3.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/changloading2.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/christmasloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/coffeeloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/computerloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/cutecatloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/dinosaurloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/earthloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/fanloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/fireloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/fishloading.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/geoloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/greenoctopusloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/handloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/labloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/leafloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/lineloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/lionloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/liquidloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/loadingbike.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/magicloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/manloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/marvelloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/milkloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/mloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/monkeyloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/musicloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/octopusloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/paperloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/pencilloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/phoneloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/pizzaloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/planeloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/planeloading2.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/pointloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/pointsloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/rocketloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/sandglassloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/sandwichloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/snowloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/snowmanloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/suntomoonloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/tealoading.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/threeballloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/threeloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/timg.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/trainloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/triloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/triloading2.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/twoloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/waterballloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/waveloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/waveloading2.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/waveloading3.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/whaleloading.gif"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/yellowloading.gif"></p>
          </div>

<div class="note info"><small>※图片搜集自百度图片</small></div>]]></content>
      <categories>
        <category>折腾记录</category>
      </categories>
      <tags>
        <tag>Loading</tag>
      </tags>
  </entry>
  <entry>
    <title>iOS快捷指令 | iPicGo，随时随地用手机上传图片到图床</title>
    <url>/posts/223c1a0c.html</url>
    <content><![CDATA[<h1 id="iOS快捷指令版PicGo"><a href="#iOS快捷指令版PicGo" class="headerlink" title="iOS快捷指令版PicGo"></a>iOS快捷指令版PicGo</h1><blockquote>
<p>功能：<strong>上传手机图片到Github，并将其在jsdelivr的CDN图片链接复制到剪切板。</strong></p>
<p>当然我主要是为了方便发图片链接到<a href="/essay/">哔哔</a>😀。哔哔来自<a href="https://immmmm.com/bb-by-wechat-pro/">木木木木木</a>，iOS<a href="https://www.icloud.com/shortcuts/8e9e01fd2fc14124b1a7cf43a5ea64bd">哔哔发射</a>捷径来自<a href="https://blog.zhheo.com/p/27be0e44.html">Heo</a></p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210326105717.png" alt="image-20210326105717200"></p>
<h2 id="1-申请github的personal-access-token"><a href="#1-申请github的personal-access-token" class="headerlink" title="1. 申请github的personal access token"></a>1. 申请github的personal access token</h2><p>点击Settings-Developer settings-Personal access tokens-Generate new token-取个名字勾选repo-复制token（!!!）即可获得token</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210326132347.png" alt="image-20210326132347250"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210326132516.png" alt="image-20210326132516102"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210326132545.png" alt="image-20210326132545789"></p>
<h2 id="2-使用iOS-的iPicGo捷径"><a href="#2-使用iOS-的iPicGo捷径" class="headerlink" title="2. 使用iOS 的iPicGo捷径"></a>2. 使用iOS 的iPicGo捷径</h2><p>使用手机Safari浏览器打开<a href="https://www.icloud.com/shortcuts/7c950e63f0ff4533b125253705e18f7c">快捷指令链接</a>，修改第一块<code>词典</code>里面的参数。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210326130845.png" alt="06B2762F01E8C962472455EBA7B39F19"></p>
<p>其中参数如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &#x27;name&#x27;: github的用户名,</span><br><span class="line">    &#x27;repo&#x27;: github图床的仓库名,</span><br><span class="line">    &#x27;path&#x27;: 你想要上传的子路径名，例如：image或者image/pic，首尾无斜杠,</span><br><span class="line">    &#x27;token&#x27;: 申请到的github personal access token</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中path部分默认是有子路径的，因为我有😀，所以没有增加判断…可以自行修改url链接，如下图所示URL部分：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210326131817.png" alt="image-20210326131817492"></p>
<p>修改完成后即可实现手机图片上传到github的功能。</p>
<h2 id="3-使用iPicGo和哔哔发射"><a href="#3-使用iPicGo和哔哔发射" class="headerlink" title="3. 使用iPicGo和哔哔发射"></a>3. 使用iPicGo和哔哔发射</h2><p>所以现在，我就可以先使用iPicGo捷径上传到github图床，然后捷径会自动返回图片链接到剪切板，再打开哔哔发射，粘贴图片链接，就可以方便哔哔了。当然，木木大佬的哔哔点啥公众号也可以发图片😂。</p>
<p>Gif演示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210326134511.gif" alt="20201105174303"></p>
<style>
    img{max-height: 450px;}
</style>]]></content>
      <categories>
        <category>折腾记录</category>
      </categories>
      <tags>
        <tag>iOS</tag>
        <tag>捷径</tag>
      </tags>
  </entry>
  <entry>
    <title>iOS快捷指令 | 早安，让Siri唤醒你的美好一天</title>
    <url>/posts/62966.html</url>
    <content><![CDATA[<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/7f907f6c-ba49-78e4-24e4-b3594dc3a1f2.jpg"/>
<blockquote class="wp-block-quote is-style-default"><p>捷径 （英文名：Shortcuts）是苹果收购的 Workflow 在 iOS 中整合后的成果。用户可以通过该APP创建各种模块化操作，以提高iPhone的处理相关任务的效率 </p></blockquote>

<p>根据捷径便捷操作iOS的特性，可以使用它编写强大的便捷功能，如“早安”捷径，只需要使用Siri说“早安”，便能够实现以下等功能： </p>
<p>1、开启蓝牙;</p>
<p>2、开启蜂窝移动数据;</p>
<p>3、开启WIFI；</p>
<p>4、关闭勿扰模式;</p>
<p>5、关闭低电量模式;</p>
<p>6、播报天气;</p>
<p>7、播放音乐 （网易云/QQ音乐）</p>
<p>获取链接为：（捷径名称保存后修改为早安即可）</p>
<p>（1）打开网易云音乐<a href="https://www.icloud.com/shortcuts/e058bafd928f4f72ad7862ec2058d019">https://www.icloud.com/shortcuts/e058bafd928f4f72ad7862ec2058d019</a></p>
<p>（2）打开QQ音乐<a href="https://www.icloud.com/shortcuts/24c1ecfc35da419d9780c4a6fa9adf6a">https://www.icloud.com/shortcuts/24c1ecfc35da419d9780c4a6fa9adf6a</a></p>
<p class="has-text-align-center"><strong>一些Tips：</strong></p>
<p>URL中设置<strong>orpheus://download</strong>即为打开网易云音乐下载音乐页面，并自动播放。</p>
<p>当然还有其他链接：</p>
<p>（1）打开网易云热歌榜单并自动播放：</p>
<p><strong>orpheus://playlist/3778678/?autoplay=1</strong></p>
<p>（2）打开网易云飙升榜并自动播放：</p>
<p><strong>orpheus://playlist/19723756/?autoplay=1</strong></p>
<p>当然打开QQ音乐为：</p>
<p>（1）QQ音乐“本地播放”：</p>
<p><strong>qqmusic://today?mid=31&k1=3&k4=0</strong><br></p>
<p>（2）QQ音乐“最近播放”：</p>
<p><strong>qqmusic://today?mid=31&k1=2&k4=0</strong><br></p>
<p>（3）QQ音乐“个性电台”：</p>
<p><strong>qqmusic://qq.com/media/playRadio?p=%7B%22radioId%22%3A%2299%22%7D</strong></p>]]></content>
      <categories>
        <category>折腾记录</category>
      </categories>
      <tags>
        <tag>iOS</tag>
        <tag>捷径</tag>
      </tags>
  </entry>
  <entry>
    <title>Python指南 | 在linux上安装python3.7</title>
    <url>/posts/39201.html</url>
    <content><![CDATA[<p>今天在腾讯云服务器上安装了python3，又学到的知识。</p>
<span id="more"></span>

<h1 id="如何在Linux环境中安装Python3-7-0以上"><a href="#如何在Linux环境中安装Python3-7-0以上" class="headerlink" title="如何在Linux环境中安装Python3.7.0以上"></a>如何在Linux环境中安装Python3.7.0以上</h1><h4 id="1-下载python"><a href="#1-下载python" class="headerlink" title="1.下载python"></a>1.下载python</h4><figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">cd</span> /home</span><br><span class="line"><span class="attribute">wget</span> http://cdn.npm.taobao.org/dist/python/<span class="number">3</span>.<span class="number">7</span>.<span class="number">4</span>/Python-<span class="number">3</span>.<span class="number">7</span>.<span class="number">4</span>.tgz</span><br></pre></td></tr></table></figure>
<ul>
<li>使用了wget软件，从指定URL下载文件</li>
</ul>
<h4 id="2-解压Python安装文件"><a href="#2-解压Python安装文件" class="headerlink" title="2.解压Python安装文件"></a>2.解压Python安装文件</h4><figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">tar</span> -zxvf Python-<span class="number">3</span>.<span class="number">7</span>.<span class="number">4</span>.tgz</span><br></pre></td></tr></table></figure>
<ul>
<li>tar是Linux自带的解压命令</li>
</ul>
<h4 id="3-安装编译Python3-7以上的源文件所需的编译环境"><a href="#3-安装编译Python3-7以上的源文件所需的编译环境" class="headerlink" title="3.安装编译Python3.7以上的源文件所需的编译环境"></a>3.安装编译Python3.7以上的源文件所需的编译环境</h4><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">yum <span class="keyword">install </span>-y gcc</span><br><span class="line">yum <span class="keyword">install </span>-y zlib*</span><br><span class="line">yum -y <span class="keyword">install </span>zlib-devel <span class="keyword">bzip2-devel </span>openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel libffi-devel</span><br></pre></td></tr></table></figure>

<h4 id="4-进入Python3-源文件文件夹"><a href="#4-进入Python3-源文件文件夹" class="headerlink" title="4.进入Python3 源文件文件夹"></a>4.进入Python3 源文件文件夹</h4><figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">cd</span> Python-<span class="number">3</span>.<span class="number">6</span>.<span class="number">5</span>/</span><br></pre></td></tr></table></figure>

<h4 id="5-指定安装目录"><a href="#5-指定安装目录" class="headerlink" title="5.指定安装目录"></a>5.指定安装目录</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">.<span class="regexp">/configure --prefix=/u</span>sr<span class="regexp">/local/</span>python3 --with-ssl</span><br></pre></td></tr></table></figure>
<ul>
<li>不要忘记最前面的“.”</li>
</ul>
<h4 id="6-编译源文件"><a href="#6-编译源文件" class="headerlink" title="6.编译源文件"></a>6.编译源文件</h4><figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">make</span></span><br></pre></td></tr></table></figure>

<h4 id="7-正式安装"><a href="#7-正式安装" class="headerlink" title="7.正式安装"></a>7.正式安装</h4><figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">make <span class="keyword">install</span></span><br></pre></td></tr></table></figure>
<h4 id="8-建立软连接"><a href="#8-建立软连接" class="headerlink" title="8.建立软连接"></a>8.建立软连接</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">ln -s <span class="regexp">/usr/</span>local<span class="regexp">/python3/</span>bin<span class="regexp">/python3 /u</span>sr<span class="regexp">/bin/</span>python3 </span><br><span class="line">ln -s <span class="regexp">/usr/</span>local<span class="regexp">/python3/</span>bin<span class="regexp">/pip3 /u</span>sr<span class="regexp">/bin/</span>pip3 </span><br></pre></td></tr></table></figure>
<ul>
<li>软连接就相当于win下的快捷方式。你可以通过快捷方式打开你想要使用的软件</li>
</ul>
<h4 id="9-安装Python3的XXXXX包。直接在终端使用如下命令即可："><a href="#9-安装Python3的XXXXX包。直接在终端使用如下命令即可：" class="headerlink" title="9.安装Python3的XXXXX包。直接在终端使用如下命令即可："></a>9.安装Python3的XXXXX包。直接在终端使用如下命令即可：</h4><figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">pip3 <span class="keyword">install</span> XXXXX</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>折腾记录</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Github | 解决github头像加载不出来</title>
    <url>/posts/60270.html</url>
    <content><![CDATA[<h2 id="1-查看失效头像链接"><a href="#1-查看失效头像链接" class="headerlink" title="1. 查看失效头像链接"></a>1. 查看失效头像链接</h2><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210209142745.png"></p>
<p>例如，域名可能为<code>avatars.githubusercontent.com</code></p>
<h2 id="2-查找域名对应IP"><a href="#2-查找域名对应IP" class="headerlink" title="2. 查找域名对应IP"></a>2. 查找域名对应IP</h2><p><a href="https://www.ipaddress.com/">https://www.ipaddress.com/</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210209142320.png"></p>
<h2 id="3-解决问题：修改hosts"><a href="#3-解决问题：修改hosts" class="headerlink" title="3. 解决问题：修改hosts"></a>3. 解决问题：修改hosts</h2><p>解决方法，打开路径C:\Windows\System32\drivers\etc下的hosts文件，并在后面添加下列信息，将IP与域名对应即可</p>
<span id="more"></span>

<figure class="highlight accesslog"><table><tr><td class="code"><pre><span class="line"># GitHub Start </span><br><span class="line"><span class="number">140.82.113.3</span>      github.com</span><br><span class="line"><span class="number">140.82.113.4</span>     gist.github.com</span><br><span class="line"></span><br><span class="line"><span class="number">151.101.184.133</span>    assets-cdn.github.com</span><br><span class="line"><span class="number">151.101.184.133</span>    raw.githubusercontent.com</span><br><span class="line"><span class="number">151.101.184.133</span>    gist.githubusercontent.com</span><br><span class="line"><span class="number">151.101.184.133</span>    cloud.githubusercontent.com</span><br><span class="line"><span class="number">151.101.184.133</span>    camo.githubusercontent.com</span><br><span class="line"><span class="number">199.232.96.133</span>     avatars.githubusercontent.com</span><br><span class="line"><span class="number">151.101.184.133</span>    avatars0.githubusercontent.com</span><br><span class="line"><span class="number">199.232.96.133</span>     avatars0.githubusercontent.com</span><br><span class="line"><span class="number">151.101.184.133</span>    avatars1.githubusercontent.com</span><br><span class="line"><span class="number">199.232.96.133</span>     avatars1.githubusercontent.com</span><br><span class="line"><span class="number">151.101.184.133</span>    avatars2.githubusercontent.com</span><br><span class="line"><span class="number">199.232.96.133</span>     avatars2.githubusercontent.com</span><br><span class="line"><span class="number">151.101.184.133</span>    avatars3.githubusercontent.com</span><br><span class="line"><span class="number">199.232.96.133</span>     avatars3.githubusercontent.com</span><br><span class="line"><span class="number">151.101.184.133</span>    avatars4.githubusercontent.com</span><br><span class="line"><span class="number">199.232.96.133</span>     avatars4.githubusercontent.com</span><br><span class="line"><span class="number">151.101.184.133</span>    avatars5.githubusercontent.com</span><br><span class="line"><span class="number">199.232.96.133</span>     avatars5.githubusercontent.com</span><br><span class="line"><span class="number">151.101.184.133</span>    avatars6.githubusercontent.com</span><br><span class="line"><span class="number">199.232.96.133</span>     avatars6.githubusercontent.com</span><br><span class="line"><span class="number">151.101.184.133</span>    avatars7.githubusercontent.com</span><br><span class="line"><span class="number">199.232.96.133</span>     avatars7.githubusercontent.com</span><br><span class="line"><span class="number">151.101.184.133</span>    avatars8.githubusercontent.com</span><br><span class="line"><span class="number">199.232.96.133</span>     avatars8.githubusercontent.com</span><br><span class="line"></span><br><span class="line"># GitHub End</span><br></pre></td></tr></table></figure>

<p>如果受管理权限限制，则新建并复制。</p>
]]></content>
      <categories>
        <category>折腾记录</category>
      </categories>
      <tags>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title>大学课程 | 计算机网络学习笔记</title>
    <url>/posts/28758.html</url>
    <content><![CDATA[<p>大二计算机网络课程笔记</p>
<span id="more"></span>

<h2 id="第一章-概述"><a href="#第一章-概述" class="headerlink" title="第一章 概述"></a>第一章 概述</h2><h3 id="1-1-计算机网络在信息时代中的作用"><a href="#1-1-计算机网络在信息时代中的作用" class="headerlink" title="1.1 计算机网络在信息时代中的作用"></a>1.1 计算机网络在信息时代中的作用</h3><ol>
<li>21世纪的重要特征：数字化，网络化，信息化</li>
<li>21世纪是以网络为核心的信息时代</li>
<li>常见三类网络：电信网络，有线电视网络，计算机网络</li>
<li>Internet 的中文译名：<br>（1）因特网<br>（2）互联网：由数量极大的各种计算机网络互连起来</li>
<li>互联网具有两个重要的特点：<strong>连通性</strong>和<strong>共享</strong><br>（1）连通性：互联网使上网用户之间不管相距多远，都可以非常方便的交换各种信息，好像这些用户中端是直接连通的<br>（2）共享：就是指资源共享，资源包括信息，软件，硬件</li>
<li> 互联网+</li>
</ol>
<h3 id="1-2-互联网概述"><a href="#1-2-互联网概述" class="headerlink" title="1.2 互联网概述"></a>1.2 互联网概述</h3><h4 id="1-2-1-网络的网络"><a href="#1-2-1-网络的网络" class="headerlink" title="1.2.1 网络的网络"></a>1.2.1 网络的网络</h4><p>1.计算机网络：由若干<strong>结点</strong>和连接这些结点的<strong>链路</strong>组成。</p>
<ul>
<li>结点包括：计算机，集线器，交换机，路由器</li>
</ul>
<p>2.<strong>互连网</strong>：网络之间通过路由器互连起来，就构成了一个覆盖范围更大的计算机网络，因此互连网是“网络中的网络”<br>3.网络：网络把许多计算机连接在一起，而互连网则把许多网络通过路由器连接在一起。与网络相连的计算机称为<strong>主机</strong>。<br>4.计算机网络的三种定义：</p>
<ul>
<li>广义观点：实现远程信息处理的系统或能进一步达到资源共享的系统</li>
<li>资源共享观点：以能够相互共享资源的方式互联起来的自治计算机系统的集合</li>
<li>用户透明性观点：存在一个能为用户自动管理资源的网络操作系统，它能够调用用户所需要的资源，而整个网络就像一个大的计算机系统一样对用户是透明的</li>
</ul>
<h4 id="1-2-2-互联基础结构发展的三个阶段"><a href="#1-2-2-互联基础结构发展的三个阶段" class="headerlink" title="1.2.2 互联基础结构发展的三个阶段"></a>1.2.2 互联基础结构发展的三个阶段</h4><p>1.第一阶段：<strong>单个网络ARPANET</strong>向互连网发展的过程</p>
<ul>
<li>互联网的雏形：单个的分组交换网ARPANET</li>
<li>1983年TCP/IP协议成为ARPANET的标准协议</li>
<li>internet（互连网）：泛指由多个计算机网络互连而成的计算机网络</li>
<li>Internet（互联网）：指当前全球最大的，开放的，由众多网络相互连接而成的特定互连网，它采用TCP/IP协议族作为通信的规则，且前身为美国的ARPANET</li>
</ul>
<p>2.第二阶段：<strong>三级结构的互联网</strong></p>
<ul>
<li>三级计算机网络：主干网，地区网，校园网（或企业网）</li>
</ul>
<p>3.第三阶段：形成了<strong>多层次的ISP结构的互联网</strong></p>
<ul>
<li>互联网服务提供者ISP</li>
<li>流程：<br>（1）ISP向互联网管理机构申请很多IP地址，同时拥有通信线路以及路由器等连网设备<br>（2）任何机构和个人只要向某个ISP交纳规定的费用，就可以从该ISP获取所需IP地址的使用权，并可通过该ISP接入到互联网</li>
<li>ISP层次:主干ISP，地区ISP，本地ISP</li>
</ul>
<p>4.<strong>互联网交换点IXP</strong>：</p>
<ul>
<li>作用：<strong>允许两个网络直接相连并交换分组，而不需要再通过第三个网络来转发分组</strong>。</li>
<li>IXP常采用工作在数据链路层的网络交换机，这些网络交换机都用局域网互连起来</li>
</ul>
<p>5.<strong>万维网WWW</strong>：</p>
<blockquote>
<p>万维网（亦作“Web”、“WWW”、“’W3’”，英文全称为“World Wide Web”），是一个由许多互相链接的超文本组成的系统，通过互联网访问。在这个系统中，每个有用的事物，称为一样“资源”；并且由一个全局“统一资源标识符”（URI）标识；这些资源通过超文本传输协议（Hypertext Transfer Protocol）传送给用户，而后者通过点击链接来获得资源。万维网联盟（英语：World Wide Web Consortium，简称W3C），又称W3C理事会。1994年10月在麻省理工学院（MIT）计算机科学实验室成立。万维网联盟的创建者是万维网的发明者蒂姆·伯纳斯-李。<br>                                                                     —百度百科</p>
</blockquote>
<h4 id="1-2-3-互联网的标准化工作"><a href="#1-2-3-互联网的标准化工作" class="headerlink" title="1.2.3 互联网的标准化工作"></a>1.2.3 互联网的标准化工作</h4><ul>
<li>互联网协会（ISOC）<ul>
<li>互联网体系结构委员会IAB<ul>
<li>互联网工程部IETF<ul>
<li>互联网工程指导小组IESG：主要针对协议的开发和标准化</li>
</ul>
</li>
<li>互联网研究部IRTF<ul>
<li>互联网研究指导小组IRSG：（RFC“请求评论”）<ul>
<li>指定互联网标准的三个阶段：<br>  （1）互联网草案<br>  （2）建议标准<br>  （3）互联网标准</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="1-3-互联网的组成"><a href="#1-3-互联网的组成" class="headerlink" title="1.3 互联网的组成"></a>1.3 互联网的组成</h3><ul>
<li>从工作方式上看：<br>（1）边缘部分：用户直接使用的部分（主机）<br>（2）核心部分：为边缘部分提供服务的（连通性和交换）（网络和路由器）</li>
<li>从组成部分来看：<br>（1）硬件<br>（2）软件<br>（3）协议</li>
<li>从功能组成上来看：<br>（1）通信子网（数据传输，交换，控制，存储）<br>（2）资源子网（实现硬件，软件，数据资源共享的设备及其软件的集合）</li>
</ul>
<h4 id="1-3-1-互联网的边缘部分"><a href="#1-3-1-互联网的边缘部分" class="headerlink" title="1.3.1 互联网的边缘部分"></a>1.3.1 互联网的边缘部分</h4><ul>
<li>端系统：处在互联网边缘的部分就是连接在互联网上的所有的主机。这些主机又称为端系统</li>
<li>端系统之间的通信方式：客户-服务器方式(C/S)；对等方式（P2P）</li>
</ul>
<p>1.客户-服务器方式：<br>主机A运行客户程序&lt;————&gt;主机B运行服务器程序</p>
<ul>
<li>A向B发出服务请求，B向A提供服务</li>
<li>客户是服务的请求方，服务器是服务的提供方</li>
<li>对于客户程序：<br>（1）被用户<strong>调用后运行</strong>，在通信时<strong>主动</strong>向远地服务器发起通信，因此客户程序<strong>必须知道服务器程序的地址</strong><br>（2）不需要特殊的硬件和很复杂的操作系统</li>
<li>对于服务器程序：<br>（1）是一种专门来提供某种服务的程序，可<strong>同时处理多个</strong>客户请求<br>（2）系统启动后<strong>自动调用</strong>并不断运行，<strong>被动等待</strong>接受来自各地的客户的请求，因此服务器<strong>不需要知道客户程序的地址</strong><br>（3）一般需要有强大的硬件和高级的操作系统支持</li>
</ul>
<p>2.对等连接方式：P2P</p>
<ul>
<li>P2P方式：只要两台主机都运行了对等连接软件（P2P软件），就能进行平等的，对等连接通信</li>
</ul>
<h4 id="1-3-2-互联网的核心部分"><a href="#1-3-2-互联网的核心部分" class="headerlink" title="1.3.2 互联网的核心部分"></a>1.3.2 互联网的核心部分</h4><ul>
<li>在网络中心起特殊作用的是<strong>路由器</strong>，它是一种专用计算机（但不叫主机）</li>
<li>路由器是实现<strong>分组交换</strong>的关键构件，其任务是<strong>转发收到的分组</strong>，这是网络核心部分最重要的功能</li>
<li>互联网的核心部分是由许多网络和把它们互连起来的路由器组成，而主机处在互联网的边缘部分</li>
<li>互联网核心部分中的路由器之间一般是用高速链路连接，而在网络边缘的主机接入到核心部分则通常以相对较低速率的链路相连接</li>
</ul>
<ol>
<li>电路交换的特点<ul>
<li>N 部电话机两两直接相连，需 N(N – 1)/2 对电线。这种直接连接方法所需要的电线对的数量与电话机数量的平方（ N2 ）成正比。</li>
<li>当电话机的数量增多时，就要使用<strong>交换机</strong>来完成全网的交换任务。</li>
<li><strong>电路交换</strong> (circuit switching)：每一部电话都直接连接到交换机上，而交换机使用交换的方法，让电话用户彼此之间可以很方便地通信。<br><img src="https://s2.ax1x.com/2019/09/03/nFaU7d.png" alt="nFaU7d.png"></li>
<li>交换：按照某种方式动态的分配传输线路的资源</li>
<li>电路交换必定是<strong>面向连接</strong>的</li>
<li>电路交换的三个阶段：<br>（1）<strong>建立连接</strong>：（占用通信资源）<br>（2）<strong>通信</strong>：（一直占用）<br>（3）<strong>释放连接</strong>：（归还通信资源）</li>
<li>在通话的全部时间内，通话的两个用户始终占用端到端的通信资源（利用率低）</li>
<li>计算机数据具有突发性</li>
</ul>
</li>
<li>分组交换的主要特点：<ul>
<li>分组交换网采用<strong>存储转发</strong>技术</li>
<li>分组交换是面向无连接的</li>
<li>Internet网络层是分组交换</li>
<li><strong>报文</strong>：要发送的整块数据</li>
<li>在发送端，先把较长的报文划分成较短的，固定长度的<strong>数据段</strong></li>
<li>在每一个数据段前面添加上<strong>首部</strong>构成<strong>分组</strong>，分组又叫“包”，而分组的首部也可以称为“包头”</li>
<li>主机是为用户进行信息处理的；路由器则是用来转发分组的，即进行分组交换</li>
<li>分组是在互联网中传送的<strong>数据单元</strong>。依次把各分组发送到接收端</li>
<li>分组的首部包含了目的地址，源地址等重要控制信息。</li>
<li>分组交换网中的结点交换机根据收到的分组首部的地址信息，把分组转发到下一个结点交换机</li>
<li>每一个分组在互联网中独立地选择传输路径</li>
<li>接收端收到分组后剥去首部还原成报文</li>
<li>路由器处理分组的过程：<br>（1）把收到的<strong>分组先放入缓存</strong>（暂时存储）；<br>（2）<strong>查找转发表</strong>，找出到某个目的地址应从哪个端口转发；<br>（3）把分组送到适当的<strong>端口转发</strong>出去。 </li>
</ul>
</li>
</ol>
<table>
<thead>
<tr>
<th>优点</th>
<th>所采用的手段</th>
</tr>
</thead>
<tbody><tr>
<td>高效</td>
<td>在分组传输过程中动态分配传输带宽，对通信链路是逐段占用</td>
</tr>
<tr>
<td>灵活</td>
<td>为每一个分组独立地选择最合适的转发路由</td>
</tr>
<tr>
<td>迅速</td>
<td>以分组作为传送单位，可以不先建立连接就能向其他主机发送分组</td>
</tr>
<tr>
<td>可靠</td>
<td>保证可靠性的网络协议；分布式多路由的分组交换网，使网络有很好的生存性</td>
</tr>
</tbody></table>
<ul>
<li>分组交换带来的问题：<br>（1）分组在各结点存储转发时需要<strong>排队</strong>，这就会造成一定的<strong>时延</strong>。<br>（2）分组必须携带的首部（里面有必不可少的控制信息）也造成了一定的<strong>开销</strong>。 </li>
</ul>
<ol start="3">
<li>三种交换的比较：<br><img src="https://s2.ax1x.com/2019/09/03/nFaTjU.png" alt="nFaTjU.png"></li>
</ol>
<ul>
<li>电路交换：整个报文的比特流连续地从源点直达终点，好像在一个管道中传送（面向连接）</li>
<li>报文交换：整个报文先传送到相邻结点，全部存储下来后查询转发表，转发到下一个结点。（面向无连接）</li>
<li>分组交换：单个分组传送到相邻结点，存储下来后查找转发表，转发到下一个结点（面向无连接）</li>
</ul>
<h3 id="1-4-计算机网络在我国的发展"><a href="#1-4-计算机网络在我国的发展" class="headerlink" title="1.4 计算机网络在我国的发展"></a>1.4 计算机网络在我国的发展</h3><ul>
<li>规模最大的就是下面这五个：<br>(1) 中国电信互联网 CHINANET（也就是原来的中国公用计算机互联网）<br>(2) 中国联通互联网 UNINET<br>(3) 中国移动互联网 CMNET<br>(4) 中国教育和科研计算机网 CERNET<br>(5) 中国科学技术网 CSTNET</li>
</ul>
<h3 id="1-5-计算机网络的类别"><a href="#1-5-计算机网络的类别" class="headerlink" title="1.5 计算机网络的类别"></a>1.5 计算机网络的类别</h3><h4 id="1-5-1-计算机网络的定义"><a href="#1-5-1-计算机网络的定义" class="headerlink" title="1.5.1 计算机网络的定义"></a>1.5.1 计算机网络的定义</h4><ul>
<li>定义：<u>计算机网络主要是由一些<strong>通用的、可编程的硬件</strong>互连而成的，而这些硬件并非专门用来实现某一特定目的（例如，传送数据或视频信号）。这些<strong>可编程的硬件</strong>能够用来传送多种不同类型的数据，并能支持广泛的和日益增长的应用。</u></li>
<li>根据定义：<br>(1) 计算机网络所连接的硬件，并不限于一般的计算机，而是包括了智能手机。<br>(2) 计算机网络并非专门用来传送数据，而是能够支持很多种的应用（包括今后可能出现的各种应用）</li>
<li>可编程的硬件表明<u>这种硬件一定包含有中央处理机CPU</u></li>
</ul>
<h4 id="1-5-2-计算机网络的类别"><a href="#1-5-2-计算机网络的类别" class="headerlink" title="1.5.2 计算机网络的类别"></a>1.5.2 计算机网络的类别</h4><ol>
<li>按照网络的作用范围进行分类：<br>（1）广域网WAN<br>（2）城域网MAN<br>（3）局域网LAN<br>（4）个人区域网PAN<ul>
<li>无线个人区域网WPAN</li>
</ul>
</li>
</ol>
<ul>
<li>若中央处理机之间的距离非常近（如仅1米的数量级甚至更小些），则一般就称之为<strong>多处理机系统</strong>，而不称它为计算机网络。 </li>
</ul>
<ol start="2">
<li>按照网络使用者分类：<br>（1）公用网<br>（2）专用网</li>
<li>用来把用户接入到互联网的网络</li>
</ol>
<ul>
<li>接入网AN，它又称为本地接入网或居民接入网</li>
<li>接入网是一类比较特殊计算机网络，用于讲用户接入互联网</li>
<li><u>接入网本身既不属于互联网的核心部分，也不属于互联网的边缘部分。</u></li>
<li>接入网是从某个<strong>用户端系统</strong>到<strong>互联网</strong>中的<strong>第一个路由器</strong>（也称为<strong>边缘路由器</strong>）<strong>之间</strong>的一种网络。</li>
</ul>
<h3 id="1-6-计算机网络的性能"><a href="#1-6-计算机网络的性能" class="headerlink" title="1.6 计算机网络的性能"></a>1.6 计算机网络的性能</h3><h4 id="1-6-1-计算机网络的性能指标"><a href="#1-6-1-计算机网络的性能指标" class="headerlink" title="1.6.1 计算机网络的性能指标"></a>1.6.1 计算机网络的性能指标</h4><ol>
<li><strong>速率</strong>：</li>
</ol>
<ul>
<li><strong>比特</strong>（bit）是计算机中数据量的单位，也是信息论中使用的信息量的单位。</li>
<li>速率是计算机网络中最重要的一个性能指标，指的是<strong>数据的传送速率</strong>，它也称为<strong>数据率</strong> (data rate)或<strong>比特率</strong> (bit rate)。</li>
<li>速率的单位是 bit/s，或 kbit/s、Mbit/s、 Gbit/s 等。例如 4 × 10^10 bit/s 的数据率就记为 40 Gbit/s。</li>
<li><strong>速率往往是指额定速率或标称速率，非实际运行速率</strong>。</li>
</ul>
<ol start="2">
<li><strong>带宽</strong>：</li>
</ol>
<ul>
<li>两种不同意义：<br>（1）“带宽”(bandwidth) 本来是指信号具有的频带宽度，其单位是赫（或千赫、兆赫、吉赫等）。（频域）<br>（2）在计算机网络中，带宽用来表示网络中某<strong>通道</strong>传送数据的能力。表示在单位时间内网络中的某信道所能通过的“<strong>最高数据率</strong>”。单位是 bit/s ，即 “比特每秒”（时域）</li>
</ul>
<ol start="3">
<li><strong>吞吐量</strong>：</li>
</ol>
<ul>
<li>吞吐量 (throughput) 表示在<strong>单位时间</strong>内通过某个网络（或信道、接口）的<strong>数据量</strong>。</li>
<li>吞吐量更经常地用于对现实世界中的网络的一种测量，以便知道<strong>实际上</strong>到底有多少数据量能够通过网络。</li>
<li>吞吐量受网络的带宽或网络的额定速率的限制。  </li>
</ul>
<ol start="4">
<li><strong>时延</strong>：</li>
</ol>
<ul>
<li>时延是指数据（一个报文或分组，甚至比特）从网络（或链路）的<strong>一端传送到另一端</strong>所需的时间。</li>
<li>有时也称为延迟或迟延。</li>
<li>网络中的时延由以下几个不同的部分组成：<br>(1) 发送时延（传输时延）：指主机或路由器发送数据帧所需要的时间<br><img src="https://s2.ax1x.com/2019/09/03/nFdpjO.png" alt="nFdpjO.png"><br>(2) 传播时延：是电磁波在信道中传播一定的距离需要花费的时间<br><img src="https://s2.ax1x.com/2019/09/03/nFdCuD.png" alt="nFdCuD.png"></li>
</ul>
<p><strong>发送时延发送在机器内部的发送器中，与传输信道的长度无关</strong>，<strong>传播时延发生在机器外部的传输信道媒体上</strong>，与信号的发送速率无关。<strong>信号传送的距离越远，传播时延就越大</strong><br>(3) 处理时延</p>
<ul>
<li>主机或路由器在<strong>收到分组时</strong>，为处理分组（例如分析首部、提取数据、差错检验或查找路由）所花费的时间。<br>(4) 排队时延</li>
<li>分组在路由器输入输出队列中排队<strong>等待处理所经历的时延</strong>。</li>
<li>排队时延的长短往往取决于网络中当时的通信量。</li>
</ul>
<p>总时延 = 发送时延+传播时延+处理时延+排队时延</p>
<ul>
<li>对于<strong>高速网络链路</strong>，我们提高的仅仅是数据的<strong>发送速率</strong>而不是比特在链路上的传播速率。 </li>
<li>提高链路<strong>带宽</strong>减小了数据的<strong>发送时延</strong>。</li>
</ul>
<ol start="5">
<li>时延带宽积：</li>
</ol>
<ul>
<li>链路的时延带宽积又称为以比特为单位的链路长度。<br><img src="https://s2.ax1x.com/2019/09/03/nFweo9.png" alt="nFweo9.png"></li>
<li>只有在代表链路的管道都充满比特时，<br>链路才得到了充分利用。</li>
</ul>
<ol start="6">
<li>往返时间RTT：</li>
</ol>
<ul>
<li>互联网上的信息不仅仅单方向传输，而是双向交互的。因此，有时很需要知道双向交互一次所需的时间。</li>
<li><u>往返时间表示从发送方发送数据开始，到发送方收到来自接收方的确认，总共经历的时间</u>。</li>
<li>在互联网中，往返时间还包括各中间结点的处理时延、排队时延以及转发数据时的发送时延。</li>
<li>发送时间=数据长度/发送速率</li>
<li>有效数据率=数据长度/（发送时间+RTT）</li>
</ul>
<ol start="7">
<li>利用率：</li>
</ol>
<ul>
<li>利用率分为<strong>信道利用率</strong>和<strong>网络利用率</strong></li>
<li>信道利用率<strong>不是</strong>越高越好，根据排队论的理论，当某信道的<strong>利用率增大</strong>时，该信道引起的<strong>时延也就迅速增加</strong>。 </li>
<li>若令 D0 表示网络空闲时的时延，D 表示网络当前的时延，则在适当的假定条件下，可以用下面的简单公式表示 D 和 D0之间的关系：<br><img src="https://s2.ax1x.com/2019/09/03/nFwJdH.png" alt="nFwJdH.png"></li>
<li>信道或网络利用率过高会产生非常大的时延</li>
</ul>
<h4 id="1-6-2-计算机网络的非性能指标"><a href="#1-6-2-计算机网络的非性能指标" class="headerlink" title="1.6.2 计算机网络的非性能指标"></a>1.6.2 计算机网络的非性能指标</h4><ol>
<li>费用</li>
<li>质量</li>
<li>标准化</li>
<li>可靠性</li>
<li>可扩展性和可升级性</li>
<li>易于管理和维护</li>
</ol>
<h3 id="1-7-计算机网络体系结构"><a href="#1-7-计算机网络体系结构" class="headerlink" title="1.7 计算机网络体系结构"></a>1.7 计算机网络体系结构</h3><h4 id="1-7-1-计算机网络体系结构的形成"><a href="#1-7-1-计算机网络体系结构的形成" class="headerlink" title="1.7.1 计算机网络体系结构的形成"></a>1.7.1 计算机网络体系结构的形成</h4><ul>
<li>计算机网络是个非常复杂的系统。</li>
<li>相互通信的两个计算机系统必须<strong>高度协调工作</strong>才行，而这种“协调”是相当复杂的。 </li>
<li>“分层”可将庞大而复杂的问题，转化为若干较小的局部问题，而这些较小的局部问题就比较易于研究和处理。 </li>
<li>1974 年，美国的 IBM 公司宣布了<strong>系统网络体系结构SNA</strong> (System Network Architecture)。这个著名的网络标准就是按照<strong>分层</strong>的方法制定的。</li>
<li>由于<u>网络体系结构的不同，不同公司的设备很难互相连通</u>。</li>
<li>为了使不同体系结构的计算机网络都能互连，国际标准化组织 ISO 于 1977 年成立了专门机构研究该问题。他们提出了一个试图<u>使各种计算机在世界范围内互连成网的标准框架</u>，即<strong>著名的开放系统互连基本参考模型 OSI/RM</strong> (Open Systems Interconnection Reference Model)，简称为<strong>OSI</strong>。</li>
<li><u>只要遵循 OSI 标准，一个系统就可以和位于世界上任何地方的、也遵循这同一标准的其他任何系统进行通信。</u></li>
<li>开放是指非独家垄断，系统是指在现实的系统中与互连有关的各部分</li>
<li>OSI 只获得了一些理论研究的成果，在市场化方面却失败了</li>
<li><strong>法律上的国际标准 OSI</strong> 并没有得到市场的认可。非国际标准 TCP/IP 却获得了最广泛的应用。<strong>TCP/IP</strong> 常被称为<strong>事实上的国际标准</strong>。</li>
</ul>
<h4 id="1-7-2-协议与划分层次"><a href="#1-7-2-协议与划分层次" class="headerlink" title="1.7.2 协议与划分层次"></a>1.7.2 协议与划分层次</h4><ul>
<li>计算机网络中的数据交换必须遵守事先约定好的规则。 <strong>这些规则明确规定了所交换的数据的格式以及有关的同步问题</strong>（<strong>同步含有时序</strong>的意思）。</li>
<li><strong>网络协议</strong> (network protocol)，简称为协议，是<strong>为进行网络中的数据交换而建立的规则、标准或约定</strong>。 </li>
<li>协议主要由以下三个要素组成：<br>（1）语法：数据与控制信息的结构或格式<br>（2）语义：需要发出何种控制信息，完成何种动作以及做出何种响应<br>（3）同步：事件实现顺序的详细说明</li>
<li>协议的两种形式：<br>（1）一种是使用便于人来阅读和理解的<strong>文字描述</strong>。<br>（2）另一种是使用让计算机能够理解的<strong>程序代码</strong>。<ul>
<li>这两种不同形式的协议都必须能够对网络上信息交换过程做出精确的解释。</li>
</ul>
</li>
<li>分层的好处：<br>（1）各层之间是独立的。<br>（2）灵活性好。<br>（3）结构上可分割开。<br>（4）易于实现和维护。<br>（5）能促进标准化工作<br>缺点：<br>（1）降低效率。<br>（2）有些功能会在不同的层次中重复出现，因而产生了额外开销。</li>
<li>通常各层要完成的功能：<br>（1）差错控制<br>（2）流量控制<br>（3）分段和重装<br>（4）复用和分用<br>（5）连接建立和释放</li>
<li>计算机网络的<strong>体系结构</strong> (architecture) 是<strong>计算机网络的各层及其协议的集合</strong>。 </li>
<li>体系结构就是这个计算机网络及其部件所应完成的功能的精确定义。</li>
<li><strong>实现</strong> (implementation) 是遵循这种体系结构的前提下用何种硬件或软件完成这些功能的问题。</li>
<li><strong>体系结构</strong>是<strong>抽象</strong>的，而<strong>实现</strong>则是<strong>具体</strong>的，是真正在运行的计算机硬件和软件。   </li>
</ul>
<h4 id="1-7-3-具有五层协议的体系结构"><a href="#1-7-3-具有五层协议的体系结构" class="headerlink" title="1.7.3 具有五层协议的体系结构"></a>1.7.3 具有五层协议的体系结构</h4><p><img src="https://s2.ax1x.com/2019/09/03/nFwNFA.png" alt="nFwNFA.png"></p>
<ol>
<li>应用层：</li>
</ol>
<ul>
<li>通过应用进程间的交互来完成特定网络应用</li>
<li>应用层协议定义的是应用程序间通信和交互的规则</li>
<li>例如：域名系统DNS，支持万维网应用的HTTP协议，支持电子邮件的SMTP协议</li>
<li>我们把应用层交互的数据单元称为报文</li>
</ul>
<ol start="2">
<li>运输层：</li>
</ol>
<ul>
<li>负责向两台主机中进程之间的通信提供通用的数据传输服务</li>
<li>两种主要协议：<ul>
<li><strong>传输控制协议TCP</strong>：<strong>面向连接</strong>，其数据传输的单位是<strong>报文段</strong></li>
<li><strong>用户数据报协议UDP</strong>：<strong>面向无连接</strong>，尽最大努力，数据传输的单位是<strong>用户数据报</strong></li>
</ul>
</li>
</ul>
<ol start="3">
<li>网络层：</li>
</ol>
<ul>
<li>负责为分组交换网上的不同主机提供通信服务</li>
<li>在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组或包进行传输</li>
<li>在TCP/IP协议中，分组称为IP数据报</li>
<li>互联网是由大量异构网络通过路由器相互连接起来的。</li>
<li>互联网使用的网络层协议是无连接的网络协议IP和许多种路由选择协议</li>
</ul>
<ol start="4">
<li>数据链路层</li>
</ol>
<ul>
<li>数据链路层将网络层交下来的IP数据报<strong>组装成帧</strong>，在两个相邻结点间的链路上传送帧。每一帧包括<strong>数据</strong>和必要的<strong>控制信息</strong></li>
<li>控制信息可以使接受端能检测到所接收的帧有无差错，有则丢弃。</li>
</ul>
<ol start="5">
<li>物理层</li>
</ol>
<ul>
<li><p>在物理层上所传输的数据的单位是比特。<br><img src="https://s2.ax1x.com/2019/09/03/nFw0Qf.png" alt="nFw0Qf.png"></p>
</li>
<li><p>PDU (Protocol Data Unit)：协议数据单元。<br>OSI 参考模型把对等层次之间传送的数据单位称为该层的协议数据单元 PDU。</p>
</li>
<li><p>任何两个同样的层次把数据（即数据单元加上控制信息）通过水平虚线直接传递给对方。这就是所谓的“对等层”(peer layers)之间的通信。</p>
</li>
<li><p>各层协议实际上就是在各个对等层之间传递数据时的各项规定。</p>
</li>
</ul>
<h4 id="1-7-4-实体，协议，服务和服务访问点"><a href="#1-7-4-实体，协议，服务和服务访问点" class="headerlink" title="1.7.4 实体，协议，服务和服务访问点"></a>1.7.4 实体，协议，服务和服务访问点</h4><ul>
<li><strong>实体</strong> (entity) 表示<strong>任何可发送或接收信息的硬件或软件进程</strong>。 </li>
<li><strong>协议</strong>是<strong>控制两个对等实体进行通信的规则的集合</strong>。 </li>
<li>在协议的控制下，两个对等实体间的通信使得本层能够向上一层提供服务。</li>
<li>要实现本层协议，还需要使用下层所提供的服务。 </li>
<li>协议的实现保证了能够向上一层提供服务。</li>
<li>本层的服务用户只能看见服务而无法看见下面的协议。即下面的协议对上面的服务用户是透明的。 </li>
<li>协议是“水平的”，即协议是控制对等实体之间通信的规则。</li>
<li>服务是“垂直的”，即服务是由下层向上层通过层间接口提供的。</li>
<li>上层使用服务原语获得下层所提供的服务。</li>
<li>同一系统相邻两层的实体进行交互的地方，称为<strong>服务访问点 SAP</strong> (Service Access Point)。 </li>
<li>服务访问点SAP是一个抽象的概念，它实际上就是一个逻辑接口。</li>
<li>OSI把层与层之间交换的数据的单位称为服务数据单元 SDU (Service Data Unit)。</li>
<li>SDU 可以与 PDU 不一样，例如，可以是多个 SDU 合成为一个 PDU，也可以是一个 SDU 划分为几个 PDU。</li>
<li>协议必须把<strong>所有</strong>不利的条件<strong>事先都估计</strong>到，而<u>不能假定一切都是正常的和非常理想的</u>。 </li>
<li>看一个计算机网络协议是否正确，不能光看在正常情况下是否正确，还必须非常仔细地检查这个<strong>协议能否应付各种异常情况</strong>。 </li>
</ul>
<h4 id="1-7-5-TCP-IP的体系结构"><a href="#1-7-5-TCP-IP的体系结构" class="headerlink" title="1.7.5 TCP/IP的体系结构"></a>1.7.5 TCP/IP的体系结构</h4><ul>
<li><img src="https://s2.ax1x.com/2019/09/03/nFwfS0.png" alt="nFwfS0.png"></li>
<li>另一种表示方法：<br><img src="https://s2.ax1x.com/2019/09/03/nFw4yT.png" alt="nFw4yT.png"></li>
<li>还有一种表示方法：<br><img src="https://s2.ax1x.com/2019/09/03/nFwTw4.png" alt="nFwTw4.png"></li>
<li>TCP/IP协议可以为各式各样的应用提供服务，允许IP协议在各式各样的网络构成的互联网上运行。</li>
</ul>
<h2 id="第二章-物理层"><a href="#第二章-物理层" class="headerlink" title="第二章 物理层"></a>第二章 物理层</h2><h3 id="2-1-物理层的基本概念"><a href="#2-1-物理层的基本概念" class="headerlink" title="2.1 物理层的基本概念"></a>2.1 物理层的基本概念</h3><ol>
<li>物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体。</li>
<li>物理层的作用是要尽可能地屏蔽掉不同传输媒体和通信手段的差异。<br>用于物理层的协议也常称为物理层规程 (procedure)。</li>
<li>物理层的主要任务描述为确定与传输媒体的接口有关的一些特性：<br>（1）机械特性：指明接口所用接线器的形状和尺寸、引线数目和排列、固定和锁定装置等。<br>（2）电气特性：指明在接口电缆的各条线上出现的电压的范围。<br>（3）功能特性：指明某条线上出现的某一电平的电压表示何种意义。<br>（4）过程特性：指明对于不同功能的各种可能事件的出现顺序。 </li>
<li>数据在计算机内部多采用并行传输方式，但在<u>通信线路的传输方式</u>一般都是<strong>串行传输</strong></li>
</ol>
<h3 id="2-2-数据通信的基础知识"><a href="#2-2-数据通信的基础知识" class="headerlink" title="2.2 数据通信的基础知识"></a>2.2 数据通信的基础知识</h3><h4 id="2-2-1-数据通信系统的模型"><a href="#2-2-1-数据通信系统的模型" class="headerlink" title="2.2.1 数据通信系统的模型"></a>2.2.1 数据通信系统的模型</h4><ol>
<li>一个数据通信系统可以分为三个部分：<br>（1）<strong>源系统</strong>（发送端，发送方）<br>（2）<strong>传输系统</strong>（传输网络）<br>（3）<strong>目的系统</strong>（接收端，接受方）</li>
<li>源系统包括：</li>
</ol>
<ul>
<li>源点</li>
<li>发送器</li>
<li>接收器</li>
<li>终点</li>
</ul>
<ol start="3">
<li>常用术语：</li>
</ol>
<ul>
<li>通信的目的是传送<strong>消息</strong>.</li>
<li><strong>数据</strong>是运送消息的实体</li>
<li><strong>信号</strong>则是数据的电气或电磁的表现<ul>
<li>模拟信号（<strong>连续信号</strong>）：消息的参数的取值是连续的</li>
<li>数字信号（<strong>离散信号</strong>）：消息的参数的取值是离散的</li>
</ul>
</li>
</ul>
<h4 id="2-2-2-有关信道的几个基本概念"><a href="#2-2-2-有关信道的几个基本概念" class="headerlink" title="2.2.2 有关信道的几个基本概念"></a>2.2.2 有关信道的几个基本概念</h4><ol>
<li>信道：一般用来表示向<u>某一个方向</u>传送信息的媒体。</li>
</ol>
<ul>
<li>单向通信（单工通信）：只能有一个方向的通信而没有反方向的交互</li>
<li>双向交替通信（半双工通信）：通信的双方都可以发送信息，当不能双方同时发送与接收</li>
<li>双向同时通信（全双工通信）：通信的双方可以同时发送和接收信息</li>
</ul>
<ol start="2">
<li><strong>基带信号</strong>：来自信源的信号。、</li>
<li><strong>调制</strong>：为了解决许多信道不能传输这种低频分量或直流分量</li>
</ol>
<ul>
<li><strong>基带调制</strong>：仅对基带信号的波形进行变换，使它能够与信道特性相适应。<strong>变换后的信号仍然是基带信号</strong>。把这种过程称为<strong>编码</strong> (coding)。</li>
<li><strong>带通调制</strong>：使用<strong>载波</strong> (carrier)进行调制，把基带信号的频率范围搬移到较高的频段，并<strong>转换为模拟信号</strong>，这样就能够更好地在模拟信道中传输（即仅在一段频率范围内能够通过信道） 。</li>
<li>带通信号 ：经过载波调制后的信号。</li>
</ul>
<ol start="4">
<li>常用编码方式：<br>（1）<strong>不归零制</strong>：正电平代表 1，负电平代表 0。<br>（2）<strong>归零制</strong>：正脉冲代表 1，负脉冲代表 0。<br>（3）<strong>曼彻斯特编码</strong>：位周期中心的向上跳变代表 0，位周期中心的向下跳变代表 1。但也可反过来定义。<br>（4）<strong>差分曼彻斯特编码</strong>：在每一位的中心处始终都有跳变。位开始边界有跳变代表 0，而位开始边界没有跳变代表 1。<br><a href="https://imgchr.com/i/nFwbk9"><img src="https://s2.ax1x.com/2019/09/03/nFwbk9.png" alt="nFwbk9.png"></a><blockquote>
<ul>
<li>从信号波形中可以看出，曼彻斯特 (Manchester) 编码和差分曼彻斯特编码产生的信号频率比不归零制高。</li>
<li>从自同步能力来看，不归零制不能从信号波形本身中提取信号时钟频率（这叫作没有自同步能力），<u>而曼彻斯特编码和差分曼彻斯特编码具有<strong>自同步能力</strong></u>。</li>
</ul>
</blockquote>
</li>
</ol>
<ol start="5">
<li>基本的带通调制方法<br>（1）基带信号往往包含有较多的低频成分，甚至有直流成分，而许多信道并不能传输这种低频分量或直流分量。为了解决这一问题，就必须对基带信号进行<strong>调制</strong> (modulation)。<br>（2）最基本的二元制调制方法有以下几种：</li>
</ol>
<ul>
<li><strong>调幅</strong>(AM)：载波的振幅随基带数字信号而变化。 </li>
<li><strong>调频</strong>(FM)：载波的频率随基带数字信号而变化。</li>
<li><strong>调相</strong>(PM) ：载波的初始相位随基带数字信号而变化<br>（3）正交振幅调制QAM</li>
</ul>
<h4 id="2-3-信道的极限容量"><a href="#2-3-信道的极限容量" class="headerlink" title="2.3 信道的极限容量"></a>2.3 信道的极限容量</h4><ol>
<li>码元传输的速率越高，或信号传输的距离越远，或传输媒体质量越差，在信道的输出端的波形的失真就越严重。 </li>
<li>限制码元在信道上的传输速率的因素：<br>（1）信道能通过的频率范围：<br>码间串扰，奈式准则<br><u>在任何信道种，码元传输的速率是有上限的，传输速率超过此上限，就会出现严重的码间串扰的问题，使接收端对码元的判决（识别）成为不可能</u><br>（2）信噪比<br>信噪比 = 信号的平均功率/噪声的平均功率<br>常记为 S/N，并用分贝 (dB) 作为度量单位。即：<br>&nbsp;&nbsp;信噪比(dB) = 10 log10(S/N)    (dB) <blockquote>
<p>例如，当 S/N = 10 时，信噪比为 10 dB，而当 S/N = 1000时，信噪比为 30 dB。  </p>
</blockquote>
</li>
</ol>
<ul>
<li>1984年，香农 (Shannon) 用信息论的理论推导出了带宽受限且有高斯白噪声干扰的信道的<strong>极限、无差错的</strong>信息传输速率（<strong>香农公式</strong>）。<br>信道的极限信息传输速率 C 可表达为：<figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">C = W lo<span class="name">g2</span><span class="comment">(1+S/N)</span>    <span class="comment">(bit/s)</span> </span><br></pre></td></tr></table></figure></li>
<li>其中：    W 为信道的带宽（以 Hz 为单位）；<pre><code>  S 为信道内所传信号的平均功率；
  N 为信道内部的高斯噪声功率。  
</code></pre>
</li>
<li>信道的带宽或信道中的信噪比越大，则信息的极限传输速率就越高。 </li>
<li><strong>只要信息传输速率低于信道的极限信息传输速率，就一定可以找到某种办法来实现无差错的传输</strong>。 </li>
<li>若信道带宽 W 或信噪比 S/N 没有上限（当然实际信道不可能是这样的），则信道的极限信息传输速率 C 也就没有上限。</li>
<li>实际信道上能够达到的信息传输速率要比香农的极限传输速率低不少。  </li>
<li>对于频带宽度已确定的信道，如果信噪比不能再提高了，并且码元传输速率也达到了上限值，那么还有办法<strong>提高信息的传输速率</strong>。</li>
<li>这就是：<strong>用编码的方法让每一个码元携带更多比特的信息量</strong>。 </li>
</ul>
<h3 id="2-3-物理层下面的传输媒体"><a href="#2-3-物理层下面的传输媒体" class="headerlink" title="2.3 物理层下面的传输媒体"></a>2.3 物理层下面的传输媒体</h3><ul>
<li><strong>传输媒体</strong>也称为<u>传输介质或传输媒介</u>，它就是<u>数据传输系统中在发送器和接收器之间的物理通路</u>。</li>
<li>传输媒体可分为两大类，即<strong>导引型传输媒体</strong>和<strong>非导引型传输媒体</strong>。</li>
<li>在导引型传输媒体中，电磁波被导引沿着固体媒体（铜线或光纤）传播。</li>
<li>非导引型传输媒体就是指自由空间。在非导引型传输媒体中，电磁波的传输常称为无线传输。</li>
</ul>
<h4 id="2-3-1-导引型传输媒体"><a href="#2-3-1-导引型传输媒体" class="headerlink" title="2.3.1 导引型传输媒体"></a>2.3.1 导引型传输媒体</h4><ol>
<li>双绞线：</li>
</ol>
<ul>
<li>最常用的传输媒体。</li>
<li>模拟传输和数字传输都可以使用双绞线，其通信距离一般为几到十几公里。</li>
<li><strong>屏蔽双绞线</strong> STP (Shielded Twisted Pair)<br>带金属屏蔽层</li>
<li><strong>无屏蔽双绞线</strong> UTP (Unshielded Twisted Pair) </li>
</ul>
<blockquote>
<p>室内传送数据的无屏蔽双绞线和屏蔽双绞线的标准 EIA/TIA-568。<br>布线标准更新为 EIA/TIA-568-A。<br>此标准规定了 5 个种类的 UTP 标准（从 1 类线到 5 类线）。<br><strong>对传送数据来说，现在最常用的 UTP 是5类线</strong>（Category 5 或 CAT5）。</p>
</blockquote>
<ol start="2">
<li>同轴电缆：</li>
</ol>
<ul>
<li>同轴电缆具有很好的抗干扰特性，被广泛用于传输较高速率的数据。</li>
<li>同轴电缆的带宽取决于电缆的质量。</li>
<li>50 Ω 同轴电缆 —— LAN / 数字传输常用</li>
<li>75 Ω 同轴电缆 —— 有线电视 / 模拟传输常用</li>
</ul>
<ol start="3">
<li>光缆：</li>
</ol>
<ul>
<li>光纤是光纤通信的传输媒体。</li>
<li>由于可见光的频率非常高，约为 108 MHz 的量级，因此一个<u>光纤通信系统的传输带宽远远大于目前其他各种传输媒体的带宽</u>。</li>
<li>多模光纤</li>
<li>单模光纤</li>
<li>光线通信的优点：<br>(1) 通信容量非常大。<br>(2) 传输损耗小，中继距离长。<br>(2) 抗雷电和电磁干扰性能好。<br>(3) 无串音干扰，保密性好。<br>(4) 体积小，重量轻。</li>
</ul>
<h4 id="2-3-2-非引导型传输媒体"><a href="#2-3-2-非引导型传输媒体" class="headerlink" title="2.3.2 非引导型传输媒体"></a>2.3.2 非引导型传输媒体</h4><ul>
<li>将自由空间称为“非导引型传输媒体”。</li>
<li>无线传输所使用的频段很广。紫外线和更高的波段目前还不能用于通信</li>
<li><strong>短波通信</strong>（即高频通信）主要是靠电离层的反射，但短波信道的通信质量较差，传输速率低。</li>
<li><strong>微波</strong>在空间主要是直线传播。</li>
<li>传统微波通信有两种方式： <ul>
<li>地面微波接力通信</li>
<li>卫星通信  ：通信距离远，传播时延大</li>
</ul>
</li>
</ul>
<h3 id="2-4-信道复用技术"><a href="#2-4-信道复用技术" class="headerlink" title="2.4 信道复用技术"></a>2.4 信道复用技术</h3><h4 id="2-4-1-频分复用，时分复用和统计时分复用"><a href="#2-4-1-频分复用，时分复用和统计时分复用" class="headerlink" title="2.4.1 频分复用，时分复用和统计时分复用"></a>2.4.1 频分复用，时分复用和统计时分复用</h4><ul>
<li><p><strong>复用</strong> (multiplexing) 是通信技术中的基本概念。它允许用户使用一个<u>共享信道</u>进行通信，降低成本，提高利用率。</p>
</li>
<li><p><strong>频分复用</strong>FDM：<strong>频分复用的所有用户在同样的时间占用不同的带宽资源</strong>（请注意，这里的“带宽”是频率带宽而不是数据的发送速率）。 </p>
</li>
<li><p><strong>时分复用</strong>：</p>
<ul>
<li>时分复用则是将时间划分为一段段等长的时分复用帧（TDM 帧）。每一个时分复用的用户在每一个 TDM 帧中占用固定序号的时隙。</li>
<li>每一个用户所占用的时隙是周期性地出现（其周期就是 TDM  帧的长度）。</li>
<li>TDM 信号也称为<strong>等时</strong>(isochronous)信号。</li>
<li><strong>时分复用的所有用户是在不同的时间占用同样的频带宽度</strong>。</li>
<li>使用时分复用系统传送计算机数据时，由于计算机数据的突发性质，用户对分配到的子信道的利用率一般是不高的。</li>
</ul>
</li>
<li><p>在进行通信时，复用器和分用器成对的使用</p>
</li>
<li><p><strong>统计时分复用</strong>STDM：（异步时分复用）<br>STDM 帧不是固定分配时隙，而是按需动态地分配时隙。因此统计时分复用可以提高线路的利用率。</p>
</li>
<li><p><strong>波分复用</strong>WDM：波分复用就是光的频分复用。使用一根光纤来同时传输多个光载波信号。</p>
</li>
<li><p><strong>码分复用</strong>CDM：</p>
<ul>
<li>常用的名词是<strong>码分多址</strong> CDMA<br>(Code Division Multiple Access)。</li>
<li>各用户使用经过特殊挑选的不同码型，因此彼此不会造成干扰。</li>
<li>这种系统发送的信号有很强的抗干扰能力，其频谱类似于白噪声，不易被敌人发现。 </li>
<li>每一个比特时间划分为 m 个短的间隔，称为<strong>码片</strong> (chip)。</li>
<li>每个站被指派一个唯一的 m bit 码片序列。<ul>
<li>如发送比特 1，则发送自己的 m bit 码片序列。</li>
<li>如发送比特 0，则发送该码片序列的二进制反码。 </li>
</ul>
</li>
<li>例如，S 站的 8 bit 码片序列是 00011011。<ul>
<li>发送比特 1 时，就发送序列 00011011，</li>
<li>发送比特 0 时，就发送序列 11100100。</li>
</ul>
</li>
<li>S 站的码片序列：(–1 –1 –1 +1 +1 –1 +1 +1)</li>
<li>假定S站要发送信息的数据率为 b bit/s。由于每一个比特要转换成 m 个比特的码片，因此 S 站实际上发送的数据率提高到 mb bit/s，同时 S 站所占用的频带宽度也提高到原来数值的 m 倍。</li>
<li>这种通信方式是<strong>扩频</strong>(spread spectrum)通信中的一种。</li>
<li>扩频通信通常有两大类：<ul>
<li>一种是<strong>直接序列扩频DSSS</strong> (Direct Sequence Spread Spectrum)，如上面讲的使用码片序列就是这一类。</li>
<li>另一种是<strong>跳频扩频FHSS</strong> (Frequency Hopping Spread Spectrum)。</li>
</ul>
</li>
<li>每个站分配的码片序列不仅<strong>必须各不相同</strong>，并且还<strong>必须互相正交</strong> (orthogonal)。</li>
<li>在实用的系统中是使用<strong>伪随机码序列</strong>。 </li>
<li>令向量 S 表示站 S 的码片向量，令 T 表示其他任何站的码片向量。 </li>
<li>两个不同站的码片序列正交，就是向量 S 和T 的<strong>规格化内积</strong> (inner product) 等于 0：</li>
<li><u>任何一个码片向量和该码片向量自己的规格化内积都是 1 </u>。</li>
<li><u>一个码片向量和该码片反码的向量的规格化内积值是 –1。 </u></li>
</ul>
</li>
</ul>
<h3 id="2-5-数字传输系统"><a href="#2-5-数字传输系统" class="headerlink" title="2.5 数字传输系统"></a>2.5 数字传输系统</h3><ul>
<li>与模拟通信相比，数字通信无论是在传输质量上还是经济上都有明显的优势</li>
<li>目前，长途干线大都采用PCM是数字传输方式</li>
<li>脉码调制PCM体制，最初是为了在电话局之间的中继线上传送多路的电话</li>
<li>由于历史原因PCM有两个不兼容的国际标准：T1，E1</li>
<li>当需要有更高的数据率时，可以采用复用的方法</li>
<li>旧的数字传输系统存在许多缺点:<br>(1)速率标准不统一<br>(2)不是同步传输</li>
<li><u>同步光纤网</u>SONET的各级时钟都来自一个非常精确的主时钟</li>
<li><u>同步数字系列</u>SDH，适用于微波和卫星传输</li>
</ul>
<h3 id="2-6-宽带接入技术"><a href="#2-6-宽带接入技术" class="headerlink" title="2.6 宽带接入技术"></a>2.6 宽带接入技术</h3><ul>
<li>用户要接入互联网，必须先连接到某个ISP</li>
<li>美国联邦通信委员会FCC认为只要双向速率之和超过200 kbit/s就是<strong>宽带</strong></li>
<li>从宽带接入的媒体来看，可以划分为两大类：<ul>
<li>有线宽带接入</li>
<li>无线宽带接入 </li>
</ul>
</li>
</ul>
<h4 id="2-6-1-ADSL技术"><a href="#2-6-1-ADSL技术" class="headerlink" title="2.6.1 ADSL技术"></a>2.6.1 ADSL技术</h4><ul>
<li><strong>非对称数字用户线ADSL</strong>：用数字技术对现有的模拟电话用户线进行改造</li>
<li>ADSL技术就是把0~4 kHz<u>低端频谱给传统电话使用</u>，而把<strong>原来没有被利用的高端频谱留给用户上网使用</strong></li>
<li>DSL就是<strong>数字用户线</strong></li>
<li>ADSL的传输距离取决于数据率和用户线的途径</li>
<li>ADSL所得到的最高数据传输速率与实际的用户线上的信噪比密切相关</li>
<li>ADSL的特点：<ul>
<li>上行（用户到ISP）和下行（ISP到用户）带宽不对称</li>
<li>ADSL在用户线的两端各安装一个ADSL调制解调器</li>
<li>我国目前采用的方案是离散多音调DMT调制技术<ul>
<li>多音调：指多载波/多子信道</li>
<li>DMT技术：<ul>
<li>采用频分复用</li>
<li>相当于在一对用户线上使用许多小的调制解调器并行的传送数据。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>ADSL的数据率：<ul>
<li>ADSL采用自适应调制技术使用户线能够传送尽可能高的数据率</li>
<li>ADSL不能保证固定的数据率</li>
</ul>
</li>
<li>第二代ADSL：<ul>
<li>通过提高调制效率得到更高的数据率</li>
<li>采用无缝速率自适应技术</li>
</ul>
</li>
</ul>
<h4 id="2-6-2-光线同轴混合网"><a href="#2-6-2-光线同轴混合网" class="headerlink" title="2.6.2 光线同轴混合网"></a>2.6.2 光线同轴混合网</h4><ul>
<li>HFC网是在目前覆盖面很广的有线电视网CATV基础上开发的一种居民宽带接入网</li>
<li>HFC网对CATV网进行了改造</li>
<li>HFC网将原CATV网中的同轴电缆<strong>主干部分该换为光纤</strong>，并使用模拟光纤技术</li>
<li>在模拟光纤中采用光的振幅AM</li>
<li>模拟光纤从头端连接到光纤结点，即光分配结点ODN</li>
<li>HFC网采用<strong>结点体系</strong></li>
<li>HFC网具有双向传输功能，扩展了传输频带</li>
<li>用户接口盒UIB要提供三种连接：<ul>
<li>使用同轴电缆连接到机顶盒，然后再连接到用户的电视机</li>
<li>使用双绞线连接到用户的电话机</li>
<li>使用电缆调制解调器来连接到用户的计算机<ul>
<li> 电缆调制解调器是为HFC网而使用的调制解调器</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="2-6-3-FTTx技术"><a href="#2-6-3-FTTx技术" class="headerlink" title="2.6.3 FTTx技术"></a>2.6.3 FTTx技术</h4><ul>
<li>FTTx是一种实现宽带居民接入网的方案，代表多种宽带光纤接入方式</li>
</ul>
<h2 id="第三章-数据链路层"><a href="#第三章-数据链路层" class="headerlink" title="第三章 数据链路层"></a>第三章 数据链路层</h2><ul>
<li>数据链路层使用的信道主要有以下两种类型：<ul>
<li>点对点信道====》 一对一</li>
<li>广播信道====》一对多，采用专用的共享信道协议</li>
</ul>
</li>
<li>路由器只包含网络层，链路层，物理层</li>
<li>不同链路层可能采用不同的数据链路层协议</li>
</ul>
<h3 id="3-1-使用点对点信道的数据链路层"><a href="#3-1-使用点对点信道的数据链路层" class="headerlink" title="3.1 使用点对点信道的数据链路层"></a>3.1 使用点对点信道的数据链路层</h3><h4 id="3-1-1-数据链路和帧"><a href="#3-1-1-数据链路和帧" class="headerlink" title="3.1.1 数据链路和帧"></a>3.1.1 数据链路和帧</h4><ul>
<li><strong>链路</strong>（物理链路）：一条无源的点到点的物理线路段，中间没有任何其他的交换结点</li>
<li>一条链路只是一条通路的一个组成部分</li>
<li><strong>数据链路</strong>（逻辑链路）：除了<strong>物理线路</strong>外，还必须有<strong>通信协议</strong>软件来控制这些数据的传输。若是把实现这些协议的硬件和软件加到链路上，就构成了数据链路。<ul>
<li>最常用的方法是使用<strong>网络适配器</strong>（即网卡）来实现这些协议的硬件和软件。</li>
<li>一般适配器都包括了数据链路层和物理层这两方面的功能</li>
</ul>
</li>
<li>早期的数据通信协议就做通信<strong>规程</strong>，在数据链路层中，规程和协议是同义语。</li>
<li><strong>帧</strong>-数据链路层的协议数据单元</li>
<li><strong>IP数据报</strong>：网络层的协议数据单元</li>
<li>数据链路层不必考虑物理层如何实现比特传输的细节，只考虑数据的封装等</li>
</ul>
<h4 id="3-1-2-三个基本问题"><a href="#3-1-2-三个基本问题" class="headerlink" title="3.1.2 三个基本问题"></a>3.1.2 三个基本问题</h4><ol>
<li><strong>封装成帧</strong>：</li>
</ol>
<ul>
<li>封装成帧就是在一段数据的前后分别添加首部和尾部；</li>
<li>首部和尾部的一个重要作用就是<strong>帧定界</strong></li>
<li>每一种链路层协议都规定了所能传送的帧的<strong>数据部分长度上限—最大传送单元MTU</strong></li>
<li>当数据是由可打印的 ASCII 码组成的文本文件时，帧定界可以使用特殊的<strong>帧定界符</strong>。</li>
<li>控制字符 SOH (Start Of Header) 放在一帧的最前面，表示帧的首部开始。另一个控制字符 EOT (End Of Transmission) 表示帧的结束。</li>
</ul>
<ol start="2">
<li><strong>透明传输</strong>：</li>
</ol>
<ul>
<li>如果数据中的某个字节的二进制代码恰好和 SOH 或 EOT 一样，数据链路层就会错误地“找到帧的边界”。</li>
<li>解决方法：<strong>字节填充</strong> (byte stuffing) 或<strong>字符填充</strong> (character stuffing)。</li>
<li>发送端的数据链路层在<strong>数据中</strong>出现控制字符“SOH”或“EOT”的<strong>前面插入一个转义字符“ESC”</strong> (其十六进制编码是 1B)。</li>
<li>接收端的数据链路层在将数据送往网络层之前删除插入的转义字符。</li>
<li>如果转义字符也出现在<strong>数据当中</strong>，那么应在<strong>转义字符前面插入一个转义字符 ESC</strong>。当接收端收到连续的两个转义字符时，就删除其中前面的一个。 </li>
</ul>
<ol start="3">
<li><strong>差错检验</strong>：</li>
</ol>
<ul>
<li>在传输过程中可能会产生比特差错：1 可能会变成 0 而 0 也可能变成 1。</li>
<li>在一段时间内，传输错误的比特占所传输比特总数的比率称为<strong>误码率</strong> BER (Bit Error Rate)。<br>误码率与信噪比有很大的关系。</li>
<li>为了保证数据传输的可靠性，在计算机网络传输数据时，必须采用各种差错检测措施。 </li>
<li>循环冗余检验：<ul>
<li>在发送端，先把数据划分为组。假定每组 k 个比特。 </li>
<li>假设待传送的一组数据 M = 101001（现在 k = 6）。我们在 M 的后面再添加供差错检测用的 n 位<strong>冗余码</strong>一起发送。  </li>
<li>冗余码的计算：<ul>
<li>用二进制的模 2 运算进行 2^n 乘 M 的运算，这相当于在 M 后面添加 n 个 0。</li>
<li>得到的 (k + n) 位的数除以事先选定好的长度为 (n + 1) 位的除数 P，得出商是 Q 而余数是 R，余数 R 比除数 P 少 1 位，即 R 是 n 位。 </li>
<li>将余数 R 作为冗余码拼接在数据 M 后面发送出去。<blockquote>
<ul>
<li>冗余码的计算举例:<br>现在 k = 6, M = 101001。<br>设 n = 3, 除数 P = 1101，<br>被除数是 2^n*M = 101001000。<br>模 2 运算的结果是：商 Q = 110101，<br>   余数 R = 001。<br>把余数 R 作为冗余码添加在数据 M 的后面发送出去。发送的数据是：2^n*M + R<br>即：101001001，共 (k + n) 位。 </li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
<li>在数据后面添加上的冗余码称为<strong>帧检验序列FCS</strong></li>
<li>CRC是一种常用的检错方法，FCS是添加在数据后面的冗余码</li>
<li>FCS可以用CRC这种方法得出，但是CRC并非用来获得FCS的唯一方法</li>
<li>检验结果：<br>(1) 若得出的余数 R = 0，则判定这个帧没有差错，就接受 (accept)。<br>(2) 若余数 R ≠ 0，则判定这个帧有差错，就丢弃。</li>
<li>但这种检测方法并不能确定究竟是哪一个或哪几个比特出现了差错。</li>
<li>只要经过严格的挑选，并使用位数足够多的除数 P，那么出现检测不到的差错的<strong>概率</strong>就很小很小。 </li>
<li>注意：<ul>
<li>仅用循环冗余检验 CRC 差错检测技术只能做到<strong>无差错接受</strong> (accept)。</li>
<li>“<strong>无差错接受</strong>”是指：“凡是接受的帧（即不包括丢弃的帧），我们都能以非常接近于 1 的概率认为这些帧在传输过程中没有产生差错”。</li>
<li>也就是说：“凡是接收端数据链路层接受的帧都没有传输差错”（有差错的帧就丢弃而不接受）。</li>
<li><strong>要做到“可靠传输”（即发送什么就收到什么）就必须再加上确认和重传机制</strong>。  </li>
<li>应当明确，“<strong>无比特差错</strong>”与“<strong>无传输差错</strong>”是不同的概念。</li>
</ul>
</li>
<li>在数据链路层使用 CRC 检验，能够实现无比特差错的传输，但这还不是可靠传输。</li>
<li>本章介绍的数据链路层协议都<strong>不是可靠传输</strong>的协议。</li>
</ul>
<h3 id="3-2-点对点协议PPP"><a href="#3-2-点对点协议PPP" class="headerlink" title="3.2 点对点协议PPP"></a>3.2 点对点协议PPP</h3><ul>
<li>数据链路层能实现可靠传输的高级数据链路控制HDLC</li>
<li>目前使用得最广泛的数据链路层协议：点对点协议PPP</li>
</ul>
<h3 id="3-2-1-PPP协议的特点"><a href="#3-2-1-PPP协议的特点" class="headerlink" title="3.2.1 PPP协议的特点"></a>3.2.1 PPP协议的特点</h3><ol>
<li>PPP协议应满足的需求：<br>（1）<strong>简单</strong>：<strong>首要需求</strong>，提高互操作性<br>（2）<strong>封装成帧</strong>：规定特殊的字符作为<strong>帧定界符</strong><br>（3）<strong>透明性</strong>：必须保证数据传输的透明性<br>（4）<strong>多种网络层协议</strong>：<strong>在同一条物理链路上同时支持多种网络层协议</strong><br>（5）<strong>多种类型链路</strong>：<br>（6）<strong>差错检验</strong>：检测并丢弃有差错的帧<br>（7）<strong>检测连接状态</strong>：<br>（8）<strong>最大传送单元</strong>：MTU是数据链路层的帧可以载荷的<strong>数据部分</strong>的最大长度，而<strong>不是帧的总长度</strong><br>（9）<strong>网络层地址协商</strong>：<br>（10）<strong>数据压缩协商</strong>：</li>
<li>PPP协议不需要的功能：<br>（1）纠错：因为可靠传输由运输层的TCP协议负责<br>（2）流量控制<br>（3）序号<br>（4）多点线路：因为PPP只支持点对点的链路通信<br>（5）半双工或单双工：因为PPP只支持全双工链路</li>
<li>PPP协议的组成：<br>（1）一个将IP数据报封装到串行链路的方法<br>（2）链路控制协议LCP：用来建立，配置，和测试数据链路的连接<br>（3）网络控制协议NCP：</li>
</ol>
<h4 id="3-2-2-PPP协议的帧格式"><a href="#3-2-2-PPP协议的帧格式" class="headerlink" title="3.2.2 PPP协议的帧格式"></a>3.2.2 PPP协议的帧格式</h4><ol>
<li>各字段的意义：</li>
</ol>
<ul>
<li>ppp帧的首部和尾部分别为4个字段和2个字段</li>
<li>标志字段F规定为0x7E（即01111110），标志一个帧的开始和结束</li>
<li>地址字段A规定为0xFF（即111111）</li>
<li>控制字段C规定为0x03（即00000011）</li>
<li>协议字段，两个字节</li>
</ul>
<ol start="2">
<li>字节填充 </li>
</ol>
<ul>
<li><strong>PPP是面向字节的，所有的PPP帧的长度都是整数字节</strong></li>
<li>透明传输问题：<ul>
<li>PPP用在同步传输链路时，协议规定采用硬件来完成<strong>比特填充</strong></li>
<li>当PPP用在异步传输时，就使用一种特殊的<strong>字符填充法</strong></li>
<li>把转义字符定义为0x7D（即011111101）</li>
<li>PPP协议用在SONET/SDH链路时，使用同步传输，这时PPP协议采用<strong>零比特填充</strong>方法实现透明传输</li>
</ul>
</li>
</ul>
<ol start="3">
<li>零比特填充</li>
</ol>
<ul>
<li>只要发现有5个连续的1，则立即填入一个0，因此经过这种填充后的数据不会出现六个连续的1.（因为几个特殊字段内有111111）</li>
</ul>
<h4 id="3-2-3-PPP协议的工作状态"><a href="#3-2-3-PPP协议的工作状态" class="headerlink" title="3.2.3 PPP协议的工作状态"></a>3.2.3 PPP协议的工作状态</h4><ul>
<li>PPP协议已不是纯粹的数据链路层的协议，它还包含了物理层和网络层的内容。</li>
<li>链路静止状态</li>
<li>链路建立状态</li>
<li>链路打开状态</li>
<li>链路终止状态</li>
</ul>
<h3 id="3-3-使用广播信道的数据链路层"><a href="#3-3-使用广播信道的数据链路层" class="headerlink" title="3.3 使用广播信道的数据链路层"></a>3.3 使用广播信道的数据链路层</h3><h4 id="3-3-1-局域网的数据链路层"><a href="#3-3-1-局域网的数据链路层" class="headerlink" title="3.3.1 局域网的数据链路层"></a>3.3.1 局域网的数据链路层</h4><ul>
<li>局域网最主要的<strong>特点</strong>是：<ul>
<li>网络为一个单位所拥有；</li>
<li>地理范围和站点数目均有限。 </li>
</ul>
</li>
<li>局域网具有如下主要<strong>优点</strong>：<ul>
<li>具有广播功能，从一个站点可很方便地访问全网。局域网上的主机可共享连接在局域网上的各种硬件和软件资源。 </li>
<li>便于系统的扩展和逐渐地演变，各设备的位置可灵活调整和改变。</li>
<li>提高了系统的可靠性、可用性和残存性。</li>
</ul>
</li>
<li>局域网按拓扑结构分类：<ul>
<li>星型网，集线器</li>
<li>总线网，匹配电阻</li>
<li>环形网，干线耦合器</li>
</ul>
</li>
<li>局域网中的主要传输媒体： 双绞线</li>
<li>当数据率很高时，往往需要使用光纤作为传输媒体</li>
<li>媒体共享技术：<ul>
<li>静态划分信道：频分复用，时分复用，波分复用，码分复用</li>
<li>动态媒体接入控制（多点接入）：<ul>
<li>随机接入:所有用户可随机地发送信息。但是同一时刻发送信息，会产生碰撞（冲突），故需要解决碰撞的网络协议。</li>
<li>受控接入：用户不能随机发送信息，必须服从一定控制：如多点线路探询，轮询。</li>
</ul>
</li>
</ul>
</li>
</ul>
<ol>
<li>以太网的两个标准：</li>
</ol>
<ul>
<li>DIX Ethernet V2 是世界上第一个局域网产品（以太网）的规约。</li>
<li>IEEE 802.3 是第一个 IEEE 的以太网标准。</li>
<li>IEEE 802 委员会就将局域网的数据链路层拆成两个子层：<ul>
<li>逻辑链路控制 LLC (Logical Link Control)子层；</li>
<li>媒体接入控制 MAC (Medium Access Control)子层。</li>
</ul>
</li>
<li>与接入到传输媒体有关的内容都放在 MAC子层，而 LLC 子层则与传输媒体无关。</li>
<li><strong>不管采用何种协议的局域网，对 LLC 子层来说都是透明的</strong>。</li>
</ul>
<ol start="2">
<li>适配器的作用：</li>
</ol>
<ul>
<li>网络接口板又称为<strong>通信适配器</strong> (adapter) 或<strong>网络接口卡</strong> NIC (Network Interface Card)，或“<strong>网卡</strong>”。 </li>
<li>适配器的重要功能：<ul>
<li>进行串行/并行转换。</li>
<li>对数据进行缓存。</li>
<li>在计算机的操作系统安装设备驱动程序。</li>
<li>实现以太网协议。  </li>
</ul>
</li>
<li>适配器在接受和发送各种帧时，不适用计算机的CPU。当收到有差错的帧时，<strong>直接丢弃</strong>而不必通知计算机。当收到正确的帧时，使用<strong>中断</strong>来通知计算机，并交付协议栈中的网络层 。<br>当计算机要发送IP数据报时，，就由协议栈把IP数据报向下交给适配器，组装成帧后发送到局域网</li>
</ul>
<h4 id="3-3-2-CSMA-CD协议"><a href="#3-3-2-CSMA-CD协议" class="headerlink" title="3.3.2 CSMA/CD协议"></a>3.3.2 CSMA/CD协议</h4><ul>
<li><p>总线的特点：当一台计算机发送数据时，总线上所有的计算机都能检测到这个数据</p>
</li>
<li><p>为了在总线上实现一对一的通信，可以使适配器拥有一个独一无二的地址</p>
</li>
<li><p>为了通信简便，以太网采用：</p>
<ul>
<li><p>采用较为灵活的无连接的工作方式 </p>
<ul>
<li>不必先建立连接就可以直接发送数据。</li>
<li>对发送的数据帧不进行编号，也不要求对方发回确认。</li>
<li>这样做的理由是局域网信道的质量很好，因信道质量产生差错的概率是很小的。 </li>
<li>以太网提供的服务是<strong>不可靠的交付</strong>，即<strong>尽最大努力的交付</strong>。</li>
<li>当目的站收到有差错的数据帧时就丢弃此帧，其他什么也不做。<strong>差错的纠正由高层来决定。</strong></li>
<li>如果高层发现丢失了一些数据而进行重传，但<strong>以太网并不知道这是一个重传的帧，而是当作一个新的数据帧来发送</strong>。  </li>
</ul>
</li>
<li><p>以太网发送的数据都<strong>使用曼切斯特</strong>编码：</p>
<ul>
<li>缺点：占用的频带宽度比原始的基带信号增加了一倍</li>
<li>CSMA/CD协议：<ul>
<li>CSMA/CD 含义：<strong>载波监听多点接入 / 碰撞检测</strong>  (Carrier Sense Multiple Access with Collision Detection) 。</li>
<li>“<strong>多点接入</strong>”表示许多计算机以多点接入的方式连接在一根总线上。</li>
<li>“<strong>载波监听</strong>”是指每一个站在发送数据之前先要检测一下总线上是否有其他计算机在发送数据，如果有，则暂时不要发送数据，以免发生碰撞。 </li>
<li>“<strong>碰撞检测</strong>”是指边发送边监听</li>
<li>总线上并没有什么“载波”。因此， <strong>“载波监听”就是用电子技术检测总线上有没有其他计算机发送的数据信号</strong>。</li>
<li>检测到碰撞后 ： 每一个正在发送数据的站，一旦发现总线上出现了碰撞，就要<strong>立即停止发送</strong>，免得继续浪费网络资源，然后<strong>等待一段随机时间</strong>后再次发送。</li>
<li>由于电磁波在总线上的传播速率是有限的，当某个站监听到总线是空闲时，也可能总线并非真正是空闲的所以需要在发送期间进行碰撞检测，以检测冲突。  </li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>在使用CSMA/CD协议时，一个站不可能同时进行发送和接收（但必须边发送边监听信道）</p>
</li>
<li><p>因此CSMA/CD协议不可能进行全双工通信只能进行双向交替通信（<strong>半双工通信</strong>）</p>
</li>
<li><p>每个站在发送数据之后的一小段时间内，存在着遭遇碰撞的可能性。 </p>
</li>
<li><p>这种<strong>发送的不确定性</strong>使整个以太网的平均通信量远小于以太网的最高数据率。 </p>
</li>
<li><p>最先发送数据帧的站，在发送数据帧后<strong>至多</strong>经过时间<strong>2τ （两倍的端到端往返时延）</strong> 就可知道发送的数据帧是否遭受了碰撞。</p>
</li>
<li><p>以太网的端到端往返时延 2τ 称为<strong>争用期</strong>，或<strong>碰撞窗口</strong>。</p>
</li>
<li><p><strong>经过争用期这段时间还没有检测到碰撞，才能肯定这次发送不会发生碰撞</strong>。</p>
</li>
<li><p>二进制指数型退避算法：</p>
<ul>
<li>发生碰撞的站在停止发送数据后，要推迟（退避）一个<strong>随机时间</strong>才能再发送数据。</li>
<li>基本退避时间取为争用期 2τ。</li>
<li>从整数集合 [0, 1, … , (2k-1)] 中<strong>随机</strong>地取出一个数，记为 r。重传所需的时延就是 r 倍的基本退避时间。</li>
<li>参数 k 按下面的公式计算：<pre><code>       **k = Min[重传次数, 10]**
</code></pre>
</li>
<li>当 k ≤ 10 时，参数 k 等于重传次数。</li>
<li>当重传达 16 次仍不能成功时即丢弃该帧，并向高层报告。</li>
<li>以太网在发送数据时，若前 64 字节没有发生冲突，则后续的数据就不会发生冲突。<strong>最短有效帧长为 64 字节</strong></li>
</ul>
</li>
<li><p>强化碰撞：当发送数据的站一旦发现发生了碰撞时：<br>(1) 立即停止发送数据；<br>(2) 再继续发送若干比特的<strong>人为干扰信号</strong>以便让所有用户都知道现在已经发生了碰撞。  </p>
</li>
<li><p>CSMA/CD协议的要点：<br>（1）准备发送<br>（2）检测信道<br>（3）检查碰撞</p>
</li>
</ul>
<h4 id="3-3-3-使用集线器的星形拓扑"><a href="#3-3-3-使用集线器的星形拓扑" class="headerlink" title="3.3.3 使用集线器的星形拓扑"></a>3.3.3 使用集线器的星形拓扑</h4><ul>
<li>特点：</li>
<li>（1）使用集线器的以太网在<strong>逻辑上仍是一个总线网</strong>，各站<strong>共享逻辑上的总线</strong>，各适配器使用的还是CSMA/CD协议，并且同一时刻只允许一个站发送数据</li>
<li>（2）一个集线器很像一个多接口的转发器</li>
<li>（3）<strong>集线器工作在物理层</strong>，它的每一个接口仅仅简单地转发比特，不进行碰撞检测</li>
<li>（4）采用专门的芯片</li>
</ul>
<h4 id="3-3-4-以太网的信道利用率"><a href="#3-3-4-以太网的信道利用率" class="headerlink" title="3.3.4 以太网的信道利用率"></a>3.3.4 以太网的信道利用率</h4><ul>
<li>要提高以太网的信道利用率，就必须减少τ与T0之比，在以太网中定义了参数a，它是以太网<strong>单程端到端时延τ</strong>与<strong>帧的发送时间T0</strong>：<br>a=τ/T0；</li>
<li>α →0，表示一发生碰撞就立即可以检测出来， 并立即停止发送，因而信道利用率很高。</li>
<li><strong>α 越大，表明争用期所占的比例增大</strong>，每发生一次碰撞就浪费许多信道资源，<strong>使得信道利用率明显降低</strong>。 </li>
<li>为提高利用率，以太网的参数a的值应当尽可能小些。</li>
<li>对以太网参数 α 的要求是：<ul>
<li>当数据率一定时，以太网的连线的长度受到限制，否则 τ 的数值会太大。</li>
<li>以太网的帧长不能太短，否则 T0 的值会太小，使 α 值太大。 </li>
<li>只有当参数 a 远小于 1 才能得到尽可能高的极限信道利用率。</li>
</ul>
</li>
<li><strong>理想情况下的极限信道利用率</strong>Smax为：<br>Smax=T0/（T0+τ）=1/（1+a）</li>
</ul>
<h4 id="3-3-5-以太网的MAC的层"><a href="#3-3-5-以太网的MAC的层" class="headerlink" title="3.3.5 以太网的MAC的层"></a>3.3.5 以太网的MAC的层</h4><ol>
<li>MAC层的硬件地址：</li>
</ol>
<ul>
<li>在局域网中，<strong>硬件地址</strong>又称为<strong>物理地址</strong>，或<strong>MAC 地址</strong>。 </li>
<li>IEEE 802标准为局域网规定了一种48位的全球地址，是指局域网上的每一台计算机中<strong>固化在适配器的ROM中的地址</strong></li>
<li>IEEE的RA是局域网全球地址的法定管理结构，它负责分配地址字段的6个字节的前三个字节。生产局域网适配器的厂家需要向IEEE购买由这三个字节构成的组织唯一标识符OUI</li>
<li>厂家自行指派后三个字节，称为扩展标识符，用这种方法得到的48位地址称为EUI-48</li>
<li>IEEE 规定地址字段的第一字节的最低位为I/G位：I/G位为0时，地址段表示单个站地址；I/G位为1时表示组地址，用来多播</li>
<li>IEEE规定地址字段第一字节的最低第二位为G/L位：G/L位为0时是全球管理，为1时是本地管理</li>
<li>适配器由<strong>过滤功能</strong>，从网络上每收到一个MAC帧就先用硬件检查MAC帧中的目的地址。</li>
<li>发往本站的帧：单播帧，广播帧，多播帧</li>
<li>所有的适配器都至少能够识别前两种帧，即能够识别单播地址和广播地址。</li>
<li>有的适配器可用编程方法识别多播地址。</li>
<li>只有目的地址才能使用广播地址和多播地址。</li>
<li>以<strong>混杂方式</strong> (promiscuous mode) 工作的以太网适配器只要“听到”有帧在以太网上传输就都接收下来。</li>
</ul>
<ol start="2">
<li>MAC帧的格式</li>
</ol>
<ul>
<li>最常用的MAC帧是以太网V2格式</li>
<li>最后一字段是4字节的帧检验序列FCS（使用CRC检验）</li>
<li>无效的MAC帧：<ul>
<li>长度不是整数个字节</li>
<li>收到的FCS帧检验序列查出错误</li>
<li>数据位置错误</li>
</ul>
</li>
</ul>
<h3 id="3-4-扩展的以太网"><a href="#3-4-扩展的以太网" class="headerlink" title="3.4 扩展的以太网"></a>3.4 扩展的以太网</h3><h4 id="3-4-1-在物理层扩展以太网"><a href="#3-4-1-在物理层扩展以太网" class="headerlink" title="3.4.1 在物理层扩展以太网"></a>3.4.1 在物理层扩展以太网</h4><ol>
<li>使用光纤扩展</li>
<li>使用集线器扩展（碰撞域）</li>
</ol>
<ul>
<li>优点<br>（1）使原来属于不同碰撞域的以太网上的计算机能够进行跨碰撞域的通信。<br>（2）扩大了以太网覆盖的地理范围。</li>
<li>缺点<br>（1）碰撞域增大了，但总的吞吐量并未提高。<br>（2）如果不同的碰撞域使用不同的数据率，那么就不能用集线器将它们互连起来。   </li>
</ul>
<h4 id="3-4-2-在数据链路层扩展以太网"><a href="#3-4-2-在数据链路层扩展以太网" class="headerlink" title="3.4.2 在数据链路层扩展以太网"></a>3.4.2 在数据链路层扩展以太网</h4><ul>
<li>早期使用<strong>网桥</strong>，现在使用以太网<strong>交换机</strong></li>
</ul>
<ol>
<li>以太网交换机的特点</li>
</ol>
<ul>
<li>实质上是一个多接口网桥</li>
<li>工作在全双工方式</li>
<li>相互通信的主机都是独占传输媒体，无碰撞地传输数据<ul>
<li>具有并行性，能使多对主机同时通信</li>
</ul>
</li>
<li>许多以太网交换机对收到的帧采用存储转发方式进行转发，但是也有一些交换机采用直通的交换方式</li>
</ul>
<ol start="2">
<li>以太网交换机的自学习功能</li>
</ol>
<ul>
<li>即插即用，帧交换表</li>
</ul>
<ol start="3">
<li>从总线以太网到星形以太网</li>
</ol>
<ul>
<li> 仍然采用以太网的帧结构</li>
</ul>
<h4 id="3-4-3-虚拟局域网"><a href="#3-4-3-虚拟局域网" class="headerlink" title="3.4.3 虚拟局域网"></a>3.4.3 虚拟局域网</h4><ul>
<li> <strong>虚拟局域网 VLAN</strong> 是由一些局域网网段构成的与<strong>物理位置无关的逻辑组</strong>，而这些网段具有某些共同的需求。每一个 VLAN 的帧都有一个明确的标识符，指明发送这个帧的计算机是属于哪一个 VLAN。</li>
<li><strong>虚拟局域网其实只是局域网给用户提供的一种服务，而并不是一种新型局域网。</strong></li>
</ul>
<h3 id="3-5-高速以太网"><a href="#3-5-高速以太网" class="headerlink" title="3.5 高速以太网"></a>3.5 高速以太网</h3><h4 id="3-5-1-100BASE-T-以太网"><a href="#3-5-1-100BASE-T-以太网" class="headerlink" title="3.5.1  100BASE-T 以太网"></a>3.5.1  100BASE-T 以太网</h4><ul>
<li>速率达到或超过100Mbit/s的以太网称为高速以太网</li>
<li>100BASE-T以太网又叫快速以太网</li>
<li>可在全双工方式下工作而无冲突发生</li>
</ul>
<h4 id="3-5-2-吉比特以太网"><a href="#3-5-2-吉比特以太网" class="headerlink" title="3.5.2  吉比特以太网"></a>3.5.2  吉比特以太网</h4><ul>
<li>在半双工方式下使用 CSMA/CD 协议，全双工方式不使用 CSMA/CD 协议。</li>
<li>载波延伸</li>
<li>分组突发</li>
</ul>
<h4 id="3-5-3-10吉比特以太网-10GE-和更快的以太网"><a href="#3-5-3-10吉比特以太网-10GE-和更快的以太网" class="headerlink" title="3.5.3  10吉比特以太网 (10GE) 和更快的以太网"></a>3.5.3  10吉比特以太网 (10GE) 和更快的以太网</h4><ul>
<li>只工作在全双工方式</li>
</ul>
<h4 id="3-5-4-使用以太网进行宽带接入"><a href="#3-5-4-使用以太网进行宽带接入" class="headerlink" title="3.5.4  使用以太网进行宽带接入"></a>3.5.4  使用以太网进行宽带接入</h4><ul>
<li>可以提供双向的宽带通信。</li>
<li>可以根据用户对带宽的需求灵活地进行带宽升级。</li>
<li>可以实现端到端的以太网传输，中间不需要再进行帧格式的转换。这就提高了数据的传输效率且降低了传输的成本。</li>
<li>但是不支持用户身份鉴别。</li>
</ul>
<h2 id="第四章-网络层"><a href="#第四章-网络层" class="headerlink" title="第四章 网络层"></a>第四章 网络层</h2><h3 id="4-1-网络层提供的两种服务"><a href="#4-1-网络层提供的两种服务" class="headerlink" title="4.1 网络层提供的两种服务"></a>4.1 网络层提供的两种服务</h3><ul>
<li><strong>面向连接</strong>还是<strong>无连接</strong></li>
<li>互联网采用的设计思路是这样的：<strong>网络层向上只提供简单灵活的，无连接的，尽最大努力交付的数据报服务</strong>。</li>
<li><strong>网络层不提供服务质量的承诺</strong></li>
<li>通信之前先建立<strong>虚电路</strong>，以保证双方通信所需的一切网络资源。</li>
<li>虚电路表示这只是一条逻辑上的连接，分组都沿着这条逻辑连接按照存储转发方式传送</li>
</ul>
<h3 id="4-2-网际协议IP"><a href="#4-2-网际协议IP" class="headerlink" title="4.2 网际协议IP"></a>4.2 网际协议IP</h3><ul>
<li>与IP协议配套使用的三个协议：<ul>
<li>地址解析协议ARP</li>
<li>网际控制协议ICMP</li>
<li>网际组管理协议IGMP</li>
</ul>
</li>
<li>由于网际协议IP是用来使互连起来的许多计算机网络能够进行通信的，因此TCP/IP体系中的网络层常常被称为网际层或IP层</li>
</ul>
<h4 id="4-2-1-虚拟互连网络"><a href="#4-2-1-虚拟互连网络" class="headerlink" title="4.2.1 虚拟互连网络"></a>4.2.1 虚拟互连网络</h4><ul>
<li>没有一种单一的网络能够适应所有用户的需求</li>
<li>将网络互相连接起来要使用一些中间设备：<ul>
<li>物理层中继系统：<strong>转发器</strong> (repeater)。</li>
<li>数据链路层中继系统：<strong>网桥</strong> 或 <strong>桥接器</strong> (bridge)。</li>
<li>网络层中继系统：<strong>路由器</strong> (router)。</li>
<li>网桥和路由器的混合物：<strong>桥路器</strong> (brouter)。</li>
<li>网络层以上的中继系统：<strong>网关</strong> (gateway)。  </li>
</ul>
</li>
<li>网络互连都是指用路由器进行网络互连和路由选择。</li>
<li>由于历史的原因，许多有关 TCP/IP 的文献将网络层使用的路由器称为网关。</li>
<li>所谓虚拟互连网络也就是逻辑互连网络，它的意思就是互连起来的各种物理网络的异构性本来是客观存在的，但是我们利用 IP 协议就可以使这些性能各异的网络从用户看起来好像是一个统一的网络。</li>
<li>使用 IP 协议的虚拟互连网络可简称为 IP 网。</li>
<li>使用虚拟互连网络的好处是：当互联网上的主机进行通信时，就好像在一个网络上通信一样，而看不见互连的各具体的网络异构细节。</li>
<li>如果在这种覆盖全球的 IP 网的上层使用 TCP 协议，那么就是现在的互联网 (Internet)。</li>
<li>互联网可以由多种异构网络互连组成</li>
</ul>
<h4 id="4-2-2-分类的IP地址"><a href="#4-2-2-分类的IP地址" class="headerlink" title="4.2.2 分类的IP地址"></a>4.2.2 分类的IP地址</h4><ol>
<li>IP地址及其表示方法：</li>
</ol>
<ul>
<li>整个互联网就是一个<strong>单一的，抽象的网络</strong>。IP地址就是给互联网上的每一台主机（或路由器）的每一个接口分配一个全世界范围内是唯一的32位的标识符</li>
<li>IP地址现在由<strong>互联网名字和数字分配机构ICANN</strong>进行分配</li>
<li>IP地址的编制方法经过三个历史阶段：<br>（1）分类的IP地址<br>（2）子网的划分<br>（3）构成超网</li>
<li>分类的IP地址：就是将IP地址划分位若干个固定类。</li>
<li>A，B，C类地址都是由两个固定长度的字段组成，其中第一个字段是网络号，是唯一的。第二个字段是主机号，在当前网络范围内是唯一的</li>
<li>由此可见，一个IP地址在整个互联网范围内是唯一的</li>
<li>A，B，C类是单播地址，D类地址用于多播，E类地址保留</li>
<li>点分十进制记法</li>
</ul>
<ol start="2">
<li>常用的三种类别的IP地址</li>
</ol>
<ul>
<li>A类地址，<strong>网络号</strong>全0表示本网络，全1表示本地软件环回测试</li>
<li>A类地址，<strong>主机号</strong>全0表示本主机连接的单个网络地址，全1表示该网络上所有的主机</li>
<li>一般不用的特殊的IP </li>
<li>IP地址的特点：<br>（1）IP是分等级的地址结构，IP地址管理机构<strong>只分配网络号，主机号由得到网络号的单位自行分配，路由器仅根据目的主机网络号来转发分组</strong>，减小了路由表所占的存储空间以及查找路由表的时间<br>（2）IP地址标志一台主机和一条链路的<strong>接口</strong>，当一台主机同时连接到两个网络上时，该主机就必须同时具有两个相应的IP地址，其网络号必须不同。这种主机也叫做<strong>多归属主机</strong><br>（3）一个网络时指具有相同网络号net-id的主机的集合，故，<strong>用转发器或网桥连接起来的若干局域网仍是一个网络</strong>。具有不同网络号的局域网必须用路由器进行互连<br>（4）在IP地址中，所有分配到网络号的网络都是平等的</li>
<li>当两个路由器直接相连时，为了节省IP地址资源，常常不给这段连线分配IP地址，通常把这段特殊的网络叫做无编号网络或无名网络<h4 id="4-2-3-IP地址与硬件地址"><a href="#4-2-3-IP地址与硬件地址" class="headerlink" title="4.2.3 IP地址与硬件地址"></a>4.2.3 IP地址与硬件地址</h4></li>
<li>区分IP地址与硬件地址：从层次上来看，<strong>物理地址是数据链路层和物理层使用的地址，而IP地址是网络层和以上各层使用的地址，是一种逻辑地址</strong>。</li>
<li>在发送数据时，数据从高层向下到低层，然后才到通信链路上传输。使用IP地址的IP数据报一旦交给了数据链路层，就被封装成MAC帧了。MAC帧在传送时使用的源地址和目的地址都是硬件地址，这两个地址都写在MAC帧的头部。连接在通信链路上的设备在收到MAC帧时，根据MAC帧首部的硬件地址决定抛弃与否，只有在剥去MAC帧的首部和尾部后把MAC层的数据上交给网络层后，网络层才能在IP数据报的首部找到源IP地址和目的IP地址</li>
<li>注意：<br>（1）在IP层抽象的互联网上只能看到IP数据报<br>（2）路由器只根据目的站的IP地址的网络号进行路由选择<br>（3）在局域网的链路层，只能看见MAC帧<br>（4）IP层抽象的互联网频闭下层这些很复杂的细节。</li>
</ul>
<h4 id="4-2-4-地址解析协议ARP"><a href="#4-2-4-地址解析协议ARP" class="headerlink" title="4.2.4 地址解析协议ARP"></a>4.2.4 地址解析协议ARP</h4><ul>
<li>ARP常被划分为网络层的协议</li>
<li>ARP协议的用途：为了从网络层使用的IP地址，解析出在数据链路层使用的硬件地址。</li>
<li><strong>地址解析协议ARP</strong>解决这个问题的方法是在主机<strong>ARP高速缓存</strong>中存放一个从IP地址到硬件地址的映射表，并且这个映射表还经常动态更新</li>
<li>当主机A要向本局域网上的某台主机B发送IP数据报时，就先在其ARP高速缓存查看有无主机B的IP地址。如果有，查出硬件地址并写入MAC帧，如果没有，（1）ARP在本局域网广播发送一个ARP请求分组（2）在本局域网的所有主机上运行的ARP进程都收到了请求分组（3）主机B的IP地址与请求分组中要查询的IP地址一致，收下这个请求分组，并向主机A发送ARP响应分组，同时在这个ARP响应分组中写入自己的硬件地址（4）主机A收到主机B的ARP分组后，就在其ARP高速缓存中写入主机B的IP地址到硬件地址的映射</li>
<li>每一个映射地址项目都设置生存时间</li>
<li>ARP是解决同一个局域网上的主机或路由器的IP地址和硬件地址的映射问题</li>
<li>从IP地址到硬件地址的解析是自动进行的，<strong>主机的用户对这种地址解析过程是不知道的</strong></li>
</ul>
<h4 id="4-2-5-IP数据报的格式"><a href="#4-2-5-IP数据报的格式" class="headerlink" title="4.2.5 IP数据报的格式"></a>4.2.5 IP数据报的格式</h4><ol>
<li><p>IP数据报首部的固定部分中的各字段<br>（1）版本<br>（2）首部长度<br>（3）区分服务<br>（4）总长度：指首部和数据之和的长度<br>（5）标识<br>（6）标志：占3位，最低位MF；中间位DF<br>（7）片偏移<br>（8）生存时间TTL：跳数限制<br>（9）协议<br>（10）首部检验和：只检验数据报的首部，但不包括数据部分<br>（11）源地址<br>（12）目的地址</p>
</li>
<li><p>IP层转发分组的流程</p>
</li>
</ol>
<ul>
<li>在互联网上转发分组时，是从一个路由器转发到下一个路由器</li>
<li>在路由表中，对每一条路由最主要的是以下两个信息：<strong>目的网络地址，下一跳地址</strong>。</li>
<li>虽然互联网所有的分组转发都是<strong>基于目的主机所在的网络</strong>，但是存在着对特定的目的主机指明一个路由。这种路由叫做<strong>特定主机路由</strong>。</li>
<li>默认路由：减小路由表所占用的空间和搜索路由表所用的时间</li>
<li>分组转发算法：<ul>
<li>（1）从数据报首部提取目的主机IP地址D，得到目的网络N</li>
<li>（2）若N就是与此路由器直接相连的某个网络地址，则进行直接交付，否则，间接交付</li>
<li>（3）若路由表中有目的地址为D的特定主机路由，则把数据报传送给下一跳路由器，若无则（4）</li>
<li>（4）若路由器有到达网络N的路由，则把数据报传送给路由表中所指明的下一跳，否则（5）</li>
<li>（5）若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器，否者（6）</li>
<li>（6）报告转发分组失败</li>
</ul>
</li>
</ul>
<h3 id="4-3-划分子网和构造超网"><a href="#4-3-划分子网和构造超网" class="headerlink" title="4.3 划分子网和构造超网"></a>4.3 划分子网和构造超网</h3><h4 id="4-3-1-划分子网"><a href="#4-3-1-划分子网" class="headerlink" title="4.3.1 划分子网"></a>4.3.1 划分子网</h4><ol>
<li>从两级IP地址到三级IP地址</li>
</ol>
<ul>
<li>IP地址设计不合理：<br>（1）IP地址空间的<strong>利用率有时很低</strong><br>（2）给每个物理网络分配一个网络号会<strong>使路由表变得太大</strong><br>（3）两级IP地址不够灵活</li>
<li>为了解决上诉问题，IP地址中又增加了“子网号字段”，使两级地址变成三级地址—-这种做法也叫划分子网或子网寻址或子网路由选择</li>
<li>划分子网的基本思路：<br>（1）一个拥有许多物理网络的单位，可将所属的物理网络划分为若干各子网。划分子网纯属一个单位内部的事情。本网络以外的网络看不见这个网络是由多少各子网组成，因为其对外仍然表现为一个网络<br>（2）划分子网的方法是从网络的<strong>主机号</strong>借用若干位作为<strong>子网号</strong>，当然主机号也就减少了同样的位数，于是两级IP地址在本单位内就变成了三级IP地址，网络号，子网号和主机号<br>（3）凡是从其他网络发送来的IP数据报，仍是根据目的网络号找到路由器，此路由器收到IP数据报后，再按照目的网络号和子网号找到目的子网，把IP数据报交付目的主机</li>
</ul>
<ol start="2">
<li>子网掩码</li>
</ol>
<ul>
<li>从IP数据报的首部无法看出源主机或目的主机多连接的网络是否进行了子网的划分。因此使用子网掩码。</li>
<li>将子网掩码与收到的数据报的目的IP地址<strong>逐位相与</strong>，得到子网的网络地址</li>
<li>再路由器的路由表中也必须有子网掩码，如果一个网络不划分子网，那么该网络的子网掩码就使用默认子网掩码</li>
<li>子网掩码是一个网络或一个子网的重要属性</li>
<li>划分子网增加了灵活性，但却减少了能够连接在网络上的主机总机数</li>
<li>相同的IP地址和不同的子网掩码可以得到相同的网络地址</li>
</ul>
<h4 id="4-3-2-使用子网时分组的转发"><a href="#4-3-2-使用子网时分组的转发" class="headerlink" title="4.3.2 使用子网时分组的转发"></a>4.3.2 使用子网时分组的转发</h4><ul>
<li>路由表中必须包含：目的网络四肢，子网掩码，下一跳地址</li>
<li>划分子网的情况下，路由器转发分组的算法:<br>（1）从收到的IP数据报的首部提取目的IP地址D<br>（2）先判断是否为直接交付，否则执行（3）<br>（3）若路由表中有目的地址为D的特定主机路由，则把数据报传送给路由器中所指明的下一跳路由器，否则执行（4）<br>（4）对路由表中的每一行，用其中的子网码和D逐位相“与”，其结果为N。若N与该行的目的地址匹配，则把数据报传送给该行指明的下一跳路由器；否则执行（5）<br>（5）若路由器中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；否则执行（6）<br>（6）报告转发分组出错</li>
</ul>
<h4 id="4-3-3-无分类编址CIDR（构造超网）"><a href="#4-3-3-无分类编址CIDR（构造超网）" class="headerlink" title="4.3.3 无分类编址CIDR（构造超网）"></a>4.3.3 无分类编址CIDR（构造超网）</h4><ol>
<li>网络前缀</li>
</ol>
<ul>
<li>IPv4地址空间不够，IPv6出现</li>
<li>使用变长子网掩码VLSM</li>
<li>无分类域间路由选择CIDR：<br>（1）消除了传统的ABC类地址以及划分子网的概念，更能有效的分配地址空间。CIDR将地址空间分为前后两部分，前部分是网络前缀，用来指明网络，后面部分指明主机。CIDR使用斜线记法，在IP地址后面加一斜线，后面写网络前缀所占的位数<br>（2）CIDR把网络前缀都相同的连续的IP地址组成一个“CIDR地址块”，CIDR使用32为的地址掩码，例如：/20地址块的地址掩码是：11111111 11111111 11110000 0000000（即斜线后的数字是地址掩码中1的个数）</li>
<li>由于CIDR地址块中有很多地址，所以在路由表中就利用CIDR地址块来查找目的网络。这种地址的聚合常称为路由聚合。</li>
<li>除个别外，每一个CIDR地址块都包含了多个c类地址，这就是构成超网</li>
<li>网络前缀越短，其地址块中包含的地址数就越多</li>
</ul>
<ol start="2">
<li>最长前缀匹配</li>
</ol>
<ul>
<li>在查找路由表时，应当从匹配结果中选择出具有最长网络前缀的路由。</li>
</ul>
<ol start="3">
<li>使用二叉线索查找路由表</li>
</ol>
<h3 id="4-4网际控制报文协议ICMP"><a href="#4-4网际控制报文协议ICMP" class="headerlink" title="4.4网际控制报文协议ICMP"></a>4.4网际控制报文协议ICMP</h3><ul>
<li>为了更有效的转发IP数据报和提高交付成功的机会，在网际层使用了网际控制报文协议ICMP</li>
<li>ICMP允许主机或路由器报告差错情况和提供异常情况的报告</li>
</ul>
<h4 id="4-4-1-ICMP报文的种类"><a href="#4-4-1-ICMP报文的种类" class="headerlink" title="4.4.1 ICMP报文的种类"></a>4.4.1 ICMP报文的种类</h4><ul>
<li>ICMP报文有两种，即ICMP差错报告报文，ICMP询问报文</li>
<li>ICMP差错报告报文的类型：<br>（1）终点不可达<br>（2）时间超过<br>（3）参数问题<br>（4）改变路由（重定向）</li>
<li>ICMP询问报文的类型：<br>（1）回送请求和回答<br>（2）时间戳请求和回答</li>
</ul>
<h4 id="4-4-2-ICMP的应用举例"><a href="#4-4-2-ICMP的应用举例" class="headerlink" title="4.4.2 ICMP的应用举例"></a>4.4.2 ICMP的应用举例</h4><ul>
<li>ICMP的一个重要应用就是分组间探测PING，用来测试两台主机之间的连通性</li>
<li>ping使用了ICMP回送请求与回送回答报文</li>
<li>traceroute/tracert</li>
</ul>
<h3 id="4-5-互联网的路由选择协议"><a href="#4-5-互联网的路由选择协议" class="headerlink" title="4.5 互联网的路由选择协议"></a>4.5 互联网的路由选择协议</h3><h4 id="4-5-1-有关路由选择协议的几个基本概念"><a href="#4-5-1-有关路由选择协议的几个基本概念" class="headerlink" title="4.5.1 有关路由选择协议的几个基本概念"></a>4.5.1 有关路由选择协议的几个基本概念</h4><ol>
<li>理想的路由算法<br>（1）算法必须是正确的和完整的<br>（2）算法在计算上应简单<br>（3）算法应能适应通信量和网络拓扑的变化<br>（4）算法应具有稳定性<br>（5）算法应是公平的<br>（6）算法应是最佳的</li>
</ol>
<ul>
<li>从路由算法能否随网络的通信量或拓扑自适应地进行调整变化来划分，则只有两大类，即静态路由选择策略（非自适应路由选择）和动态路由选择策略（自适应路由选择）。</li>
</ul>
<ol start="2">
<li>分层次的路由选择协议</li>
</ol>
<ul>
<li>互联网采用的路由选择协议主要是自适应，分布式路由选择协议</li>
<li>自治系统AS：在单一技术管理下的一组路由器，这些路由器使用一种自治系统内部的路由选择协议和共同的度量。</li>
<li>一个AS对其他的AS表现出的是一个单一的和一致的路由选择策略</li>
<li>互联网把路由选择协议划分为两大类：<ul>
<li>内部网关协议IGP（AS内部）：包括RIP，OSPF</li>
<li>外部网关协议EGP（AS之间）：例如：BGP</li>
</ul>
</li>
</ul>
<h4 id="4-5-2-内部网关协议RIP"><a href="#4-5-2-内部网关协议RIP" class="headerlink" title="4.5.2 内部网关协议RIP"></a>4.5.2 内部网关协议RIP</h4><ol>
<li>工作原理：</li>
</ol>
<ul>
<li>RIP是一种分布式的<strong>基于距离向量的路由选择协议</strong></li>
<li>RIP协议要求网络中的每一个路由器都要维护从它自己到其他每一各目的网络的<strong>距离记录</strong>：<ul>
<li>从一路由器到直接连接的网络的距离定义为1</li>
<li>从一路由器到非直接连接的网络的距离定义为所经过的路由器数加1</li>
<li>RIP协议的“距离”也称为“跳数”，只适用于小型的互联网</li>
</ul>
</li>
<li>RIP协议的特点：<br>（1）仅和相邻路由器交换信息<br>（2）路由器交换的信息是当前本路由器所知道的全部信息，即自己现在的路由表<br>（3）按固定的时间间隔交换路由信息</li>
<li>路由器再刚刚开始工作时，它的路由表是空的，然后路由器就得出到直接相连的几个网络的距离。接着每一个路由器也之和数目非常有限的相邻路由器交换，并更新路由信息</li>
<li>“收敛”：在自治系统中所有的结点都得到正确的路由选择信息的过程</li>
<li>路由表更新的言责是找出到每一个目的网络的最短距离。这种更新算法又称为距离向量算法。</li>
</ul>
<ol start="2">
<li><p>距离向量算法<br>路由器收到相邻路由器（其地址为 X）的一个 RIP 报文：<br>(1) 先修改此 RIP 报文中的所有项目：把“下一跳”字段中的地址都改为 X，并把所有的“距离”字段的值加 1。<br>(2) 对修改后的 RIP 报文中的每一个项目，重复以下步骤：<br>  若项目中的目的网络不在路由表中，则把该项目加到路由表中。</p>
<pre><code>  否则
      若下一跳字段给出的路由器地址是同样的，则把收到的项目替换原路由表中的项目。
         否则 
             若收到项目中的距离小于路由表中的距离，则进行更新，
       否则，什么也不做。
</code></pre>
<p>(3) 若 3 分钟还没有收到相邻路由器的更新路由表，则把此相邻路由器记为不可达路由器，即将距离置为 16（表示不可达）。<br>(4) 返回。</p>
</li>
<li><p>RIP协议的报文格式</p>
</li>
</ol>
<ul>
<li>RIP协议使用运输层的用户数据报UDP进行传送</li>
<li>RIP报文由<strong>首部</strong>和<strong>路由</strong>部分组成</li>
<li>问题：<strong>当网络出现故障时，要经过比较长度的时间才能将此信息传送到所有的路由器</strong></li>
<li>特点：好消息传播的快，坏消息传播的慢</li>
<li>优点：是实现简单，开销较小</li>
</ul>
<h4 id="4-5-3-内部网关协议OSPF"><a href="#4-5-3-内部网关协议OSPF" class="headerlink" title="4.5.3 内部网关协议OSPF"></a>4.5.3 内部网关协议OSPF</h4><ol>
<li>OSPF协议的基本特点：</li>
</ol>
<ul>
<li><p>开放最短路径优先OSPF：使用了Dijkstra提出的最短路径算法SPF</p>
</li>
<li><p>OSPF只是一个协议的名字，它并不表示其他的路由选择协议不是“最短路径优先”</p>
</li>
<li><p>OSPF最主要的特征是使用分布式的<strong>链路状态协议</strong><br>（1）向本自治系统中所有路由器发送信息，洪泛法（RIP只相自己相邻的路由器发送信息）<br>（2）发送的信息就是与本路由器相邻的所有路由器的<strong>链路状态</strong>（与哪些路由器相邻+度量）<br>（3）只有当链路状态发生变化时，路由器才向所有路由器用洪泛法发送此信息</p>
</li>
<li><p>所有的路由器最终都能建立一个<strong>链路状态数据库</strong>，这个数据库实际上就是<strong>全网的拓扑结构图</strong>，这个拓扑结构图在全网范围内是一致的（链路状态数据库的同步）</p>
</li>
<li><p>OSPF的更新过程收敛快—-优点</p>
</li>
<li><p>OSPF将一个自治系统划分为若干个<strong>区域</strong></p>
</li>
<li><p>主干区域，区域边界路由器（R3，R4，R7），主干路由器（R3，R4，R5，R6，R7），自治系统边界路由器（R6）</p>
</li>
<li><p>OSPF不用UDP而是直接用IP数据报传送</p>
</li>
<li><p>OSPF首部各字段意义：<br>（1）版本<br>（2）类型<br>（3）分组长度<br>（4）路由器标识符<br>（5）区域标识符<br>（6）检验和<br>（7）鉴别类型<br>（8）鉴别</p>
</li>
<li><p>OSPF的特点：<br>（1）OSPF对于不同类型的业务看计算出不同的路由<br>（2）负载平衡<br>（3）鉴别<br>（4）OSPF支持CIDR<br>（5）OSPF让每一个链路状态带上序号，序号越大，状态越新</p>
</li>
</ul>
<ol start="2">
<li>OSPF的五种分组类型<br>（1）类型1，问候 (Hello) 分组。<br>（2）类型2，数据库描述 (Database Description) 分组。<br>（3）类型3，链路状态请求 (Link State Request) 分组。<br>（4）类型4，链路状态更新 (Link State Update) 分组，<pre><code>         用洪泛法对全网更新链路状态。
</code></pre>
（5）类型5，链路状态确认 (Link State Acknowledgment)<pre><code>          分组。 
</code></pre>
</li>
</ol>
<ul>
<li>OSPF采用的是可靠的洪泛法（收到更新分组后要发送确认）</li>
<li>OSPF每隔一段时间要刷新一次数据库中的链路状态</li>
<li>OSPF协议对多点接入的局域网采用了<strong>指定的路由器</strong>的方法</li>
</ul>
<h4 id="4-5-4-外部网关协议BGP"><a href="#4-5-4-外部网关协议BGP" class="headerlink" title="4.5.4 外部网关协议BGP"></a>4.5.4 外部网关协议BGP</h4><ul>
<li>内部网关协议主要是设法使数据报在<strong>一个AS中</strong>尽可能有效地从源站传送到目的站</li>
<li>使用BGP的原因：<br>（1）<strong>互联网的规模太大，使得自治系统AS之间路由选择非常困难</strong><br>（2）<strong>自治系统AS之间的路由选择必须考虑有关策略</strong></li>
<li>边界网关协议BGP只能是力求寻找一条能够到达目的网络且<strong>比较好</strong>的路由，而<strong>并非要寻找一条最佳路由</strong></li>
<li>BGP采用了<strong>路径向量路由选择协议</strong></li>
<li>BGP发言人与其他AS的BGP发言人要交换路由信息，就要先建立TCP连接，然后在此连接上交换BGP报文以建立<strong>BGP会话</strong>，利用BGP会话交换路由信息。</li>
<li>使用TCP连接交换路由信息的两个BGP发言人彼此成为对方发邻站或对等站</li>
<li>BGP报文：OPEN，UPDATE，KEEPALIVE，NOTIFICATION</li>
</ul>
<h4 id="4-5-5-路由器的构成"><a href="#4-5-5-路由器的构成" class="headerlink" title="4.5.5 路由器的构成"></a>4.5.5 路由器的构成</h4><ol>
<li>路由器的结构</li>
</ol>
<ul>
<li><p>路由器是一种具有多个输入端口和多个输出端口的专用计算机，其任务是转发分组，按照分组要去的目的地，从合适的端口转发给下一跳路由器。</p>
</li>
<li><p>路由器的转发分组正是网络层的主要工作</p>
</li>
<li><p>路由器结构划分为两大部分：<br>（1）<strong>路由选择部分</strong>：控制部分，核心构件是路由选择处理机，任务：①根据路由选择协议构造路由表②不断更新和维护路由表<br>（2）<strong>分组转发部分</strong>：由三部分组成：交换结构，一组输入端口，一组输出端口，</p>
</li>
<li><p>路由器的作用： 连接不同的网络</p>
</li>
</ul>
<ol start="2">
<li>交换结构</li>
</ol>
<ul>
<li>也叫（交换组织），作用：根据<strong>转发表</strong>对分组进行处理，从合适的端口转发出去。</li>
<li>路由表是根据路由选择算法得出，而转发表是从路由表得出的</li>
<li>输入端口中的查找和转发功能在路由器的交换功能中是最重要的。</li>
<li>路由器的端口收到分组时，就用中断方式通知路由选择处理机</li>
<li>路由器中的输入或输出队列产生溢出是造成分组丢失的重要原因。</li>
<li>通过存储器</li>
<li>通过总线</li>
<li>通过纵横交换结构</li>
</ul>
<h3 id="4-6-IPv6"><a href="#4-6-IPv6" class="headerlink" title="4.6 IPv6"></a>4.6 IPv6</h3><ul>
<li>双栈协议：IPv4向IPv6过渡</li>
<li>隧道技术</li>
</ul>
<h4 id="4-6-1-IPv6的基本首部"><a href="#4-6-1-IPv6的基本首部" class="headerlink" title="4.6.1 IPv6的基本首部"></a>4.6.1 IPv6的基本首部</h4><ul>
<li>变化：<br>（1）更大的地址空间，128位<br>（2）扩展的地址层次结构<br>（3）灵活的首部格式<br>（4）改进的选项<br>（5）允许协议继续扩充<br>（6）支持即插即用<br>（7）支持资源的预分配<br>（8）IPv6首部改为8字节对齐</li>
<li>IPv6数据报由两大部分组成：基本首部和有效载荷（净负荷）</li>
<li>IPv6 把原来 IPv4 首部中选项的功能都放在<strong>扩展首部</strong>中，并将扩展首部留给路径两端的源站和目的站的主机来处理。</li>
<li>数据报途中经过的路由器都不处理这些扩展首部（只有一个首部例外，即逐跳选项扩展首部）。</li>
<li>这样就大大提高了路由器的处理效率。 </li>
</ul>
<h4 id="4-6-2-IPv6的地址"><a href="#4-6-2-IPv6的地址" class="headerlink" title="4.6.2 IPv6的地址"></a>4.6.2 IPv6的地址</h4><ul>
<li>单播</li>
<li>多播</li>
<li>任播</li>
<li>IPv6 将实现 IPv6 的主机和路由器均称为<strong>结点</strong>。</li>
<li>一个结点就可能有多个与链路相连的接口。<br>IPv6 地址是分配给结点上面的接口的。<ul>
<li>一个接口可以有多个单播地址。</li>
<li>其中的任何一个地址都可以当作到达该结点的目的地址。即<strong>一个结点接口的单播地址可用来唯一地标志该结点</strong>。</li>
</ul>
</li>
<li>为了使地址再稍简洁些，IPv6 使用冒号十六进制记法</li>
<li>冒号十六进制记法可以允许零压缩 (zero compression)，即一连串连续的零可以为一对冒号所取代。<br>  FF05:0:0:0:0:0:0:B3    可压缩为：<br>  FF05::B3</li>
<li>注意：在任一地址中只能使用一次零压缩。</li>
</ul>
<h3 id="4-7-多播"><a href="#4-7-多播" class="headerlink" title="4.7 多播"></a>4.7 多播</h3><h3 id="4-8-虚拟专用网和网络地址转换NAT"><a href="#4-8-虚拟专用网和网络地址转换NAT" class="headerlink" title="4.8 虚拟专用网和网络地址转换NAT"></a>4.8 虚拟专用网和网络地址转换NAT</h3><h3 id="4-9-多协议标记交换MPLS"><a href="#4-9-多协议标记交换MPLS" class="headerlink" title="4.9 多协议标记交换MPLS"></a>4.9 多协议标记交换MPLS</h3><h2 id="第五章-运输层"><a href="#第五章-运输层" class="headerlink" title="第五章 运输层"></a>第五章 运输层</h2><h3 id="5-1-运输层协议概述"><a href="#5-1-运输层协议概述" class="headerlink" title="5.1 运输层协议概述"></a>5.1 运输层协议概述</h3><h4 id="5-1-1-进程之间的通信"><a href="#5-1-1-进程之间的通信" class="headerlink" title="5.1.1 进程之间的通信"></a>5.1.1 进程之间的通信</h4><ul>
<li><strong>运输层向它上面的应用层提供通信服务</strong></li>
<li>它属于<strong>面向通信部分的最高层</strong>，同时也是<strong>用户功能的最低层</strong></li>
<li>当网络的边缘部分中的两个主机使用网络的核心部分的功能进行端到端的通信时，只有位于网络边缘部分的主机的协议栈才有运输层，而网络核心部分中的路由器在转发分组时都只用到下三层的功能。 </li>
<li>从IP层来说，通信的两端是两台主机，但是严格来说，真正进行通信的实体是在主机中的进程（运输层）</li>
<li>网络层是为主机之间提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信</li>
<li>在一台主机中经常有<strong>多个应用进程</strong>同时分别和另一台主机中的多个应用进程通信。</li>
<li>这表明运输层有一个很重要的功能——<strong>复用</strong> (multiplexing)和<strong>分用</strong> (demultiplexing)。</li>
<li>根据应用程序的不同需求，运输层需要有两种不同的运输协议，即<strong>面向连接的 TCP</strong> 和<strong>无连接的 UDP</strong> 。</li>
<li>运输层向高层用户<strong>屏蔽</strong>了下面网络核心的细节（如网络拓扑、所采用的路由选择协议等），它使应用进程<strong>看见的就是好像</strong>在两个运输层实体之间有一条端到端的逻辑通信信道。</li>
<li>当运输层采用<strong>面向连接的 TCP 协议</strong>时，尽管<strong>下面的网络是不可靠</strong>的（只提供<strong>尽最大努力服务</strong>），但这种逻辑通信信道就<strong>相当于</strong>一条<strong>全双工的可靠信道</strong>。</li>
<li>当运输层采用<strong>无连接的 UDP 协议</strong>时，这种逻辑通信信道是一条<strong>不可靠信道</strong>。</li>
</ul>
<h4 id="5-1-2-运输层的两个主要协议"><a href="#5-1-2-运输层的两个主要协议" class="headerlink" title="5.1.2 运输层的两个主要协议"></a>5.1.2 运输层的两个主要协议</h4><ul>
<li>TCP/IP 的运输层有两个主要协议：<br>(1) <strong>用户数据报协议 UDP</strong> (User Datagram Protocol)<br>(2) <strong>传输控制协议 TCP</strong> (Transmission Control Protocol)</li>
<li>两个对等运输实体在通信时传送的数据单位叫作<strong>运输协议数据单元 TPDU</strong> </li>
<li>TCP 传送的数据单位协议是 <strong>TCP 报文段</strong></li>
<li> UDP 传送的数据单位协议是 <strong>UDP 报文</strong>或<strong>用户数据报</strong>。 </li>
<li>UDP：传输前不需要建立连接，不可靠</li>
<li>TCP：传输数据前建立连接，传输后释放，其下网络是不可靠的，但是TCP提供可靠的面向连接的运输服务，TCP不提供广播，多播服务</li>
</ul>
<h4 id="5-1-3-运输层的端口"><a href="#5-1-3-运输层的端口" class="headerlink" title="5.1.3 运输层的端口"></a>5.1.3 运输层的端口</h4><ul>
<li>复用：应用层所有的应用进程都可以通过运输层再传送到IP层</li>
<li>分用：运输层从IP层收到发送给个应用进程的数据后，必须分别交付指明的各应用进程</li>
<li>运行在计算机中的进程是用<strong>进程标识符</strong>来标志的。</li>
<li><u>但运行在应用层的各种应用进程却不应当让计算机操作系统指派它的进程标识符</u>。这是因为在互联网上使用的计算机的操作系统种类很多，而<strong>不同的操作系统又使用不同格式的进程标识符</strong>。</li>
<li>为了<strong>使运行不同操作系统的计算机的应用进程能够互相通信</strong>，就必须用统一的方法对 TCP/IP 体系的应用进程进行标志。 即使用<strong>协议端口号</strong></li>
<li>在协议栈层间的抽象的协议端口是<strong>软件端口</strong>。<br>路由器或交换机上的端口是<strong>硬件端口</strong>。</li>
<li>端口号只具有<strong>本地意义</strong>，即端口号只是为了标志<strong>本计算机应用层中的各进程</strong></li>
<li>由此可见，两个计算机中的进程要互相通信，不仅必须知道对方的 <strong>IP 地址</strong>（为了找到对方的<u>计算机</u>），而且还要知道对方的<strong>端口号</strong>（为了找到对方计算机中的<u>应用进程</u>）。</li>
</ul>
<h3 id="5-2-用户数据报协议UDP"><a href="#5-2-用户数据报协议UDP" class="headerlink" title="5.2 用户数据报协议UDP"></a>5.2 用户数据报协议UDP</h3><h4 id="5-2-1-UDP概述"><a href="#5-2-1-UDP概述" class="headerlink" title="5.2.1 UDP概述"></a>5.2.1 UDP概述</h4><ul>
<li>UDP具有复用，分用，差错检验的功能</li>
<li>UDP的特点：<br>(1) <strong>UDP 是无连接的</strong>，发送数据之前不需要建立连接，因此减少了开销和发送数据之前的时延。<br>(2) <strong>UDP 使用尽最大努力交付</strong>，即不保证可靠交付，因此主机不需要维持复杂的连接状态表。<br>(3) <strong>UDP 是面向报文的</strong>。UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。<u>UDP 一次交付一个完整的报文</u>。<br>(4) <strong>UDP 没有拥塞控制</strong>，因此网络出现的拥塞不会使源主机的发送速率降低。这对某些实时应用是很重要的。很适合多媒体通信的要求。 选择合适大小的报文<br>(5) <strong>UDP 支持一对一、一对多、多对一和多对多的交互通信</strong>。<br>(6) <strong>UDP 的首部开销小</strong>，只有 8 个字节，比 TCP 的 20 个字节的首部要短。</li>
</ul>
<h4 id="5-2-2-UDP的首部格式"><a href="#5-2-2-UDP的首部格式" class="headerlink" title="5.2.2 UDP的首部格式"></a>5.2.2 UDP的首部格式</h4><ul>
<li>首部字段很简单，只有8个字节（4个字段，每个字段2个字节）：<br>（1）源端口<br>（2）目的端口<br>（3）长度<br>（4）检验和</li>
<li>计算检验和时，再UDP用户数据报之前增加12个字节的伪首部（仅用于计算检验和）</li>
<li>IP数据报的检验和<strong>只检验IP数据报的首部</strong>，而UDP的检验和是<strong>把首部和数据部分一起都检验</strong></li>
</ul>
<h3 id="5-3-传输控制协议TCP概述"><a href="#5-3-传输控制协议TCP概述" class="headerlink" title="5.3 传输控制协议TCP概述"></a>5.3 传输控制协议TCP概述</h3><h4 id="5-3-1-TCP最主要的特点"><a href="#5-3-1-TCP最主要的特点" class="headerlink" title="5.3.1 TCP最主要的特点"></a>5.3.1 TCP最主要的特点</h4><p>（1）<strong>TCP 是面向连接的运输层协议</strong>。<br>（2）每一条 TCP 连接<strong>只能有两个端点</strong> ，每一条 TCP 连接只能是<strong>点对点</strong>的（一对一）。<br>（3）TCP 提供<strong>可靠交付</strong>的服务。<br>（4）TCP 提供<strong>全双工通信</strong>。<br>（5）<strong>面向字节流</strong></p>
<ul>
<li>TCP 中的“流”(stream)指的是流入或流出进程的字节序列。</li>
<li>“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块，但 TCP 把应用程序交下来的数据看成仅仅是一连串无结构的字节流。</li>
<li>TCP 连接是一条虚连接而不是一条真正的物理连接</li>
<li>TCP不关心应用进程一次把多长的报文发送到TCP的缓存中</li>
<li>TCP 根据对方给出的<strong>窗口值</strong>和<strong>当前网络拥塞的程度</strong>来决定一个报文段应包含多少个字节（UDP 发送的报文长度是应用进程给出的）</li>
</ul>
<h4 id="5-3-2-TCP的连接"><a href="#5-3-2-TCP的连接" class="headerlink" title="5.3.2 TCP的连接"></a>5.3.2 TCP的连接</h4><ul>
<li>TCP 把连接作为<strong>最基本的抽象</strong>。</li>
<li>每一条 TCP 连接有<strong>两个端点</strong>。</li>
<li>TCP 连接的端点不是主机，不是主机的IP 地址，不是应用进程，也不是运输层的协议端口。</li>
<li>TCP 连接的端点叫做<strong>套接字</strong> (socket) 或插口。</li>
<li><strong>端口号拼接到 (contatenated with) IP 地址即构成了套接字</strong>。   </li>
<li>套接字socket = （IP地址：端口）</li>
<li>每一条TCP连接<strong>唯一</strong>地被通信两端的<strong>两个端点</strong>（两个套接字）</li>
<li>TCP 连接 ::= {socket1, socket2} = {(IP1: port1)，(IP2: port2)}</li>
<li>TCP 连接的端点是个很抽象的套接字，即（IP 地址：端口号）。</li>
<li>同一个 IP 地址可以有多个不同的 TCP 连接。</li>
<li>同一个端口号也可以出现在多个不同的 TCP 连接中。</li>
<li>同一个名词socket可以表示多种不同的意思</li>
</ul>
<h3 id="可靠传输的工作原理"><a href="#可靠传输的工作原理" class="headerlink" title="可靠传输的工作原理"></a>可靠传输的工作原理</h3><ul>
<li>理想的传输条件有以下两个特点：<br>(1) 传输信道不产生差错。<br>(2) 不管发送方以多快的速度发送数据，接收方总是来得及处理收到的数据。</li>
<li>然而实际的网络都不具备以上两个理想条件。必须使用一些可靠传输协议，在不可靠的传输信道实现可靠传输。</li>
</ul>
<h4 id="5-4-1-停止等待协议"><a href="#5-4-1-停止等待协议" class="headerlink" title="5.4.1 停止等待协议"></a>5.4.1 停止等待协议</h4><ul>
<li>停止等待：每发送完一个分组就通知发送，等待对方的确认。在收到确认后再发送下一个分组</li>
</ul>
<ol>
<li>无差错情况</li>
<li>出现差错</li>
</ol>
<ul>
<li>在接收方 B 会出现两种情况：<ul>
<li>B 接收 M1 时检测出了差错，就丢弃 M1，其他什么也不做（不通知 A 收到有差错的分组）。</li>
<li>M1 在传输过程中丢失了，这时 B 当然什么都不知道，也什么都不做。</li>
</ul>
</li>
<li>在这两种情况下，B 都不会发送任何信息。</li>
<li>如何保证 B 正确收到了 M1 呢？</li>
<li>解决方法：<strong>超时重传</strong><br>A 为每一个已发送的分组都设置了一个<strong>超时计时器</strong>。<br>A 只要在超时计时器到期之前收到了相应的确认，就撤销该超时计时器，继续发送下一个分组 M2 。</li>
<li>A需要暂时保留已发送的分组的副本，且必须有编号，并且超时计时器设置的重传时间应当比数据在分组传输的平均往返时间更长</li>
</ul>
<ol start="3">
<li>确认丢失和确认迟到</li>
</ol>
<ul>
<li>使用上述的确认和重传机制，我们可以<strong>在不可靠的传输网络上实现可靠的通信</strong>（自动重传请求ARQ）</li>
</ul>
<ol start="4">
<li>信道利用率</li>
</ol>
<ul>
<li>为了提高传输效率，发送方可以不使用低效率的停止等待协议，而是采用<strong>流水线传输</strong>。</li>
<li><strong>流水线传输</strong>就是发送方可连续发送多个分组，不必每发完一个分组就停顿下来等待对方的确认。这样可使信道上一直有数据不间断地传送。</li>
<li>由于信道上一直有数据不间断地传送，这种传输方式可获得很高的信道利用率。</li>
</ul>
<h4 id="5-4-2-连续ARQ协议"><a href="#5-4-2-连续ARQ协议" class="headerlink" title="5.4.2 连续ARQ协议"></a>5.4.2 连续ARQ协议</h4><ul>
<li>滑动窗口协议比较复杂，是 TCP 协议的精髓所在。</li>
<li>发送方维持的<strong>发送窗口</strong>，它的意义是：<strong>位于发送窗口内的分组都可连续发送出去，而不需要等待对方的确认</strong>。这样，信道利用率就提高了。</li>
<li>连续 ARQ 协议规定，发送方每收到一个<strong>确认</strong>，就把发送窗口向前<strong>滑动一个分组</strong>的位置。</li>
<li>接收方一般采用<strong>累积确认</strong>的方式。即不必对收到的分组逐个发送确认，而是<strong>对按序到达的最后一个分组发送确认</strong>，这样就表示：<u>到这个分组为止的所有分组都已正确收到了</u>。</li>
<li>优点：容易实现，即使确认丢失也不必重传。</li>
<li>缺点：不能向发送方反映出接收方已经正确收到的所有分组的信息。</li>
<li>如果发送方发送了前 5 个分组，而中间的第 3 个分组丢失了。这时接收方只能对前两个分组发出确认。发送方无法知道后面三个分组的下落，而只好把后面的三个分组都再重传一次。这就叫做 <strong>Go-back-N</strong> （回退 N），<u>表示需要再退回来重传已发送过的 N 个分组</u>。</li>
</ul>
<h3 id="5-5-TCP报文段的首部格式"><a href="#5-5-TCP报文段的首部格式" class="headerlink" title="5.5 TCP报文段的首部格式"></a>5.5 TCP报文段的首部格式</h3><ul>
<li>TCP 虽然是面向字节流的，但 TCP 传送的数据单元却是<strong>报文段</strong>。</li>
<li>一个 TCP 报文段分为<strong>首部</strong>和<strong>数据</strong>两部分，而 TCP 的全部功能都体现在它首部中各字段的作用。</li>
<li>TCP 报文段首部的前 20 个字节是固定的，后面有 4n 字节是根据需要而增加的选项 (n 是整数)。因此 TCP 首部的最小长度是 20 字节。</li>
<li>首部固定部分各字段的意义：<br>（1）源端口和目的端口<br>（2）序号：报文段序号，每一个字节按顺序编号<br>（3）确认号：期望收到对方下一个报文段的第一个数据字节的序号<br>（4）数据偏移：<br>（5）保留：<br>（6）紧急URG：为1时，表示紧急<br>（7）确认ACK：为1确认号字段有效<br>（8）推送PSH：<br>（9）复位RST<br>（10）同步SYN<br>（11）终止FIN<br>（12）窗口：窗口值作为接收方让发送方设置器发送窗口的依据<br>（13）检验和<br>（14）紧急指针<br>（15）选项：①<strong>最大报文段长度MSS</strong>，每一个TCP报文段中的<strong>数据字段的最大长度</strong><br>②窗口扩大选项③时间戳选项④选择确认选项</li>
</ul>
<h3 id="5-6-TCP可靠传输的实现"><a href="#5-6-TCP可靠传输的实现" class="headerlink" title="5.6 TCP可靠传输的实现"></a>5.6 TCP可靠传输的实现</h3><h4 id="5-6-1-TCP以字节为单位的滑动窗口"><a href="#5-6-1-TCP以字节为单位的滑动窗口" class="headerlink" title="5.6.1 TCP以字节为单位的滑动窗口"></a>5.6.1 TCP以字节为单位的滑动窗口</h4><ul>
<li>根据 B 给出的窗口值，A 构造出自己的发送窗口。</li>
<li>发送窗口表示：在没有收到 B 的确认的情况下，A 可以连续把窗口内的数据都发送出去。 </li>
<li>发送窗口里面的序号表示允许发送的序号。</li>
<li>显然，窗口越大，发送方就可以在收到对方确认之前连续发送更多的数据，因而可能获得更高的传输效率。</li>
<li>描述发送窗口的状态：需要三个指针，p1，p2，p3，指针都指向序号</li>
<li><strong>收到确认后，发送窗口向前滑动</strong></li>
<li>A 的发送窗口内的序号都已用完，但还没有再收到确认，必须<strong>停止发送</strong>。 </li>
<li>发送窗口中的序号全是发送未确认的或未发送的</li>
<li>发送窗口只是发送缓存中的一部分</li>
<li><strong>发送缓存</strong>用来暂时存放：<ul>
<li>发送应用程序传送给发送方 TCP 准备发送的数据；</li>
<li>TCP 已发送出但尚未收到确认的数据。</li>
</ul>
</li>
<li><strong>接收缓存</strong>用来暂时存放：<ul>
<li>按序到达的、但尚未被接收应用程序读取的数据；</li>
<li>不按序到达的数据。 </li>
</ul>
</li>
<li>注意：<br>（1）第一，A 的发送窗口<strong>并不总是</strong>和 B 的接收窗口一样大（因为有一定的<strong>时间滞后</strong>）。<br>（2）第二，TCP 标准<strong>没有规定</strong>对不按序到达的数据应如何处理。通常是先临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再按序交付上层的应用进程。<br>（3）第三，TCP 要求接收方必须有<strong>累积确认</strong>的功能，这样可以减小传输开销。  </li>
<li>TCP是全双工通信，每一方都有自己的发送窗口和接受窗口</li>
</ul>
<h4 id="5-6-2-超时重传时间的选择"><a href="#5-6-2-超时重传时间的选择" class="headerlink" title="5.6.2 超时重传时间的选择"></a>5.6.2 超时重传时间的选择</h4><ul>
<li><strong>重传机制</strong>是 TCP 中最重要和最复杂的问题之一。TCP 每发送一个报文段，就对这个报文段设置一次计时器。只要计时器设置的重传时间到但还没有收到确认，就要重传这一报文段。重传时间的选择是 TCP 最复杂的问题之一。</li>
<li>TCP 采用了一种<strong>自适应算法</strong>，它记录一个报文段发出的时间，以及收到相应的确认的时间。这两个时间之差就是<strong>报文段的往返时间 RTT</strong>。</li>
<li>TCP 保留了 RTT 的一个<strong>加权平均往返时间 RTTS</strong>（这又称为<strong>平滑的往返时间</strong>）。</li>
<li>第一次测量到 RTT 样本时，RTTS 值就取为所测量到的 RTT 样本值。以后每测量到一个新的 RTT 样本，就按下式重新计算一次 RTTS：</li>
<li><strong>超时重传时间RTO</strong> (Retransmission Time-Out) 应略大于上面得出的加权平均往返时间 RTTS。<br>RFC 2988 建议使用下式计算 RTO：</li>
<li>RTTD 是 RTT 的<strong>偏差</strong>的加权平均值。<br>RFC 2988 建议这样计算 RTTD。第一次测量时，RTTD 值取为测量到的 RTT 样本值的一半。在以后的测量中，则使用下式计算加权平均的 RTTD：<br>β 是个小于 1 的系数，其推荐值是 1/4，即 0.25。</li>
<li>Karn算法：<strong>在计算平均往返时间 RTT 时，只要报文段重传了，就不采用其往返时间样本</strong>，但是这又引起新的问题。当报文段的时延突然增大了很多时，在原来得出的重传时间内，不会收到确认报文段。于是就重传报文段。但根据 Karn 算法，不考虑重传的报文段的往返时间样本。这样，超时重传时间就无法更新报文段</li>
<li>修正后的Karn算法：<strong>报文段每重传一次，就把超时重传的时间RTO增大一点。典型的做法是取新的重传时间为原来的重传时间的2倍</strong>，当不再发生报文段的重传时，才根据报文段的往返时延更新平均往返时延 RTT 和超时重传时间 RTO 的数值。</li>
</ul>
<h4 id="5-6-3-选择确认SACK"><a href="#5-6-3-选择确认SACK" class="headerlink" title="5.6.3 选择确认SACK"></a>5.6.3 选择确认SACK</h4><ul>
<li>接收方收到了和前面的字节流不连续的两个字节块。如果这些字节的序号都在接收窗口之内，那么接收方就先收下这些数据，但要把这些信息准确地告诉发送方，使发送方不要再重复发送这些已收到的数据。</li>
</ul>
<h3 id="5-7-TCP流量控制"><a href="#5-7-TCP流量控制" class="headerlink" title="5.7 TCP流量控制"></a>5.7 TCP流量控制</h3><h4 id="5-7-1-利用滑动窗口实现流量控制"><a href="#5-7-1-利用滑动窗口实现流量控制" class="headerlink" title="5.7.1 利用滑动窗口实现流量控制"></a>5.7.1 利用滑动窗口实现流量控制</h4><ul>
<li>流量控制：<strong>让发送方的发送速率不要太快，要让接收方来得及接收</strong></li>
<li>可能出现<strong>死锁</strong>：B 向 A 发送了零窗口的报文段后不久，B 的接收缓存又有了一些存储空间。于是 B 向 A 发送了 rwnd = 400 的报文段。但这个报文段在传送过程中丢失了。A 一直等待收到 B 发送的非零窗口的通知，而 B 也一直等待 A 发送的数据。如果没有其他措施，这种互相等待的<strong>死锁</strong>局面将一直延续下去。</li>
<li>为了解决这个问题，TCP 为每一个连接设有一个<strong>持续计时器</strong> (persistence timer)。<br>只要 TCP 连接的一方收到对方的零窗口通知，就启动该持续计时器。<br>若持续计时器设置的时间到期，就发送一个<strong>零窗口探测报文段</strong>（仅携带 1 字节的数据），而对方就在确认这个探测报文段时给出了现在的窗口值。<ul>
<li>若窗口仍然是零，则收到这个报文段的一方就<strong>重新设置</strong>持续计时器。</li>
<li>若窗口不是零，则死锁的僵局就可以打破了。 </li>
</ul>
</li>
</ul>
<h4 id="5-7-2-TCP的传输效率"><a href="#5-7-2-TCP的传输效率" class="headerlink" title="5.7.2 TCP的传输效率"></a>5.7.2 TCP的传输效率</h4><ul>
<li>控制 TCP 报文段的发送时机:<br>（1）第一种机制是 TCP 维持一个变量，它等于<strong>最大报文段长度 MSS</strong>。只要缓存中存放的数据达到 MSS 字节时，就组装成一个 TCP 报文段发送出去。<br>（2）第二种机制是由发送方的<strong>应用进程指明</strong>要求发送报文段，即 TCP 支持的推送 (push)操作。<br>（3）第三种机制是发送方的一个<strong>计时器</strong>期限到了，这时就把当前已有的缓存数据装入报文段（但长度不能超过 MSS）发送出去。</li>
<li><strong>Nagle算法</strong>：<ul>
<li>若发送应用进程把要发送的数据逐个字节地送到 TCP 的发送缓存，则发送方就把第一个数据字节先发送出去，把后面到达的数据字节都<strong>缓存</strong>起来。</li>
<li>当发送方收到对第一个数据字符的确认后，再把发送缓存中的所有数据组装成一个报文段发送出去，同时继续对随后到达的数据进行缓存。</li>
<li>只有在收到对前一个报文段的确认后才继续发送下一个报文段。</li>
<li>当到达的数据已达到发送窗口大小的一半或已达到报文段的最大长度时，就立即发送一个报文段。</li>
</ul>
</li>
<li>糊涂窗口综合征：接收方缓存已满，应用程序一次只读取一个，导致发送方每次只发送一个字节数据，效率降低<ul>
<li>解决方法：让接收方等待一段时间，使得接收缓存已有足够空间容纳一个最长的报文段，或等待接收缓存已有一半空闲空间，只要出现这两种情况之一，接收方就发出确认报文，并向发送方通知当前的窗口大小</li>
</ul>
</li>
</ul>
<h3 id="5-8-TCP的拥塞控制"><a href="#5-8-TCP的拥塞控制" class="headerlink" title="5.8 TCP的拥塞控制"></a>5.8 TCP的拥塞控制</h3><h4 id="5-8-1-拥塞控制的一般原理"><a href="#5-8-1-拥塞控制的一般原理" class="headerlink" title="5.8.1 拥塞控制的一般原理"></a>5.8.1 拥塞控制的一般原理</h4><ul>
<li><strong>拥塞</strong>：在某段时间，若对网络中某一资源的<strong>需求</strong>超过了该资源所提供的<strong>可用部分</strong>，网络性能变坏的情况</li>
<li>问题的<strong>实质</strong>是整个系统的各个部分（速率，缓存大小等）不匹配</li>
<li><strong>拥塞控制</strong>：<strong>防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载</strong></li>
<li>拥塞控制的前提：<strong>网络能够承受现有的网络负荷</strong>，这是一个<strong>全局性</strong>的过程</li>
<li>区分流量控制和拥塞控制：流量控制往往是指点对点通信量的控制，是端到端的问题</li>
<li>实践证明，拥塞控制是很难设计的，因为它是一个<strong>动态</strong>的（而不是静态的）问题。</li>
<li>当前网络正朝着高速化的方向发展，这很容易出现缓存不够大而造成分组的丢失。但分组的丢失是网络发生拥塞的<strong>征兆</strong>而不是原因。</li>
<li>在许多情况下，甚至正是拥塞控制本身成为引起网络性能恶化甚至发生死锁的原因。这点应特别引起重视。 </li>
<li>分类：<ul>
<li><strong>开环控制</strong>方法就是在设计网络时事先将有关发生拥塞的因素考虑周到，力求网络在工作时不产生拥塞。 </li>
<li><strong>闭环控制</strong>方法是基于反馈环路的概念。属于闭环控制的有以下几种措施：<br>(1) 监测网络系统以便检测到拥塞在何时、何处发生。<br>(2) 将拥塞发生的信息传送到可采取行动的地方。<br>(3) 调整网络系统的运行以解决出现的问题。</li>
</ul>
</li>
</ul>
<h4 id="5-8-2-TCP的拥塞控制方法"><a href="#5-8-2-TCP的拥塞控制方法" class="headerlink" title="5.8.2 TCP的拥塞控制方法"></a>5.8.2 TCP的拥塞控制方法</h4><ul>
<li>TCP 采用<strong>基于窗口</strong>的方法进行<strong>拥塞控制</strong>。该方法属于<strong>闭环控制</strong>方法。</li>
<li>TCP发送方维持一个<strong>拥塞窗口 CWND</strong> (Congestion Window)拥塞窗口的大小取决于网络的拥塞程度，并且<strong>动态地</strong>在变化。</li>
<li>发送端利用拥塞窗口根据网络的拥塞情况调整发送的数据量。</li>
<li>所以，发送窗口大小不仅取决于接收方公告的接收窗口，还取决于网络的拥塞状况</li>
<li>判断网络拥塞的依据是出现<strong>超时</strong></li>
<li>TCP进行拥塞控制的算法：<strong>慢开始，拥塞避免，快重传，快恢复</strong></li>
</ul>
<ol>
<li>慢开始和拥塞避免</li>
</ol>
<ul>
<li>慢开始算法：当主机开始发送数据时，由于并不清楚网络的负荷情况，所以如果立即把大量数据字节注入到网络，那么就有可能引起网络发生拥塞，经验证明，较好的方法是先探测以下，即<strong>由小到大逐渐增大发送窗口</strong>，也就是说，<strong>由小到大逐渐增大拥塞窗口数值</strong></li>
<li>慢开始规定，在每收到一个<strong>对新的报文段的确认</strong>后，可以把拥塞窗口增加最多一个SMSS（发送方的最大报文段）的数值。<br>拥塞窗口CWND每次的增加量：min（N，SMSS）</li>
<li>使用慢开始算法后，每经过一个<strong>传输轮次</strong> (transmission round)，拥塞窗口 cwnd 就加倍。 </li>
<li>一个<strong>传输轮次</strong>所经历的时间其实就是<strong>往返时间 RTT</strong>。</li>
<li>“传输轮次”更加强调：把拥塞窗口 cwnd 所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。</li>
<li>例如，拥塞窗口 cwnd = 4，这时的往返时间 RTT 就是发送方连续发送 4 个报文段，并收到这 4 个报文段的确认，总共经历的时间。 </li>
<li><strong>慢开始门限 ssthresh</strong> 的用法如下：<ul>
<li>当 cwnd &lt; ssthresh 时，使用慢开始算法。</li>
<li>当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。</li>
<li>当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞避免算法。</li>
</ul>
</li>
<li><strong>拥塞避免</strong>算法：让<strong>拥塞窗口 cwnd 缓慢地增大</strong>，即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 加 1，而不是加倍，使拥塞窗口 cwnd 按<strong>线性规律缓慢增长</strong>。</li>
<li>因此在拥塞避免阶段就有“<strong>加法增大</strong>”  (Additive Increase) 的特点。这表明在拥塞避免阶段，拥塞窗口 cwnd 按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。</li>
</ul>
<ol start="2">
<li>快重传算法：</li>
</ol>
<ul>
<li>采用<strong>快重传FR</strong> (Fast Retransmission) 算法可以让发送方尽早知道发生了个别报文段的丢失。</li>
<li>快重传 算法首先要求接收方不要等待自己发送数据时才进行捎带确认，而是要<strong>立即发送确认</strong>，<u>即使收到了失序的报文段也要立即发出对已收到的报文段的重复确认</u></li>
<li>发送方只要一连收到三个重复确认，就知道接收方确实没有收到报文段，因而应当立即进行重传（即“快重传”），这样就不会出现超时，发送方也不就会误认为出现了网络拥塞。</li>
<li>使用快重传可以使整个网络的吞吐量提高约20%。 </li>
<li>不难看出，快重传并非取消重传计时器，而是在某些情况下可更早地重传丢失的报文段。 </li>
</ul>
<ol start="3">
<li>快恢复算法</li>
</ol>
<h4 id="5-8-3-主动队列管理"><a href="#5-8-3-主动队列管理" class="headerlink" title="5.8.3 主动队列管理"></a>5.8.3 主动队列管理</h4><h3 id="5-9-TCP的运输连接管理"><a href="#5-9-TCP的运输连接管理" class="headerlink" title="5.9 TCP的运输连接管理"></a>5.9 TCP的运输连接管理</h3><ul>
<li>TCP是面向连接的协议，运输连接是用来传送TCP报文的</li>
<li>运输连接有三个阶段：<ul>
<li>连接建立：采用C/S方式</li>
<li>数据传送</li>
<li>连接释放</li>
</ul>
</li>
</ul>
<h4 id="5-9-1-TCP的连接建立"><a href="#5-9-1-TCP的连接建立" class="headerlink" title="5.9.1 TCP的连接建立"></a>5.9.1 TCP的连接建立</h4><ul>
<li>TCP建立连接的过程叫做<strong>握手</strong></li>
<li>握手需要在客户和服务器之间交换三个 TCP 报文段。称之为<strong>三报文握手</strong>。</li>
<li>采用三报文握手主要是为了防止已失效的连接请求报文段突然又传送到了，因而产生错误。</li>
<li>一开始B的TCP服务器进程先创建传输控制块TCB，A的TCP客户进程也是首先创建传输控制模块TCB</li>
<li>A 的 TCP 向 B 发出连接请求报文段，其首部中的<strong>同步位 SYN = 1</strong>，并<strong>选择序号 seq = x</strong>，表明传送数据时的第一个数据字节的序号是 x。TCP规定SYN报文段不能携带数据，但要消耗一个序号</li>
<li>B 的 TCP 收到连接请求报文段后，如同意，则发回确认。<br>B 在<strong>确认报文段</strong>中应使 SYN = 1，使 ACK = 1，其确认号ack = x + 1，自己选择的序号 seq = y。</li>
<li>A 收到此报文段后向 B 给出确认，其 ACK = 1， 确认号 ack = y + 1。 A 的 TCP 通知上层应用进程，连接已经建立。   </li>
<li>B 的 TCP 收到主机 A 的确认后，也通知其上层应用进程：TCP 连接已经建立。</li>
</ul>
<h4 id="5-9-2-TCP的连接释放"><a href="#5-9-2-TCP的连接释放" class="headerlink" title="5.9.2 TCP的连接释放"></a>5.9.2 TCP的连接释放</h4><ul>
<li><p>数据传输结束后，通信的双方都可释放连接。</p>
</li>
<li><p>TCP 连接释放过程是<strong>四报文握手</strong>。</p>
</li>
<li><p>连接释放报文段首部的<strong>终止控制位</strong>FIN</p>
</li>
<li><p>数据传输结束后，通信的双方都可释放连接。</p>
</li>
<li><p> 现在 A 的应用进程先向其 TCP 发出连接释放报文段，并停止再发送数据，主动关闭 TCP连接。</p>
</li>
<li><p>A 把连接释放报文段首部的 FIN = 1，其序号seq = u，等待 B 的确认。</p>
</li>
<li><p>B 发出确认，确认号 ack = u + 1，而这个报文段自己的序号 seq = v。</p>
</li>
<li><p>TCP 服务器进程通知高层应用进程。</p>
</li>
<li><p>从 A 到 B 这个方向的连接就释放了，TCP 连接处于半关闭状态。B 若发送数据，A 仍要接收。</p>
</li>
<li><p>若 B 已经没有要向 A 发送的数据，其应用进程就通知 TCP 释放连接。 </p>
</li>
<li><p>A 收到连接释放报文段后，必须发出确认。在确认报文段中 ACK = 1，确认号 ack = w + 1，自己的序号 seq = u + 1，然后进入TIME-WAIT状态。 </p>
</li>
<li><p>为什么A在TIME-WAIT状态必须等待2MSL：<br>（1）第一，为了保证 A 发送的最后一个 ACK 报文段能够到达 B。<br>（2）第二，防止 “已失效的连接请求报文段”出现在本连接中。A 在发送完最后一个 ACK 报文段后，<strong>再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段，都从网络中消失</strong>。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。</p>
</li>
<li><p>保活计时器</p>
</li>
</ul>
<h2 id="第六章-应用层"><a href="#第六章-应用层" class="headerlink" title="第六章 应用层"></a>第六章 应用层</h2><ul>
<li>应用层协议是为了解决某一类应用问题，而问题的解决往往是通过位于不同主机中的多个应用进程之间的通信和协同工作来完成的。</li>
<li>应用层的具体内容就是规定应用进程在通信时所遵循的协议</li>
<li>应用层的许多协议都是基于C/S模式，客户和服务器都是通信中所涉及的两个应用进程</li>
</ul>
<h3 id="6-1-域名系统DNS"><a href="#6-1-域名系统DNS" class="headerlink" title="6.1 域名系统DNS"></a>6.1 域名系统DNS</h3><h4 id="6-1-1-域名系统概述"><a href="#6-1-1-域名系统概述" class="headerlink" title="6.1.1 域名系统概述"></a>6.1.1 域名系统概述</h4><ul>
<li>许多应用层软件经常直接使用<strong>域名系统 DNS</strong> (Domain Name System)，但计算机的用户只是<strong>间接</strong>而不是直接使用域名系统。 </li>
<li>互联网采用层次结构的命名树作为主机的名字，并使用<strong>分布式</strong>的域名系统 DNS。</li>
<li>名字到 IP 地址的解析是由若干个域名服务器程序完成的。域名服务器程序在专设的结点上运行，运行该程序的机器称为<strong>域名服务器</strong>。  </li>
</ul>
<ul>
<li>互联网采用了<strong>层次树状结构</strong>的命名方法。</li>
<li>任何一个连接在互联网上的主机或路由器，都有一个<strong>唯一</strong>的层次结构的名字，即<strong>域名</strong>。</li>
<li>域名的结构由标号序列组成，各标号之间用点隔开：<br><code>… . 三级域名 . 二级域名 . 顶级域名</code></li>
<li>各标号分别代表不同级别的域名。  </li>
<li>域名只是个<strong>逻辑概念</strong>，并不代表计算机所在的物理地点。</li>
<li>变长的域名和使用有助记忆的字符串，是为了便于人来使用</li>
<li>每一个域名中“点”的数目则不一定正好是三个</li>
<li>顶级域名：<ul>
<li>（1）国家顶级域名 nTLD<br>.cn表示中国<br>.us表示美国<br>.uk表示英国<br>等等</li>
<li>（2）通用顶级域名 gTLD<br>最早的顶级域名<br>.com公司和企业<br>.net网络服务机构<br>.org非盈利性组织<br>.edu美国专用教育机构<br>.gov美国专用政府部门<br>.mil美国专用军事部门<br>.int国际组织<br>新增通用顶级域名<br>.aero<br>.biz<br>.cat<br>.name<br>等等</li>
<li>（3）基础结构域名<br>这种顶级域名只有一个，即<strong>arpa</strong><br>用于反响域名解析，因此又称为<strong>反向域名</strong></li>
</ul>
</li>
</ul>
<h4 id="6-1-3-域名服务器"><a href="#6-1-3-域名服务器" class="headerlink" title="6.1.3 域名服务器"></a>6.1.3 域名服务器</h4><ul>
<li>一个服务器所管辖的范围叫做<strong>区</strong></li>
<li>各单位根据具体情况来<strong>划分</strong>自己管辖范围的区。但在一个区中的所有节点必须是能够连通的。</li>
<li>每一个区设置相应的<strong>权限域名服务器</strong>，用来保存该区中的所有主机的域名到 IP 地址的映射。</li>
<li>DNS 服务器的管辖范围不是以“域”为单位，而是以“<strong>区</strong>”为单位。  </li>
<li>域名服务器有以下四种类型：<ul>
<li><strong>根域名服务器</strong><ul>
<li>最高层次的域名服务器，也是最重要的域名服务器。所有的根域名服务器都知道所有的顶级域名服务器的域名和 IP 地址。</li>
<li>不管是哪一个本地域名服务器，若要对互联网上任何一个域名进行解析，只要自己无法解析，就首先求助于根域名服务器。</li>
<li>根域名服务器并不直接把域名直接转换成 IP 地址。</li>
<li>在使用迭代查询时，根域名服务器把下一步应当找的顶级域名服务器的 IP 地址告诉本地域名服务器。</li>
<li><strong>根域名服务器共有 13 套装置，不是 13 个机器</strong>（a~m）</li>
</ul>
</li>
<li><strong>顶级域名服务器</strong><ul>
<li>顶级域名服务器（即 TLD 服务器）负责管理在该顶级域名服务器注册的所有<strong>二级域名</strong>。</li>
</ul>
</li>
<li>权限域名服务器<ul>
<li>负责一个区的域名服务器</li>
</ul>
</li>
<li>本地域名服务器<ul>
<li>当一个主机发出 DNS 查询请求时，这个查询请求报文就发送给本地域名服务器</li>
<li>这种域名服务器有时也称为<strong>默认域名服务器</strong>；</li>
</ul>
</li>
</ul>
</li>
<li>提高域名服务器的可靠性：<ul>
<li>DNS 域名服务器都把<strong>数据复制</strong>到几个域名服务器来保存，其中的一个是<strong>主域名服务器</strong>，其他的是<strong>辅助域名服务器</strong>。</li>
<li>当主域名服务器出故障时，辅助域名服务器可以保证 DNS 的查询工作不会中断。</li>
<li>主域名服务器<strong>定期</strong>把数据复制到辅助域名服务器中，而更改数据<strong>只能在主域名服务器</strong>中进行。这样就保证了数据的一致性。 </li>
</ul>
</li>
<li>域名解析过程：<ul>
<li>主机向<strong>本地域名服务器</strong>的查询一般都是采用<strong>递归查询</strong>。如果主机所询问的本地域名服务器不知道被查询域名的 IP 地址，那么本地域名服务器就以 DNS 客户的身份，向其他根域名服务器继续发出查询请求报文。</li>
<li>本地域名服务器向<strong>根域名服务器</strong>的查询通常是采用<strong>迭代查询</strong>。当根域名服务器收到本地域名服务器的迭代查询请求报文时，要么给出所要查询的 IP 地址，要么告诉本地域名服务器：“你下一步应当向哪一个域名服务器进行查询”。然后让本地域名服务器进行后续的查询。</li>
</ul>
</li>
<li><strong>每个域名服务器都维护一个高速缓存</strong>，存放<strong>最近用过</strong>的名字以及从何处获得名字映射信息的记录</li>
</ul>
<h3 id="6-2-文件传送协议"><a href="#6-2-文件传送协议" class="headerlink" title="6.2 文件传送协议"></a>6.2 文件传送协议</h3><h4 id="6-2-1-FTP概述"><a href="#6-2-1-FTP概述" class="headerlink" title="6.2.1 FTP概述"></a>6.2.1 FTP概述</h4><ul>
<li><strong>文件传送协议 FTP</strong> (File Transfer Protocol) 是互联网上使用得最广泛的文件传送协议。</li>
<li>FTP 提供<strong>交互式</strong>的访问，允许客户指明文件的类型与格式，并允许文件具有存取权限。</li>
<li>FTP 屏蔽了各计算机系统的细节，因而适合于在异构网络中任意计算机之间传送文件。</li>
<li>文件传送非常困难。原因是众多的计算机厂商研制出的文件系统多达数百种，且差别很大</li>
</ul>
<h4 id="6-2-2-FTP的基本工作原理"><a href="#6-2-2-FTP的基本工作原理" class="headerlink" title="6.2.2 FTP的基本工作原理"></a>6.2.2 FTP的基本工作原理</h4><ul>
<li><p>网络环境下复制文件的复杂性：<br>(1) 计算机存储数据的格式不同。<br>(2) 文件的目录结构和文件命名的规定不同。<br>(3) 对于相同的文件存取功能，操作系统使用的命令不同。<br>(4) 访问控制方法不同。 </p>
</li>
<li><p>FTP的特点：<br>（1）只提供文件传送的一些基本的服务<br>（2）使用TCP可靠的运输服务<br>（3）减少消除在不同操作系统下处理文件的不兼容性<br>（4）FTP使用C/S模式。一个FTP服务器进程可以同时为多个客户进程提供服务。<br>（5）FTP的服务器进程有两大部分：<br>  一个主进程，负责接受新的请求；<br>  若干个从属进程，负责处理单个请求</p>
</li>
<li><p>两个连接：</p>
<ul>
<li>控制连接：控制进程</li>
<li>数据连接：数据传送进程</li>
</ul>
</li>
<li><p>当客户进程向服务器进程发出建立连接请求时，要寻找连接服务器进程的<strong>熟知端口</strong> (21)，同时还要告诉服务器进程自己的<strong>另一个端口号码</strong>，用于建立数据传送连接。接着，服务器进程用自己传送数据的熟知端口 (20) 与客户进程所提供的端口号码建立数据传送连接。由于 FTP 使用了<strong>两个不同的端口号</strong>，所以数据连接与控制连接不会发生混乱。</p>
</li>
<li><p>使用两个不同端口号：</p>
<ul>
<li>使协议更加简单和更容易实现。</li>
<li>在传输文件时还可以利用控制连接（例如，客户发送请求终止传输）。 </li>
</ul>
</li>
<li><p>NFS：</p>
<ul>
<li>NFS 允许应用进程打开一个远地文件，并能在该文件的某一个特定的位置上开始读写数据。</li>
<li>NFS 在网络上传送的只是<strong>少量的修改数据</strong></li>
</ul>
</li>
</ul>
<h4 id="6-2-3-简单文件传送协议TFTP"><a href="#6-2-3-简单文件传送协议TFTP" class="headerlink" title="6.2.3 简单文件传送协议TFTP"></a>6.2.3 简单文件传送协议TFTP</h4><ul>
<li>TFTP (Trivial File Transfer Protocol) 是一个很小且易于实现的文件传送协议。</li>
<li>TFTP 使用<strong>客户服务器方式</strong>和使用 <strong>UDP</strong> 数据报，因此 TFTP 需要有自己的差错改正措施。</li>
<li>TFTP 只支持文件传输而不支持交互。</li>
<li>TFTP 没有一个庞大的命令集，没有列目录的功能，也不能对用户进行身份鉴别。 </li>
<li>特点：<br>(1) 每次传送的数据 PDU 中有 512 字节的数据，但最后一次可不足 512 字节。<br>(2) 数据 <strong>PDU</strong> 也称为<strong>文件块</strong> (block)，每个块按序编号，从 1 开始。<br>(3) 支持 ASCII 码或二进制传送。<br>(4) 可对文件进行读或写。<br>(5) 使用很简单的首部。 </li>
<li>TFTP 的工作很像停止等待协议</li>
</ul>
<h3 id="6-3-远程终端协议TELNET"><a href="#6-3-远程终端协议TELNET" class="headerlink" title="6.3 远程终端协议TELNET"></a>6.3 远程终端协议TELNET</h3><ul>
<li><strong>TELNET</strong> 是一个简单的<strong>远程终端协议</strong>，也是互联网的正式标准。</li>
<li>用户用 TELNET 就可在其所在地通过 TCP 连接注册（即登录）到远地的另一个主机上（使用主机名或 IP 地址）。</li>
<li>TELNET 也使用<strong>客户-服务器方式</strong>。在本地系统运行 TELNET 客户进程，而在远地主机则运行 TELNET 服务器进程。</li>
<li>和 FTP 的情况相似，服务器中的<strong>主进程</strong>等待新的请求，并产生<strong>从属进程</strong>来处理每一个连接</li>
<li>TELNET 使用网络虚拟终端 NVT 格式 </li>
</ul>
<h3 id="6-4-万维网WWW"><a href="#6-4-万维网WWW" class="headerlink" title="6.4 万维网WWW"></a>6.4 万维网WWW</h3><h4 id="6-4-1-万维网概述"><a href="#6-4-1-万维网概述" class="headerlink" title="6.4.1 万维网概述"></a>6.4.1 万维网概述</h4><ul>
<li><strong>万维网</strong> WWW (World Wide Web) 并非某种特殊的计算机网络。</li>
<li>万维网是一个大规模的、联机式的<strong>信息储藏所</strong>。</li>
<li>万维网用<strong>链接</strong>的方法能非常方便地从互联网上的一个站点访问另一个站点，从而主动地按需获取丰富的信息。这种访问方式称为“<strong>链接</strong>”。</li>
<li>万维网提供<strong>分布式服务</strong>：</li>
<li>万维网是<strong>分布式超媒体</strong> (hypermedia) 系统，它是<strong>超文本</strong>系统的扩充。</li>
<li><strong>一个超文本由多个信息源链接成</strong>。利用一个链接可使用户找到另一个文档。这些文档可以位于世界上任何一个接在互联网上的超文本系统中。超文本是万维网的基础。</li>
<li><strong>超媒体与超文本的区别是文档内容不同</strong>。超文本文档<u>仅包含文本信息</u>，而超媒体文档还包含<u>其他表示方式的信息</u>，如图形、图像、声音、动画，甚至活动视频图像。</li>
<li>万维网的工作方式：<br>（1）万维网以<strong>客户-服务器方式</strong>工作。<br>（2）<strong>浏览器</strong>就是在用户计算机上的万维网<strong>客户程序</strong>。万维网<strong>文档所驻留的计算机</strong>则运行<strong>服务器程序</strong>，因此这个计算机也称为<strong>万维网服务器</strong>。<br>（3）客户程序向服务器程序发出请求，服务器程序向客户程序送回客户所要的<strong>万维网文档</strong>。<br>（4）在一个客户程序主窗口上显示出的万维网文档称为<strong>页面</strong> (page)。</li>
<li>万维网解决的问题：<ul>
<li>怎样标志分布在整个互联网上的万维网文档？ <ul>
<li>使用<strong>统一资源定位符 URL</strong> 来标志万维网上的各种文档。</li>
<li>使每一个文档在整个互联网的范围内具有<strong>唯一</strong>的标识符 URL。 </li>
</ul>
</li>
<li>用何协议实现万维网上各种超链的链接？ <ul>
<li>在万维网客户程序与万维网服务器程序之间进行交互所使用的协议，是<strong>超文本传送协议 HTTP</strong>。</li>
<li>HTTP (HyperText Transfer Protocol) 是一个<strong>应用层协议</strong>，它使用 <strong>TCP 连接</strong>进行可靠的传送。 </li>
</ul>
</li>
<li>怎样使各种万维网文档都能在互联网上的各种计算机上显示出来，同时使用户清楚地知道在什么地方存在着超链？ <ul>
<li><strong>超文本标记语言 HTML</strong> 使得万维网页面的设计者可以很方便地用一个超链从本页面的某处链接到互联网上的任何一个万维网页面，并且能够在自己的计算机屏幕上将这些页面显示出来。 </li>
</ul>
</li>
<li>怎样使用户能够很方便地找到所需的信息？ <ul>
<li>为了在万维网上方便地查找信息，用户可使用各种的<strong>搜索工具</strong>（即<strong>搜索引擎</strong>）。 </li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="6-4-2-同一资源定位符URL"><a href="#6-4-2-同一资源定位符URL" class="headerlink" title="6.4.2 同一资源定位符URL"></a>6.4.2 同一资源定位符URL</h4><p>1.URL的格式：URL 相当于一个文件名在网络范围的扩展</p>
<ul>
<li>字符对大小写无要求</li>
<li>://是格式规定</li>
<li>&lt;主机&gt;是存放资源的主机在互联网中的域名</li>
<li>:&lt;端口&gt;/&lt;路径&gt;   有时可以省略（http的默认端口80）</li>
</ul>
<h4 id="6-4-3-超文本传送协议HTTP"><a href="#6-4-3-超文本传送协议HTTP" class="headerlink" title="6.4.3 超文本传送协议HTTP"></a>6.4.3 超文本传送协议HTTP</h4><ol>
<li>HTTP的操作过程</li>
</ol>
<ul>
<li>HTTP是<strong>面向事务的</strong>应用层协议</li>
</ul>
<ol start="2">
<li>HTTP的主要特点</li>
</ol>
<ul>
<li>HTTP是<strong>面向事务</strong>的<strong>客户-服务器协议</strong></li>
<li>HTTP协议是<strong>无状态</strong>，<strong>持续连接</strong>的<ul>
<li>持续连接有两种工作方式：非流水线方式；流水线方式</li>
</ul>
</li>
<li>HTTP协议本身也是<strong>无连接</strong>的，他使用了面向连接的TCP向上提供的服务 </li>
</ul>
<ol start="3">
<li>代理服务器：</li>
</ol>
<ul>
<li><strong>代理服务器</strong> (proxy server) 又称为<strong>万维网高速缓存</strong> (Web cache)，它代表浏览器发出 HTTP 请求。</li>
<li>万维网高速缓存把<strong>最近的</strong>一些请求和响应暂存在本地磁盘中。</li>
<li>当与暂时存放的请求<strong>相同</strong>的新请求到达时，万维网高速缓存就<strong>把暂存的响应发送出去</strong>，而不需要按 URL 的地址再去互联网访问该资源</li>
<li>使用高速缓存可以<strong>减少</strong>访问互联网服务器的时延</li>
</ul>
<ol start="4">
<li>HTTP的报文结构：</li>
</ol>
<ul>
<li>HTTP有两种报文：<ul>
<li>请求报文</li>
<li>响应报文</li>
</ul>
</li>
<li>HTTP是面向正文的，因此在报文中的每一个字段都是一些ASCll码串</li>
<li>报文由三个部分组成，即<strong>开始行</strong>、<strong>首部行</strong>和<strong>实体主体</strong>。</li>
<li>在<strong>请求报文</strong>中，开始行就是请求行。</li>
<li>“<strong>方法</strong>”是面向对象技术中使用的专门名词。所谓“方法”就是<strong>对所请求的对象进行的操作</strong>，因此这些方法实际上也就是一些<strong>命令</strong>。因此，请求报文的类型是由它所采用的方法决定的。 </li>
<li>在<strong>响应报文</strong>中，开始行就是状态行</li>
<li>状态行包括三项内容，即 <strong>HTTP 的版本</strong>，<strong>状态码</strong>，以及解释状态码的<strong>简单短语</strong>。 </li>
<li>状态码都是三位数字：</li>
</ul>
<p><strong>1xx 表示通知信息</strong>的，如请求收到了或正在进行处理。<br><strong>2xx 表示成功</strong>，如接受或知道了。<br><strong>3xx 表示重定向</strong>，表示要完成请求还必须采取进一步的行动。<br><strong>4xx 表示客户的差错</strong>，如请求中有错误的语法或不能完成。<br><strong>5xx 表示服务器的差错</strong>，如服务器失效无法完成请求。<br>4. 在服务器上存放用户的信息</p>
<ul>
<li>万维网站点使用 <strong>Cookie</strong> 来跟踪用户。</li>
<li>Cookie 表示在 HTTP 服务器和客户之间传递的<strong>状态信息</strong>。</li>
<li>使用 Cookie 的网站服务器为用户产生一个<strong>唯一的识别码</strong>。利用此识别码，网站就能够跟踪该用户在该网站的活动。  </li>
</ul>
<h4 id="6-4-4-万维网的文档"><a href="#6-4-4-万维网的文档" class="headerlink" title="6.4.4 万维网的文档"></a>6.4.4 万维网的文档</h4><ol>
<li>超文本标记语言HTML</li>
</ol>
<ul>
<li>超文本标记语言 HTML 中的 Markup 的意思就是“设置标记”。</li>
<li>HTML 定义了许多用于<strong>排版的命令</strong>（即标签）。</li>
<li>HTML 把各种标签嵌入到万维网的页面中。这样就构成了所谓的 HTML 文档。HTML 文档是一种可以用任何文本编辑器创建的 ASCII 码文件。   </li>
<li>仅当 HTML 文档是以 .html 或 .htm 为后缀时，浏览器才对此文档的各种标签进行解释</li>
<li>HTML还规定了链接的设置方法。每个链接都有一个起点和终点。</li>
<li><strong>远程链接</strong>：超链的终点是其他网点上的页面。</li>
<li><strong>本地链接</strong>：超链指向本计算机中的某个文件</li>
<li><strong>XML</strong>：</li>
<li>XML (Extensible Markup Language)是<strong>可扩展标记语言</strong>，它和HTML很相似。</li>
<li>但XML的设计宗旨是<strong>传输数据</strong>，而不是显示数据（<u>HTML是为了在浏览器上显示数据</u>）。</li>
<li>XML 不是要替换 HTML，而是对 HTML 的补充</li>
<li>XHTML：是可扩展超文本标记语言，是更为严格的HTML版本</li>
<li>CSS是<strong>层叠样式表</strong>，用于为 HTML 文档定义布局。<ul>
<li>CSS 与 HTML 的区别就是：HTML 用于结构化内容，而 CSS 则用于格式化结构化的内容</li>
</ul>
</li>
</ul>
<ol start="2">
<li>动态万维网文档：</li>
</ol>
<ul>
<li><strong>静态文档</strong>是指该文档创作完毕后就存放在万维网服务器中，在被用户浏览的过程中，内容不会改变。 </li>
<li><strong>动态文档</strong>是指文档的内容是在浏览器访问万维网服务器时才由应用程序动态创建。</li>
<li>动态文档和静态文档之间的主要差别体现在<strong>服务器</strong>一端。这主要是<strong>文档内容的生成方法不同</strong>。而从浏览器的角度看，这两种文档并没有区别。</li>
<li><strong>通关网关接口CGI</strong>：<u>定义了动态文档应如何创建，输入数据应如何提供给应用程序，以及输出结果应如何使用</u></li>
<li>CGI 程序的正式名字是 <strong>CGI 脚本</strong> (script)或cgi-bin脚本。</li>
<li>“脚本”指的是一个程序，它被另一个程序（解释程序）而不是计算机的处理机来解释或执行。</li>
<li>脚本运行起来要比一般的编译程序要慢，因为它的每一条指令先要被另一个程序来处理（这就要一些附加的指令），而不是直接被指令处理器来处理</li>
</ul>
<ol start="3">
<li>活动万维网文档</li>
</ol>
<ul>
<li><strong>活动文档</strong> (active document) 技术把所有的工作都<strong>转移给浏览器端</strong>，提供屏幕连续更新技术。</li>
</ul>
<h3 id="6-5-电子邮件"><a href="#6-5-电子邮件" class="headerlink" title="6.5 电子邮件"></a>6.5 电子邮件</h3><h4 id="6-5-1-电子邮件概述"><a href="#6-5-1-电子邮件概述" class="headerlink" title="6.5.1 电子邮件概述"></a>6.5.1 电子邮件概述</h4><ul>
<li> <strong>电子邮件</strong> (e-mail) 是互联网上使用得最多的和最受用户欢迎的一种应用</li>
<li>电子邮件把邮件发送到收件人使用的邮件服务器，并放在其中的收件人<strong>邮箱</strong>中，收件人可随时上网到自己使用的邮件服务器进行读取</li>
<li>传递迅速，费用低廉</li>
<li>发送邮件的协议：<strong>简单邮件传送协议SMTP</strong>（7位ASCll码邮件）<br>读取邮件的协议：<strong>邮局协议POP3</strong> 和 <strong>IMAP</strong></li>
<li><strong>通用互联网邮件扩充MIME</strong> 在其邮件首部中说明了邮件的数据类型(如文本、声音、图像、视像等)，使用 MIME 可在邮件中同时传送多种类型的数据。 </li>
<li>一个电子邮件系统应该具有三个主要组成构件：<ul>
<li><strong>用户代理</strong></li>
<li><strong>邮件服务器</strong></li>
<li><strong>邮件发送协议，邮件读取协议</strong></li>
</ul>
</li>
<li>用户代理UA（电子邮件客户端软件）：<ul>
<li>用户代理的功能：<strong>撰写，显示，处理，通信</strong></li>
<li>邮件服务器按照<strong>客户-服务器方式</strong>工作</li>
</ul>
</li>
<li>电子邮件的组成：<ul>
<li><strong>信封</strong></li>
<li><strong>内容</strong></li>
</ul>
</li>
<li>电子邮件的传输程序根据邮件信封上的信息来传送邮件。用户在从自己的邮箱中读取邮件时才能见到邮件的内容</li>
<li>TCP/IP 体系的电子邮件系统规定<strong>电子邮件地址</strong>的格式如下：<br>   收件人邮箱名@邮箱所在主机的域名</li>
<li>符号“@”读作“at”，表示“在”的意思。 </li>
</ul>
<h4 id="6-5-2-简单邮件传送协议SMTP"><a href="#6-5-2-简单邮件传送协议SMTP" class="headerlink" title="6.5.2 简单邮件传送协议SMTP"></a>6.5.2 简单邮件传送协议SMTP</h4><ul>
<li>SMTP 所规定的就是在<strong>两个相互通信的 SMTP 进程之间应如何交换信息</strong>。</li>
<li>由于 SMTP 使用<strong>客户服务器方式</strong>，因此负责发送邮件的 SMTP 进程就是 SMTP 客户，而负责接收邮件的 SMTP 进程就是 SMTP 服务器。</li>
<li>SMTP 规定了 14 条命令和 21 种应答信息。每条命令用 4 个字母组成，而每一种应答信息一般只有一行信息，由一个 3 位数字的代码开始，后面附上（也可不附上）很简单的文字说明</li>
<li>SMTP通信的三个阶段：</li>
</ul>
<ol>
<li><strong>连接建立</strong>：<strong>SMTP不使用中间的邮件服务器</strong></li>
<li><strong>邮件传送</strong></li>
<li><strong>连接释放</strong>：邮件发送完毕，SMTP应释放TCP连接</li>
</ol>
<h4 id="6-5-3-电子邮件的信息格式"><a href="#6-5-3-电子邮件的信息格式" class="headerlink" title="6.5.3 电子邮件的信息格式"></a>6.5.3 电子邮件的信息格式</h4><ul>
<li>一个电子邮件分为<strong>信封</strong>和<strong>内容</strong>两大部分。</li>
<li>RFC 822 只规定了邮件<strong>内容</strong>中的<strong>首部</strong>(header) 格式，而对邮件的<strong>主体</strong> (body )部分则让用户自由撰写。</li>
<li>用户写好首部后，邮件系统将自动地将信封所需的信息提取出来并写在信封上。所以用户不需要填写电子邮件信封上的信息。</li>
<li>邮件内容首部包括一些关键字，后面加上冒号。最重要的关键字是：To（写到地址簿） 和 Subject（主题）。   </li>
<li>其他还有 ：<br>“Cc”：抄送，复写副本；<br>“Bcc”：盲复写副本，暗送；<br>“From”：发送人的电子邮件地址<br>“Date”：发信日期</li>
</ul>
<h4 id="6-5-4-邮件读取协议POP3和IMAP"><a href="#6-5-4-邮件读取协议POP3和IMAP" class="headerlink" title="6.5.4 邮件读取协议POP3和IMAP"></a>6.5.4 邮件读取协议POP3和IMAP</h4><ul>
<li>邮局协议POP使用C/S方式</li>
<li>网际报文存取协议IMAP：C/S方式，联机协议</li>
</ul>
<h4 id="6-5-5-基于万维网的电子邮件"><a href="#6-5-5-基于万维网的电子邮件" class="headerlink" title="6.5.5 基于万维网的电子邮件"></a>6.5.5 基于万维网的电子邮件</h4><ul>
<li>浏览器和互联网上的邮件服务器之间传送邮件时，使用HTTP协议</li>
<li>个邮件服务器之间传送邮件时，使用SMTP协议</li>
</ul>
<h3 id="6-6-动态主机配置协议DHCP"><a href="#6-6-动态主机配置协议DHCP" class="headerlink" title="6.6 动态主机配置协议DHCP"></a>6.6 动态主机配置协议DHCP</h3><ul>
<li>为了将软件协议做成通用的和便于移植，协议软件的编写者把协议软件参数化，一台计算机和另一台计算机的区别，都可通过一些不同的参数来体现，在协议软件中给这些参数赋值的动作叫做<strong>协议配置</strong></li>
<li>互联网广泛使用的<strong>动态主机配置协议 DHCP</strong>，提供了<strong>即插即用连网</strong>的机制。</li>
<li>需要 IP 地址的主机在启动时就向 DHCP 服务器<strong>广播发送发现报文</strong></li>
<li>本地网络上所有主机都能收到此广播报文，但只有 DHCP 服务器才回答此广播报文</li>
<li>DHCP 服务器的回答报文叫做<strong>提供报文</strong></li>
<li>DHCP <strong>中继代理</strong>，它配置了 DHCP 服务器的 IP 地址信息</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>大学课程</tag>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL | 阿里云轻量应用服务器如何配置mysql</title>
    <url>/posts/355a5fb2.html</url>
    <content><![CDATA[<p>在购买阿里云轻量应用服务器之后的环境是都帮你搭配好的，但是数据库就需要自己操作配置了，比如说<strong>如何使用阿里云数据管理DMS远程操纵数据库</strong>，其在部署的过程中还是有许多坑</p>
<span id="more"></span>

<blockquote>
<p>参考自<a href="https://blog.csdn.net/weixin_40862011/article/details/86260700">阿里云轻量应用服务器 配置mysql详解</a></p>
</blockquote>
 <p><span style="font-size:20px;">在</span>购买了阿里云轻量应用服务器后，我结合自身的能力选择了建站相对简单的wordpress，毕竟对于阿里云学生机而言，每个月9.5元确实很便宜👍，最初的配置很简单，只需要参考阿里提供的步骤就能完成（除了升级php版本的时候踩了不少坑，详见<a href="/posts/10224.html">阿里云轻量应用服务器Wordpress升级php步骤</a>），但是当我在服务器中输入`mysql -uroot -p`时，我发现没有找到命令。</p>

<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/1.png"/>

<p>后来我才发现，我应该使用<code>sudo /usr/local/mysql/bin/mysql -uroot -p密码</code>命令😂,其实购买服务器之后的环境是都帮你搭配好的，但是数据库就需要自己操作配置了，比如说<strong>如何使用阿里云数据管理DMS远程操纵数据库</strong>，其在部署的过程中还是有许多坑。</p>
<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/2.png"/>

<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/3.png"/>

<p>1.通过上述步骤，先在应用详情获取Mysql密码，方法即是点击MySQL的远程连接，然后复制命令输入获取密码<br>2.点击轻量应用服务器左侧导航找到防火墙，在里面添加MYSQL规则，对应端口3306<br>3.在顶部搜索框中搜索<code>数据管理DMS</code></p>
<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/4.png"/>

<p>4.进入数据管理DMS，查看左侧导航，点击自建库（ESC、公网）,选择新增数据库，开始创建你的数据库</p>
<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/5.png"/>

<p>5.选择Mysql与公网自建，输入一系列信息，然后会出现一行报错<code>Host XX.XX.XX.XX is not allowed to connect Mysql server</code>,记录此时的IP值</p>
<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/6.png"/>
<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/7.png"/>

<p>6.回到阿里云轻量应用服务器控制台，远程连接服务器<br>（1）使用命令行方式通过MySQL的账号密码（密码即是之前步骤中获取到的数据库默认的账号和密码）连接到MySQL当中,输入 <code>sudo /usr/local/mysql/bin/mysql -uroot -p密码</code><br> (2)再输入<code>GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;远程连接的新密码&#39; WITH GRANT OPTION;</code>,上面命令中<code>%</code>代表从任何主机都可以连接到mysql服务器的话，如果要指定ip即把%替换<code>ip地址</code>即可,例如第5步保存的ip地址<br>（3）最后输入<code>FLUSH PRIVILEGES; </code>刷新先前的修改<br>7.回到自建数据库界面输入公网ip，自己设置的数据库密码就可登录，登录后即可远程访问数据库，也可看到相关数据库的运行实例，也可以进行数据库相应的操作。</p>
<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/post/8.png"/>
]]></content>
      <categories>
        <category>折腾记录</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title>印象笔记APP | 如何将enex格式转化为markdown格式</title>
    <url>/posts/10406.html</url>
    <content><![CDATA[<p>印象笔记导出的enex格式如何转换成markdown格式</p>
<h1 id="第一步"><a href="#第一步" class="headerlink" title="第一步"></a>第一步</h1><ul>
<li>导出笔记为enex格式</li>
</ul>
<h1 id="第二步"><a href="#第二步" class="headerlink" title="第二步"></a>第二步</h1><ul>
<li>确认安装了nodejs环境</li>
</ul>
<h1 id="第三步"><a href="#第三步" class="headerlink" title="第三步"></a>第三步</h1><ul>
<li>在对应路径下使用npm安装：</li>
</ul>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">npm <span class="keyword">install</span> -g enex-dump</span><br></pre></td></tr></table></figure>

<ul>
<li>导出md文件</li>
</ul>
<figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line">enex-dump <span class="params">--src</span> <span class="string">./XXXXXXXXXX.enex</span></span><br></pre></td></tr></table></figure>

<ul>
<li>之后会在该路径下生成一个dump文件夹，其中dump/notes 下为转换后的md文件，dump/attachments下为图片与其他资源…</li>
</ul>
]]></content>
      <categories>
        <category>折腾记录</category>
      </categories>
      <tags>
        <tag>印象笔记</tag>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>WordPress | 阿里云轻量应用服务器wordpress升级php步骤</title>
    <url>/posts/10224.html</url>
    <content><![CDATA[<p>当我买了阿里云轻量应用服务器wordpress镜像后，发现很多主题需要升级php…</p>
<span id="more"></span>


<h2 id="1-首先更新依赖包。"><a href="#1-首先更新依赖包。" class="headerlink" title="1.首先更新依赖包。"></a>1.首先更新依赖包。</h2><figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">yum -y update</span></span><br></pre></td></tr></table></figure>

<h2 id="2-安装依赖包"><a href="#2-安装依赖包" class="headerlink" title="2.安装依赖包"></a>2.安装依赖包</h2><figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">yum</span> -y install libxml<span class="number">2</span> libxml<span class="number">2</span>-devel openssl openssl-devel bzip<span class="number">2</span> bzip<span class="number">2</span>-devel libcurl libcurl-devel libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel gmp gmp-devel libmcrypt libmcrypt-devel readline readline-devel libxslt libxslt-devel zlib zlib-devel glibc glibc-devel glib<span class="number">2</span> glib<span class="number">2</span>-devel ncurses curl gdbm-devel db<span class="number">4</span>-devel libXpm-devel libX<span class="number">11</span>-devel gd-devel gmp-devel expat-devel xmlrpc-c xmlrpc-c-devel libicu-devel libmcrypt-devel libmemcached-devel libzip gcc-c++</span><br></pre></td></tr></table></figure>

<h2 id="3-转到-usr-local-src-目录，下载php7-3-5"><a href="#3-转到-usr-local-src-目录，下载php7-3-5" class="headerlink" title="3.转到 /usr/local/src 目录，下载php7.3.5"></a>3.转到 /usr/local/src 目录，下载php7.3.5</h2><p><code>cd /usr/local/src</code><br><code>wget https://www.php.net/distributions/php-7.3.5.tar.gz</code></p>
<h2 id="4-解压安装包-并进入目录"><a href="#4-解压安装包-并进入目录" class="headerlink" title="4.解压安装包,并进入目录"></a>4.解压安装包,并进入目录</h2><figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">tar</span> -zxvf php-<span class="number">7</span>.<span class="number">3</span>.<span class="number">5</span>.tar.gz</span><br><span class="line"><span class="attribute">cd</span> php-<span class="number">7</span>.<span class="number">3</span>.<span class="number">5</span></span><br></pre></td></tr></table></figure>

<h2 id="5-添加用户和组"><a href="#5-添加用户和组" class="headerlink" title="5.添加用户和组"></a>5.添加用户和组</h2><figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">groupadd www</span></span><br><span class="line"><span class="attribute">useradd -g www www</span></span><br></pre></td></tr></table></figure>

<h2 id="6-开始编译"><a href="#6-开始编译" class="headerlink" title="6.开始编译"></a>6.开始编译</h2><figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line"><span class="string">./configure</span> <span class="params">--prefix=/usr/local/php</span> <span class="params">--with-fpm-user=www</span> <span class="params">--with-fpm-group=www</span> <span class="params">--with-curl</span> <span class="params">--with-freetype-dir</span> <span class="params">--with-gd</span> <span class="params">--with-gettext</span> <span class="params">--with-iconv-dir</span> <span class="params">--with-kerberos</span> <span class="params">--with-libdir=lib64</span> <span class="params">--with-libxml-dir</span> <span class="params">--with-mysqli</span> <span class="params">--with-openssl</span> <span class="params">--with-pcre-regex</span> <span class="params">--with-pdo-mysql</span> <span class="params">--with-pdo-sqlite</span> <span class="params">--with-pear</span> <span class="params">--with-png-dir</span> <span class="params">--with-jpeg-dir</span> <span class="params">--with-xmlrpc</span> <span class="params">--with-xsl</span> <span class="params">--with-zlib</span> <span class="params">--with-bz2</span> <span class="params">--with-mhash</span> <span class="params">--enable-fpm</span> <span class="params">--enable-bcmath</span> <span class="params">--enable-libxml</span> <span class="params">--enable-inline-optimization</span> <span class="params">--enable-mbregex</span> <span class="params">--enable-mbstring</span> <span class="params">--enable-opcache</span> <span class="params">--enable-pcntl</span> <span class="params">--enable-shmop</span> <span class="params">--enable-soap</span> <span class="params">--enable-sockets</span> <span class="params">--enable-sysvsem</span> <span class="params">--enable-sysvshm</span> <span class="params">--enable-xml</span> <span class="params">--enable-zip</span> <span class="params">--enable-fpm</span></span><br></pre></td></tr></table></figure>

<p>这里会提示 <code>configure: error: Please reinstall the libzip distribution</code>，我们需要移除libzip,手动安装最新版本</p>
<h2 id="7-安装libzip"><a href="#7-安装libzip" class="headerlink" title="7.安装libzip"></a>7.安装libzip</h2><p>（1）先安装cmake</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">cd <span class="regexp">/usr/</span>local/src</span><br><span class="line">wget https:<span class="regexp">//gi</span>thub.com<span class="regexp">/Kitware/</span>CMake<span class="regexp">/releases/</span>download<span class="regexp">/v3.14.3/</span>cmake-<span class="number">3.14</span>.<span class="number">3</span>.tar.gz</span><br><span class="line">tar -zxvf cmake-<span class="number">3.14</span>.<span class="number">3</span>.tar.gz</span><br><span class="line">cd cmake-<span class="number">3.14</span>.<span class="number">3</span></span><br><span class="line">./bootstrap</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<p>（2）再编译安装libzip</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">yum</span> remove libzip -y</span><br><span class="line"><span class="attribute">cd</span> /usr/local/src</span><br><span class="line"><span class="attribute">wget</span> https://libzip.org/download/libzip-<span class="number">1</span>.<span class="number">5</span>.<span class="number">2</span>.tar.gz</span><br><span class="line"><span class="attribute">tar</span> -zxvf libzip-<span class="number">1</span>.<span class="number">5</span>.<span class="number">2</span>.tar.gz</span><br><span class="line"><span class="attribute">cd</span> libzip-<span class="number">1</span>.<span class="number">5</span>.<span class="number">2</span></span><br><span class="line"><span class="attribute">mkdir</span> build</span><br><span class="line"><span class="attribute">cd</span> build</span><br><span class="line"><span class="attribute">cmake</span> ..</span><br><span class="line"><span class="attribute">make</span> &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<p>（3）执行以下命令</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">vi <span class="regexp">/etc/</span>ld.so.conf</span><br><span class="line"><span class="comment">#添加如下几行</span></span><br><span class="line"><span class="regexp">/usr/</span>local/lib64</span><br><span class="line"><span class="regexp">/usr/</span>local/lib</span><br><span class="line"><span class="regexp">/usr/</span>lib</span><br><span class="line"><span class="regexp">/usr/</span>lib64</span><br><span class="line"><span class="comment">#保存退出</span></span><br><span class="line">ldconfig -v </span><br><span class="line"><span class="comment"># 使之生效 </span></span><br></pre></td></tr></table></figure>

<h2 id="8-再次编译PHP7-3"><a href="#8-再次编译PHP7-3" class="headerlink" title="8.再次编译PHP7.3"></a>8.再次编译PHP7.3</h2><p><code>make &amp;&amp; make install</code></p>
<h2 id="9-编译完成后，添加环境变量"><a href="#9-编译完成后，添加环境变量" class="headerlink" title="9.编译完成后，添加环境变量"></a>9.编译完成后，添加环境变量</h2><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line">vi /etc/profile</span><br><span class="line"><span class="comment">#添加以下内容到最后</span></span><br><span class="line">PATH=<span class="variable">$PATH</span><span class="symbol">:/usr/local/php/bin&lt;br&gt;export</span> PATH</span><br><span class="line"><span class="comment">#刷新环境变量</span></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<h2 id="10-配置文件"><a href="#10-配置文件" class="headerlink" title="10.配置文件"></a>10.配置文件</h2><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将启动脚本复制到init.d中。</span></span><br><span class="line">cp <span class="regexp">/usr/</span>local<span class="regexp">/src/</span>php-<span class="number">7.3</span>.<span class="number">5</span><span class="regexp">/sapi/</span>fpm<span class="regexp">/init.d.php-fpm /</span>etc<span class="regexp">/init.d/</span>php-fpm73</span><br><span class="line"><span class="comment"># 给启动脚本加上执行权限</span></span><br><span class="line">chmod +x <span class="regexp">/etc/i</span>nit.d/php-fpm73</span><br><span class="line"><span class="comment"># 将默认配置文件复制为.conf文件</span></span><br><span class="line">cp <span class="regexp">/usr/</span>local<span class="regexp">/php/</span>etc<span class="regexp">/php-fpm.conf.default $&#123;PHP73_DIR&#125;/</span>etc/php-fpm.conf</span><br><span class="line"><span class="comment"># 添加pool的配置</span></span><br><span class="line">cat &lt;&lt; EOF &gt; <span class="regexp">/usr/</span>local<span class="regexp">/php/</span>etc<span class="regexp">/php-fpm.d/</span>www.conf</span><br><span class="line">[www]</span><br><span class="line">listen = <span class="regexp">/home/</span>www<span class="regexp">/logs/</span>php73-fpm.sock</span><br><span class="line">listen.mode = <span class="number">0666</span></span><br><span class="line">user = www</span><br><span class="line">group = www</span><br><span class="line">pm = dynamic</span><br><span class="line">pm.max_children = <span class="number">128</span></span><br><span class="line">pm.start_servers = <span class="number">5</span></span><br><span class="line">pm.min_spare_servers = <span class="number">5</span></span><br><span class="line">pm.max_spare_servers = <span class="number">15</span></span><br><span class="line">pm.max_requests = <span class="number">300</span></span><br><span class="line">rlimit_files = <span class="number">1024</span></span><br><span class="line">slowlog = <span class="regexp">/home/</span>www<span class="regexp">/logs/</span>php73-fpm-slow.log</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h2 id="11-修改apache"><a href="#11-修改apache" class="headerlink" title="11.修改apache"></a>11.修改apache</h2><p>镜像中默认是用的php-fpm，使用的是socket方式的监听，Apache对应配置文件<code>/usr/local/apache/conf/httpd.conf</code>，其中配置如下:</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210304220934.png"></p>
<p>需要修改其中socket的文件路径指向到新版本的PHP就可以了，在<code>/usr/local/php73/etc/php-fpm.d/www.conf</code>有指定，新的配置到<code>/home/www/logs/php73-fpm.sock</code>即可，如图:</p>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/20210304221206.png"></p>
<h2 id="12-重启服务"><a href="#12-重启服务" class="headerlink" title="12.重启服务"></a>12.重启服务</h2><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 停止旧版本的PHP(实际不停止也不影响，停止可以减少一些系统资源占用)</span></span><br><span class="line"><span class="regexp">/etc/i</span>nit.d/php-fpm stop</span><br><span class="line"><span class="comment"># 启动新版PHP-FPM</span></span><br><span class="line"><span class="regexp">/etc/i</span>nit.d/php-fpm73 start</span><br><span class="line"><span class="comment">#启动报错请修改文件名</span></span><br><span class="line">修改<span class="regexp">/usr/</span>local<span class="regexp">/php/</span>etc/php-fpm.conf.default为php-fpm.conf</span><br><span class="line"><span class="comment"># 重启apache</span></span><br><span class="line"><span class="regexp">/etc/i</span>nit.d/apachectl restart</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>折腾记录</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>阿里云</tag>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title>生活VLOG |  一个人说走就走的旅行</title>
    <url>/posts/5b7875dc.html</url>
    <content><![CDATA[<p>今天看腾讯视频，翻出来了我2018年十一独自出去玩的vlog🦌<br><a href="https://v.qq.com/txp/iframe/player.html?vid=e0728waf7bs">https://v.qq.com/txp/iframe/player.html?vid=e0728waf7bs</a></p>
<ul><li>时间：2018年10月1日</li><li>地点：哈尔滨太阳岛</li><li>vlog-BGM：Nevada </li><li>剪辑：PR</li></ul>
<div class="myvideo"><iframe frameborder="0" src="https://v.qq.com/txp/iframe/player.html?vid=e0728waf7bs" allowFullScreen="true"></iframe></div>
<style>
.myvideo{
    position: relative;
    width: 100%;
    height: 0;
    padding-bottom: 75%;
}
.myvideo iframe {
    position: absolute;
    width: 100%;
    height: 100%;
    left: 0;
    top: 0;
}
</style>]]></content>
      <categories>
        <category>生活琐事</category>
      </categories>
      <tags>
        <tag>旅拍</tag>
        <tag>vlog</tag>
      </tags>
  </entry>
  <entry>
    <title>生活中的仪式感 | Happy Birthday</title>
    <url>/posts/59673.html</url>
    <content><![CDATA[<div id="tab_1">
    <iframe src="/love/qmj/book.html"
            height="600"
            width="100%"
            frameborder="0"
            scrolling="0"
    ></iframe>
</div>
<div style="text-align:center;">
            <p>宝贝,生日快乐鸭</p>
            <p>惟愿永远18岁的你,成为自己的骄傲与惊喜</p>
            <p>惟愿你心中有光,眼神清澈明亮</p>
            <p>惟愿你的眼角眉梢都是笑意</p>
            <p>惟愿你从此不必逞强不会伤心</p>
            <p>惟愿你想要的明天都会如约而至</p>
            <p>惟愿我就是那个对的人</p>
            <p>从此幸运，伴你一世温暖长情</p>
            <p>Happy Birthday, 蕉蕉!</p>
            <p>♥爱你的小明</p>
</div>
<div>
<p>这幅画是我画的(๑•̀ㅂ•́)و✧</p>
<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/happybirthdat.png"/>
</div>]]></content>
      <categories>
        <category>生活琐事</category>
      </categories>
      <tags>
        <tag>生日</tag>
      </tags>
  </entry>
  <entry>
    <title>随笔记录 | 漫威DC观影指南</title>
    <url>/posts/604a50ec.html</url>
    <content><![CDATA[<h2 id="Marvel"><a href="#Marvel" class="headerlink" title="Marvel"></a>Marvel</h2><h3 id="MCU-漫威电影宇宙"><a href="#MCU-漫威电影宇宙" class="headerlink" title="MCU(漫威电影宇宙)"></a>MCU(漫威电影宇宙)</h3><p>十年漫威，一战终局，英雄已去，传奇依旧</p>
<p><big>对</big>于MCU（漫威电影宇宙）的<strong>电影</strong>观看顺序，上映顺序就是最好的指南</p>
<table>
<thead>
<tr>
<th>阶段</th>
<th>观影顺序（↓）</th>
<th>上映时间</th>
</tr>
</thead>
<tbody><tr>
<td>《无限传奇》第一阶段</td>
<td>钢铁侠</td>
<td>2008</td>
</tr>
<tr>
<td></td>
<td>无敌浩克</td>
<td>2008</td>
</tr>
<tr>
<td></td>
<td>钢铁侠2</td>
<td>2010</td>
</tr>
<tr>
<td></td>
<td>雷神</td>
<td>2011</td>
</tr>
<tr>
<td></td>
<td>美国队长：复仇者先锋</td>
<td>2011</td>
</tr>
<tr>
<td></td>
<td>复仇者联盟</td>
<td>2012</td>
</tr>
<tr>
<td>《无限传奇》第二阶段</td>
<td>钢铁侠3</td>
<td>2013</td>
</tr>
<tr>
<td></td>
<td>雷神2：黑暗世界</td>
<td>2013</td>
</tr>
<tr>
<td></td>
<td>美国队长2：冬日战士</td>
<td>2014</td>
</tr>
<tr>
<td></td>
<td>银河护卫队</td>
<td>2014</td>
</tr>
<tr>
<td></td>
<td>复仇者联盟2：奥创纪元</td>
<td>2015</td>
</tr>
<tr>
<td></td>
<td>蚁人</td>
<td>2015</td>
</tr>
<tr>
<td>《无限传奇》第三阶段</td>
<td>美国队长3：内战</td>
<td>2016</td>
</tr>
<tr>
<td></td>
<td>奇异博士</td>
<td>2016</td>
</tr>
<tr>
<td></td>
<td>银河护卫队2</td>
<td>2017</td>
</tr>
<tr>
<td></td>
<td>蜘蛛侠：英雄归来</td>
<td>2017</td>
</tr>
<tr>
<td></td>
<td>雷神3：诸神黄昏</td>
<td>2017</td>
</tr>
<tr>
<td></td>
<td>黑豹</td>
<td>2018</td>
</tr>
<tr>
<td></td>
<td>复仇者联盟3：无限战争</td>
<td>2018</td>
</tr>
<tr>
<td></td>
<td>蚁人2：黄蜂女现身</td>
<td>2018</td>
</tr>
<tr>
<td></td>
<td>惊奇队长</td>
<td>2019</td>
</tr>
<tr>
<td></td>
<td>复仇者联盟4：终局之战</td>
<td>2019</td>
</tr>
<tr>
<td></td>
<td>蜘蛛侠2：英雄远征（2019）</td>
<td>2019</td>
</tr>
</tbody></table>
<ul>
<li>下面是完整的电影，电视剧以及短片的观影顺序图：</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/d01373f082025aafc11ca80500690662024f1a59.jpg"></p>
<h3 id="X战警宇宙"><a href="#X战警宇宙" class="headerlink" title="X战警宇宙"></a>X战警宇宙</h3><table>
<thead>
<tr>
<th>系列名称</th>
<th>观影顺序（↓）</th>
<th>上映时间</th>
</tr>
</thead>
<tbody><tr>
<td>X战警系列作品</td>
<td>《金刚狼》X-Men Origins:Wolverine</td>
<td>2009</td>
</tr>
<tr>
<td></td>
<td>《X战警：第一战》X-Men:First Class</td>
<td>2011</td>
</tr>
<tr>
<td></td>
<td>《X战警》X-Men</td>
<td>2000</td>
</tr>
<tr>
<td></td>
<td>《X战警2》X2</td>
<td>2003</td>
</tr>
<tr>
<td></td>
<td>《X战警：背水一战》X-Men:The Last Stand</td>
<td>2006</td>
</tr>
<tr>
<td></td>
<td>《金刚狼2》The Wolverine</td>
<td>2013</td>
</tr>
<tr>
<td></td>
<td>《X战警：逆转未来》X-Men:Days of Future Past</td>
<td>2014</td>
</tr>
<tr>
<td></td>
<td>《死侍》Dead pool</td>
<td>2016</td>
</tr>
<tr>
<td></td>
<td>《X战警：天启》X-Men:Apocalypse</td>
<td>2016</td>
</tr>
<tr>
<td></td>
<td>《金刚狼3：殊死一战》Logan</td>
<td>2017</td>
</tr>
<tr>
<td></td>
<td>《死侍2：我爱我家》Deadpool2</td>
<td>2018</td>
</tr>
<tr>
<td></td>
<td>《X战警：黑凤凰》Dark Phoenix</td>
<td>2019</td>
</tr>
<tr>
<td></td>
<td>《新变种人》The New Mutants</td>
<td>2020</td>
</tr>
</tbody></table>
<h3 id="索尼电影宇宙"><a href="#索尼电影宇宙" class="headerlink" title="索尼电影宇宙"></a>索尼电影宇宙</h3><table>
<thead>
<tr>
<th>系列名称</th>
<th>观影顺序（↓）</th>
<th>上映时间</th>
</tr>
</thead>
<tbody><tr>
<td>索尼漫威宇宙</td>
<td>《蜘蛛侠》</td>
<td>2002</td>
</tr>
<tr>
<td></td>
<td>《蜘蛛侠2》</td>
<td>2004</td>
</tr>
<tr>
<td></td>
<td>《蜘蛛侠3》</td>
<td>2007</td>
</tr>
<tr>
<td></td>
<td>《超凡蜘蛛侠》</td>
<td>2012</td>
</tr>
<tr>
<td></td>
<td>《超凡蜘蛛侠2》</td>
<td>2014</td>
</tr>
<tr>
<td></td>
<td>《毒液：致命守护者》</td>
<td>2018</td>
</tr>
<tr>
<td></td>
<td>《蜘蛛侠：平行宇宙》（动画电影）</td>
<td>2018</td>
</tr>
</tbody></table>
<h3 id="其他漫威电影"><a href="#其他漫威电影" class="headerlink" title="其他漫威电影"></a>其他漫威电影</h3><table>
<thead>
<tr>
<th>电影名</th>
<th>上映时间</th>
</tr>
</thead>
<tbody><tr>
<td>《新神奇四侠》</td>
<td>2015</td>
</tr>
<tr>
<td>《超能陆战队》（动画电影）</td>
<td>2014</td>
</tr>
<tr>
<td>《恶灵骑士2：复仇时刻》</td>
<td>2011</td>
</tr>
<tr>
<td>《惩罚者2》</td>
<td>2008</td>
</tr>
<tr>
<td>《神奇四侠2：银影侠来袭》</td>
<td>2007</td>
</tr>
<tr>
<td>《恶灵骑士》</td>
<td>2007</td>
</tr>
<tr>
<td>《神奇四侠》</td>
<td>2005</td>
</tr>
<tr>
<td>《类人体》</td>
<td>2005</td>
</tr>
<tr>
<td>《艾丽卡》</td>
<td>2005</td>
</tr>
<tr>
<td>《惩罚者》</td>
<td>2004</td>
</tr>
<tr>
<td>《刀锋战士3》</td>
<td>2004</td>
</tr>
<tr>
<td>《夜魔侠》</td>
<td>2003</td>
</tr>
<tr>
<td>《浩克》</td>
<td>2003</td>
</tr>
<tr>
<td>《刀锋战士2》</td>
<td>2002</td>
</tr>
<tr>
<td>《刀锋战士》</td>
<td>1998</td>
</tr>
<tr>
<td>《神奇四侠》</td>
<td>1994</td>
</tr>
<tr>
<td>《惩罚者》</td>
<td>1989</td>
</tr>
<tr>
<td>《霍华德怪鸭》</td>
<td>1986</td>
</tr>
</tbody></table>
<h2 id="DC"><a href="#DC" class="headerlink" title="DC"></a>DC</h2><h3 id="DCEU（DC扩展宇宙）"><a href="#DCEU（DC扩展宇宙）" class="headerlink" title="DCEU（DC扩展宇宙）"></a>DCEU（DC扩展宇宙）</h3><table>
<thead>
<tr>
<th>电影名</th>
<th>上映时间</th>
</tr>
</thead>
<tbody><tr>
<td>《超人：钢铁之躯》</td>
<td>2013</td>
</tr>
<tr>
<td>《DC电影出品：正义联盟黎明》</td>
<td>2016</td>
</tr>
<tr>
<td>《蝙蝠侠大战超人：正义黎明》</td>
<td>2016</td>
</tr>
<tr>
<td>《自杀小队》</td>
<td>2016</td>
</tr>
<tr>
<td>《神奇女侠》</td>
<td>2017</td>
</tr>
<tr>
<td>《正义联盟》</td>
<td>2017</td>
</tr>
<tr>
<td>《海王》</td>
<td>2018</td>
</tr>
<tr>
<td>《雷霆沙赞》</td>
<td>2019</td>
</tr>
</tbody></table>
<h3 id="其他DC电影"><a href="#其他DC电影" class="headerlink" title="其他DC电影"></a>其他DC电影</h3><ul>
<li>太过久远的电影就不罗列了</li>
</ul>
<table>
<thead>
<tr>
<th>电影名</th>
<th>上映时间</th>
</tr>
</thead>
<tbody><tr>
<td>《猫女》</td>
<td>2004</td>
</tr>
<tr>
<td>《康斯坦丁》</td>
<td>2005</td>
</tr>
<tr>
<td>《V字仇杀队》</td>
<td>2005</td>
</tr>
<tr>
<td>《蝙蝠侠：侠影之谜》</td>
<td>2005</td>
</tr>
<tr>
<td>《超人归来》</td>
<td>2006</td>
</tr>
<tr>
<td>《黑暗骑士》</td>
<td>2008</td>
</tr>
<tr>
<td>《守望者》</td>
<td>2009</td>
</tr>
<tr>
<td>《失败者》</td>
<td>2010</td>
</tr>
<tr>
<td>《西部英雄约拿·哈克斯》</td>
<td>2010</td>
</tr>
<tr>
<td>《绿灯侠》</td>
<td>2011</td>
</tr>
<tr>
<td>《黑暗骑士崛起》</td>
<td>2012</td>
</tr>
<tr>
<td>《乐高蝙蝠侠大电影》</td>
<td>2017</td>
</tr>
<tr>
<td>《小丑》</td>
<td>2019</td>
</tr>
</tbody></table>
<h2 id="壁纸"><a href="#壁纸" class="headerlink" title="壁纸"></a>壁纸</h2><div class="fj-gallery"><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/444211.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/344e370b0a0d5fb463724cc556458d22.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/4c1svpbxcfh.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/4fcd5y13bws.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/bi3wrjelcd4.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/db2984b3a973e7e8cdc6834de4f69704.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/e7530dec43be8a8c7718752306bbbb54.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/ijelpz2bnxp.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/op3pktbhatl.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/qhoo4nupjp5.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/zfx1it4hq3i.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN2/post/zjykzjztrjg.jpg"></p>
          </div>]]></content>
      <categories>
        <category>生活琐事</category>
      </categories>
      <tags>
        <tag>超级英雄</tag>
        <tag>电影</tag>
      </tags>
  </entry>
  <entry>
    <title>生活琐事 | 新加坡国立大学短期交流总结</title>
    <url>/posts/92550e63.html</url>
    <content><![CDATA[<div class="fj-gallery"><p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus%20%281%29.jpeg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus%20%282%29.jpeg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus%20%283%29.jpeg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus%20%284%29.jpeg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus%20%285%29.jpeg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus%20%286%29.jpeg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus%20%287%29.jpeg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus%20%288%29.jpeg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/1%20%2828%29.jpg"></p>
          </div>


<h2 id="赴新加坡国立大学交流学习总结"><a href="#赴新加坡国立大学交流学习总结" class="headerlink" title="赴新加坡国立大学交流学习总结"></a>赴新加坡国立大学交流学习总结</h2><p>姓名：Justlovesmile    时间：2019年8月</p>
<p>首先非常感谢学校给我们创造了如此难得的条件赴新加坡国立大学（National University of Singapore）交流学习。我非常庆幸自己能拥有如此有趣的学习和生活经历。那21天的生活，转瞬即逝，尽管异国的生活环境和教育体系是小小的阻碍，但是我们收获的却是更多的，受益终生的知识和眼界。对于这21天的学习生活我做了如下总结：</p>
<h2 id="一，-课程学习"><a href="#一，-课程学习" class="headerlink" title="一，    课程学习"></a>一，    课程学习</h2><p>在来到新加坡国立大学之前，我们就已经在学校官网上选择了cluster。我选择的cluster是人工智能和信息安全。其下有很多分支，需要在学习了这个cluster下所有课的先导课后再做决定。在新加坡国立大学学习了先导课后，我选择了深度学习，这是一门非常有意思的课程，我非常喜欢。<br>·对于我的项目内容：</p>
<ul>
<li>我选择的是<code>deep learning </code>课题，这个课题最后是和智能小车一起接受检查。最开始的时候我们是在教授的带领下，去对<code>deep learning</code>进行系统学习，但是由于时间有限，所以讲的都十分快。之后我们就开始根据教授提供的文件和资料对之前所讲的，稍做练习。然后就是给我们时间去做第一个任务，即控制小车去走迷宫，并识别各种位置，可能被部分遮挡或颠倒的猫的图片，并分析出四种猫的种类。最开始我们的工作是选择出一个较好的模型。所以我们在网上找了这四种猫的大量图片做训练集和测试集。然后在经过了多次训练和测试后保存了效果比较好的权重文件。之后我们和小车组的队友一起合作，使用小车树莓派相机拍照，并传到我的电脑上分析。最终我们每一张图片都准确的识别出来了。在完成了第一个任务之后，我们又开始了最终项目的讨论，在教授的帮助和我们的研讨之下，我们决定做一个小车跟随目标前进并自动避障的项目。在老师的建议下，我们使用了<code>YOLO（You Only Look Once）</code>目标检测方法。经过我们的不懈努力，终于完成了项目，得到了教授的赞赏。</li>
</ul>
<p>对于课程学习我有如下的体会：</p>
<ol>
<li>   英语非常重要，最基本的就是要会听说读。在新加坡国立大学全英文的教学模式下，课程学习的难点就是听懂教授所讲的东西，并且大多数印度籍和新加坡本地的老师的英语口音非常重，需要你认真去听，去结合前后语句去理解。</li>
<li>   一定要多问。在新加坡国立大学的学习生活中，由于我们的时间有限，所以教授只是对每一个知识点简要讲解，所以最后要做项目时，必然会遇到很多问题，无论是项目所使用的方法，还是编程时遇到的bug等等，如果你只是自己琢磨，必然会花费大量的时间，费力不讨好，正确的做法是，先自己谷歌或百度，如果发现不能解决，立即去询问同学，助教和教授，这样才能高效的解决问题。</li>
<li>   多和同学沟通。在我的课题，教授要求同一学校的学生不能组队，所以我们的队友都是来自不同的学校的陌生人，所以为了接下来的学习和工作，我们一定要和队友处好关系，并且我所选的课题是深度学习，是和智能小车课题的小组合作，所以我们不仅需要和队友时常沟通，加强友谊，还需要随时了解合作小组的学习进度和技术，以便最后合作时能够尽快的成功。</li>
<li>   课后多专研。对于我们的课题，由于深度学习可以使用的预训练模型和方法比较多，但是不同的人由于数据集和参数的设置不同，会有不同的正确率，所以，在课后可以选择多个模型结合学校提供的GPU，自己训练以获得更好的权重，来满足项目要求。再比如我们在使用训练好的权重时，经常会遇到问题，例如读取权重的函数在主文件中可以运行，但是在其他文件中调用时会出错。在经过我们的不断调试以及谷歌百度下，终于得到解决。</li>
<li>   融会贯通。由于最后我们的检验标准是做一个项目，所以我们需要掌握多种编程语言，和其他技术，并且需要你能将这些都结合起来一起使用。</li>
</ol>
<h2 id="二，-异国生活"><a href="#二，-异国生活" class="headerlink" title="二，    异国生活"></a>二，    异国生活</h2><ol>
<li>住宿。这次交流项目，我们是住在新加坡国立大学的学生宿舍（位于<code>University Town</code>）。新加坡国立大学的宿舍都非常人性化，一人一间，各项设施一应俱全，宿舍楼层内设有卫生间，淋浴，厨房，洗衣房，活动室。可以说是非常全面了。并且每个房间都有空调和风扇。<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus1.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus2.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus3.jpg"></li>
<li>饮食。由于新加坡人口有70%是华人，所以新加坡的饮食很多是偏向中式餐饮的，当然也有很多印度菜，泰国菜等。价格方面普遍偏贵。新加坡国立大学食堂比较多，我只探索了三个食堂。下附图片：<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus4.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus5.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus6.jpg"></li>
<li>交通。新加坡的交通非常便利，新加坡国立大学给每个学生办了一张<code>Ezlink</code>卡片，里面预存了钱，无论去哪都比较方便。并且Ezlink卡可以在地铁站和便利店里充值（便利店会收取少量手续费）。</li>
<li>通讯。在我们到达新加坡国立大学时，新加坡国立大学的助教会拿我们的护照去帮我们免费办理电话卡，并预存了话费和流量，足够我们的21天的通讯和上网所需。并且NUS是WiFi全覆盖的，所以无需担心上网问题，值得注意的是在新加坡蹭网是违法的。</li>
<li>生活所需。我们住的地方位于新加坡国立大学（NUS）的<code>University town</code>里面有食堂，有超市，有餐厅，有自习室，生活所需都能满足。并且<code>u-town</code>里面有一个大草坪叫做<code>Town green</code>，每天都有很多人在上面玩耍，非常适合在草坪上休息。<br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus7.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus8.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/1%20%2835%29.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/1%20%2841%29.jpg"></li>
<li>法律。在来到新加坡之前，我就听说新加坡的法律非常严格，罚款很重，并且还保留了鞭刑这种刑法。但是实际上到了新加坡之后，发现新加坡也没有传说中的那么可怕，只要你规规矩矩的，一般也没有人会去举报你。对于新加坡的法律，经常听到的就是：地铁公交上不能吃喝东西；不能嚼口香糖（虽然也买不到）；不能裸露（即使别人拿望眼镜偷看你家窗户，但是我看见了一个裸上半身跑步的也没被抓啊…）；等等</li>
<li>旅游。新加坡的旅游景点还是蛮多的。比如鱼尾狮公园，植物园，夜间动物园，环球影城，牛车水，小印度，克拉码头，圣淘沙岛，滨海湾公园，乌节路等等…在学习生活之余，我们也会去这些地方，去感受一下新加坡的魅力。旅游不仅可以增长见识，还可以放松心情，劳逸结合。</li>
<li>烟花。每年8月9日是新加坡的国庆日，虽然这次我们没能赶上新加坡 的国庆，但是我们赶上了国庆烟花预演，美丽的烟花表演让人称叹。</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus9.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/nus10.jpg"><br><img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gallery/1%20%2839%29.jpg"></p>
<h2 id="三，-心得体会"><a href="#三，-心得体会" class="headerlink" title="三，    心得体会"></a>三，    心得体会</h2><p>在新加坡国立大学的21天学习生活转瞬即逝，回想这些日子的学习和生活的点点滴滴，感触颇多。</p>
<ul>
<li><p>来新加坡之前，我深切的感受到了办理签证的繁琐，对异国生活的忐忑和激动。真正来到这个陌生的地方后，却发现这里有着70%的华人人口，无论是饮食还是生活都和国内区别极小，唯一需要注意的只是语言方面，通过这一次的交流学习，我深刻的认识到了语言的重要性，这更加激励了我认真学习语言，尤其是当你直面某些问题时，例如和你同届的同学能够在课堂上和教授愉快的互动，而你还在揣测教授说的话时，你就会真正的看见一些差距。</p>
</li>
<li><p>对于新加坡国立大学组织的这次交流活动，我觉得最珍贵的就是开阔眼界，在世界一流大学感受他们的学习氛围，并且和来自全国各地的队友们自相比较，认识到自己的不足，并给自己定下一个小小的目标，做一个有追求的人。再者就是认识更多的人，更加的了解这个世界，举个小小的例子，我们在香港转机时，坐我旁边的是一位新加坡小姐姐，当她得知我是中国内地的时候，会拿出她随身带的报纸，和我分享她对于香港前段时间发生的问题的看法。我认为这些都是一些宝贵的回忆，会或多或少的影响我们的思维，以至于影响我们的人生。</p>
</li>
<li><p>在学习之余，旅游也是不错的选择，去感受文化的差异，去了解每一个国家的生活方式。正所谓读万卷书，行万里路，一路走来，你就会发现自己也学到了很多书本上不能学到的知识。每个人都应该有适合自己的独特的生活方式，只有去探索过后你才会发现适合自己的生活，无论现在还是将来，最重要的是，做自己。</p>
</li>
<li><p>这21天的时间，我学到了太多太多，无论是以前了解的还是不熟悉的知识，最重要，最宝贵的就是那些永远留在我们脑海中的记忆，特别感谢学校给我们这样的机会，让我们能无感受新的世界，这些天，我收获了知识，增长了见识。世界很大，生命很短，让我们放开眼界，活在当下，享受人生。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>生活琐事</category>
      </categories>
      <tags>
        <tag>新加坡国立大学</tag>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title>生活VLOG | 哈尔滨的春雪</title>
    <url>/posts/1f068f9e.html</url>
    <content><![CDATA[<p>北国风光VLOG❄<br><a href="https://v.qq.com/txp/iframe/player.html?vid=f30744qsih5">https://v.qq.com/txp/iframe/player.html?vid=f30744qsih5</a></p>
<ul><li>时间：2019年3月12日</li><li>地点：哈尔滨工程大学</li><li>vlog-BGM：Heaven Sent </li><li>剪辑：PR</li></ul>
<div class="myvideo"><iframe frameborder="0" src="https://v.qq.com/txp/iframe/player.html?vid=f30744qsih5" allowFullScreen="true"></iframe></div>
<style>
.myvideo{position: relative;width: 100%;height: 0;padding-bottom: 75%;}
.myvideo iframe {position: absolute;width: 100%;height: 100%;left: 0;top: 0;}
</style>]]></content>
      <categories>
        <category>生活琐事</category>
      </categories>
      <tags>
        <tag>旅拍</tag>
        <tag>vlog</tag>
      </tags>
  </entry>
  <entry>
    <title>生活琐事 | 爱与考研数学中的极限</title>
    <url>/posts/36558.html</url>
    <content><![CDATA[<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gif/1.gif">
<span id="more"></span>
<div style="text-align:center;"><p style="color:red;">♥</p></div>
<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/gif/2.gif">

<p>今天在看张宇考研数学的视频时发现了👇这个有趣的片段，极限是什么？</p>
<p><video controls poster="" src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/video/limit.mp4" style="width: 100%;"></video></p>
<ul>
<li>lim我=你↔♥即使给我整个世界，我也只在你的身边♥</li>
</ul>
<div style="text-align:center;">
<p>😘</p>
</div>]]></content>
      <categories>
        <category>生活琐事</category>
      </categories>
      <tags>
        <tag>考研</tag>
      </tags>
  </entry>
  <entry>
    <title>生活VLOG | 滑雪旅拍，北境踏雪</title>
    <url>/posts/14353.html</url>
    <content><![CDATA[<p><a href="https://v.qq.com/txp/iframe/player.html?vid=k0821tyiv85">https://v.qq.com/txp/iframe/player.html?vid=k0821tyiv85</a></p>
<img src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/image/snow1.jpg" alt="" class="wp-image-94"/>
<span id="more"></span>
<ul><li>时间：2018年12月</li><li>地点：哈尔滨</li><li>vlog-BGM：Your Radio</li><li>剪辑：PR</li></ul>
<div class="myvideo"><iframe frameborder="0" src="https://v.qq.com/txp/iframe/player.html?vid=k0821tyiv85" allowFullScreen="true"></iframe></div>
<style>
.myvideo{
    position: relative;
    width: 100%;
    height: 0;              /*高度设置这里无效，设置为0，用padding撑开div*/
    padding-bottom: 75%;    /*68%到80%都可以*/
}
.myvideo iframe {
    position: absolute;
    width: 100%;
    height: 100%;
    left: 0;
    top: 0;
}
</style>

<p>上面是第一次去滑雪时拍摄的vlog🏂，不得不说，银装素裹的哈尔滨真的超美</p>]]></content>
      <categories>
        <category>生活琐事</category>
      </categories>
      <tags>
        <tag>旅拍</tag>
        <tag>vlog</tag>
      </tags>
  </entry>
</search>
